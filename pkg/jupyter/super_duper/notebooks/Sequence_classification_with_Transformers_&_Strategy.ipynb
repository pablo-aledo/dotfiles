{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sequence classification with Transformers & Strategy",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGqVkG2-7qfu"
      },
      "source": [
        "# Sequence Classification with Transformers using TensorFlow's Strategies\n",
        "\n",
        "This colab notebook will guide you through using the Transformers library to obtain state-of-the-art results on the sequence classification task. It uses strategies which can be used on TPU via the TPUStrategy. It is attached to the following tutorial TODO.\n",
        "\n",
        "We will be using HuggingFace's own model: DistilBERT.\n",
        "\n",
        "The models from the `Transformers` repository need TF2 installed. You may be prompted to restart the runtime before the changes take effect.\n",
        "\n",
        "This colab notebook was inspired by several other notebooks/tutorials:\n",
        "\n",
        "[The official TensorFlow input pipeline for BERT](https://github.com/tensorflow/models/blob/master/official/nlp/bert/input_pipeline.py)\n",
        "\n",
        "[The official TensorFlow modeling utils for BERT](https://github.com/tensorflow/models/blob/master/official/modeling/model_training_utils.py)\n",
        "\n",
        "[The official TFRecord documentation](https://www.tensorflow.org/tutorials/load_data/tfrecord)\n",
        "\n",
        "[The official custom training with Strategy tutorial by TensorFlow](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/distribute/custom_training.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZIeAC0_tGXj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "467806a6-11bd-40c6-fb3d-2b29d3946e2a"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 3.3MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 43.1MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 33.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 33.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /tensorflow-2.1.0/python3.6 (from transformers) (2.23.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: numpy in /tensorflow-2.1.0/python3.6 (from transformers) (1.18.1)\n",
            "Requirement already satisfied: six in /tensorflow-2.1.0/python3.6 (from sacremoses->transformers) (1.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /tensorflow-2.1.0/python3.6 (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /tensorflow-2.1.0/python3.6 (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /tensorflow-2.1.0/python3.6 (from requests->transformers) (1.25.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /tensorflow-2.1.0/python3.6 (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=d1f0bdde7318bb20a6b4c328255fb1f2e86c21d41c84a9ae5ebef38e10af9be3\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFkyo148RDH_"
      },
      "source": [
        "### Imports\n",
        "\n",
        "We'll only be importing the components that we'll use during this tutorial: the TensorFlow model alongside the model specific tokenizer. The last two imports will manage the pre-processing of our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhpauvOIJzzf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "90df6920-590b-41ef-8e16-bd938babc02d"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "import os\n",
        "from transformers import (TFDistilBertForSequenceClassification, \n",
        "                          DistilBertTokenizer, \n",
        "                          glue_convert_examples_to_features, \n",
        "                          glue_processors)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzr0z5K0ECUC"
      },
      "source": [
        "# Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvSts80A8BF3"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "We'll be using the MRPC dataset that was used in the previous example, as a means of comparison. The way the dataset is handled by the `glue_convert_examples_to_features` was detailed in the [previous notebook](https://colab.research.google.com/drive/1l39vWjZ5jRUimSQDoUcuWGIoNjLjA2zu#scrollTo=ipMamgbw6bjL) so you should refer to it if you do not understand how this works.\n",
        "\n",
        "The difference in this example is that we'll be building an input pipeline beforehand. This input pipeline will be used to feed the data to tf.Example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP0QxTsyAV8l"
      },
      "source": [
        "### Importing the data\n",
        "\n",
        "We'll use the handy `tensorflow_datasets` package to import our data. As we are using a TPU we do not have access to our local filesystem, we therefore use a Google Cloud Platform bucket to save our data.\n",
        "\n",
        "**You will not be able to use our bucket for this notebook. Please create your own and replace the string corresponding to the bucket.**\n",
        "\n",
        "The data is handled exactly the same way as in the previous tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms1P9gHoIV_L"
      },
      "source": [
        "bucket = \"gs://huggingface-bucket/public\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UY6xtsSb_eys",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "79f4bfb9-eae4-4313-fc8a-855f8d6bbf78"
      },
      "source": [
        "import tensorflow_datasets\n",
        "\n",
        "IS_COLAB_BACKEND = 'COLAB_GPU' in os.environ  # this is always set on Colab, the value is 0 or 1 depending on GPU presence\n",
        "if IS_COLAB_BACKEND:\n",
        "    from google.colab import auth\n",
        "    # Authenticates the Colab machine and also the TPU using your\n",
        "    # credentials so that they can access your private GCS buckets.\n",
        "    auth.authenticate_user()\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "data, info = tensorflow_datasets.load('glue/mrpc', with_info=True, data_dir=bucket)\n",
        "train_examples = info.splits['train'].num_examples\n",
        "validation_examples = info.splits['validation'].num_examples\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 128\n",
        "\n",
        "# Prepare dataset for GLUE as a tf.data.Dataset instance\n",
        "train_dataset_w_features = glue_convert_examples_to_features(data['train'], tokenizer, MAX_SEQUENCE_LENGTH, 'mrpc')\n",
        "validation_dataset_w_features = glue_convert_examples_to_features(data['validation'], tokenizer, MAX_SEQUENCE_LENGTH, 'mrpc')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 2653183.99B/s]\n",
            "INFO:absl:Overwrite dataset info from restored data version.\n",
            "INFO:absl:Reusing dataset glue (gs://huggingface-bucket/public/glue/mrpc/0.0.2)\n",
            "INFO:absl:Constructing tf.data.Dataset for split None, from gs://huggingface-bucket/public/glue/mrpc/0.0.2\n",
            "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6tea-6XBEag"
      },
      "source": [
        "### Serialization\n",
        "\n",
        "Here we are using [TFRecord alongside tf.Example](https://www.tensorflow.org/tutorials/load_data/tfrecord) as a way to read data efficiently. Feeding data to a TPU can very easily be a bottleneck, we therefore store our data in a file that can be used during training.\n",
        "\n",
        "**Unless you change the bucket to your own, you will not be able to run this cell as we have not given public access to write on our public folder. If you change this cell to your own bucket in order to run it, you will have to change the URL from which you download the TFRecord to your bucket URL.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2GRMvxxBExe"
      },
      "source": [
        "skip = True\n",
        "\n",
        "if not skip:\n",
        "    # Prepare tf.Examples and tf.Features and write them as TFRecords\n",
        "    def save_tfrecord_to_bucket(features_dataset, bucket_url, file_name):\n",
        "        with tf.compat.v1.python_io.TFRecordWriter(f\"{bucket_url}/{file_name}.tfrecord\") as tfwriter:\n",
        "            for train_feature in features_dataset:\n",
        "                example, label = train_feature\n",
        "                feature_key_value_pair = {\n",
        "                    'input_ids': tf.train.Feature(int64_list=tf.train.Int64List(value=example['input_ids'])),\n",
        "                    'attention_mask': tf.train.Feature(int64_list=tf.train.Int64List(value=example['attention_mask'])),\n",
        "                    'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))\n",
        "                }\n",
        "                features = tf.train.Features(feature=feature_key_value_pair)\n",
        "                example = tf.train.Example(features=features)\n",
        "\n",
        "                tfwriter.write(example.SerializeToString())\n",
        "        print(f\"Saved {file_name}.\")\n",
        "\n",
        "    save_tfrecord_to_bucket(train_dataset_w_features, bucket, \"glue_mnli_train\")\n",
        "    save_tfrecord_to_bucket(validation_dataset_w_features, bucket, \"glue_mnli_valid\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jShcjelNEFq0"
      },
      "source": [
        "# Building the training system"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IX4SPt3mHf0L"
      },
      "source": [
        "## Strategy\n",
        "\n",
        "We make use of TensorFlow's strategies, which handle the data distribution as well as the distributed training that happens on the devices available. In this example we'll be using a `MirroredStrategy` which can be used to train on a multiple GPUs in a distributed manner. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17Bnz94tuBFX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "outputId": "9ee943ba-f758-4bf1-b593-5674df96801d"
      },
      "source": [
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: 10.45.234.42:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: 10.45.234.42:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.tpu.topology.Topology at 0x7f546f000f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mIc_Ue7HWBm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "outputId": "99705657-d63a-47e9-f660-942391431bc8"
      },
      "source": [
        "strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of accelerators:  8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t6ihoFbKoOB"
      },
      "source": [
        "## Loading the Dataset with the strategy\n",
        "\n",
        "Here we define a batch size for each replica. We set it to be a multiple of 8 to best leverage the systolic array as defined in the [Google TPU performance guide](https://cloud.google.com/tpu/docs/performance-guide#rule_of_thumb_pick_efficient_values_for_batch_and_feature_dimensions)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfwCFAt9_iCD"
      },
      "source": [
        "BATCH_SIZE_PER_REPLICA = 8\n",
        "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
        "EPOCHS = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TBaFqenUXq8"
      },
      "source": [
        "### Retrieving the TFRecord dataset\n",
        "\n",
        "The TFRecord dataset is now entirely processed and ready to be used as input by our training loop. We load it, shuffle it and batch it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmMlC1i0COBW"
      },
      "source": [
        "def get_tfrecord_dataset(bucket_url, file_name):\n",
        "    features = {\n",
        "        'input_ids': tf.io.FixedLenFeature([MAX_SEQUENCE_LENGTH], tf.int64),\n",
        "        'attention_mask': tf.io.FixedLenFeature([MAX_SEQUENCE_LENGTH], tf.int64),\n",
        "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "    }\n",
        "\n",
        "    dataset = tf.data.TFRecordDataset(f\"{bucket_url}/{file_name}.tfrecord\")\n",
        "\n",
        "    # Taken from the TensorFlow models repository: https://github.com/tensorflow/models/blob/befbe0f9fe02d6bc1efb1c462689d069dae23af1/official/nlp/bert/input_pipeline.py#L24\n",
        "    def decode_record(record, features):\n",
        "        \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
        "        example = tf.io.parse_single_example(record, features)\n",
        "\n",
        "        # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n",
        "        # So cast all int64 to int32.\n",
        "        for name in list(example.keys()):\n",
        "            t = example[name]\n",
        "            if t.dtype == tf.int64:\n",
        "                t = tf.cast(t, tf.int32)\n",
        "            example[name] = t\n",
        "        return example\n",
        "\n",
        "\n",
        "    def select_data_from_record(record):\n",
        "        x = {\n",
        "            'input_ids': record['input_ids'],\n",
        "            'attention_mask': record['attention_mask'],\n",
        "        }\n",
        "        y = record['label']\n",
        "        return (x, y)\n",
        "\n",
        "\n",
        "    dataset = dataset.map(lambda record: decode_record(record, features))\n",
        "    dataset = dataset.map(select_data_from_record)\n",
        "    dataset = dataset.shuffle(100)\n",
        "    return dataset.batch(GLOBAL_BATCH_SIZE)\n",
        "\n",
        "train_dataset = get_tfrecord_dataset(bucket, \"glue_mnli_train\")\n",
        "train_dataset.prefetch(1024)\n",
        "\n",
        "validation_dataset = get_tfrecord_dataset(bucket, \"glue_mnli_valid\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkXR1MK0J7Zp"
      },
      "source": [
        "There is an additional step here to distribute the dataset among the different TPU cores. We make use of a strategy method to do so.\n",
        "\n",
        "Every item held in the dataset (which is a batched dataset) will now be split over the TPU workers. As the TPU we're using has 8 workers and our batch is of size 64, every example will be evenly split in batches of (64 / 8 =) 8 and distributed across workers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lv2zz8vYJ7vh"
      },
      "source": [
        "train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\n",
        "validation_dist_dataset = strategy.experimental_distribute_dataset(validation_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmC9J6brHN0B"
      },
      "source": [
        "## Model creation\n",
        "\n",
        "We create a function that will instantiate a new model when called."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1C-9yTS2GTj"
      },
      "source": [
        "def model_fn():\n",
        "    return TFDistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS1dc5mvHXNa"
      },
      "source": [
        "## Hyperparameters initialization\n",
        "\n",
        "While in the strategy's scope, we define a sparse categorical crossentropy loss. We define a method `compute_loss` which will be called to compute the loss between the model's prediction and the expected result (or label).\n",
        "\n",
        "In order to measure the accuracy during training and evaluation, we define two metrics which are both sparse categorical accuracy.\n",
        "\n",
        "Finally, we initialize a model and create an optimizer object using the Adam optimizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rItpKUam2JSb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2815e93d-1053-47b4-b778-1f1ca372b4b0"
      },
      "source": [
        "with strategy.scope():\n",
        "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE, from_logits=True)\n",
        "\n",
        "    def compute_loss(labels, predictions):\n",
        "        per_example_loss = loss_object(labels, predictions)\n",
        "        return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)\n",
        "\n",
        "    test_loss_metric = tf.keras.metrics.Mean(name='test_loss')\n",
        "    test_accuracy_metric = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
        "\n",
        "    train_loss_metric = tf.keras.metrics.Mean('training_loss', dtype=tf.float32)\n",
        "    train_accuracy_metric = tf.keras.metrics.SparseCategoricalAccuracy('training_accuracy')\n",
        "    \n",
        "    model = model_fn()\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 492/492 [00:00<00:00, 104703.31B/s]\n",
            "100%|██████████| 363423424/363423424 [00:10<00:00, 33184074.84B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIzuZKDMIuft"
      },
      "source": [
        "## Steps\n",
        "\n",
        "We create two functions that will be called during the training and test steps. These two methods are very similar but differ regarding the gradient computing: there is no need to compute the gradient during evaluation, and the optimizer does not need to adjust the weights.\n",
        "\n",
        "We make sure to take the first item returned by our model. The `TFDistilBertForSequenceClassification`, like all our models, return the output values as well as the values computed by each layer (called hidden states). Those values are helpful in am myriad of settings, but not in this case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZIqCzhL2R6z"
      },
      "source": [
        "with strategy.scope():\n",
        "    def train_step(inputs):\n",
        "        features, labels = inputs\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = model(features, training=True)[0]  # Gather only the outputs of the text-classification head\n",
        "            loss = compute_loss(labels, predictions)\n",
        "\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "        train_loss_metric.update_state(loss)\n",
        "        train_accuracy_metric.update_state(labels, predictions)\n",
        "\n",
        "    def test_step(inputs):\n",
        "        features, labels = inputs\n",
        "\n",
        "        predictions = model(features, training=False)[0]  # Gather only the outputs of the text-classification head\n",
        "        t_loss = compute_loss(labels, predictions)\n",
        "\n",
        "        test_loss_metric.update_state(t_loss)\n",
        "        test_accuracy_metric.update_state(labels, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqhnTfbEJ9fa"
      },
      "source": [
        "## Training & Evaluation\n",
        "\n",
        "Finally, using all the previously defined attributes, we create two traced tf.function which will execute the training and test steps in a distributed manner. There is no need for them to return anything as the metrics will directly be updated in the steps described beforehand.\n",
        "\n",
        "We loop over the number of epochs, training the model and evaluating it at the end of each epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_chN1Sy3IXn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "outputId": "d76851d8-f818-43e7-f486-9d5f2b957155"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "with strategy.scope():\n",
        "    @tf.function\n",
        "    def distributed_train_step(dataset):\n",
        "        strategy.experimental_run_v2(train_step, args=(dataset,))\n",
        " \n",
        "\n",
        "    @tf.function\n",
        "    def distributed_test_step(dataset):\n",
        "        strategy.experimental_run_v2(test_step, args=(dataset,))\n",
        "\n",
        "\n",
        "    global_step = 0\n",
        "    for epoch in range(EPOCHS):\n",
        "        total_loss = 0.0\n",
        "        training_steps = 10\n",
        "        epoch_step = 0\n",
        "        print_every = 10\n",
        "\n",
        "        ### Training loop ###\n",
        "        for tensor in tqdm(train_dist_dataset, desc=\"Training\"):\n",
        "            distributed_train_step(tensor)  \n",
        "\n",
        "            train_loss = train_loss_metric.result().numpy().astype(float)\n",
        "            train_accuracy = train_accuracy_metric.result().numpy()\n",
        "\n",
        "            global_step += 1\n",
        "            epoch_step += 1\n",
        "\n",
        "            if epoch_step % print_every == 0:\n",
        "                print(f\"Training step {epoch_step} Accuracy: {train_accuracy}, Training loss: {train_loss}\")\n",
        "\n",
        "\n",
        "        ### Test loop ###\n",
        "        for tensor in tqdm(validation_dist_dataset, desc=\"Evaluating\"):\n",
        "            distributed_test_step(tensor)\n",
        "            \n",
        "        \n",
        "        ### Output results ###\n",
        "        test_accuracy = test_accuracy_metric.result().numpy()\n",
        "        test_loss = test_loss_metric.result().numpy()\n",
        "        print(f'Epoch: [{epoch}] Validation accuracy = {test_accuracy}')\n",
        "\n",
        "        ### Reset metrics ###\n",
        "        test_loss_metric.reset_states()\n",
        "        train_accuracy_metric.reset_states()\n",
        "        train_loss_metric.reset_states()\n",
        "        test_accuracy_metric.reset_states()\n",
        "        epoch_step = 0\n",
        "\n",
        "        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training: 11it [00:46,  1.43s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 10 Accuracy: 0.6499999761581421, Training loss: 0.08133892714977264\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 21it [00:48,  5.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 20 Accuracy: 0.66796875, Training loss: 0.07936723530292511\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 31it [00:49,  6.23it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 30 Accuracy: 0.667187511920929, Training loss: 0.07885921001434326\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 41it [00:51,  6.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 40 Accuracy: 0.6675781011581421, Training loss: 0.07801492512226105\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 51it [00:53,  6.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 50 Accuracy: 0.6775000095367432, Training loss: 0.07582151144742966\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 58it [01:10,  5.07s/it]\n",
            "Evaluating: 7it [00:09,  2.55s/it]\n",
            "Training: 0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [0] Validation accuracy = 0.718137264251709\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 11it [00:02,  5.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 10 Accuracy: 0.753125011920929, Training loss: 0.05832377076148987\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 21it [00:03,  6.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 20 Accuracy: 0.7789062261581421, Training loss: 0.056860826909542084\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 31it [00:05,  6.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 30 Accuracy: 0.78125, Training loss: 0.056746941059827805\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 41it [00:07,  6.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 40 Accuracy: 0.78515625, Training loss: 0.05594119429588318\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 51it [00:08,  6.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 50 Accuracy: 0.7990624904632568, Training loss: 0.053302664309740067\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 58it [00:09,  6.29it/s]\n",
            "Evaluating: 7it [00:01,  3.69it/s]\n",
            "Training: 0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [1] Validation accuracy = 0.8284313678741455\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 11it [00:02,  5.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 10 Accuracy: 0.8828125, Training loss: 0.03771297633647919\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 21it [00:03,  6.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 20 Accuracy: 0.883593738079071, Training loss: 0.035818397998809814\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 31it [00:05,  6.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 30 Accuracy: 0.8880208134651184, Training loss: 0.034640006721019745\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 41it [00:07,  6.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 40 Accuracy: 0.8863281011581421, Training loss: 0.0344291552901268\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 51it [00:08,  6.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 50 Accuracy: 0.8928124904632568, Training loss: 0.032859668135643005\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 58it [00:09,  5.94it/s]\n",
            "Evaluating: 7it [00:01,  4.99it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [2] Validation accuracy = 0.8504902124404907\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_E-1t2T4IEq"
      },
      "source": [
        "# Congrats !\n",
        "\n",
        "You've successfully fine-tuned DistilBERT on MRPC, on a TPU. Feel free to tune the hyper-parameters or change models: simply switch the model, tokenizer and checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dv-zxY174Y-x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}