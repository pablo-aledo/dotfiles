{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "robust querydesc-passage Zhuyun BERT IR",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkTLZ3I4_7c_"
      },
      "source": [
        "# BERT finetuning tasks in 5 minutes with Cloud TPU\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\" >\n",
        " <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wtjs1QDb3DX"
      },
      "source": [
        "**BERT**, or **B**idirectional **E**mbedding **R**epresentations from **T**ransformers, is a new method of pre-training language representations which obtains state-of-the-art results on a wide array of Natural Language Processing (NLP) tasks. The academic paper can be found here: https://arxiv.org/abs/1810.04805.\n",
        "\n",
        "This Colab demonstates using a free Colab Cloud TPU to fine-tune sentence and sentence-pair classification tasks built on top of pretrained BERT models.\n",
        "\n",
        "**Note:**  You will need a GCP (Google Compute Engine) account and a GCS (Google Cloud \n",
        "Storage) bucket for this Colab to run.\n",
        "\n",
        "Please follow the [Google Cloud TPU quickstart](https://cloud.google.com/tpu/docs/quickstart) for how to create GCP account and GCS bucket. You have [$300 free credit](https://cloud.google.com/free/) to get started with any GCP product. You can learn more about Cloud TPU at https://cloud.google.com/tpu/docs.\n",
        "\n",
        "Once you finish the setup, let's start!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycHMh-bhC-vX"
      },
      "source": [
        "**Firstly**, we need to set up Colab TPU running environment, verify a TPU device is succesfully connected and upload credentials to TPU for GCS bucket usage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "191zq3ZErihP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "0255c458-2674-4412-f56b-3ed86cdd87bf"
      },
      "source": [
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.23.109.42:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 3369616037017264270),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 2622471493146608794),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 1798304136644219600),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 10581187294090197416),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 12329653481336770435),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 14528859872554398856),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 17707723227843171150),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 3881497008498220576),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 8157979055802369997),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 3291712269752196463),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 5835223111330970448)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0825 17:52:06.277870 139820775229312 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFJrTvzMw6tf"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUBP35oCDmbF"
      },
      "source": [
        "**Secondly**, prepare and import BERT modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wzwke0sxS6W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "df05faaf-f1ae-45bf-f654-e2704ad25527"
      },
      "source": [
        "import sys\n",
        "!rm -r bert_repo6\n",
        "!test -d bert_repo6 || git clone https://github.com/AdeDZY/SIGIR19-BERT-IR bert_repo6\n",
        "if not 'bert_repo6' in sys.path:\n",
        "  sys.path += ['bert_repo6']\n",
        "if not '.' in sys.path:\n",
        "  sys.path += ['.']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert_repo6'...\n",
            "remote: Enumerating objects: 69, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/69)\u001b[K\rremote: Counting objects:   2% (2/69)\u001b[K\rremote: Counting objects:   4% (3/69)\u001b[K\rremote: Counting objects:   5% (4/69)\u001b[K\rremote: Counting objects:   7% (5/69)\u001b[K\rremote: Counting objects:   8% (6/69)\u001b[K\rremote: Counting objects:  10% (7/69)\u001b[K\rremote: Counting objects:  11% (8/69)\u001b[K\rremote: Counting objects:  13% (9/69)\u001b[K\rremote: Counting objects:  14% (10/69)\u001b[K\rremote: Counting objects:  15% (11/69)\u001b[K\rremote: Counting objects:  17% (12/69)\u001b[K\rremote: Counting objects:  18% (13/69)\u001b[K\rremote: Counting objects:  20% (14/69)\u001b[K\rremote: Counting objects:  21% (15/69)\u001b[K\rremote: Counting objects:  23% (16/69)\u001b[K\rremote: Counting objects:  24% (17/69)\u001b[K\rremote: Counting objects:  26% (18/69)\u001b[K\rremote: Counting objects:  27% (19/69)\u001b[K\rremote: Counting objects:  28% (20/69)\u001b[K\rremote: Counting objects:  30% (21/69)\u001b[K\rremote: Counting objects:  31% (22/69)\u001b[K\rremote: Counting objects:  33% (23/69)\u001b[K\rremote: Counting objects:  34% (24/69)\u001b[K\rremote: Counting objects:  36% (25/69)\u001b[K\rremote: Counting objects:  37% (26/69)\u001b[K\rremote: Counting objects:  39% (27/69)\u001b[K\rremote: Counting objects:  40% (28/69)\u001b[K\rremote: Counting objects:  42% (29/69)\u001b[K\rremote: Counting objects:  43% (30/69)\u001b[K\rremote: Counting objects:  44% (31/69)\u001b[K\rremote: Counting objects:  46% (32/69)\u001b[K\rremote: Counting objects:  47% (33/69)\u001b[K\rremote: Counting objects:  49% (34/69)\u001b[K\rremote: Counting objects:  50% (35/69)\u001b[K\rremote: Counting objects:  52% (36/69)\u001b[K\rremote: Counting objects:  53% (37/69)\u001b[K\rremote: Counting objects:  55% (38/69)\u001b[K\rremote: Counting objects:  56% (39/69)\u001b[K\rremote: Counting objects:  57% (40/69)\u001b[K\rremote: Counting objects:  59% (41/69)\u001b[K\rremote: Counting objects:  60% (42/69)\u001b[K\rremote: Counting objects:  62% (43/69)\u001b[K\rremote: Counting objects:  63% (44/69)\u001b[K\rremote: Counting objects:  65% (45/69)\u001b[K\rremote: Counting objects:  66% (46/69)\u001b[K\rremote: Counting objects:  68% (47/69)\u001b[K\rremote: Counting objects:  69% (48/69)\u001b[K\rremote: Counting objects:  71% (49/69)\u001b[K\rremote: Counting objects:  72% (50/69)\u001b[K\rremote: Counting objects:  73% (51/69)\u001b[K\rremote: Counting objects:  75% (52/69)\u001b[K\rremote: Counting objects:  76% (53/69)\u001b[K\rremote: Counting objects:  78% (54/69)\u001b[K\rremote: Counting objects:  79% (55/69)\u001b[K\rremote: Counting objects:  81% (56/69)\u001b[K\rremote: Counting objects:  82% (57/69)\u001b[K\rremote: Counting objects:  84% (58/69)\u001b[K\rremote: Counting objects:  85% (59/69)\u001b[K\rremote: Counting objects:  86% (60/69)\u001b[K\rremote: Counting objects:  88% (61/69)\u001b[K\rremote: Counting objects:  89% (62/69)\u001b[K\rremote: Counting objects:  91% (63/69)\u001b[K\rremote: Counting objects:  92% (64/69)\u001b[K\rremote: Counting objects:  94% (65/69)\u001b[K\rremote: Counting objects:  95% (66/69)\u001b[K\rremote: Counting objects:  97% (67/69)\u001b[K\rremote: Counting objects:  98% (68/69)\u001b[K\rremote: Counting objects: 100% (69/69)\u001b[K\rremote: Counting objects: 100% (69/69), done.\u001b[K\n",
            "remote: Compressing objects:   1% (1/51)\u001b[K\rremote: Compressing objects:   3% (2/51)\u001b[K\rremote: Compressing objects:   5% (3/51)\u001b[K\rremote: Compressing objects:   7% (4/51)\u001b[K\rremote: Compressing objects:   9% (5/51)\u001b[K\rremote: Compressing objects:  11% (6/51)\u001b[K\rremote: Compressing objects:  13% (7/51)\u001b[K\rremote: Compressing objects:  15% (8/51)\u001b[K\rremote: Compressing objects:  17% (9/51)\u001b[K\rremote: Compressing objects:  19% (10/51)\u001b[K\rremote: Compressing objects:  21% (11/51)\u001b[K\rremote: Compressing objects:  23% (12/51)\u001b[K\rremote: Compressing objects:  25% (13/51)\u001b[K\rremote: Compressing objects:  27% (14/51)\u001b[K\rremote: Compressing objects:  29% (15/51)\u001b[K\rremote: Compressing objects:  31% (16/51)\u001b[K\rremote: Compressing objects:  33% (17/51)\u001b[K\rremote: Compressing objects:  35% (18/51)\u001b[K\rremote: Compressing objects:  37% (19/51)\u001b[K\rremote: Compressing objects:  39% (20/51)\u001b[K\rremote: Compressing objects:  41% (21/51)\u001b[K\rremote: Compressing objects:  43% (22/51)\u001b[K\rremote: Compressing objects:  45% (23/51)\u001b[K\rremote: Compressing objects:  47% (24/51)\u001b[K\rremote: Compressing objects:  49% (25/51)\u001b[K\rremote: Compressing objects:  50% (26/51)\u001b[K\rremote: Compressing objects:  52% (27/51)\u001b[K\rremote: Compressing objects:  54% (28/51)\u001b[K\rremote: Compressing objects:  56% (29/51)\u001b[K\rremote: Compressing objects:  58% (30/51)\u001b[K\rremote: Compressing objects:  60% (31/51)\u001b[K\rremote: Compressing objects:  62% (32/51)\u001b[K\rremote: Compressing objects:  64% (33/51)\u001b[K\rremote: Compressing objects:  66% (34/51)\u001b[K\rremote: Compressing objects:  68% (35/51)\u001b[K\rremote: Compressing objects:  70% (36/51)\u001b[K\rremote: Compressing objects:  72% (37/51)\u001b[K\rremote: Compressing objects:  74% (38/51)\u001b[K\rremote: Compressing objects:  76% (39/51)\u001b[K\rremote: Compressing objects:  78% (40/51)\u001b[K\rremote: Compressing objects:  80% (41/51)\u001b[K\rremote: Compressing objects:  82% (42/51)\u001b[K\rremote: Compressing objects:  84% (43/51)\u001b[K\rremote: Compressing objects:  86% (44/51)\u001b[K\rremote: Compressing objects:  88% (45/51)\u001b[K\rremote: Compressing objects:  90% (46/51)\u001b[K\rremote: Compressing objects:  92% (47/51)\u001b[K\rremote: Compressing objects:  94% (48/51)\u001b[K\rremote: Compressing objects:  96% (49/51)\u001b[K\rremote: Compressing objects:  98% (50/51)\u001b[K\rremote: Compressing objects: 100% (51/51)\u001b[K\rremote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "Unpacking objects:   1% (1/69)   \rUnpacking objects:   2% (2/69)   \rUnpacking objects:   4% (3/69)   \rUnpacking objects:   5% (4/69)   \rUnpacking objects:   7% (5/69)   \rUnpacking objects:   8% (6/69)   \rUnpacking objects:  10% (7/69)   \rUnpacking objects:  11% (8/69)   \rUnpacking objects:  13% (9/69)   \rUnpacking objects:  14% (10/69)   \rUnpacking objects:  15% (11/69)   \rUnpacking objects:  17% (12/69)   \rUnpacking objects:  18% (13/69)   \rUnpacking objects:  20% (14/69)   \rUnpacking objects:  21% (15/69)   \rUnpacking objects:  23% (16/69)   \rUnpacking objects:  24% (17/69)   \rUnpacking objects:  26% (18/69)   \rUnpacking objects:  27% (19/69)   \rUnpacking objects:  28% (20/69)   \rUnpacking objects:  30% (21/69)   \rUnpacking objects:  31% (22/69)   \rUnpacking objects:  33% (23/69)   \rUnpacking objects:  34% (24/69)   \rUnpacking objects:  36% (25/69)   \rUnpacking objects:  37% (26/69)   \rUnpacking objects:  39% (27/69)   \rUnpacking objects:  40% (28/69)   \rUnpacking objects:  42% (29/69)   \rUnpacking objects:  43% (30/69)   \rUnpacking objects:  44% (31/69)   \rUnpacking objects:  46% (32/69)   \rUnpacking objects:  47% (33/69)   \rUnpacking objects:  49% (34/69)   \rUnpacking objects:  50% (35/69)   \rUnpacking objects:  52% (36/69)   \rUnpacking objects:  53% (37/69)   \rUnpacking objects:  55% (38/69)   \rremote: Total 69 (delta 32), reused 36 (delta 15), pack-reused 0\u001b[K\n",
            "Unpacking objects:  56% (39/69)   \rUnpacking objects:  57% (40/69)   \rUnpacking objects:  59% (41/69)   \rUnpacking objects:  60% (42/69)   \rUnpacking objects:  62% (43/69)   \rUnpacking objects:  63% (44/69)   \rUnpacking objects:  65% (45/69)   \rUnpacking objects:  66% (46/69)   \rUnpacking objects:  68% (47/69)   \rUnpacking objects:  69% (48/69)   \rUnpacking objects:  71% (49/69)   \rUnpacking objects:  72% (50/69)   \rUnpacking objects:  73% (51/69)   \rUnpacking objects:  75% (52/69)   \rUnpacking objects:  76% (53/69)   \rUnpacking objects:  78% (54/69)   \rUnpacking objects:  79% (55/69)   \rUnpacking objects:  81% (56/69)   \rUnpacking objects:  82% (57/69)   \rUnpacking objects:  84% (58/69)   \rUnpacking objects:  85% (59/69)   \rUnpacking objects:  86% (60/69)   \rUnpacking objects:  88% (61/69)   \rUnpacking objects:  89% (62/69)   \rUnpacking objects:  91% (63/69)   \rUnpacking objects:  92% (64/69)   \rUnpacking objects:  94% (65/69)   \rUnpacking objects:  95% (66/69)   \rUnpacking objects:  97% (67/69)   \rUnpacking objects:  98% (68/69)   \rUnpacking objects: 100% (69/69)   \rUnpacking objects: 100% (69/69), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRhM1Zc3uurM"
      },
      "source": [
        "sys.path = ['',\n",
        " '/env/python',\n",
        " '/usr/lib/python36.zip',\n",
        " '/usr/lib/python3.6',\n",
        " '/usr/lib/python3.6/lib-dynload',\n",
        " '/usr/local/lib/python3.6/dist-packages',\n",
        " '/usr/lib/python3/dist-packages',\n",
        " '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n",
        " '/root/.ipython',\n",
        " '.',\n",
        " 'bert_repo6']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_G1me7e7wBCR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9ec4ff5e-9b3e-425f-cd85-02b84f1a9d51"
      },
      "source": [
        "sys.path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '/env/python',\n",
              " '/usr/lib/python36.zip',\n",
              " '/usr/lib/python3.6',\n",
              " '/usr/lib/python3.6/lib-dynload',\n",
              " '/usr/local/lib/python3.6/dist-packages',\n",
              " '/usr/lib/python3/dist-packages',\n",
              " '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n",
              " '/root/.ipython',\n",
              " '.',\n",
              " 'bert_repo6']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDFZNHKk2ksX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "22495a82-7a92-4fc9-8bff-a9010c7384f7"
      },
      "source": [
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import collections\n",
        "import csv\n",
        "import os\n",
        "import modeling\n",
        "import optimization\n",
        "import tokenization\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import json\n",
        "from run_qe_classifier import *\n",
        "import random\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0825 17:52:48.086066 139820775229312 deprecation_wrapper.py:119] From bert_repo6/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfr2rQ3e3cZl"
      },
      "source": [
        "FOLD=5 #@param {type:\"integer\"}\n",
        "QUERY_FIELD=\"desc\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl4yhhXMZHXa"
      },
      "source": [
        "class MyRobust04Processor(DataProcessor):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.max_test_depth = 100\n",
        "        self.max_train_depth = 1000\n",
        "        self.n_folds = 5\n",
        "        self.fold = FOLD\n",
        "        self.q_fields = QUERY_FIELD.split(' ')\n",
        "        tf.logging.info(\"Using query fields {}\".format(' '.join(self.q_fields)))\n",
        "\n",
        "        self.train_folds = [(self.fold + i) % self.n_folds + 1 for i in range(self.n_folds - 1)]\n",
        "        self.dev_fold = (self.fold + self.n_folds - 2) % self.n_folds + 1\n",
        "        self.test_folds = (self.fold + self.n_folds - 1) % self.n_folds + 1\n",
        "        tf.logging.info(\"Train Folds: {}\".format(str(self.train_folds)))\n",
        "        tf.logging.info(\"Dev Fold: {}\".format(str(self.dev_fold)))\n",
        "        tf.logging.info(\"Test Fold: {}\".format(str(self.test_folds)))\n",
        "\n",
        "    def get_train_examples(self, data_dir):\n",
        "        examples = []\n",
        "        train_files = [\"{}.trec.with_json\".format(i) for i in self.train_folds]\n",
        "\n",
        "        qrel_file = tf.gfile.Open(os.path.join(data_dir, \"qrels\"))\n",
        "        qrels = self._read_qrel(qrel_file)\n",
        "        tf.logging.info(\"Qrel size: {}\".format(len(qrels)))\n",
        "\n",
        "        query_file = tf.gfile.Open(os.path.join(data_dir, \"queries.json\"))\n",
        "        qid2queries = self._read_queries(query_file)\n",
        "        tf.logging.info(\"Loaded {} queries.\".format(len(qid2queries)))\n",
        "\n",
        "        for file_name in train_files:\n",
        "            train_file = tf.gfile.Open(os.path.join(data_dir, file_name))\n",
        "            for i, line in enumerate(train_file):\n",
        "               \n",
        "                items = line.strip().split('#')\n",
        "                trec_line = items[0]\n",
        "\n",
        "                qid, _, docid, r, _, _ = trec_line.strip().split(' ')\n",
        "                \n",
        "                if int(docid.split('_')[-1].split('-')[-1])!=0 and random.random() > 0.1:\n",
        "                    continue\n",
        "                    \n",
        "                assert qid in qid2queries, \"QID {} not found\".format(qid)\n",
        "                q_json_dict = qid2queries[qid]\n",
        "                q_text_list = [tokenization.convert_to_unicode(q_json_dict[field]) for field in self.q_fields]\n",
        "\n",
        "                json_dict = json.loads('#'.join(items[1:]))\n",
        "                d = tokenization.convert_to_unicode(json_dict[\"doc\"][\"body\"])\n",
        "\n",
        "                r = int(r)\n",
        "                if r > self.max_train_depth:\n",
        "                    continue\n",
        "                label = tokenization.convert_to_unicode(\"0\")\n",
        "                if (qid, docid) in qrels or (qid, docid.split('_')[0]) in qrels:\n",
        "                    label = tokenization.convert_to_unicode(\"1\")\n",
        "                guid = \"train-%s-%s\" % (qid, docid)\n",
        "                examples.append(\n",
        "                    InputExample(guid=guid, text_a_list=q_text_list, text_b=d, label=label)\n",
        "                )\n",
        "            train_file.close()\n",
        "        random.shuffle(examples)\n",
        "        return examples\n",
        "\n",
        "    def get_dev_examples(self, data_dir):\n",
        "        examples = []\n",
        "        dev_file = tf.gfile.Open(os.path.join(data_dir, \"{}.trec.with_json\".format(self.dev_folds)))\n",
        "        qrel_file = tf.gfile.Open(os.path.join(data_dir, \"qrels\"))\n",
        "        qrels = self._read_qrel(qrel_file)\n",
        "        tf.logging.info(\"Qrel size: {}\".format(len(qrels)))\n",
        "\n",
        "        query_file = tf.gfile.Open(os.path.join(data_dir, \"queries.json\"))\n",
        "        qid2queries = self._read_queries(query_file)\n",
        "        tf.logging.info(\"Loaded {} queries.\".format(len(qid2queries)))\n",
        "        \n",
        "        flag = False\n",
        "        for i, line in enumerate(dev_file):\n",
        "            items = line.strip().split('#')\n",
        "            trec_line = items[0]\n",
        "\n",
        "            qid, _, docid, r, _, _ = trec_line.strip().split(' ')\n",
        "            assert qid in qid2queries, \"QID {} not found\".format(qid)\n",
        "            q_json_dict = qid2queries[qid]\n",
        "            q_text_list = [tokenization.convert_to_unicode(q_json_dict[field]) for field in self.q_fields]\n",
        "\n",
        "            json_dict = json.loads('#'.join(items[1:]))\n",
        "            d = tokenization.convert_to_unicode(json_dict[\"doc\"][\"body\"])\n",
        "\n",
        "            r = int(r)\n",
        "            if r > self.max_test_depth:\n",
        "                continue\n",
        "            label = tokenization.convert_to_unicode(\"0\")\n",
        "            if (qid, docid) in qrels or (qid, docid.split('_')[0]) in qrels:\n",
        "                label = tokenization.convert_to_unicode(\"1\")\n",
        "                flag = True\n",
        "            guid = \"dev-%s-%s\" % (qid, docid)\n",
        "            examples.append(\n",
        "                InputExample(guid=guid, text_a_list=q_text_list, text_b=d, label=label)\n",
        "            )\n",
        "        dev_file.close()\n",
        "        if not flag:\n",
        "            tf.logging.warning(\"No relevant document is labeled!\")\n",
        "        return examples\n",
        "\n",
        "    def get_test_examples(self, data_dir):\n",
        "        examples = []\n",
        "        dev_file = tf.gfile.Open(os.path.join(data_dir, \"{}.trec.with_json\".format(self.test_folds)))\n",
        "        qrel_file = tf.gfile.Open(os.path.join(data_dir, \"qrels\"))\n",
        "        qrels = self._read_qrel(qrel_file)\n",
        "        tf.logging.info(\"Qrel size: {}\".format(len(qrels)))\n",
        "\n",
        "        query_file = tf.gfile.Open(os.path.join(data_dir, \"queries.json\"))\n",
        "        qid2queries = self._read_queries(query_file)\n",
        "        tf.logging.info(\"Loaded {} queries.\".format(len(qid2queries)))\n",
        "\n",
        "        for i, line in enumerate(dev_file):\n",
        "            items = line.strip().split('#')\n",
        "            trec_line = items[0]\n",
        "\n",
        "            qid, _, docid, r, _, _ = trec_line.strip().split(' ')\n",
        "            assert qid in qid2queries, \"QID {} not found\".format(qid)\n",
        "            q_json_dict = qid2queries[qid]\n",
        "            q_text_list = [tokenization.convert_to_unicode(q_json_dict[field]) for field in self.q_fields]\n",
        "\n",
        "            json_dict = json.loads('#'.join(items[1:]))\n",
        "            d = tokenization.convert_to_unicode(json_dict[\"doc\"][\"body\"])\n",
        "\n",
        "            r = int(r)\n",
        "            if r > self.max_test_depth:\n",
        "                continue\n",
        "            label = tokenization.convert_to_unicode(\"0\")\n",
        "            if (qid, docid) in qrels or (qid, docid.split('_')[0]) in qrels:\n",
        "                label = tokenization.convert_to_unicode(\"1\")\n",
        "            guid = \"test-%s-%s\" % (qid, docid)\n",
        "            examples.append(\n",
        "                InputExample(guid=guid, text_a_list=q_text_list, text_b=d, label=label)\n",
        "            )\n",
        "        dev_file.close()\n",
        "        return examples\n",
        "\n",
        "    def _read_qrel(self, qrel_file):\n",
        "        qrels = set()\n",
        "        for line in qrel_file:\n",
        "            qid, _, docid, rel = line.strip().split(' ')\n",
        "            rel = int(rel)\n",
        "            if rel > 0:\n",
        "                qrels.add((qid, docid))\n",
        "        return qrels\n",
        "\n",
        "    def _read_queries(self, query_file):\n",
        "        qid2queries = {}\n",
        "        for i, line in enumerate(query_file):\n",
        "            json_dict = json.loads(line)\n",
        "            qid = json_dict['qid']\n",
        "            qid2queries[qid] = json_dict\n",
        "            if i < 3:\n",
        "              tf.logging.info(\"Example Q: {}\".format(json_dict))\n",
        "        return qid2queries\n",
        "   \n",
        "    def get_labels(self):\n",
        "        return [\"0\", \"1\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRu1aKO1D7-Z"
      },
      "source": [
        "**Thirdly**, prepare for training:\n",
        "\n",
        "*  Specify task and download training data.\n",
        "*  Specify BERT pretrained model\n",
        "*  Specify GS bucket, create output directory for model checkpoints and eval results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYkaAlJNfhul",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "bffd7a54-4607-4b81-ad6f-b96833abd491"
      },
      "source": [
        "TASK = 'robust-descinit-passage' #@param {type:\"string\"}\n",
        "\n",
        "# Available pretrained model checkpoints:\n",
        "#   uncased_L-12_H-768_A-12: uncased BERT base model\n",
        "#   uncased_L-24_H-1024_A-16: uncased BERT large model\n",
        "#   cased_L-12_H-768_A-12: cased BERT large model\n",
        "BERT_MODEL = 'uncased_L-12_H-768_A-12' #@param {type:\"string\"}\n",
        "BERT_PRETRAINED_DIR = 'gs://cloud-tpu-checkpoints/bert/' + BERT_MODEL\n",
        "print('***** BERT pretrained directory: {} *****'.format(BERT_PRETRAINED_DIR))\n",
        "!gsutil ls $BERT_PRETRAINED_DIR\n",
        "\n",
        "BUCKET = 'bertir' #@param {type:\"string\"}\n",
        "assert BUCKET, 'Must specify an existing GCS bucket name'\n",
        "OUTPUT_DIR = 'gs://{}/bert/models/{}-fold{}'.format(BUCKET, TASK, FOLD)\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n",
        "\n",
        "DATA_DIR = \"robust/cv_descinit_passages/\" #@param {type:\"string\"}\n",
        "TASK_DATA_DIR = 'gs://{}/{}'.format(BUCKET, DATA_DIR) \n",
        "\n",
        "!gsutil ls $TASK_DATA_DIR\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** BERT pretrained directory: gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12 *****\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_config.json\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_model.ckpt.index\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_model.ckpt.meta\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/checkpoint\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/vocab.txt\n",
            "***** Model output directory: gs://bertir/bert/models/robust-descinit-passage-fold5 *****\n",
            "gs://bertir/robust/cv_descinit_passages/1.trec.with_json\n",
            "gs://bertir/robust/cv_descinit_passages/2.trec.with_json\n",
            "gs://bertir/robust/cv_descinit_passages/3.trec.with_json\n",
            "gs://bertir/robust/cv_descinit_passages/4.trec.with_json\n",
            "gs://bertir/robust/cv_descinit_passages/5.trec.with_json\n",
            "gs://bertir/robust/cv_descinit_passages/qrels\n",
            "gs://bertir/robust/cv_descinit_passages/queries.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hcpfl4N2EdOk"
      },
      "source": [
        "**Now, let's play!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu2dQ_TId-uH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "a6ba3454-faaf-4d25-8483-9e0e3f3b8c03"
      },
      "source": [
        "# Setup task specific model and TPU running config.\n",
        "\n",
        "import modeling\n",
        "import optimization\n",
        "import tokenization\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0' \n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "\n",
        "# Model Hyper Parameters\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "EVAL_BATCH_SIZE = 8\n",
        "PREDICT_BATCH_SIZE = 32\n",
        "\n",
        "LEARNING_RATE = 1e-5\n",
        "NUM_TRAIN_EPOCHS = 1.0\n",
        "WARMUP_PROPORTION = 0.1\n",
        "MAX_SEQCONCAT_LENGTH = 256\n",
        "\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 20000\n",
        "ITERATIONS_PER_LOOP = 1000\n",
        "NUM_TPU_CORES = 8\n",
        "VOCAB_FILE = os.path.join(BERT_PRETRAINED_DIR, 'vocab.txt')\n",
        "CONFIG_FILE = os.path.join(BERT_PRETRAINED_DIR, 'bert_config.json')\n",
        "INIT_CHECKPOINT = os.path.join(BERT_PRETRAINED_DIR, 'bert_model.ckpt')\n",
        "DO_LOWER_CASE = BERT_MODEL.startswith('uncased')\n",
        "\n",
        "\n",
        "processor = MyRobust04Processor()\n",
        "label_list = processor.get_labels()\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file=VOCAB_FILE, do_lower_case=DO_LOWER_CASE)\n",
        "\n",
        "tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "run_config = tf.contrib.tpu.RunConfig(\n",
        "    cluster=tpu_cluster_resolver,\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        iterations_per_loop=ITERATIONS_PER_LOOP,\n",
        "        num_shards=NUM_TPU_CORES,\n",
        "        per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n",
        "\n",
        "#\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I0825 17:54:57.573493 139820775229312 <ipython-input-8-74853bd7f2a8>:9] Using query fields desc\n",
            "I0825 17:54:57.577228 139820775229312 <ipython-input-8-74853bd7f2a8>:14] Train Folds: [1, 2, 3, 4]\n",
            "I0825 17:54:57.579711 139820775229312 <ipython-input-8-74853bd7f2a8>:15] Dev Fold: 4\n",
            "I0825 17:54:57.582394 139820775229312 <ipython-input-8-74853bd7f2a8>:16] Test Fold: 5\n",
            "W0825 17:54:57.584985 139820775229312 deprecation_wrapper.py:119] From bert_repo6/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQl1UDtRMcZM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "outputId": "d34dd062-8289-4de5-fae9-b2401aaaec17"
      },
      "source": [
        "train_examples = processor.get_train_examples(TASK_DATA_DIR)\n",
        "num_train_steps = int(len(train_examples) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "model_fn = model_fn_builder(\n",
        "    bert_config=modeling.BertConfig.from_json_file(CONFIG_FILE),\n",
        "    num_labels=len(label_list),\n",
        "    init_checkpoint=INIT_CHECKPOINT,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    num_train_steps=num_train_steps,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    use_tpu=True,\n",
        "    use_one_hot_embeddings=True)\n",
        "\n",
        "estimator = tf.contrib.tpu.TPUEstimator(\n",
        "    use_tpu=True,\n",
        "    model_fn=model_fn,\n",
        "    config=run_config,\n",
        "    train_batch_size=TRAIN_BATCH_SIZE,\n",
        "    eval_batch_size=EVAL_BATCH_SIZE,\n",
        "    predict_batch_size=PREDICT_BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I0825 17:55:07.429852 139820775229312 <ipython-input-8-74853bd7f2a8>:24] Qrel size: 17412\n",
            "I0825 17:55:07.624071 139820775229312 <ipython-input-8-74853bd7f2a8>:155] Example Q: {'title': 'Islamic Revolution', 'qid': '669', 'question': 'what is Islamic Revolution', 'narr': 'Relevant documents must discuss the reasons that relations between the Islamic world and the United States have deteriorated.', 'desc_short': 'causes Islamic Revolution relative relations US', 'desc': 'What were the causes for the Islamic Revolution relative to relations with the U.S.?'}\n",
            "I0825 17:55:07.625161 139820775229312 <ipython-input-8-74853bd7f2a8>:155] Example Q: {'title': 'poverty, disease', 'qid': '668', 'question': 'what is the relation ship between poverty and disease', 'narr': 'Documents that do not link poverty to diseases directly but mention a link between poverty and health care are relevant. Documents that simply mention poverty and disease but do not draw a connection are not relevant.', 'desc_short': 'relationship poverty disease', 'desc': 'What is the relationship between poverty and disease?'}\n",
            "I0825 17:55:07.625879 139820775229312 <ipython-input-8-74853bd7f2a8>:155] Example Q: {'title': 'unmarried-partner households', 'qid': '667', 'question': 'what is unmarried-partner households', 'narr': 'Reference to any laws pertaining to such households as well as same sex households are relevant.', 'desc_short': 'increasing trend creation unmarried partner households US', 'desc': 'the increasing trend toward creation of unmarried-partner households in the U.S.'}\n",
            "I0825 17:55:07.634006 139820775229312 <ipython-input-8-74853bd7f2a8>:28] Loaded 250 queries.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-0b8b8e6e8336>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_train_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTASK_DATA_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnum_train_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_examples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mTRAIN_BATCH_SIZE\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mNUM_TRAIN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnum_warmup_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_train_steps\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mWARMUP_PROPORTION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m model_fn = model_fn_builder(\n",
            "\u001b[0;32m<ipython-input-8-74853bd7f2a8>\u001b[0m in \u001b[0;36mget_train_examples\u001b[0;34m(self, data_dir)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mtrain_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'#'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;34mr\"\"\"Reads the next line from the file. Leaves the '\\n' at the end.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preread_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_buf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReadLineAsString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mReadLineAsString\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mReadLineAsString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2319\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_pywrap_tensorflow_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBufferedInputStream_ReadLineAsString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2320\u001b[0m \u001b[0mBufferedInputStream_swigregister\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pywrap_tensorflow_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBufferedInputStream_swigregister\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2321\u001b[0m \u001b[0mBufferedInputStream_swigregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBufferedInputStream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U_c8s2AvhgL"
      },
      "source": [
        "# Train the model.\n",
        "train_file = os.path.join(OUTPUT_DIR, \"train.tf_record\")\n",
        "#train_features = file_based_convert_examples_to_features(\n",
        "#    train_examples, label_list, MAX_SEQCONCAT_LENGTH, tokenizer, train_file)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBotBeY2SmOF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6820
        },
        "outputId": "b2c0bfba-59d3-46d8-816e-813c08bdefa3"
      },
      "source": [
        "train_file = os.path.join(OUTPUT_DIR, \"train.tf_record\")\n",
        "\n",
        "print('***** Started training at {} *****'.format(datetime.datetime.now()))\n",
        "print('  Batch size = {}'.format(TRAIN_BATCH_SIZE))\n",
        "tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
        "train_input_fn = file_based_input_fn_builder(\n",
        "    input_file=train_file,\n",
        "    seq_length=MAX_SEQCONCAT_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=True)\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "print('***** Finished training at {} *****'.format(datetime.datetime.now()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Started training at 2019-02-18 14:04:37.471168 *****\n",
            "  Batch size = 16\n",
            "INFO:tensorflow:  Num steps = 23407\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.21.22.90:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 13578720447639949201)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 14271873016053651699)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 1639536778088073386)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 10243009842499693073)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 16560172941151807449)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 18010399173247951364)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 8111210075232632492)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 11107389456202213627)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 8142808385908642993)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 6488428855171638688)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 1511485327206774183)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From bert_repo6/run_qe_classifier.py:671: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "WARNING:tensorflow:From bert_repo6/run_qe_classifier.py:651: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:1720: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
            "INFO:tensorflow:*** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (2, 256)\n",
            "INFO:tensorflow:  name = input_mask, shape = (2, 256)\n",
            "INFO:tensorflow:  name = is_real_example, shape = (2,)\n",
            "INFO:tensorflow:  name = label_ids, shape = (2,)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (2, 256)\n",
            "WARNING:tensorflow:From bert_repo6/modeling.py:359: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From bert_repo6/modeling.py:673: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = output_weights:0, shape = (2, 768)\n",
            "INFO:tensorflow:  name = output_bias:0, shape = (2,)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into gs://bertir/bert/models/robust-descinit-passage-fold5/model.ckpt.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Installing graceful shutdown hook.\n",
            "INFO:tensorflow:Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "INFO:tensorflow:Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 7 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.0025119926, step = 1000\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.015060525, step = 2000 (65.763 sec)\n",
            "INFO:tensorflow:global_step/sec: 15.2061\n",
            "INFO:tensorflow:examples/sec: 243.297\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.0017745428, step = 3000 (60.765 sec)\n",
            "INFO:tensorflow:global_step/sec: 16.4568\n",
            "INFO:tensorflow:examples/sec: 263.308\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.00062035816, step = 4000 (61.265 sec)\n",
            "INFO:tensorflow:global_step/sec: 16.3226\n",
            "INFO:tensorflow:examples/sec: 261.161\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.00027305144, step = 5000 (60.760 sec)\n",
            "INFO:tensorflow:global_step/sec: 16.458\n",
            "INFO:tensorflow:examples/sec: 263.328\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.000449248, step = 6000 (61.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 16.3376\n",
            "INFO:tensorflow:examples/sec: 261.402\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.0018095829, step = 7000 (61.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 16.3604\n",
            "INFO:tensorflow:examples/sec: 261.766\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.0008009917, step = 8000 (60.689 sec)\n",
            "INFO:tensorflow:global_step/sec: 16.4775\n",
            "INFO:tensorflow:examples/sec: 263.64\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.00010036843, step = 9000 (60.735 sec)\n",
            "INFO:tensorflow:global_step/sec: 16.4648\n",
            "INFO:tensorflow:examples/sec: 263.437\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 4.9171427e-05, step = 10000 (61.226 sec)\n",
            "INFO:tensorflow:global_step/sec: 16.333\n",
            "INFO:tensorflow:examples/sec: 261.328\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.002244358, step = 11000 (60.743 sec)\n",
            "INFO:tensorflow:global_step/sec: 16.4628\n",
            "INFO:tensorflow:examples/sec: 263.404\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.00068509864, step = 12000 (61.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 16.3522\n",
            "INFO:tensorflow:examples/sec: 261.636\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.00068892556, step = 13000 (61.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 16.3464\n",
            "INFO:tensorflow:examples/sec: 261.543\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.0001663341, step = 14000 (60.700 sec)\n",
            "INFO:tensorflow:global_step/sec: 16.4747\n",
            "INFO:tensorflow:examples/sec: 263.595\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.0002990259, step = 15000 (60.705 sec)\n",
            "INFO:tensorflow:global_step/sec: 16.4732\n",
            "INFO:tensorflow:examples/sec: 263.571\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.0046846736, step = 16000 (61.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 16.3495\n",
            "INFO:tensorflow:examples/sec: 261.592\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 9.411598e-05, step = 17000 (60.675 sec)\n",
            "INFO:tensorflow:global_step/sec: 16.4812\n",
            "INFO:tensorflow:examples/sec: 263.699\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.00013206204, step = 18000 (61.128 sec)\n",
            "INFO:tensorflow:global_step/sec: 16.3591\n",
            "INFO:tensorflow:examples/sec: 261.745\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.00032481892, step = 19000 (61.289 sec)\n",
            "INFO:tensorflow:global_step/sec: 16.3161\n",
            "INFO:tensorflow:examples/sec: 261.057\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Saving checkpoints for 20000 into gs://bertir/bert/models/robust-descinit-passage-fold5/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.00026798475, step = 20000 (78.535 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.7332\n",
            "INFO:tensorflow:examples/sec: 203.732\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.00012217756, step = 21000 (60.700 sec)\n",
            "INFO:tensorflow:global_step/sec: 16.4744\n",
            "INFO:tensorflow:examples/sec: 263.591\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.0001532934, step = 22000 (61.259 sec)\n",
            "INFO:tensorflow:global_step/sec: 16.3241\n",
            "INFO:tensorflow:examples/sec: 261.185\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.00011776264, step = 23000 (60.757 sec)\n",
            "INFO:tensorflow:global_step/sec: 16.4591\n",
            "INFO:tensorflow:examples/sec: 263.345\n",
            "INFO:tensorflow:Enqueue next (407) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (407) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.00019886174, step = 23407 (25.878 sec)\n",
            "INFO:tensorflow:global_step/sec: 15.7279\n",
            "INFO:tensorflow:examples/sec: 251.647\n",
            "INFO:tensorflow:Saving checkpoints for 23407 into gs://bertir/bert/models/robust-descinit-passage-fold5/model.ckpt.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:Loss for final step: 0.00019886174.\n",
            "INFO:tensorflow:training_loop marked as finished\n",
            "***** Finished training at 2019-02-18 14:31:05.303677 *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMoAi_LYLBRm"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDgZbmLnUaLf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "outputId": "16132686-b5ef-42bd-8c9d-27abeffe8c6e"
      },
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "predict_examples = processor.get_test_examples(TASK_DATA_DIR)\n",
        "num_actual_predict_examples = len(predict_examples)\n",
        "assert num_actual_predict_examples > 0\n",
        "predict_batch_size = 32\n",
        "while len(predict_examples) % predict_batch_size != 0:\n",
        "  predict_examples.append(PaddingInputExample())\n",
        "\n",
        "predict_file = os.path.join(OUTPUT_DIR, \"predict.tf_record\")\n",
        "file_based_convert_examples_to_features(predict_examples, label_list,\n",
        "                                        MAX_SEQCONCAT_LENGTH, tokenizer,\n",
        "                                        predict_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Qrel size: 17412\n",
            "INFO:tensorflow:Example Q: {'title': 'Islamic Revolution', 'qid': '669', 'question': 'what is Islamic Revolution', 'narr': 'Relevant documents must discuss the reasons that relations between the Islamic world and the United States have deteriorated.', 'desc_short': 'causes Islamic Revolution relative relations US', 'desc': 'What were the causes for the Islamic Revolution relative to relations with the U.S.?'}\n",
            "INFO:tensorflow:Example Q: {'title': 'poverty, disease', 'qid': '668', 'question': 'what is the relation ship between poverty and disease', 'narr': 'Documents that do not link poverty to diseases directly but mention a link between poverty and health care are relevant. Documents that simply mention poverty and disease but do not draw a connection are not relevant.', 'desc_short': 'relationship poverty disease', 'desc': 'What is the relationship between poverty and disease?'}\n",
            "INFO:tensorflow:Example Q: {'title': 'unmarried-partner households', 'qid': '667', 'question': 'what is unmarried-partner households', 'narr': 'Reference to any laws pertaining to such households as well as same sex households are relevant.', 'desc_short': 'increasing trend creation unmarried partner households US', 'desc': 'the increasing trend toward creation of unmarried-partner households in the U.S.'}\n",
            "INFO:tensorflow:Loaded 250 queries.\n",
            "INFO:tensorflow:Writing example 0 of 57472\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: test-604-LA061389-0087_passage-0\n",
            "INFO:tensorflow:tokens: [CLS] what evidence is there to link tick - borne l ##yme disease with arthritis ? [SEP] dr . lee ##ber cohen was the active sort when he lived back in mt . ki ##sco , n . y . , always pedal ##ing his bicycle , jogging down the streets , practicing the piano or put ##tering in his back - yard flower beds in the po ##sh westchester county suburb . but about two years ago , the ob ##ste ##tric ##ian , then 32 , suddenly experienced a mysterious weakness in his right arm . first , medical colleagues said he must have suffered nerve damage while cycling . then came terrible mig ##raine headache ##s , which the experts blamed on stress . and when dizzy spells came on , an intern ##ist gave cohen medication for vertigo . nothing helped . after two months of feeling lou ##sy , cohen came up with his own theory - - that he had l ##yme disease , a sometimes hard - to - recognize , potentially cr ##ip ##pling mala ##dy borne largely by deer tick ##s that he may have picked up in the garden . ' very serious complaints ' several blood tests , spinal taps , cat scans and intra ##ven ##ous anti ##biotic treatments later , [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2054 3350 2003 2045 2000 4957 16356 1011 15356 1048 25219 4295 2007 27641 1029 102 2852 1012 3389 5677 9946 2001 1996 3161 4066 2043 2002 2973 2067 1999 11047 1012 11382 9363 1010 1050 1012 1061 1012 1010 2467 15749 2075 2010 10165 1010 28233 2091 1996 4534 1010 12560 1996 3682 2030 2404 17989 1999 2010 2067 1011 4220 6546 9705 1999 1996 13433 4095 25489 2221 7575 1012 2021 2055 2048 2086 3283 1010 1996 27885 13473 12412 2937 1010 2059 3590 1010 3402 5281 1037 8075 11251 1999 2010 2157 2849 1012 2034 1010 2966 8628 2056 2002 2442 2031 4265 9113 4053 2096 9670 1012 2059 2234 6659 19117 26456 14978 2015 1010 2029 1996 8519 11248 2006 6911 1012 1998 2043 14849 11750 2234 2006 1010 2019 25204 2923 2435 9946 14667 2005 28246 1012 2498 3271 1012 2044 2048 2706 1997 3110 10223 6508 1010 9946 2234 2039 2007 2010 2219 3399 1011 1011 2008 2002 2018 1048 25219 4295 1010 1037 2823 2524 1011 2000 1011 6807 1010 9280 13675 11514 14353 28935 5149 15356 4321 2011 8448 16356 2015 2008 2002 2089 2031 3856 2039 1999 1996 3871 1012 1005 2200 3809 10821 1005 2195 2668 5852 1010 16492 25316 1010 4937 27404 1998 26721 8159 3560 3424 26591 13441 2101 1010 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 1 (id = 1)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: test-604-LA061389-0087_passage-1\n",
            "INFO:tensorflow:tokens: [CLS] what evidence is there to link tick - borne l ##yme disease with arthritis ? [SEP] which the experts blamed on stress . and when dizzy spells came on , an intern ##ist gave cohen medication for vertigo . nothing helped . after two months of feeling lou ##sy , cohen came up with his own theory - - that he had l ##yme disease , a sometimes hard - to - recognize , potentially cr ##ip ##pling mala ##dy borne largely by deer tick ##s that he may have picked up in the garden . ' very serious complaints ' several blood tests , spinal taps , cat scans and intra ##ven ##ous anti ##biotic treatments later , cohen thinks he has shaken the illness , though he still has a ringing in his ears that may never go away . \" i had never really been on the other side of the bed before , \" said cohen , who has since moved his practice to chicago . \" this was a very frustrating experience for me because i had very serious complaints that weren ' t taken seriously for a long time . \" unfortunately , cohen ' s experience is becoming increasingly common in some [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2054 3350 2003 2045 2000 4957 16356 1011 15356 1048 25219 4295 2007 27641 1029 102 2029 1996 8519 11248 2006 6911 1012 1998 2043 14849 11750 2234 2006 1010 2019 25204 2923 2435 9946 14667 2005 28246 1012 2498 3271 1012 2044 2048 2706 1997 3110 10223 6508 1010 9946 2234 2039 2007 2010 2219 3399 1011 1011 2008 2002 2018 1048 25219 4295 1010 1037 2823 2524 1011 2000 1011 6807 1010 9280 13675 11514 14353 28935 5149 15356 4321 2011 8448 16356 2015 2008 2002 2089 2031 3856 2039 1999 1996 3871 1012 1005 2200 3809 10821 1005 2195 2668 5852 1010 16492 25316 1010 4937 27404 1998 26721 8159 3560 3424 26591 13441 2101 1010 9946 6732 2002 2038 16697 1996 7355 1010 2295 2002 2145 2038 1037 13060 1999 2010 5551 2008 2089 2196 2175 2185 1012 1000 1045 2018 2196 2428 2042 2006 1996 2060 2217 1997 1996 2793 2077 1010 1000 2056 9946 1010 2040 2038 2144 2333 2010 3218 2000 3190 1012 1000 2023 2001 1037 2200 25198 3325 2005 2033 2138 1045 2018 2200 3809 10821 2008 4694 1005 1056 2579 5667 2005 1037 2146 2051 1012 1000 6854 1010 9946 1005 1055 3325 2003 3352 6233 2691 1999 2070 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 1 (id = 1)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: test-604-LA061389-0087_passage-2\n",
            "INFO:tensorflow:tokens: [CLS] what evidence is there to link tick - borne l ##yme disease with arthritis ? [SEP] cohen thinks he has shaken the illness , though he still has a ringing in his ears that may never go away . \" i had never really been on the other side of the bed before , \" said cohen , who has since moved his practice to chicago . \" this was a very frustrating experience for me because i had very serious complaints that weren ' t taken seriously for a long time . \" unfortunately , cohen ' s experience is becoming increasingly common in some parts of the country as americans head into another summer vacation season with something lurking in the trees and brush far more dangerous than poison ivy . \" most of us grew up in a situation where you don ' t have to worry much about walking in the woods and catching diseases , \" said phillip j . pe ##lli ##tter ##i , an en ##tom ##ologist and l ##yme expert at the university of wisconsin . \" that ' s changed . \" first identified only 14 years ago in old l ##yme , con ##n . , [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2054 3350 2003 2045 2000 4957 16356 1011 15356 1048 25219 4295 2007 27641 1029 102 9946 6732 2002 2038 16697 1996 7355 1010 2295 2002 2145 2038 1037 13060 1999 2010 5551 2008 2089 2196 2175 2185 1012 1000 1045 2018 2196 2428 2042 2006 1996 2060 2217 1997 1996 2793 2077 1010 1000 2056 9946 1010 2040 2038 2144 2333 2010 3218 2000 3190 1012 1000 2023 2001 1037 2200 25198 3325 2005 2033 2138 1045 2018 2200 3809 10821 2008 4694 1005 1056 2579 5667 2005 1037 2146 2051 1012 1000 6854 1010 9946 1005 1055 3325 2003 3352 6233 2691 1999 2070 3033 1997 1996 2406 2004 4841 2132 2046 2178 2621 10885 2161 2007 2242 24261 1999 1996 3628 1998 8248 2521 2062 4795 2084 9947 7768 1012 1000 2087 1997 2149 3473 2039 1999 1037 3663 2073 2017 2123 1005 1056 2031 2000 4737 2172 2055 3788 1999 1996 5249 1998 9105 7870 1010 1000 2056 10852 1046 1012 21877 6894 12079 2072 1010 2019 4372 20389 8662 1998 1048 25219 6739 2012 1996 2118 1997 5273 1012 1000 2008 1005 1055 2904 1012 1000 2034 4453 2069 2403 2086 3283 1999 2214 1048 25219 1010 9530 2078 1012 1010 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 1 (id = 1)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: test-604-LA061389-0087_passage-3\n",
            "INFO:tensorflow:tokens: [CLS] what evidence is there to link tick - borne l ##yme disease with arthritis ? [SEP] parts of the country as americans head into another summer vacation season with something lurking in the trees and brush far more dangerous than poison ivy . \" most of us grew up in a situation where you don ' t have to worry much about walking in the woods and catching diseases , \" said phillip j . pe ##lli ##tter ##i , an en ##tom ##ologist and l ##yme expert at the university of wisconsin . \" that ' s changed . \" first identified only 14 years ago in old l ##yme , con ##n . , l ##yme disease has swept across much of the northeast and upper midwest . experts say it has hit epidemic levels in a few hot spots , most seriously in new york , where more than 2 , 500 cases were diagnosed last year alone . the u . s . centers for disease control have detected a nine - fold annual increase in cases since it first began systematic tracking of l ##yme . a spokesman for the atlanta - based centers said more than 14 , 000 cases had been reported [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2054 3350 2003 2045 2000 4957 16356 1011 15356 1048 25219 4295 2007 27641 1029 102 3033 1997 1996 2406 2004 4841 2132 2046 2178 2621 10885 2161 2007 2242 24261 1999 1996 3628 1998 8248 2521 2062 4795 2084 9947 7768 1012 1000 2087 1997 2149 3473 2039 1999 1037 3663 2073 2017 2123 1005 1056 2031 2000 4737 2172 2055 3788 1999 1996 5249 1998 9105 7870 1010 1000 2056 10852 1046 1012 21877 6894 12079 2072 1010 2019 4372 20389 8662 1998 1048 25219 6739 2012 1996 2118 1997 5273 1012 1000 2008 1005 1055 2904 1012 1000 2034 4453 2069 2403 2086 3283 1999 2214 1048 25219 1010 9530 2078 1012 1010 1048 25219 4295 2038 7260 2408 2172 1997 1996 4794 1998 3356 13608 1012 8519 2360 2009 2038 2718 16311 3798 1999 1037 2261 2980 7516 1010 2087 5667 1999 2047 2259 1010 2073 2062 2084 1016 1010 3156 3572 2020 11441 2197 2095 2894 1012 1996 1057 1012 1055 1012 6401 2005 4295 2491 2031 11156 1037 3157 1011 10671 3296 3623 1999 3572 2144 2009 2034 2211 11778 9651 1997 1048 25219 1012 1037 14056 2005 1996 5865 1011 2241 6401 2056 2062 2084 2403 1010 2199 3572 2018 2042 2988 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 1 (id = 1)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: test-604-LA061389-0087_passage-4\n",
            "INFO:tensorflow:tokens: [CLS] what evidence is there to link tick - borne l ##yme disease with arthritis ? [SEP] l ##yme disease has swept across much of the northeast and upper midwest . experts say it has hit epidemic levels in a few hot spots , most seriously in new york , where more than 2 , 500 cases were diagnosed last year alone . the u . s . centers for disease control have detected a nine - fold annual increase in cases since it first began systematic tracking of l ##yme . a spokesman for the atlanta - based centers said more than 14 , 000 cases had been reported nationwide since 1980 , most of them on the east coast or in wisconsin and minnesota . because l ##yme is so new and symptoms vary so widely , doctors can fail to recognize the disease and cases may go un ##re ##port ##ed . at the same time , however , some experts warn that most outbreak ##s are localized and suggest that the l ##yme threat has been over ##bl ##own in the media , un ##ne ##ces ##sari ##ly scar ##ing many people at low risk and sending h ##yp ##och ##ond ##ria ##cs sc ##ur ##ry ##ing to their [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2054 3350 2003 2045 2000 4957 16356 1011 15356 1048 25219 4295 2007 27641 1029 102 1048 25219 4295 2038 7260 2408 2172 1997 1996 4794 1998 3356 13608 1012 8519 2360 2009 2038 2718 16311 3798 1999 1037 2261 2980 7516 1010 2087 5667 1999 2047 2259 1010 2073 2062 2084 1016 1010 3156 3572 2020 11441 2197 2095 2894 1012 1996 1057 1012 1055 1012 6401 2005 4295 2491 2031 11156 1037 3157 1011 10671 3296 3623 1999 3572 2144 2009 2034 2211 11778 9651 1997 1048 25219 1012 1037 14056 2005 1996 5865 1011 2241 6401 2056 2062 2084 2403 1010 2199 3572 2018 2042 2988 9053 2144 3150 1010 2087 1997 2068 2006 1996 2264 3023 2030 1999 5273 1998 5135 1012 2138 1048 25219 2003 2061 2047 1998 8030 8137 2061 4235 1010 7435 2064 8246 2000 6807 1996 4295 1998 3572 2089 2175 4895 2890 6442 2098 1012 2012 1996 2168 2051 1010 2174 1010 2070 8519 11582 2008 2087 8293 2015 2024 22574 1998 6592 2008 1996 1048 25219 5081 2038 2042 2058 16558 12384 1999 1996 2865 1010 4895 2638 9623 22740 2135 11228 2075 2116 2111 2012 2659 3891 1998 6016 1044 22571 11663 15422 4360 6169 8040 3126 2854 2075 2000 2037 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 1 (id = 1)\n",
            "INFO:tensorflow:Writing example 10000 of 57472\n",
            "INFO:tensorflow:Writing example 20000 of 57472\n",
            "INFO:tensorflow:Writing example 30000 of 57472\n",
            "INFO:tensorflow:Writing example 40000 of 57472\n",
            "INFO:tensorflow:Writing example 50000 of 57472\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRC2z8LcKxNv"
      },
      "source": [
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "#predict_file=\"gs://bertir/bert/models/marco/predict.tf_record\"\n",
        "#num_actual_predict_examples = 999240\n",
        "tf.logging.info(\"***** Running prediction*****\")\n",
        "#tf.logging.info(\"  Num examples = %d (%d actual, %d padding)\",\n",
        "#                    len(predict_examples), num_actual_predict_examples,\n",
        "#                    len(predict_examples) - num_actual_predict_examples)\n",
        "tf.logging.info(\"  Batch size = %d\", PREDICT_BATCH_SIZE)\n",
        "\n",
        "predict_drop_remainder = True \n",
        "predict_input_fn = file_based_input_fn_builder(\n",
        "        input_file=predict_file,\n",
        "        seq_length=MAX_SEQCONCAT_LENGTH,\n",
        "        is_training=False,\n",
        "        drop_remainder=predict_drop_remainder)\n",
        "\n",
        "result = estimator.predict(input_fn=predict_input_fn)\n",
        "\n",
        "output_predict_file = os.path.join(OUTPUT_DIR, \"test_results.tsv\")\n",
        "with tf.gfile.GFile(output_predict_file, \"w\") as writer:\n",
        "  num_written_lines = 0\n",
        "  tf.logging.info(\"***** Predict results *****\")\n",
        "  for (i, prediction) in enumerate(result):\n",
        "    probabilities = prediction[\"probabilities\"]\n",
        "    if i >= num_actual_predict_examples:\n",
        "      break\n",
        "    output_line = \"\\t\".join(\n",
        "            str(class_probability)\n",
        "            for class_probability in probabilities) + \"\\n\"\n",
        "    writer.write(output_line)\n",
        "    num_written_lines += 1\n",
        "    if num_written_lines % 100000 == 0:\n",
        "      print(num_written_lines)\n",
        "assert num_written_lines == num_actual_predict_examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lqHzLU8LBad"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoXRtSPZvdiS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "d5102b4c-c22a-48d9-efdb-b5289b04a5e8"
      },
      "source": [
        "# Eval the model.\n",
        "eval_examples = processor.get_dev_examples(TASK_DATA_DIR)\n",
        "eval_features = run_classifier.convert_examples_to_features(\n",
        "    eval_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "print('***** Started evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "print('  Num examples = {}'.format(len(eval_examples)))\n",
        "print('  Batch size = {}'.format(EVAL_BATCH_SIZE))\n",
        "# Eval will be slightly WRONG on the TPU because it will truncate\n",
        "# the last batch.\n",
        "eval_steps = int(len(eval_examples) / EVAL_BATCH_SIZE)\n",
        "eval_input_fn = run_classifier.input_fn_builder(\n",
        "    features=eval_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=True)\n",
        "result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)\n",
        "print('***** Finished evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "output_eval_file = os.path.join(OUTPUT_DIR, \"eval_results.txt\")\n",
        "with tf.gfile.GFile(output_eval_file, \"w\") as writer:\n",
        "  print(\"***** Eval results *****\")\n",
        "  for key in sorted(result.keys()):\n",
        "    print('  {} = {}'.format(key, str(result[key])))\n",
        "    writer.write(\"%s = %s\\n\" % (key, str(result[key])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-8f3170d2c22c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meval_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dev_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTASK_DATA_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m eval_features = run_classifier.convert_examples_to_features(\n\u001b[1;32m      3\u001b[0m     eval_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'***** Started evaluation at {} *****'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'  Num examples = {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-9de44a9836ed>\u001b[0m in \u001b[0;36mget_dev_examples\u001b[0;34m(self, data_dir)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_dev_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mexamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mdev_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{}.trec.with_json\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdev_folds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mqrel_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"qrels\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mqrels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_qrel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqrel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'MyClueWebProcessor' object has no attribute 'dev_folds'"
          ]
        }
      ]
    }
  ]
}