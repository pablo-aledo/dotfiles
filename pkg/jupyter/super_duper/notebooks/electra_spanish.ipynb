{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "electra-spanish",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e11b8a161c624fe19e09e2a6337fa49e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f0a1e2bf315942508dc727b3573d8775",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c97308973177453bbbcfe76d39f10bde",
              "IPY_MODEL_9f0c1401610942bfa31613b72cad8f3f"
            ]
          }
        },
        "f0a1e2bf315942508dc727b3573d8775": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c97308973177453bbbcfe76d39f10bde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a744a42897724a9ba47bb83d694aa16f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 625,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 625,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f35d989d2f8f48458cd0c1c22159614b"
          }
        },
        "9f0c1401610942bfa31613b72cad8f3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f463ffd8a96044f1b2c57fec99042877",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 625/625 [00:00&lt;00:00, 16.9kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_71415fb39ac84936a12a69368c0d0572"
          }
        },
        "a744a42897724a9ba47bb83d694aa16f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f35d989d2f8f48458cd0c1c22159614b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f463ffd8a96044f1b2c57fec99042877": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "71415fb39ac84936a12a69368c0d0572": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c6e469843dfe4977ad6cbbe68db41b7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9ffee1a5bff34d3596800a53d666bea3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aeb0448b527a447a96ec5a48a375f15d",
              "IPY_MODEL_ff286e2fee8d4cffac3e4b17b4465ec1"
            ]
          }
        },
        "9ffee1a5bff34d3596800a53d666bea3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aeb0448b527a447a96ec5a48a375f15d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_08c8fa39acd644e0a1a0e506832eeb86",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 995526,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 995526,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_88abf1ac0af34839ac0002b2bbac351c"
          }
        },
        "ff286e2fee8d4cffac3e4b17b4465ec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4a9c8fc5ba6c41e2ace0d802f2493e07",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 996k/996k [00:00&lt;00:00, 1.47MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2de088388cb1417e8c08cc8ca74fd6c9"
          }
        },
        "08c8fa39acd644e0a1a0e506832eeb86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "88abf1ac0af34839ac0002b2bbac351c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4a9c8fc5ba6c41e2ace0d802f2493e07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2de088388cb1417e8c08cc8ca74fd6c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1Rtfvo0rzHD"
      },
      "source": [
        "# Pre-train ELECTRA from Scratch for Spanish"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIHC6Pg66zHg"
      },
      "source": [
        "## 1. Introduction\n",
        "\n",
        "At ICLR 2020, [ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators](https://openreview.net/pdf?id=r1xMH1BtvB), a new method for self-supervised language representation learning, was introduced. ELECTRA is another member of the Transformer pre-training method family, whose previous members such as BERT, GPT-2, RoBERTa have achieved many state-of-the-art results in Natural Language Processing benchmarks.\n",
        "\n",
        "Different from other masked language modeling methods, ELECTRA is a more sample-efficient pre-training task called replaced token detection. At a small scale, ELECTRA-small can be trained on a single GPU for 4 days to outperform [GPT (Radford et al., 2018)](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf) (trained using 30x more compute) on the GLUE benchmark. At a large scale, ELECTRA-large outperforms [ALBERT (Lan et al., 2019)]() on GLUE and sets a new state-of-the-art for SQuAD 2.0.\n",
        "\n",
        "![](https://github.com/chriskhanhtran/spanish-bert/blob/master/img/electra-performance.JPG?raw=true)\n",
        "*ELECTRA consistently outperforms masked language model pre-training approaches.*\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkVcyxKD6mqE"
      },
      "source": [
        "## 2. Method\n",
        "\n",
        "Masked language modeling pre-training methods such as [BERT (Devlin et al., 2019)](https://arxiv.org/abs/1810.04805) corrupt the input by replacing some tokens (typically 15% of the input) with `[MASK]` and then train a model to re-construct the original tokens.\n",
        "\n",
        "Instead of masking, ELECTRA corrupts the input by replacing some tokens with samples from the outputs of a smalled masked language model. Then, a discriminative model is trained to predict whether each token was an original or a replacement. After pre-training, the generator is thrown out and the discriminator is fine-tuned on downstream tasks.\n",
        "\n",
        "![](https://github.com/chriskhanhtran/spanish-bert/blob/master/img/electra-overview.JPG?raw=true)\n",
        "*An overview of ELECTRA.*\n",
        "\n",
        "Although having a generator and a discriminator like GAN, ELECTRA is not adversarial in that the generator producing corrupted tokens is trained with maximum likelihood rather than being trained to fool the discriminator.\n",
        "\n",
        "**Why is ELECTRA so efficient?**\n",
        "\n",
        "With a new training objective, ELECTRA can achieve comparable performance to strong models such as [RoBERTa (Liu et al., (2019)](https://arxiv.org/abs/1907.11692) which has more parameters and needs 4x more compute for training. In the paper, an analysis was conducted to understand what really contribute to ELECTRA's efficiency. The key findings are:\n",
        "\n",
        "- ELECTRA is greatly benefiting from having a loss defined over all input tokens rather than just a subset. More specifically, in ELECTRA, the discriminator predicts on every token in the input, while in BERT, the generator only predicts 15% masked tokens of the input.\n",
        "- BERT's performance is slightly harmed because in the pre-training phase, the model sees `[MASK]` tokens, while it is not the case in the fine-tuning phase.\n",
        "\n",
        "![](https://github.com/chriskhanhtran/spanish-bert/blob/master/img/electra-vs-bert.JPG?raw=true)\n",
        "*ELECTRA vs. BERT*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYla4vyCMoJl"
      },
      "source": [
        "## 3. Pre-train ELECTRA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RedlfwNM2Ii"
      },
      "source": [
        "In this section, we will train ELECTRA from scratch with TensorFlow using scripts provided by ELECTRA's authors in [google-research/electra](https://github.com/google-research/electra). Then we will convert the model to PyTorch's checkpoint, which can be easily fine-tuned on downstream tasks using Hugging Face's `transformers` library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIN5qf3dffb0"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sbjt-5WFfecT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2233c5f3-3c3c-4589-917d-b035b6e56832"
      },
      "source": [
        "!pip install tensorflow==1.15\n",
        "!pip install transformers==2.8.0\n",
        "!git clone https://github.com/google-research/electra.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 412.3MB 42kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.0.8)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.8MB 52.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.34.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.29.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.18.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.2.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 512kB 52.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.9.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.2.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (47.1.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=75e39d1c6b2716e57766ae45ce0b53e9510c37a1882c25b7bbc4cc6c2dd6cc4d\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, gast, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.2.2\n",
            "    Uninstalling tensorboard-2.2.2:\n",
            "      Successfully uninstalled tensorboard-2.2.2\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: tensorflow 2.2.0\n",
            "    Uninstalling tensorflow-2.2.0:\n",
            "      Successfully uninstalled tensorflow-2.2.0\n",
            "Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n",
            "Collecting transformers==2.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 573kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 24.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.18.5)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.7MB 43.4MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 49.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.13.23)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (4.41.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (0.15.1)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.17.0,>=1.16.23 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (1.16.23)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.23->boto3->transformers==2.8.0) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.23->boto3->transformers==2.8.0) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=50e2390dd39e4b1be593344303d2727b128e16009bb51848c342d0fc389f77d7\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.5.2 transformers-2.8.0\n",
            "Cloning into 'electra'...\n",
            "remote: Enumerating objects: 104, done.\u001b[K\n",
            "remote: Total 104 (delta 0), reused 0 (delta 0), pack-reused 104\u001b[K\n",
            "Receiving objects: 100% (104/104), 95.45 KiB | 574.00 KiB/s, done.\n",
            "Resolving deltas: 100% (46/46), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwVUonN9juIU"
      },
      "source": [
        "import os\n",
        "import json\n",
        "from transformers import AutoTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNWDG4fac5DJ"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCGeCYwXOJZD"
      },
      "source": [
        "We will pre-train ELECTRA on a Spanish movie subtitle dataset retrieved from OpenSubtitles. This dataset is 5.4 GB in size and we will train on a small subset of ~30 MB for presentation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIJS29L1Pcv4"
      },
      "source": [
        "DATA_DIR = \"./data\" #@param {type: \"string\"}\n",
        "TRAIN_SIZE = 1000000 #@param {type:\"integer\"}\n",
        "MODEL_NAME = \"electra-spanish\" #@param {type: \"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqSykAtvfQ6-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c102a803-dbf5-4ee8-f0cd-f70ab23e800b"
      },
      "source": [
        "# Download and unzip the Spanish movie substitle dataset\n",
        "if not os.path.exists(DATA_DIR):\n",
        "  !mkdir -p $DATA_DIR\n",
        "  !wget \"https://object.pouta.csc.fi/OPUS-OpenSubtitles/v2016/mono/es.txt.gz\" -O $DATA_DIR/OpenSubtitles.txt.gz\n",
        "  !gzip -d $DATA_DIR/OpenSubtitles.txt.gz\n",
        "  !head -n $TRAIN_SIZE $DATA_DIR/OpenSubtitles.txt > $DATA_DIR/train_data.txt \n",
        "  !rm $DATA_DIR/OpenSubtitles.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-11 19:49:04--  https://object.pouta.csc.fi/OPUS-OpenSubtitles/v2016/mono/es.txt.gz\n",
            "Resolving object.pouta.csc.fi (object.pouta.csc.fi)... 86.50.254.18, 86.50.254.19\n",
            "Connecting to object.pouta.csc.fi (object.pouta.csc.fi)|86.50.254.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1859673728 (1.7G) [application/gzip]\n",
            "Saving to: â€˜./data/OpenSubtitles.txt.gzâ€™\n",
            "\n",
            "./data/OpenSubtitle 100%[===================>]   1.73G  71.9MB/s    in 25s     \n",
            "\n",
            "2020-06-11 19:49:30 (71.9 MB/s) - â€˜./data/OpenSubtitles.txt.gzâ€™ saved [1859673728/1859673728]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATU2mz_MQGPD"
      },
      "source": [
        "Before building the pre-training dataset, we should make sure the corpus has the following format:\n",
        "- each line is a sentence\n",
        "- a blank line separates two documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O40aslMjfXvW"
      },
      "source": [
        "### Build Pretraining Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHnGR1u2zv8r"
      },
      "source": [
        "We will use the tokenizer of `bert-base-multilingual-cased` to process Spanish texts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quw-oiRCf_xl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166,
          "referenced_widgets": [
            "e11b8a161c624fe19e09e2a6337fa49e",
            "f0a1e2bf315942508dc727b3573d8775",
            "c97308973177453bbbcfe76d39f10bde",
            "9f0c1401610942bfa31613b72cad8f3f",
            "a744a42897724a9ba47bb83d694aa16f",
            "f35d989d2f8f48458cd0c1c22159614b",
            "f463ffd8a96044f1b2c57fec99042877",
            "71415fb39ac84936a12a69368c0d0572",
            "c6e469843dfe4977ad6cbbe68db41b7c",
            "9ffee1a5bff34d3596800a53d666bea3",
            "aeb0448b527a447a96ec5a48a375f15d",
            "ff286e2fee8d4cffac3e4b17b4465ec1",
            "08c8fa39acd644e0a1a0e506832eeb86",
            "88abf1ac0af34839ac0002b2bbac351c",
            "4a9c8fc5ba6c41e2ace0d802f2493e07",
            "2de088388cb1417e8c08cc8ca74fd6c9"
          ]
        },
        "outputId": "825f4fd2-c500-47e7-9e7e-d840466af706"
      },
      "source": [
        "# Save the pretrained WordPiece tokenizer to get `vocab.txt`\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "tokenizer.save_pretrained(DATA_DIR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e11b8a161c624fe19e09e2a6337fa49e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6e469843dfe4977ad6cbbe68db41b7c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./data/vocab.txt',\n",
              " './data/special_tokens_map.json',\n",
              " './data/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27b8facRPvjv"
      },
      "source": [
        "We use `build_pretraining_dataset.py` to create a pre-training dataset from a dump of raw text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nM0rKREphcl7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "184cd9a9-015e-4db1-e6fd-ae2892421e78"
      },
      "source": [
        "!python3 electra/build_pretraining_dataset.py \\\n",
        "  --corpus-dir $DATA_DIR \\\n",
        "  --vocab-file $DATA_DIR/vocab.txt \\\n",
        "  --output-dir $DATA_DIR/pretrain_tfrecords \\\n",
        "  --max-seq-length 128 \\\n",
        "  --blanks-separate-docs False \\\n",
        "  --no-lower-case \\\n",
        "  --num-processes 5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Job 0: Creating example writer\n",
            "Job 1: Creating example writer\n",
            "Job 2: Creating example writer\n",
            "Job 3: Creating example writer\n",
            "Job 4: Creating example writer\n",
            "Job 1: Writing tf examples\n",
            "Job 1: Done!\n",
            "Job 0: Writing tf examples\n",
            "Job 0: Done!\n",
            "Job 3: Writing tf examples\n",
            "Job 2: Writing tf examples\n",
            "Job 2: Done!\n",
            "Job 4: Writing tf examples\n",
            "Job 4: Done!\n",
            "Job 3: Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yb3PQwU0jFEF"
      },
      "source": [
        "### Start Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1InjwsFRXeN"
      },
      "source": [
        "We use `run_pretraining.py` to pre-train an ELECTRA model.\n",
        "\n",
        "To train a small ELECTRA model for 1 million steps, run:\n",
        "\n",
        "```\n",
        "python3 run_pretraining.py --data-dir $DATA_DIR --model-name electra_small\n",
        "```\n",
        "\n",
        "This takes slightly over 4 days on a Tesla V100 GPU. However, the model should achieve decent results after 200k steps (10 hours of training on the v100 GPU).\n",
        "\n",
        "To customize the training, create a `.json` file containing the hyperparameters. Please refer [`configure_pretraining.py`](https://github.com/google-research/electra/blob/master/configure_pretraining.py) for default values of all hyperparameters.\n",
        "\n",
        "Below, we set the hyperparameters to train the model for only 100 steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LntOzQIopBzX"
      },
      "source": [
        "hparams = {\n",
        "    \"do_train\": \"true\",\n",
        "    \"do_eval\": \"false\",\n",
        "    \"model_size\": \"small\",\n",
        "    \"do_lower_case\": \"false\",\n",
        "    \"vocab_size\": 119547,\n",
        "    \"num_train_steps\": 100,\n",
        "    \"save_checkpoints_steps\": 100,\n",
        "    \"train_batch_size\": 32,\n",
        "}\n",
        "           \n",
        "with open(\"hparams.json\", \"w\") as f:\n",
        "    json.dump(hparams, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHskrniLXFQ8"
      },
      "source": [
        "Let's start training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjoPP5rrlAQj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "86c1bf26-8dd7-4c6a-a496-5c325d974103"
      },
      "source": [
        "!python3 electra/run_pretraining.py \\\n",
        "  --data-dir $DATA_DIR \\\n",
        "  --model-name $MODEL_NAME \\\n",
        "  --hparams \"hparams.json\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "Config:\n",
            "================================================================================\n",
            "debug False\n",
            "disallow_correct False\n",
            "disc_weight 50.0\n",
            "do_eval false\n",
            "do_lower_case false\n",
            "do_train true\n",
            "electra_objective True\n",
            "embedding_size 128\n",
            "eval_batch_size 128\n",
            "gcp_project None\n",
            "gen_weight 1.0\n",
            "generator_hidden_size 0.25\n",
            "generator_layers 1.0\n",
            "iterations_per_loop 200\n",
            "keep_checkpoint_max 5\n",
            "learning_rate 0.0005\n",
            "lr_decay_power 1.0\n",
            "mask_prob 0.15\n",
            "max_predictions_per_seq 19\n",
            "max_seq_length 128\n",
            "model_dir ./data/models/electra-spanish\n",
            "model_hparam_overrides {}\n",
            "model_name electra-spanish\n",
            "model_size small\n",
            "num_eval_steps 100\n",
            "num_tpu_cores 1\n",
            "num_train_steps 100\n",
            "num_warmup_steps 10000\n",
            "pretrain_tfrecords ./data/pretrain_tfrecords/pretrain_data.tfrecord*\n",
            "results_pkl ./data/models/electra-spanish/results/unsup_results.pkl\n",
            "results_txt ./data/models/electra-spanish/results/unsup_results.txt\n",
            "save_checkpoints_steps 100\n",
            "temperature 1.0\n",
            "tpu_job_name None\n",
            "tpu_name None\n",
            "tpu_zone None\n",
            "train_batch_size 32\n",
            "uniform_generator False\n",
            "untied_generator True\n",
            "untied_generator_embeddings False\n",
            "use_tpu False\n",
            "vocab_file ./data/vocab.txt\n",
            "vocab_size 119547\n",
            "weight_decay_rate 0.01\n",
            "\n",
            "================================================================================\n",
            "Running training\n",
            "================================================================================\n",
            "Model is built!\n",
            "2020-06-11 19:58:41.802603: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
            "2020-06-11 19:58:41.807311: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000185000 Hz\n",
            "2020-06-11 19:58:41.807544: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2a3fb80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-06-11 19:58:41.807575: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-06-11 19:58:41.809576: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-06-11 19:58:41.949517: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-11 19:58:41.950258: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2a3fd40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-06-11 19:58:41.950295: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-06-11 19:58:41.950502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-11 19:58:41.951073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-06-11 19:58:41.951444: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-06-11 19:58:41.952684: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-06-11 19:58:41.953835: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-06-11 19:58:41.954221: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-06-11 19:58:41.955607: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-06-11 19:58:41.956651: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-06-11 19:58:41.960010: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-06-11 19:58:41.960130: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-11 19:58:41.960715: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-11 19:58:41.961272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-06-11 19:58:41.961346: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-06-11 19:58:41.962510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-06-11 19:58:41.962539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-06-11 19:58:41.962550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-06-11 19:58:41.962672: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-11 19:58:41.963265: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-11 19:58:41.963816: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-06-11 19:58:41.963856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "2020-06-11 19:59:11.523172: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "1/100 = 1.0%, SPS: 0.1, ELAP: 12, ETA: 20:20 - loss: 44.5215\n",
            "2/100 = 2.0%, SPS: 0.1, ELAP: 24, ETA: 19:19 - loss: 44.6073\n",
            "3/100 = 3.0%, SPS: 0.1, ELAP: 24, ETA: 12:58 - loss: 44.4563\n",
            "4/100 = 4.0%, SPS: 0.2, ELAP: 24, ETA: 9:48 - loss: 44.1886\n",
            "5/100 = 5.0%, SPS: 0.2, ELAP: 25, ETA: 7:53 - loss: 44.1641\n",
            "6/100 = 6.0%, SPS: 0.2, ELAP: 25, ETA: 6:37 - loss: 44.1740\n",
            "7/100 = 7.0%, SPS: 0.3, ELAP: 26, ETA: 5:42 - loss: 43.8158\n",
            "8/100 = 8.0%, SPS: 0.3, ELAP: 26, ETA: 5:01 - loss: 43.7843\n",
            "9/100 = 9.0%, SPS: 0.3, ELAP: 27, ETA: 4:29 - loss: 43.5424\n",
            "10/100 = 10.0%, SPS: 0.4, ELAP: 27, ETA: 4:03 - loss: 43.4347\n",
            "11/100 = 11.0%, SPS: 0.4, ELAP: 27, ETA: 3:42 - loss: 43.1497\n",
            "12/100 = 12.0%, SPS: 0.4, ELAP: 28, ETA: 3:24 - loss: 42.9232\n",
            "13/100 = 13.0%, SPS: 0.5, ELAP: 28, ETA: 3:09 - loss: 42.8332\n",
            "14/100 = 14.0%, SPS: 0.5, ELAP: 29, ETA: 2:56 - loss: 42.5384\n",
            "15/100 = 15.0%, SPS: 0.5, ELAP: 29, ETA: 2:45 - loss: 42.4274\n",
            "16/100 = 16.0%, SPS: 0.5, ELAP: 29, ETA: 2:35 - loss: 41.7284\n",
            "17/100 = 17.0%, SPS: 0.6, ELAP: 30, ETA: 2:26 - loss: 41.5500\n",
            "18/100 = 18.0%, SPS: 0.6, ELAP: 30, ETA: 2:18 - loss: 41.2966\n",
            "19/100 = 19.0%, SPS: 0.6, ELAP: 31, ETA: 2:11 - loss: 41.2277\n",
            "20/100 = 20.0%, SPS: 0.6, ELAP: 31, ETA: 2:05 - loss: 40.8964\n",
            "21/100 = 21.0%, SPS: 0.7, ELAP: 32, ETA: 1:59 - loss: 40.3670\n",
            "22/100 = 22.0%, SPS: 0.7, ELAP: 32, ETA: 1:53 - loss: 40.1468\n",
            "23/100 = 23.0%, SPS: 0.7, ELAP: 32, ETA: 1:48 - loss: 39.6726\n",
            "24/100 = 24.0%, SPS: 0.7, ELAP: 33, ETA: 1:44 - loss: 39.4794\n",
            "25/100 = 25.0%, SPS: 0.8, ELAP: 33, ETA: 1:40 - loss: 39.0210\n",
            "26/100 = 26.0%, SPS: 0.8, ELAP: 34, ETA: 1:36 - loss: 38.5399\n",
            "27/100 = 27.0%, SPS: 0.8, ELAP: 34, ETA: 1:32 - loss: 38.2217\n",
            "28/100 = 28.0%, SPS: 0.8, ELAP: 34, ETA: 1:29 - loss: 37.6185\n",
            "29/100 = 29.0%, SPS: 0.8, ELAP: 35, ETA: 1:25 - loss: 37.6189\n",
            "30/100 = 30.0%, SPS: 0.8, ELAP: 35, ETA: 1:22 - loss: 37.2389\n",
            "31/100 = 31.0%, SPS: 0.9, ELAP: 36, ETA: 1:19 - loss: 37.2002\n",
            "32/100 = 32.0%, SPS: 0.9, ELAP: 36, ETA: 1:17 - loss: 36.6630\n",
            "33/100 = 33.0%, SPS: 0.9, ELAP: 37, ETA: 1:14 - loss: 36.5022\n",
            "34/100 = 34.0%, SPS: 0.9, ELAP: 37, ETA: 1:12 - loss: 36.0744\n",
            "35/100 = 35.0%, SPS: 0.9, ELAP: 37, ETA: 1:09 - loss: 35.4534\n",
            "36/100 = 36.0%, SPS: 1.0, ELAP: 38, ETA: 1:07 - loss: 35.4503\n",
            "37/100 = 37.0%, SPS: 1.0, ELAP: 38, ETA: 1:05 - loss: 35.2517\n",
            "38/100 = 38.0%, SPS: 1.0, ELAP: 39, ETA: 1:03 - loss: 34.8728\n",
            "39/100 = 39.0%, SPS: 1.0, ELAP: 39, ETA: 1:01 - loss: 34.5759\n",
            "40/100 = 40.0%, SPS: 1.0, ELAP: 39, ETA: 59 - loss: 34.7085\n",
            "41/100 = 41.0%, SPS: 1.0, ELAP: 40, ETA: 57 - loss: 34.2624\n",
            "42/100 = 42.0%, SPS: 1.0, ELAP: 40, ETA: 56 - loss: 33.9370\n",
            "43/100 = 43.0%, SPS: 1.1, ELAP: 41, ETA: 54 - loss: 33.6452\n",
            "44/100 = 44.0%, SPS: 1.1, ELAP: 41, ETA: 52 - loss: 33.3298\n",
            "45/100 = 45.0%, SPS: 1.1, ELAP: 42, ETA: 51 - loss: 33.3387\n",
            "46/100 = 46.0%, SPS: 1.1, ELAP: 42, ETA: 49 - loss: 33.1828\n",
            "47/100 = 47.0%, SPS: 1.1, ELAP: 42, ETA: 48 - loss: 33.0942\n",
            "48/100 = 48.0%, SPS: 1.1, ELAP: 43, ETA: 46 - loss: 32.6892\n",
            "49/100 = 49.0%, SPS: 1.1, ELAP: 43, ETA: 45 - loss: 32.5414\n",
            "50/100 = 50.0%, SPS: 1.1, ELAP: 44, ETA: 44 - loss: 32.5794\n",
            "51/100 = 51.0%, SPS: 1.2, ELAP: 44, ETA: 42 - loss: 32.4226\n",
            "52/100 = 52.0%, SPS: 1.2, ELAP: 44, ETA: 41 - loss: 32.3161\n",
            "53/100 = 53.0%, SPS: 1.2, ELAP: 45, ETA: 40 - loss: 32.0524\n",
            "54/100 = 54.0%, SPS: 1.2, ELAP: 45, ETA: 39 - loss: 32.1660\n",
            "55/100 = 55.0%, SPS: 1.2, ELAP: 46, ETA: 37 - loss: 32.1424\n",
            "56/100 = 56.0%, SPS: 1.2, ELAP: 46, ETA: 36 - loss: 31.8814\n",
            "57/100 = 57.0%, SPS: 1.2, ELAP: 47, ETA: 35 - loss: 31.7143\n",
            "58/100 = 58.0%, SPS: 1.2, ELAP: 47, ETA: 34 - loss: 31.8782\n",
            "59/100 = 59.0%, SPS: 1.2, ELAP: 47, ETA: 33 - loss: 31.6823\n",
            "60/100 = 60.0%, SPS: 1.3, ELAP: 48, ETA: 32 - loss: 31.8082\n",
            "61/100 = 61.0%, SPS: 1.3, ELAP: 48, ETA: 31 - loss: 31.7206\n",
            "62/100 = 62.0%, SPS: 1.3, ELAP: 49, ETA: 30 - loss: 31.4123\n",
            "63/100 = 63.0%, SPS: 1.3, ELAP: 49, ETA: 29 - loss: 31.4699\n",
            "64/100 = 64.0%, SPS: 1.3, ELAP: 50, ETA: 28 - loss: 31.6463\n",
            "65/100 = 65.0%, SPS: 1.3, ELAP: 50, ETA: 27 - loss: 31.8149\n",
            "66/100 = 66.0%, SPS: 1.3, ELAP: 50, ETA: 26 - loss: 31.4668\n",
            "67/100 = 67.0%, SPS: 1.3, ELAP: 51, ETA: 25 - loss: 31.8245\n",
            "68/100 = 68.0%, SPS: 1.3, ELAP: 51, ETA: 24 - loss: 31.6392\n",
            "69/100 = 69.0%, SPS: 1.3, ELAP: 52, ETA: 23 - loss: 31.6179\n",
            "70/100 = 70.0%, SPS: 1.3, ELAP: 52, ETA: 22 - loss: 31.4328\n",
            "71/100 = 71.0%, SPS: 1.4, ELAP: 52, ETA: 21 - loss: 31.6268\n",
            "72/100 = 72.0%, SPS: 1.4, ELAP: 53, ETA: 21 - loss: 31.6552\n",
            "73/100 = 73.0%, SPS: 1.4, ELAP: 53, ETA: 20 - loss: 31.3738\n",
            "74/100 = 74.0%, SPS: 1.4, ELAP: 54, ETA: 19 - loss: 31.8869\n",
            "75/100 = 75.0%, SPS: 1.4, ELAP: 54, ETA: 18 - loss: 31.4453\n",
            "76/100 = 76.0%, SPS: 1.4, ELAP: 55, ETA: 17 - loss: 31.1743\n",
            "77/100 = 77.0%, SPS: 1.4, ELAP: 55, ETA: 16 - loss: 31.4532\n",
            "78/100 = 78.0%, SPS: 1.4, ELAP: 55, ETA: 16 - loss: 31.3459\n",
            "79/100 = 79.0%, SPS: 1.4, ELAP: 56, ETA: 15 - loss: 31.4810\n",
            "80/100 = 80.0%, SPS: 1.4, ELAP: 56, ETA: 14 - loss: 31.4841\n",
            "81/100 = 81.0%, SPS: 1.4, ELAP: 57, ETA: 13 - loss: 31.5455\n",
            "82/100 = 82.0%, SPS: 1.4, ELAP: 57, ETA: 13 - loss: 31.5891\n",
            "83/100 = 83.0%, SPS: 1.4, ELAP: 57, ETA: 12 - loss: 31.4888\n",
            "84/100 = 84.0%, SPS: 1.5, ELAP: 58, ETA: 11 - loss: 31.5130\n",
            "85/100 = 85.0%, SPS: 1.5, ELAP: 58, ETA: 10 - loss: 31.4236\n",
            "86/100 = 86.0%, SPS: 1.5, ELAP: 59, ETA: 10 - loss: 31.6434\n",
            "87/100 = 87.0%, SPS: 1.5, ELAP: 59, ETA: 9 - loss: 31.4698\n",
            "88/100 = 88.0%, SPS: 1.5, ELAP: 1:00, ETA: 8 - loss: 31.5160\n",
            "89/100 = 89.0%, SPS: 1.5, ELAP: 1:00, ETA: 7 - loss: 31.8139\n",
            "90/100 = 90.0%, SPS: 1.5, ELAP: 1:00, ETA: 7 - loss: 31.2753\n",
            "91/100 = 91.0%, SPS: 1.5, ELAP: 1:01, ETA: 6 - loss: 31.4636\n",
            "92/100 = 92.0%, SPS: 1.5, ELAP: 1:01, ETA: 5 - loss: 31.6117\n",
            "93/100 = 93.0%, SPS: 1.5, ELAP: 1:02, ETA: 5 - loss: 31.3865\n",
            "94/100 = 94.0%, SPS: 1.5, ELAP: 1:02, ETA: 4 - loss: 31.4105\n",
            "95/100 = 95.0%, SPS: 1.5, ELAP: 1:03, ETA: 3 - loss: 31.7218\n",
            "96/100 = 96.0%, SPS: 1.5, ELAP: 1:03, ETA: 3 - loss: 31.4233\n",
            "97/100 = 97.0%, SPS: 1.5, ELAP: 1:03, ETA: 2 - loss: 31.5741\n",
            "98/100 = 98.0%, SPS: 1.5, ELAP: 1:04, ETA: 1 - loss: 31.2651\n",
            "99/100 = 99.0%, SPS: 1.5, ELAP: 1:04, ETA: 1 - loss: 31.1856\n",
            "100/100 = 100.0%, SPS: 1.5, ELAP: 1:07, ETA: 0 - loss: 31.4049\n",
            "100/100 = 100.0%, SPS: 1.5, ELAP: 1:07, ETA: 0\n",
            "================================================================================\n",
            "Running evaluation\n",
            "================================================================================\n",
            "Model is built!\n",
            "2020-06-11 20:00:12.539906: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-11 20:00:12.540394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-06-11 20:00:12.540515: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-06-11 20:00:12.540545: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-06-11 20:00:12.540570: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-06-11 20:00:12.540596: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-06-11 20:00:12.540618: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-06-11 20:00:12.540642: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-06-11 20:00:12.540667: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-06-11 20:00:12.540753: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-11 20:00:12.541167: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-11 20:00:12.541532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-06-11 20:00:12.541572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-06-11 20:00:12.541586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-06-11 20:00:12.541596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-06-11 20:00:12.541704: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-11 20:00:12.542140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-11 20:00:12.542531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "1/100 = 1.0%, SPS: 0.6, ELAP: 2, ETA: 3:00 - loss: 31.6430\n",
            "2/100 = 2.0%, SPS: 0.8, ELAP: 3, ETA: 2:07 - loss: 31.3903\n",
            "3/100 = 3.0%, SPS: 0.9, ELAP: 3, ETA: 1:49 - loss: 31.4452\n",
            "4/100 = 4.0%, SPS: 1.0, ELAP: 4, ETA: 1:40 - loss: 31.1587\n",
            "5/100 = 5.0%, SPS: 1.0, ELAP: 5, ETA: 1:34 - loss: 31.3817\n",
            "6/100 = 6.0%, SPS: 1.0, ELAP: 6, ETA: 1:30 - loss: 31.3262\n",
            "7/100 = 7.0%, SPS: 1.1, ELAP: 7, ETA: 1:26 - loss: 31.3267\n",
            "8/100 = 8.0%, SPS: 1.1, ELAP: 7, ETA: 1:24 - loss: 31.3488\n",
            "9/100 = 9.0%, SPS: 1.1, ELAP: 8, ETA: 1:22 - loss: 31.2048\n",
            "10/100 = 10.0%, SPS: 1.1, ELAP: 9, ETA: 1:20 - loss: 31.3682\n",
            "11/100 = 11.0%, SPS: 1.1, ELAP: 10, ETA: 1:18 - loss: 31.4079\n",
            "12/100 = 12.0%, SPS: 1.2, ELAP: 10, ETA: 1:16 - loss: 31.3681\n",
            "13/100 = 13.0%, SPS: 1.2, ELAP: 11, ETA: 1:15 - loss: 31.4021\n",
            "14/100 = 14.0%, SPS: 1.2, ELAP: 12, ETA: 1:14 - loss: 31.2928\n",
            "15/100 = 15.0%, SPS: 1.2, ELAP: 13, ETA: 1:12 - loss: 31.3125\n",
            "16/100 = 16.0%, SPS: 1.2, ELAP: 14, ETA: 1:11 - loss: 31.3690\n",
            "17/100 = 17.0%, SPS: 1.2, ELAP: 14, ETA: 1:10 - loss: 31.2370\n",
            "18/100 = 18.0%, SPS: 1.2, ELAP: 15, ETA: 1:09 - loss: 31.3646\n",
            "19/100 = 19.0%, SPS: 1.2, ELAP: 16, ETA: 1:08 - loss: 31.2909\n",
            "20/100 = 20.0%, SPS: 1.2, ELAP: 17, ETA: 1:07 - loss: 31.3656\n",
            "21/100 = 21.0%, SPS: 1.2, ELAP: 17, ETA: 1:06 - loss: 31.2302\n",
            "22/100 = 22.0%, SPS: 1.2, ELAP: 18, ETA: 1:05 - loss: 31.4770\n",
            "23/100 = 23.0%, SPS: 1.2, ELAP: 19, ETA: 1:04 - loss: 31.3651\n",
            "24/100 = 24.0%, SPS: 1.2, ELAP: 20, ETA: 1:03 - loss: 31.3731\n",
            "25/100 = 25.0%, SPS: 1.2, ELAP: 21, ETA: 1:02 - loss: 31.4175\n",
            "26/100 = 26.0%, SPS: 1.2, ELAP: 21, ETA: 1:01 - loss: 31.2371\n",
            "27/100 = 27.0%, SPS: 1.2, ELAP: 22, ETA: 1:00 - loss: 31.2095\n",
            "28/100 = 28.0%, SPS: 1.2, ELAP: 23, ETA: 59 - loss: 31.3616\n",
            "29/100 = 29.0%, SPS: 1.2, ELAP: 24, ETA: 58 - loss: 31.3938\n",
            "30/100 = 30.0%, SPS: 1.2, ELAP: 25, ETA: 57 - loss: 31.3747\n",
            "31/100 = 31.0%, SPS: 1.2, ELAP: 25, ETA: 56 - loss: 31.4303\n",
            "32/100 = 32.0%, SPS: 1.2, ELAP: 26, ETA: 56 - loss: 31.2491\n",
            "33/100 = 33.0%, SPS: 1.2, ELAP: 27, ETA: 55 - loss: 31.3821\n",
            "34/100 = 34.0%, SPS: 1.2, ELAP: 28, ETA: 54 - loss: 31.5747\n",
            "35/100 = 35.0%, SPS: 1.2, ELAP: 29, ETA: 53 - loss: 31.3489\n",
            "36/100 = 36.0%, SPS: 1.2, ELAP: 29, ETA: 52 - loss: 31.2885\n",
            "37/100 = 37.0%, SPS: 1.2, ELAP: 30, ETA: 51 - loss: 31.3520\n",
            "38/100 = 38.0%, SPS: 1.2, ELAP: 31, ETA: 50 - loss: 31.3287\n",
            "39/100 = 39.0%, SPS: 1.2, ELAP: 32, ETA: 50 - loss: 31.3144\n",
            "40/100 = 40.0%, SPS: 1.2, ELAP: 32, ETA: 49 - loss: 31.1548\n",
            "41/100 = 41.0%, SPS: 1.2, ELAP: 33, ETA: 48 - loss: 31.2494\n",
            "42/100 = 42.0%, SPS: 1.2, ELAP: 34, ETA: 47 - loss: 31.2715\n",
            "43/100 = 43.0%, SPS: 1.2, ELAP: 35, ETA: 46 - loss: 31.3421\n",
            "44/100 = 44.0%, SPS: 1.2, ELAP: 36, ETA: 45 - loss: 31.3793\n",
            "45/100 = 45.0%, SPS: 1.2, ELAP: 36, ETA: 45 - loss: 31.4719\n",
            "46/100 = 46.0%, SPS: 1.2, ELAP: 37, ETA: 44 - loss: 31.3930\n",
            "47/100 = 47.0%, SPS: 1.2, ELAP: 38, ETA: 43 - loss: 31.2300\n",
            "48/100 = 48.0%, SPS: 1.2, ELAP: 39, ETA: 42 - loss: 31.3565\n",
            "49/100 = 49.0%, SPS: 1.2, ELAP: 40, ETA: 41 - loss: 31.2705\n",
            "50/100 = 50.0%, SPS: 1.2, ELAP: 40, ETA: 40 - loss: 31.3525\n",
            "51/100 = 51.0%, SPS: 1.2, ELAP: 41, ETA: 40 - loss: 31.2257\n",
            "52/100 = 52.0%, SPS: 1.2, ELAP: 42, ETA: 39 - loss: 31.2440\n",
            "53/100 = 53.0%, SPS: 1.2, ELAP: 43, ETA: 38 - loss: 31.3988\n",
            "54/100 = 54.0%, SPS: 1.2, ELAP: 44, ETA: 37 - loss: 31.4200\n",
            "55/100 = 55.0%, SPS: 1.2, ELAP: 44, ETA: 36 - loss: 31.5069\n",
            "56/100 = 56.0%, SPS: 1.2, ELAP: 45, ETA: 36 - loss: 31.5065\n",
            "57/100 = 57.0%, SPS: 1.2, ELAP: 46, ETA: 35 - loss: 31.4055\n",
            "58/100 = 58.0%, SPS: 1.2, ELAP: 47, ETA: 34 - loss: 31.3401\n",
            "59/100 = 59.0%, SPS: 1.2, ELAP: 48, ETA: 33 - loss: 31.3814\n",
            "60/100 = 60.0%, SPS: 1.2, ELAP: 48, ETA: 32 - loss: 31.2524\n",
            "61/100 = 61.0%, SPS: 1.2, ELAP: 49, ETA: 31 - loss: 31.3021\n",
            "62/100 = 62.0%, SPS: 1.2, ELAP: 50, ETA: 31 - loss: 31.3574\n",
            "63/100 = 63.0%, SPS: 1.2, ELAP: 51, ETA: 30 - loss: 31.2381\n",
            "64/100 = 64.0%, SPS: 1.2, ELAP: 52, ETA: 29 - loss: 31.3165\n",
            "65/100 = 65.0%, SPS: 1.2, ELAP: 52, ETA: 28 - loss: 31.2940\n",
            "66/100 = 66.0%, SPS: 1.2, ELAP: 53, ETA: 27 - loss: 31.2981\n",
            "67/100 = 67.0%, SPS: 1.2, ELAP: 54, ETA: 27 - loss: 31.4411\n",
            "68/100 = 68.0%, SPS: 1.2, ELAP: 55, ETA: 26 - loss: 31.4202\n",
            "69/100 = 69.0%, SPS: 1.2, ELAP: 56, ETA: 25 - loss: 31.2063\n",
            "70/100 = 70.0%, SPS: 1.2, ELAP: 56, ETA: 24 - loss: 31.3240\n",
            "71/100 = 71.0%, SPS: 1.2, ELAP: 57, ETA: 23 - loss: 31.3489\n",
            "72/100 = 72.0%, SPS: 1.2, ELAP: 58, ETA: 23 - loss: 31.3642\n",
            "73/100 = 73.0%, SPS: 1.2, ELAP: 59, ETA: 22 - loss: 31.3774\n",
            "74/100 = 74.0%, SPS: 1.2, ELAP: 1:00, ETA: 21 - loss: 31.3782\n",
            "75/100 = 75.0%, SPS: 1.2, ELAP: 1:00, ETA: 20 - loss: 31.2378\n",
            "76/100 = 76.0%, SPS: 1.2, ELAP: 1:01, ETA: 19 - loss: 31.4264\n",
            "77/100 = 77.0%, SPS: 1.2, ELAP: 1:02, ETA: 19 - loss: 31.4639\n",
            "78/100 = 78.0%, SPS: 1.2, ELAP: 1:03, ETA: 18 - loss: 31.3288\n",
            "79/100 = 79.0%, SPS: 1.2, ELAP: 1:04, ETA: 17 - loss: 31.5887\n",
            "80/100 = 80.0%, SPS: 1.2, ELAP: 1:04, ETA: 16 - loss: 31.4192\n",
            "81/100 = 81.0%, SPS: 1.2, ELAP: 1:05, ETA: 15 - loss: 31.3186\n",
            "82/100 = 82.0%, SPS: 1.2, ELAP: 1:06, ETA: 15 - loss: 31.3438\n",
            "83/100 = 83.0%, SPS: 1.2, ELAP: 1:07, ETA: 14 - loss: 31.2641\n",
            "84/100 = 84.0%, SPS: 1.2, ELAP: 1:08, ETA: 13 - loss: 31.2983\n",
            "85/100 = 85.0%, SPS: 1.2, ELAP: 1:08, ETA: 12 - loss: 31.3115\n",
            "86/100 = 86.0%, SPS: 1.2, ELAP: 1:09, ETA: 11 - loss: 31.3484\n",
            "87/100 = 87.0%, SPS: 1.2, ELAP: 1:10, ETA: 10 - loss: 31.1415\n",
            "88/100 = 88.0%, SPS: 1.2, ELAP: 1:11, ETA: 10 - loss: 31.3516\n",
            "89/100 = 89.0%, SPS: 1.2, ELAP: 1:12, ETA: 9 - loss: 31.5588\n",
            "90/100 = 90.0%, SPS: 1.2, ELAP: 1:13, ETA: 8 - loss: 31.3156\n",
            "91/100 = 91.0%, SPS: 1.2, ELAP: 1:13, ETA: 7 - loss: 31.3847\n",
            "92/100 = 92.0%, SPS: 1.2, ELAP: 1:14, ETA: 6 - loss: 31.3112\n",
            "93/100 = 93.0%, SPS: 1.2, ELAP: 1:15, ETA: 6 - loss: 31.3240\n",
            "94/100 = 94.0%, SPS: 1.2, ELAP: 1:16, ETA: 5 - loss: 31.3320\n",
            "95/100 = 95.0%, SPS: 1.2, ELAP: 1:17, ETA: 4 - loss: 31.3780\n",
            "96/100 = 96.0%, SPS: 1.2, ELAP: 1:17, ETA: 3 - loss: 31.3720\n",
            "97/100 = 97.0%, SPS: 1.2, ELAP: 1:18, ETA: 2 - loss: 31.3384\n",
            "98/100 = 98.0%, SPS: 1.2, ELAP: 1:19, ETA: 2 - loss: 31.4253\n",
            "99/100 = 99.0%, SPS: 1.2, ELAP: 1:20, ETA: 1 - loss: 31.4571\n",
            "100/100 = 100.0%, SPS: 1.2, ELAP: 1:21, ETA: 0 - loss: 31.6313\n",
            "100/100 = 100.0%, SPS: 1.2, ELAP: 1:21, ETA: 0\n",
            "  disc_accuracy = 0.8616748\n",
            "  disc_auc = 0.62998134\n",
            "  disc_loss = 0.3935465\n",
            "  disc_precision = 0.0\n",
            "  disc_recall = 0.0\n",
            "  global_step = 100\n",
            "  loss = 31.352026\n",
            "  masked_lm_accuracy = 0.0\n",
            "  masked_lm_loss = 11.678689\n",
            "  sampled_masked_lm_accuracy = 1.6795291e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVfMwezaTZQc"
      },
      "source": [
        "If you are training on a virtual machine, run the following lines on the terminal to moniter the training process with TensorBoard.\n",
        "\n",
        "```\n",
        "pip install -U tensorboard\n",
        "tensorboard dev upload --logdir data/models/electra-spanish\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IdyWDK7Yh7a"
      },
      "source": [
        "This is the [TensorBoard](https://tensorboard.dev/experiment/AmaGBV3RTGOB1leXGGsJmw/#scalars) of training ELECTRA-small for 1 million steps in 4 days on a V100 GPU.\n",
        "\n",
        "![](https://github.com/chriskhanhtran/spanish-bert/blob/master/img/electra-tensorboard.JPG?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU4uE_LxXVOa"
      },
      "source": [
        "## 4. Convert Tensorflow checkpoints to PyTorch format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJfzThSQySKD"
      },
      "source": [
        "Hugging Face has [a tool](https://huggingface.co/transformers/converting_tensorflow_models.html) to convert Tensorflow checkpoints to PyTorch. However, this tool has yet been updated for ELECTRA. Fortunately, I found a GitHub repo by @lonePatient that can help us with this task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtnLZBugZTMY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "9d5ca28c-feeb-4f26-829f-3f3376477bb2"
      },
      "source": [
        "!git clone https://github.com/lonePatient/electra_pytorch.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'electra_pytorch'...\n",
            "remote: Enumerating objects: 191, done.\u001b[K\n",
            "remote: Counting objects: 100% (191/191), done.\u001b[K\n",
            "remote: Compressing objects: 100% (141/141), done.\u001b[K\n",
            "remote: Total 191 (delta 88), reused 124 (delta 46), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (191/191), 402.65 KiB | 1.27 MiB/s, done.\n",
            "Resolving deltas: 100% (88/88), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZGvNz-w0fXi"
      },
      "source": [
        "MODEL_DIR = \"data/models/electra-spanish/\"\n",
        "\n",
        "config = {\n",
        "  \"vocab_size\": 119547,\n",
        "  \"embedding_size\": 128,\n",
        "  \"hidden_size\": 256,\n",
        "  \"num_hidden_layers\": 12,\n",
        "  \"num_attention_heads\": 4,\n",
        "  \"intermediate_size\": 1024,\n",
        "  \"generator_size\":\"0.25\",\n",
        "  \"hidden_act\": \"gelu\",\n",
        "  \"hidden_dropout_prob\": 0.1,\n",
        "  \"attention_probs_dropout_prob\": 0.1,\n",
        "  \"max_position_embeddings\": 512,\n",
        "  \"type_vocab_size\": 2,\n",
        "  \"initializer_range\": 0.02\n",
        "}\n",
        "\n",
        "with open(MODEL_DIR + \"config.json\", \"w\") as f:\n",
        "    json.dump(config, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XazVpTLltlrp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "88340239-e203-4c80-df40-ae8865375a8a"
      },
      "source": [
        "!python electra_pytorch/convert_electra_tf_checkpoint_to_pytorch.py \\\n",
        "    --tf_checkpoint_path=$MODEL_DIR \\\n",
        "    --electra_config_file=$MODEL_DIR/config.json \\\n",
        "    --pytorch_dump_path=$MODEL_DIR/pytorch_model.bin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:model.configuration_utils:loading configuration file data/models/electra-spanish//config.json\n",
            "INFO:model.configuration_utils:Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"embedding_size\": 128,\n",
            "  \"finetuning_task\": null,\n",
            "  \"generator_size\": \"0.25\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 1024,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 4,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n",
            "INFO:model.modeling_electra:Converting TensorFlow checkpoint from /content/data/models/electra-spanish\n",
            "INFO:model.modeling_electra:Loading TF weight discriminator_predictions/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight discriminator_predictions/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight discriminator_predictions/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight discriminator_predictions/dense/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight discriminator_predictions/dense/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight discriminator_predictions/dense/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight discriminator_predictions/dense_1/bias with shape [1]\n",
            "INFO:model.modeling_electra:Loading TF weight discriminator_predictions/dense_1/bias/adam_m with shape [1]\n",
            "INFO:model.modeling_electra:Loading TF weight discriminator_predictions/dense_1/bias/adam_v with shape [1]\n",
            "INFO:model.modeling_electra:Loading TF weight discriminator_predictions/dense_1/kernel with shape [256, 1]\n",
            "INFO:model.modeling_electra:Loading TF weight discriminator_predictions/dense_1/kernel/adam_m with shape [256, 1]\n",
            "INFO:model.modeling_electra:Loading TF weight discriminator_predictions/dense_1/kernel/adam_v with shape [256, 1]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/embeddings/LayerNorm/beta with shape [128]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/embeddings/LayerNorm/beta/adam_m with shape [128]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/embeddings/LayerNorm/beta/adam_v with shape [128]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/embeddings/LayerNorm/gamma with shape [128]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/embeddings/LayerNorm/gamma/adam_m with shape [128]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/embeddings/LayerNorm/gamma/adam_v with shape [128]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/embeddings/position_embeddings with shape [512, 128]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/embeddings/position_embeddings/adam_m with shape [512, 128]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/embeddings/position_embeddings/adam_v with shape [512, 128]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/embeddings/token_type_embeddings with shape [2, 128]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/embeddings/token_type_embeddings/adam_m with shape [2, 128]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/embeddings/token_type_embeddings/adam_v with shape [2, 128]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/embeddings/word_embeddings with shape [119547, 128]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/embeddings/word_embeddings/adam_m with shape [119547, 128]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/embeddings/word_embeddings/adam_v with shape [119547, 128]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/embeddings_project/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/embeddings_project/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/embeddings_project/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/embeddings_project/kernel with shape [128, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/embeddings_project/kernel/adam_m with shape [128, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/embeddings_project/kernel/adam_v with shape [128, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/attention/output/LayerNorm/beta with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/attention/output/LayerNorm/beta/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/attention/output/LayerNorm/beta/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/attention/output/LayerNorm/gamma with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/attention/output/LayerNorm/gamma/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/attention/output/LayerNorm/gamma/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/attention/output/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/attention/output/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/attention/output/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/attention/output/dense/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/attention/output/dense/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/attention/output/dense/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/attention/self/key/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/attention/self/key/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/attention/self/key/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/attention/self/key/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/attention/self/key/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/attention/self/key/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/attention/self/query/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/attention/self/query/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/attention/self/query/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/attention/self/query/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/attention/self/query/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/attention/self/query/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/attention/self/value/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/attention/self/value/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/attention/self/value/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/attention/self/value/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/attention/self/value/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/attention/self/value/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/intermediate/dense/bias with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/intermediate/dense/bias/adam_m with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/intermediate/dense/bias/adam_v with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/intermediate/dense/kernel with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/intermediate/dense/kernel/adam_m with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/intermediate/dense/kernel/adam_v with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/output/LayerNorm/beta with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/output/LayerNorm/beta/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/output/LayerNorm/beta/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/output/LayerNorm/gamma with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/output/LayerNorm/gamma/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/output/LayerNorm/gamma/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/output/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/output/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/output/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/output/dense/kernel with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/output/dense/kernel/adam_m with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_0/output/dense/kernel/adam_v with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/attention/output/LayerNorm/beta with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/attention/output/LayerNorm/beta/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/attention/output/LayerNorm/beta/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/attention/output/LayerNorm/gamma with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/attention/output/LayerNorm/gamma/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/attention/output/LayerNorm/gamma/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/attention/output/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/attention/output/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/attention/output/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/attention/output/dense/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/attention/output/dense/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/attention/output/dense/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/attention/self/key/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/attention/self/key/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/attention/self/key/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/attention/self/key/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/attention/self/key/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/attention/self/key/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/attention/self/query/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/attention/self/query/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/attention/self/query/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/attention/self/query/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/attention/self/query/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/attention/self/query/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/attention/self/value/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/attention/self/value/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/attention/self/value/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/attention/self/value/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/attention/self/value/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/attention/self/value/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/intermediate/dense/bias with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/intermediate/dense/bias/adam_m with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/intermediate/dense/bias/adam_v with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/intermediate/dense/kernel with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/intermediate/dense/kernel/adam_m with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/intermediate/dense/kernel/adam_v with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/output/LayerNorm/beta with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/output/LayerNorm/beta/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/output/LayerNorm/beta/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/output/LayerNorm/gamma with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/output/LayerNorm/gamma/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/output/LayerNorm/gamma/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/output/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/output/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/output/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/output/dense/kernel with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/output/dense/kernel/adam_m with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_1/output/dense/kernel/adam_v with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/attention/output/LayerNorm/beta with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/attention/output/LayerNorm/beta/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/attention/output/LayerNorm/beta/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/attention/output/LayerNorm/gamma with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/attention/output/LayerNorm/gamma/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/attention/output/LayerNorm/gamma/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/attention/output/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/attention/output/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/attention/output/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/attention/output/dense/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/attention/output/dense/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/attention/output/dense/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/attention/self/key/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/attention/self/key/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/attention/self/key/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/attention/self/key/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/attention/self/key/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/attention/self/key/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/attention/self/query/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/attention/self/query/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/attention/self/query/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/attention/self/query/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/attention/self/query/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/attention/self/query/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/attention/self/value/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/attention/self/value/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/attention/self/value/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/attention/self/value/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/attention/self/value/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/attention/self/value/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/intermediate/dense/bias with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/intermediate/dense/bias/adam_m with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/intermediate/dense/bias/adam_v with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/intermediate/dense/kernel with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/intermediate/dense/kernel/adam_m with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/intermediate/dense/kernel/adam_v with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/output/LayerNorm/beta with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/output/LayerNorm/beta/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/output/LayerNorm/beta/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/output/LayerNorm/gamma with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/output/LayerNorm/gamma/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/output/LayerNorm/gamma/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/output/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/output/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/output/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/output/dense/kernel with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/output/dense/kernel/adam_m with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_10/output/dense/kernel/adam_v with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/attention/output/LayerNorm/beta with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/attention/output/LayerNorm/beta/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/attention/output/LayerNorm/beta/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/attention/output/LayerNorm/gamma with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/attention/output/LayerNorm/gamma/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/attention/output/LayerNorm/gamma/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/attention/output/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/attention/output/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/attention/output/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/attention/output/dense/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/attention/output/dense/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/attention/output/dense/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/attention/self/key/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/attention/self/key/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/attention/self/key/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/attention/self/key/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/attention/self/key/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/attention/self/key/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/attention/self/query/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/attention/self/query/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/attention/self/query/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/attention/self/query/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/attention/self/query/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/attention/self/query/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/attention/self/value/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/attention/self/value/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/attention/self/value/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/attention/self/value/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/attention/self/value/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/attention/self/value/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/intermediate/dense/bias with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/intermediate/dense/bias/adam_m with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/intermediate/dense/bias/adam_v with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/intermediate/dense/kernel with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/intermediate/dense/kernel/adam_m with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/intermediate/dense/kernel/adam_v with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/output/LayerNorm/beta with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/output/LayerNorm/beta/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/output/LayerNorm/beta/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/output/LayerNorm/gamma with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/output/LayerNorm/gamma/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/output/LayerNorm/gamma/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/output/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/output/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/output/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/output/dense/kernel with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/output/dense/kernel/adam_m with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_11/output/dense/kernel/adam_v with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/attention/output/LayerNorm/beta with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/attention/output/LayerNorm/beta/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/attention/output/LayerNorm/beta/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/attention/output/LayerNorm/gamma with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/attention/output/LayerNorm/gamma/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/attention/output/LayerNorm/gamma/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/attention/output/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/attention/output/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/attention/output/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/attention/output/dense/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/attention/output/dense/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/attention/output/dense/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/attention/self/key/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/attention/self/key/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/attention/self/key/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/attention/self/key/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/attention/self/key/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/attention/self/key/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/attention/self/query/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/attention/self/query/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/attention/self/query/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/attention/self/query/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/attention/self/query/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/attention/self/query/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/attention/self/value/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/attention/self/value/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/attention/self/value/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/attention/self/value/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/attention/self/value/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/attention/self/value/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/intermediate/dense/bias with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/intermediate/dense/bias/adam_m with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/intermediate/dense/bias/adam_v with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/intermediate/dense/kernel with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/intermediate/dense/kernel/adam_m with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/intermediate/dense/kernel/adam_v with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/output/LayerNorm/beta with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/output/LayerNorm/beta/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/output/LayerNorm/beta/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/output/LayerNorm/gamma with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/output/LayerNorm/gamma/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/output/LayerNorm/gamma/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/output/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/output/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/output/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/output/dense/kernel with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/output/dense/kernel/adam_m with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_2/output/dense/kernel/adam_v with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/attention/output/LayerNorm/beta with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/attention/output/LayerNorm/beta/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/attention/output/LayerNorm/beta/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/attention/output/LayerNorm/gamma with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/attention/output/LayerNorm/gamma/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/attention/output/LayerNorm/gamma/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/attention/output/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/attention/output/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/attention/output/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/attention/output/dense/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/attention/output/dense/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/attention/output/dense/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/attention/self/key/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/attention/self/key/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/attention/self/key/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/attention/self/key/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/attention/self/key/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/attention/self/key/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/attention/self/query/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/attention/self/query/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/attention/self/query/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/attention/self/query/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/attention/self/query/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/attention/self/query/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/attention/self/value/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/attention/self/value/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/attention/self/value/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/attention/self/value/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/attention/self/value/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/attention/self/value/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/intermediate/dense/bias with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/intermediate/dense/bias/adam_m with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/intermediate/dense/bias/adam_v with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/intermediate/dense/kernel with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/intermediate/dense/kernel/adam_m with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/intermediate/dense/kernel/adam_v with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/output/LayerNorm/beta with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/output/LayerNorm/beta/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/output/LayerNorm/beta/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/output/LayerNorm/gamma with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/output/LayerNorm/gamma/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/output/LayerNorm/gamma/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/output/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/output/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/output/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/output/dense/kernel with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/output/dense/kernel/adam_m with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_3/output/dense/kernel/adam_v with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/attention/output/LayerNorm/beta with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/attention/output/LayerNorm/beta/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/attention/output/LayerNorm/beta/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/attention/output/LayerNorm/gamma with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/attention/output/LayerNorm/gamma/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/attention/output/LayerNorm/gamma/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/attention/output/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/attention/output/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/attention/output/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/attention/output/dense/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/attention/output/dense/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/attention/output/dense/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/attention/self/key/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/attention/self/key/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/attention/self/key/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/attention/self/key/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/attention/self/key/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/attention/self/key/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/attention/self/query/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/attention/self/query/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/attention/self/query/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/attention/self/query/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/attention/self/query/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/attention/self/query/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/attention/self/value/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/attention/self/value/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/attention/self/value/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/attention/self/value/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/attention/self/value/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/attention/self/value/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/intermediate/dense/bias with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/intermediate/dense/bias/adam_m with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/intermediate/dense/bias/adam_v with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/intermediate/dense/kernel with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/intermediate/dense/kernel/adam_m with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/intermediate/dense/kernel/adam_v with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/output/LayerNorm/beta with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/output/LayerNorm/beta/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/output/LayerNorm/beta/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/output/LayerNorm/gamma with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/output/LayerNorm/gamma/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/output/LayerNorm/gamma/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/output/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/output/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/output/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/output/dense/kernel with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/output/dense/kernel/adam_m with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_4/output/dense/kernel/adam_v with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/attention/output/LayerNorm/beta with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/attention/output/LayerNorm/beta/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/attention/output/LayerNorm/beta/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/attention/output/LayerNorm/gamma with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/attention/output/LayerNorm/gamma/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/attention/output/LayerNorm/gamma/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/attention/output/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/attention/output/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/attention/output/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/attention/output/dense/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/attention/output/dense/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/attention/output/dense/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/attention/self/key/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/attention/self/key/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/attention/self/key/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/attention/self/key/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/attention/self/key/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/attention/self/key/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/attention/self/query/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/attention/self/query/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/attention/self/query/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/attention/self/query/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/attention/self/query/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/attention/self/query/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/attention/self/value/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/attention/self/value/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/attention/self/value/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/attention/self/value/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/attention/self/value/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/attention/self/value/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/intermediate/dense/bias with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/intermediate/dense/bias/adam_m with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/intermediate/dense/bias/adam_v with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/intermediate/dense/kernel with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/intermediate/dense/kernel/adam_m with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/intermediate/dense/kernel/adam_v with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/output/LayerNorm/beta with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/output/LayerNorm/beta/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/output/LayerNorm/beta/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/output/LayerNorm/gamma with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/output/LayerNorm/gamma/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/output/LayerNorm/gamma/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/output/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/output/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/output/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/output/dense/kernel with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/output/dense/kernel/adam_m with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_5/output/dense/kernel/adam_v with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/attention/output/LayerNorm/beta with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/attention/output/LayerNorm/beta/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/attention/output/LayerNorm/beta/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/attention/output/LayerNorm/gamma with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/attention/output/LayerNorm/gamma/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/attention/output/LayerNorm/gamma/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/attention/output/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/attention/output/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/attention/output/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/attention/output/dense/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/attention/output/dense/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/attention/output/dense/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/attention/self/key/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/attention/self/key/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/attention/self/key/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/attention/self/key/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/attention/self/key/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/attention/self/key/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/attention/self/query/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/attention/self/query/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/attention/self/query/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/attention/self/query/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/attention/self/query/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/attention/self/query/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/attention/self/value/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/attention/self/value/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/attention/self/value/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/attention/self/value/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/attention/self/value/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/attention/self/value/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/intermediate/dense/bias with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/intermediate/dense/bias/adam_m with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/intermediate/dense/bias/adam_v with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/intermediate/dense/kernel with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/intermediate/dense/kernel/adam_m with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/intermediate/dense/kernel/adam_v with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/output/LayerNorm/beta with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/output/LayerNorm/beta/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/output/LayerNorm/beta/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/output/LayerNorm/gamma with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/output/LayerNorm/gamma/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/output/LayerNorm/gamma/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/output/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/output/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/output/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/output/dense/kernel with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/output/dense/kernel/adam_m with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_6/output/dense/kernel/adam_v with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/attention/output/LayerNorm/beta with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/attention/output/LayerNorm/beta/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/attention/output/LayerNorm/beta/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/attention/output/LayerNorm/gamma with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/attention/output/LayerNorm/gamma/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/attention/output/LayerNorm/gamma/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/attention/output/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/attention/output/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/attention/output/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/attention/output/dense/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/attention/output/dense/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/attention/output/dense/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/attention/self/key/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/attention/self/key/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/attention/self/key/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/attention/self/key/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/attention/self/key/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/attention/self/key/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/attention/self/query/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/attention/self/query/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/attention/self/query/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/attention/self/query/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/attention/self/query/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/attention/self/query/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/attention/self/value/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/attention/self/value/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/attention/self/value/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/attention/self/value/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/attention/self/value/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/attention/self/value/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/intermediate/dense/bias with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/intermediate/dense/bias/adam_m with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/intermediate/dense/bias/adam_v with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/intermediate/dense/kernel with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/intermediate/dense/kernel/adam_m with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/intermediate/dense/kernel/adam_v with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/output/LayerNorm/beta with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/output/LayerNorm/beta/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/output/LayerNorm/beta/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/output/LayerNorm/gamma with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/output/LayerNorm/gamma/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/output/LayerNorm/gamma/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/output/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/output/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/output/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/output/dense/kernel with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/output/dense/kernel/adam_m with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_7/output/dense/kernel/adam_v with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/attention/output/LayerNorm/beta with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/attention/output/LayerNorm/beta/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/attention/output/LayerNorm/beta/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/attention/output/LayerNorm/gamma with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/attention/output/LayerNorm/gamma/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/attention/output/LayerNorm/gamma/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/attention/output/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/attention/output/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/attention/output/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/attention/output/dense/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/attention/output/dense/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/attention/output/dense/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/attention/self/key/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/attention/self/key/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/attention/self/key/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/attention/self/key/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/attention/self/key/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/attention/self/key/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/attention/self/query/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/attention/self/query/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/attention/self/query/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/attention/self/query/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/attention/self/query/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/attention/self/query/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/attention/self/value/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/attention/self/value/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/attention/self/value/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/attention/self/value/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/attention/self/value/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/attention/self/value/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/intermediate/dense/bias with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/intermediate/dense/bias/adam_m with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/intermediate/dense/bias/adam_v with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/intermediate/dense/kernel with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/intermediate/dense/kernel/adam_m with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/intermediate/dense/kernel/adam_v with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/output/LayerNorm/beta with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/output/LayerNorm/beta/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/output/LayerNorm/beta/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/output/LayerNorm/gamma with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/output/LayerNorm/gamma/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/output/LayerNorm/gamma/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/output/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/output/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/output/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/output/dense/kernel with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/output/dense/kernel/adam_m with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_8/output/dense/kernel/adam_v with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/attention/output/LayerNorm/beta with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/attention/output/LayerNorm/beta/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/attention/output/LayerNorm/beta/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/attention/output/LayerNorm/gamma with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/attention/output/LayerNorm/gamma/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/attention/output/LayerNorm/gamma/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/attention/output/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/attention/output/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/attention/output/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/attention/output/dense/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/attention/output/dense/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/attention/output/dense/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/attention/self/key/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/attention/self/key/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/attention/self/key/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/attention/self/key/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/attention/self/key/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/attention/self/key/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/attention/self/query/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/attention/self/query/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/attention/self/query/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/attention/self/query/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/attention/self/query/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/attention/self/query/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/attention/self/value/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/attention/self/value/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/attention/self/value/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/attention/self/value/kernel with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/attention/self/value/kernel/adam_m with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/attention/self/value/kernel/adam_v with shape [256, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/intermediate/dense/bias with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/intermediate/dense/bias/adam_m with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/intermediate/dense/bias/adam_v with shape [1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/intermediate/dense/kernel with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/intermediate/dense/kernel/adam_m with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/intermediate/dense/kernel/adam_v with shape [256, 1024]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/output/LayerNorm/beta with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/output/LayerNorm/beta/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/output/LayerNorm/beta/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/output/LayerNorm/gamma with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/output/LayerNorm/gamma/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/output/LayerNorm/gamma/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/output/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/output/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/output/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/output/dense/kernel with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/output/dense/kernel/adam_m with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight electra/encoder/layer_9/output/dense/kernel/adam_v with shape [1024, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/embeddings_project/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/embeddings_project/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/embeddings_project/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/embeddings_project/kernel with shape [128, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/embeddings_project/kernel/adam_m with shape [128, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/embeddings_project/kernel/adam_v with shape [128, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/attention/output/LayerNorm/beta with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/attention/output/LayerNorm/beta/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/attention/output/LayerNorm/beta/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/attention/output/LayerNorm/gamma with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/attention/output/LayerNorm/gamma/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/attention/output/LayerNorm/gamma/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/attention/output/dense/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/attention/output/dense/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/attention/output/dense/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/attention/output/dense/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/attention/output/dense/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/attention/output/dense/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/attention/self/key/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/attention/self/key/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/attention/self/key/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/attention/self/key/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/attention/self/key/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/attention/self/key/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/attention/self/query/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/attention/self/query/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/attention/self/query/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/attention/self/query/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/attention/self/query/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/attention/self/query/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/attention/self/value/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/attention/self/value/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/attention/self/value/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/attention/self/value/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/attention/self/value/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/attention/self/value/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/intermediate/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/intermediate/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/intermediate/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/intermediate/dense/kernel with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/intermediate/dense/kernel/adam_m with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/intermediate/dense/kernel/adam_v with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/output/LayerNorm/beta with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/output/LayerNorm/beta/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/output/LayerNorm/beta/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/output/LayerNorm/gamma with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/output/LayerNorm/gamma/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/output/LayerNorm/gamma/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/output/dense/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/output/dense/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/output/dense/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/output/dense/kernel with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/output/dense/kernel/adam_m with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_0/output/dense/kernel/adam_v with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/attention/output/LayerNorm/beta with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/attention/output/LayerNorm/beta/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/attention/output/LayerNorm/beta/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/attention/output/LayerNorm/gamma with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/attention/output/LayerNorm/gamma/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/attention/output/LayerNorm/gamma/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/attention/output/dense/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/attention/output/dense/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/attention/output/dense/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/attention/output/dense/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/attention/output/dense/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/attention/output/dense/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/attention/self/key/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/attention/self/key/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/attention/self/key/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/attention/self/key/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/attention/self/key/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/attention/self/key/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/attention/self/query/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/attention/self/query/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/attention/self/query/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/attention/self/query/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/attention/self/query/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/attention/self/query/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/attention/self/value/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/attention/self/value/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/attention/self/value/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/attention/self/value/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/attention/self/value/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/attention/self/value/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/intermediate/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/intermediate/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/intermediate/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/intermediate/dense/kernel with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/intermediate/dense/kernel/adam_m with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/intermediate/dense/kernel/adam_v with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/output/LayerNorm/beta with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/output/LayerNorm/beta/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/output/LayerNorm/beta/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/output/LayerNorm/gamma with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/output/LayerNorm/gamma/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/output/LayerNorm/gamma/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/output/dense/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/output/dense/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/output/dense/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/output/dense/kernel with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/output/dense/kernel/adam_m with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_1/output/dense/kernel/adam_v with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/attention/output/LayerNorm/beta with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/attention/output/LayerNorm/beta/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/attention/output/LayerNorm/beta/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/attention/output/LayerNorm/gamma with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/attention/output/LayerNorm/gamma/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/attention/output/LayerNorm/gamma/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/attention/output/dense/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/attention/output/dense/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/attention/output/dense/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/attention/output/dense/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/attention/output/dense/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/attention/output/dense/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/attention/self/key/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/attention/self/key/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/attention/self/key/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/attention/self/key/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/attention/self/key/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/attention/self/key/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/attention/self/query/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/attention/self/query/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/attention/self/query/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/attention/self/query/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/attention/self/query/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/attention/self/query/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/attention/self/value/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/attention/self/value/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/attention/self/value/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/attention/self/value/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/attention/self/value/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/attention/self/value/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/intermediate/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/intermediate/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/intermediate/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/intermediate/dense/kernel with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/intermediate/dense/kernel/adam_m with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/intermediate/dense/kernel/adam_v with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/output/LayerNorm/beta with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/output/LayerNorm/beta/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/output/LayerNorm/beta/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/output/LayerNorm/gamma with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/output/LayerNorm/gamma/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/output/LayerNorm/gamma/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/output/dense/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/output/dense/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/output/dense/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/output/dense/kernel with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/output/dense/kernel/adam_m with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_10/output/dense/kernel/adam_v with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/attention/output/LayerNorm/beta with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/attention/output/LayerNorm/beta/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/attention/output/LayerNorm/beta/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/attention/output/LayerNorm/gamma with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/attention/output/LayerNorm/gamma/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/attention/output/LayerNorm/gamma/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/attention/output/dense/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/attention/output/dense/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/attention/output/dense/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/attention/output/dense/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/attention/output/dense/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/attention/output/dense/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/attention/self/key/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/attention/self/key/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/attention/self/key/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/attention/self/key/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/attention/self/key/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/attention/self/key/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/attention/self/query/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/attention/self/query/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/attention/self/query/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/attention/self/query/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/attention/self/query/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/attention/self/query/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/attention/self/value/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/attention/self/value/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/attention/self/value/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/attention/self/value/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/attention/self/value/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/attention/self/value/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/intermediate/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/intermediate/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/intermediate/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/intermediate/dense/kernel with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/intermediate/dense/kernel/adam_m with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/intermediate/dense/kernel/adam_v with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/output/LayerNorm/beta with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/output/LayerNorm/beta/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/output/LayerNorm/beta/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/output/LayerNorm/gamma with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/output/LayerNorm/gamma/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/output/LayerNorm/gamma/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/output/dense/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/output/dense/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/output/dense/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/output/dense/kernel with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/output/dense/kernel/adam_m with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_11/output/dense/kernel/adam_v with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/attention/output/LayerNorm/beta with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/attention/output/LayerNorm/beta/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/attention/output/LayerNorm/beta/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/attention/output/LayerNorm/gamma with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/attention/output/LayerNorm/gamma/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/attention/output/LayerNorm/gamma/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/attention/output/dense/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/attention/output/dense/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/attention/output/dense/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/attention/output/dense/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/attention/output/dense/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/attention/output/dense/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/attention/self/key/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/attention/self/key/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/attention/self/key/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/attention/self/key/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/attention/self/key/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/attention/self/key/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/attention/self/query/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/attention/self/query/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/attention/self/query/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/attention/self/query/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/attention/self/query/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/attention/self/query/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/attention/self/value/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/attention/self/value/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/attention/self/value/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/attention/self/value/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/attention/self/value/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/attention/self/value/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/intermediate/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/intermediate/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/intermediate/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/intermediate/dense/kernel with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/intermediate/dense/kernel/adam_m with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/intermediate/dense/kernel/adam_v with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/output/LayerNorm/beta with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/output/LayerNorm/beta/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/output/LayerNorm/beta/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/output/LayerNorm/gamma with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/output/LayerNorm/gamma/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/output/LayerNorm/gamma/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/output/dense/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/output/dense/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/output/dense/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/output/dense/kernel with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/output/dense/kernel/adam_m with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_2/output/dense/kernel/adam_v with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/attention/output/LayerNorm/beta with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/attention/output/LayerNorm/beta/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/attention/output/LayerNorm/beta/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/attention/output/LayerNorm/gamma with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/attention/output/LayerNorm/gamma/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/attention/output/LayerNorm/gamma/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/attention/output/dense/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/attention/output/dense/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/attention/output/dense/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/attention/output/dense/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/attention/output/dense/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/attention/output/dense/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/attention/self/key/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/attention/self/key/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/attention/self/key/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/attention/self/key/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/attention/self/key/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/attention/self/key/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/attention/self/query/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/attention/self/query/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/attention/self/query/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/attention/self/query/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/attention/self/query/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/attention/self/query/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/attention/self/value/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/attention/self/value/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/attention/self/value/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/attention/self/value/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/attention/self/value/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/attention/self/value/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/intermediate/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/intermediate/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/intermediate/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/intermediate/dense/kernel with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/intermediate/dense/kernel/adam_m with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/intermediate/dense/kernel/adam_v with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/output/LayerNorm/beta with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/output/LayerNorm/beta/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/output/LayerNorm/beta/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/output/LayerNorm/gamma with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/output/LayerNorm/gamma/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/output/LayerNorm/gamma/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/output/dense/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/output/dense/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/output/dense/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/output/dense/kernel with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/output/dense/kernel/adam_m with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_3/output/dense/kernel/adam_v with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/attention/output/LayerNorm/beta with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/attention/output/LayerNorm/beta/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/attention/output/LayerNorm/beta/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/attention/output/LayerNorm/gamma with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/attention/output/LayerNorm/gamma/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/attention/output/LayerNorm/gamma/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/attention/output/dense/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/attention/output/dense/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/attention/output/dense/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/attention/output/dense/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/attention/output/dense/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/attention/output/dense/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/attention/self/key/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/attention/self/key/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/attention/self/key/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/attention/self/key/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/attention/self/key/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/attention/self/key/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/attention/self/query/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/attention/self/query/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/attention/self/query/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/attention/self/query/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/attention/self/query/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/attention/self/query/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/attention/self/value/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/attention/self/value/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/attention/self/value/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/attention/self/value/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/attention/self/value/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/attention/self/value/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/intermediate/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/intermediate/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/intermediate/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/intermediate/dense/kernel with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/intermediate/dense/kernel/adam_m with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/intermediate/dense/kernel/adam_v with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/output/LayerNorm/beta with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/output/LayerNorm/beta/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/output/LayerNorm/beta/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/output/LayerNorm/gamma with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/output/LayerNorm/gamma/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/output/LayerNorm/gamma/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/output/dense/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/output/dense/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/output/dense/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/output/dense/kernel with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/output/dense/kernel/adam_m with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_4/output/dense/kernel/adam_v with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/attention/output/LayerNorm/beta with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/attention/output/LayerNorm/beta/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/attention/output/LayerNorm/beta/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/attention/output/LayerNorm/gamma with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/attention/output/LayerNorm/gamma/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/attention/output/LayerNorm/gamma/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/attention/output/dense/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/attention/output/dense/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/attention/output/dense/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/attention/output/dense/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/attention/output/dense/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/attention/output/dense/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/attention/self/key/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/attention/self/key/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/attention/self/key/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/attention/self/key/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/attention/self/key/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/attention/self/key/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/attention/self/query/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/attention/self/query/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/attention/self/query/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/attention/self/query/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/attention/self/query/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/attention/self/query/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/attention/self/value/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/attention/self/value/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/attention/self/value/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/attention/self/value/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/attention/self/value/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/attention/self/value/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/intermediate/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/intermediate/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/intermediate/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/intermediate/dense/kernel with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/intermediate/dense/kernel/adam_m with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/intermediate/dense/kernel/adam_v with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/output/LayerNorm/beta with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/output/LayerNorm/beta/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/output/LayerNorm/beta/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/output/LayerNorm/gamma with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/output/LayerNorm/gamma/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/output/LayerNorm/gamma/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/output/dense/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/output/dense/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/output/dense/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/output/dense/kernel with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/output/dense/kernel/adam_m with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_5/output/dense/kernel/adam_v with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/attention/output/LayerNorm/beta with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/attention/output/LayerNorm/beta/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/attention/output/LayerNorm/beta/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/attention/output/LayerNorm/gamma with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/attention/output/LayerNorm/gamma/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/attention/output/LayerNorm/gamma/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/attention/output/dense/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/attention/output/dense/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/attention/output/dense/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/attention/output/dense/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/attention/output/dense/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/attention/output/dense/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/attention/self/key/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/attention/self/key/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/attention/self/key/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/attention/self/key/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/attention/self/key/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/attention/self/key/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/attention/self/query/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/attention/self/query/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/attention/self/query/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/attention/self/query/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/attention/self/query/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/attention/self/query/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/attention/self/value/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/attention/self/value/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/attention/self/value/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/attention/self/value/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/attention/self/value/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/attention/self/value/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/intermediate/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/intermediate/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/intermediate/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/intermediate/dense/kernel with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/intermediate/dense/kernel/adam_m with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/intermediate/dense/kernel/adam_v with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/output/LayerNorm/beta with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/output/LayerNorm/beta/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/output/LayerNorm/beta/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/output/LayerNorm/gamma with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/output/LayerNorm/gamma/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/output/LayerNorm/gamma/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/output/dense/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/output/dense/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/output/dense/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/output/dense/kernel with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/output/dense/kernel/adam_m with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_6/output/dense/kernel/adam_v with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/attention/output/LayerNorm/beta with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/attention/output/LayerNorm/beta/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/attention/output/LayerNorm/beta/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/attention/output/LayerNorm/gamma with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/attention/output/LayerNorm/gamma/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/attention/output/LayerNorm/gamma/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/attention/output/dense/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/attention/output/dense/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/attention/output/dense/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/attention/output/dense/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/attention/output/dense/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/attention/output/dense/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/attention/self/key/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/attention/self/key/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/attention/self/key/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/attention/self/key/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/attention/self/key/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/attention/self/key/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/attention/self/query/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/attention/self/query/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/attention/self/query/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/attention/self/query/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/attention/self/query/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/attention/self/query/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/attention/self/value/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/attention/self/value/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/attention/self/value/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/attention/self/value/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/attention/self/value/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/attention/self/value/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/intermediate/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/intermediate/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/intermediate/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/intermediate/dense/kernel with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/intermediate/dense/kernel/adam_m with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/intermediate/dense/kernel/adam_v with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/output/LayerNorm/beta with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/output/LayerNorm/beta/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/output/LayerNorm/beta/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/output/LayerNorm/gamma with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/output/LayerNorm/gamma/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/output/LayerNorm/gamma/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/output/dense/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/output/dense/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/output/dense/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/output/dense/kernel with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/output/dense/kernel/adam_m with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_7/output/dense/kernel/adam_v with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/attention/output/LayerNorm/beta with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/attention/output/LayerNorm/beta/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/attention/output/LayerNorm/beta/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/attention/output/LayerNorm/gamma with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/attention/output/LayerNorm/gamma/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/attention/output/LayerNorm/gamma/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/attention/output/dense/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/attention/output/dense/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/attention/output/dense/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/attention/output/dense/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/attention/output/dense/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/attention/output/dense/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/attention/self/key/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/attention/self/key/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/attention/self/key/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/attention/self/key/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/attention/self/key/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/attention/self/key/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/attention/self/query/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/attention/self/query/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/attention/self/query/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/attention/self/query/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/attention/self/query/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/attention/self/query/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/attention/self/value/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/attention/self/value/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/attention/self/value/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/attention/self/value/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/attention/self/value/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/attention/self/value/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/intermediate/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/intermediate/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/intermediate/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/intermediate/dense/kernel with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/intermediate/dense/kernel/adam_m with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/intermediate/dense/kernel/adam_v with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/output/LayerNorm/beta with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/output/LayerNorm/beta/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/output/LayerNorm/beta/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/output/LayerNorm/gamma with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/output/LayerNorm/gamma/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/output/LayerNorm/gamma/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/output/dense/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/output/dense/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/output/dense/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/output/dense/kernel with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/output/dense/kernel/adam_m with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_8/output/dense/kernel/adam_v with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/attention/output/LayerNorm/beta with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/attention/output/LayerNorm/beta/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/attention/output/LayerNorm/beta/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/attention/output/LayerNorm/gamma with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/attention/output/LayerNorm/gamma/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/attention/output/LayerNorm/gamma/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/attention/output/dense/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/attention/output/dense/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/attention/output/dense/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/attention/output/dense/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/attention/output/dense/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/attention/output/dense/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/attention/self/key/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/attention/self/key/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/attention/self/key/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/attention/self/key/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/attention/self/key/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/attention/self/key/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/attention/self/query/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/attention/self/query/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/attention/self/query/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/attention/self/query/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/attention/self/query/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/attention/self/query/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/attention/self/value/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/attention/self/value/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/attention/self/value/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/attention/self/value/kernel with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/attention/self/value/kernel/adam_m with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/attention/self/value/kernel/adam_v with shape [64, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/intermediate/dense/bias with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/intermediate/dense/bias/adam_m with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/intermediate/dense/bias/adam_v with shape [256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/intermediate/dense/kernel with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/intermediate/dense/kernel/adam_m with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/intermediate/dense/kernel/adam_v with shape [64, 256]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/output/LayerNorm/beta with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/output/LayerNorm/beta/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/output/LayerNorm/beta/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/output/LayerNorm/gamma with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/output/LayerNorm/gamma/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/output/LayerNorm/gamma/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/output/dense/bias with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/output/dense/bias/adam_m with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/output/dense/bias/adam_v with shape [64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/output/dense/kernel with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/output/dense/kernel/adam_m with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator/encoder/layer_9/output/dense/kernel/adam_v with shape [256, 64]\n",
            "INFO:model.modeling_electra:Loading TF weight generator_predictions/LayerNorm/beta with shape [128]\n",
            "INFO:model.modeling_electra:Loading TF weight generator_predictions/LayerNorm/beta/adam_m with shape [128]\n",
            "INFO:model.modeling_electra:Loading TF weight generator_predictions/LayerNorm/beta/adam_v with shape [128]\n",
            "INFO:model.modeling_electra:Loading TF weight generator_predictions/LayerNorm/gamma with shape [128]\n",
            "INFO:model.modeling_electra:Loading TF weight generator_predictions/LayerNorm/gamma/adam_m with shape [128]\n",
            "INFO:model.modeling_electra:Loading TF weight generator_predictions/LayerNorm/gamma/adam_v with shape [128]\n",
            "INFO:model.modeling_electra:Loading TF weight generator_predictions/dense/bias with shape [128]\n",
            "INFO:model.modeling_electra:Loading TF weight generator_predictions/dense/bias/adam_m with shape [128]\n",
            "INFO:model.modeling_electra:Loading TF weight generator_predictions/dense/bias/adam_v with shape [128]\n",
            "INFO:model.modeling_electra:Loading TF weight generator_predictions/dense/kernel with shape [64, 128]\n",
            "INFO:model.modeling_electra:Loading TF weight generator_predictions/dense/kernel/adam_m with shape [64, 128]\n",
            "INFO:model.modeling_electra:Loading TF weight generator_predictions/dense/kernel/adam_v with shape [64, 128]\n",
            "INFO:model.modeling_electra:Loading TF weight generator_predictions/output_bias with shape [119547]\n",
            "INFO:model.modeling_electra:Loading TF weight generator_predictions/output_bias/adam_m with shape [119547]\n",
            "INFO:model.modeling_electra:Loading TF weight generator_predictions/output_bias/adam_v with shape [119547]\n",
            "INFO:model.modeling_electra:Loading TF weight global_step with shape []\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['discriminator_predictions', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping discriminator_predictions/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping discriminator_predictions/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['discriminator_predictions', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping discriminator_predictions/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping discriminator_predictions/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['discriminator_predictions', 'classifier', 'bias']\n",
            "INFO:model.modeling_electra:Skipping discriminator_predictions/classifier/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping discriminator_predictions/classifier/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['discriminator_predictions', 'classifier', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping discriminator_predictions/classifier/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping discriminator_predictions/classifier/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'embeddings', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping electra/embeddings/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/embeddings/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'embeddings', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping electra/embeddings/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/embeddings/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'embeddings', 'position_embeddings']\n",
            "INFO:model.modeling_electra:Skipping electra/embeddings/position_embeddings/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/embeddings/position_embeddings/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'embeddings', 'token_type_embeddings']\n",
            "INFO:model.modeling_electra:Skipping electra/embeddings/token_type_embeddings/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/embeddings/token_type_embeddings/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'embeddings', 'word_embeddings']\n",
            "INFO:model.modeling_electra:Skipping electra/embeddings/word_embeddings/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/embeddings/word_embeddings/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'embeddings_project', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/embeddings_project/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/embeddings_project/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'embeddings_project', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/embeddings_project/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/embeddings_project/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_0/attention/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_0/attention/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_0/attention/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_0/attention/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_0/attention/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_0/attention/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_0/attention/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_0/attention/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_0', 'attention', 'self', 'key', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_0/attention/self/key/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_0/attention/self/key/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_0', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_0/attention/self/key/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_0/attention/self/key/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_0', 'attention', 'self', 'query', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_0/attention/self/query/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_0/attention/self/query/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_0', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_0/attention/self/query/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_0/attention/self/query/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_0', 'attention', 'self', 'value', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_0/attention/self/value/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_0/attention/self/value/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_0', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_0/attention/self/value/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_0/attention/self/value/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_0', 'intermediate', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_0/intermediate/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_0/intermediate/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_0', 'intermediate', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_0/intermediate/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_0/intermediate/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_0', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_0/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_0/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_0', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_0/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_0/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_0', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_0/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_0/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_0', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_0/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_0/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_1/attention/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_1/attention/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_1/attention/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_1/attention/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_1/attention/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_1/attention/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_1/attention/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_1/attention/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_1', 'attention', 'self', 'key', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_1/attention/self/key/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_1/attention/self/key/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_1', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_1/attention/self/key/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_1/attention/self/key/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_1', 'attention', 'self', 'query', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_1/attention/self/query/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_1/attention/self/query/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_1', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_1/attention/self/query/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_1/attention/self/query/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_1', 'attention', 'self', 'value', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_1/attention/self/value/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_1/attention/self/value/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_1', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_1/attention/self/value/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_1/attention/self/value/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_1', 'intermediate', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_1/intermediate/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_1/intermediate/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_1', 'intermediate', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_1/intermediate/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_1/intermediate/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_1', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_1/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_1/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_1', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_1/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_1/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_1', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_1/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_1/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_1', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_1/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_1/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_10/attention/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_10/attention/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_10/attention/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_10/attention/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_10/attention/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_10/attention/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_10/attention/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_10/attention/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_10', 'attention', 'self', 'key', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_10/attention/self/key/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_10/attention/self/key/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_10', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_10/attention/self/key/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_10/attention/self/key/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_10', 'attention', 'self', 'query', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_10/attention/self/query/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_10/attention/self/query/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_10', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_10/attention/self/query/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_10/attention/self/query/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_10', 'attention', 'self', 'value', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_10/attention/self/value/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_10/attention/self/value/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_10', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_10/attention/self/value/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_10/attention/self/value/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_10', 'intermediate', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_10/intermediate/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_10/intermediate/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_10', 'intermediate', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_10/intermediate/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_10/intermediate/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_10', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_10/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_10/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_10', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_10/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_10/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_10', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_10/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_10/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_10', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_10/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_10/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_11/attention/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_11/attention/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_11/attention/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_11/attention/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_11/attention/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_11/attention/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_11/attention/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_11/attention/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_11', 'attention', 'self', 'key', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_11/attention/self/key/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_11/attention/self/key/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_11', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_11/attention/self/key/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_11/attention/self/key/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_11', 'attention', 'self', 'query', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_11/attention/self/query/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_11/attention/self/query/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_11', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_11/attention/self/query/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_11/attention/self/query/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_11', 'attention', 'self', 'value', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_11/attention/self/value/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_11/attention/self/value/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_11', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_11/attention/self/value/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_11/attention/self/value/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_11', 'intermediate', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_11/intermediate/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_11/intermediate/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_11', 'intermediate', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_11/intermediate/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_11/intermediate/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_11', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_11/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_11/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_11', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_11/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_11/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_11', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_11/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_11/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_11', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_11/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_11/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_2/attention/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_2/attention/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_2/attention/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_2/attention/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_2/attention/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_2/attention/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_2/attention/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_2/attention/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_2', 'attention', 'self', 'key', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_2/attention/self/key/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_2/attention/self/key/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_2', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_2/attention/self/key/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_2/attention/self/key/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_2', 'attention', 'self', 'query', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_2/attention/self/query/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_2/attention/self/query/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_2', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_2/attention/self/query/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_2/attention/self/query/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_2', 'attention', 'self', 'value', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_2/attention/self/value/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_2/attention/self/value/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_2', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_2/attention/self/value/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_2/attention/self/value/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_2', 'intermediate', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_2/intermediate/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_2/intermediate/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_2', 'intermediate', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_2/intermediate/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_2/intermediate/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_2', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_2/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_2/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_2', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_2/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_2/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_2', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_2/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_2/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_2', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_2/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_2/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_3/attention/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_3/attention/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_3/attention/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_3/attention/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_3/attention/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_3/attention/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_3/attention/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_3/attention/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_3', 'attention', 'self', 'key', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_3/attention/self/key/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_3/attention/self/key/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_3', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_3/attention/self/key/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_3/attention/self/key/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_3', 'attention', 'self', 'query', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_3/attention/self/query/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_3/attention/self/query/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_3', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_3/attention/self/query/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_3/attention/self/query/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_3', 'attention', 'self', 'value', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_3/attention/self/value/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_3/attention/self/value/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_3', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_3/attention/self/value/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_3/attention/self/value/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_3', 'intermediate', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_3/intermediate/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_3/intermediate/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_3', 'intermediate', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_3/intermediate/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_3/intermediate/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_3', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_3/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_3/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_3', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_3/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_3/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_3', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_3/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_3/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_3', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_3/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_3/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_4/attention/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_4/attention/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_4/attention/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_4/attention/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_4/attention/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_4/attention/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_4/attention/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_4/attention/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_4', 'attention', 'self', 'key', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_4/attention/self/key/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_4/attention/self/key/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_4', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_4/attention/self/key/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_4/attention/self/key/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_4', 'attention', 'self', 'query', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_4/attention/self/query/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_4/attention/self/query/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_4', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_4/attention/self/query/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_4/attention/self/query/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_4', 'attention', 'self', 'value', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_4/attention/self/value/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_4/attention/self/value/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_4', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_4/attention/self/value/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_4/attention/self/value/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_4', 'intermediate', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_4/intermediate/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_4/intermediate/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_4', 'intermediate', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_4/intermediate/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_4/intermediate/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_4', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_4/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_4/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_4', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_4/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_4/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_4', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_4/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_4/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_4', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_4/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_4/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_5/attention/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_5/attention/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_5/attention/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_5/attention/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_5/attention/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_5/attention/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_5/attention/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_5/attention/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_5', 'attention', 'self', 'key', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_5/attention/self/key/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_5/attention/self/key/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_5', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_5/attention/self/key/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_5/attention/self/key/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_5', 'attention', 'self', 'query', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_5/attention/self/query/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_5/attention/self/query/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_5', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_5/attention/self/query/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_5/attention/self/query/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_5', 'attention', 'self', 'value', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_5/attention/self/value/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_5/attention/self/value/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_5', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_5/attention/self/value/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_5/attention/self/value/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_5', 'intermediate', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_5/intermediate/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_5/intermediate/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_5', 'intermediate', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_5/intermediate/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_5/intermediate/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_5', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_5/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_5/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_5', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_5/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_5/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_5', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_5/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_5/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_5', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_5/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_5/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_6/attention/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_6/attention/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_6/attention/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_6/attention/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_6/attention/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_6/attention/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_6/attention/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_6/attention/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_6', 'attention', 'self', 'key', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_6/attention/self/key/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_6/attention/self/key/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_6', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_6/attention/self/key/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_6/attention/self/key/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_6', 'attention', 'self', 'query', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_6/attention/self/query/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_6/attention/self/query/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_6', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_6/attention/self/query/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_6/attention/self/query/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_6', 'attention', 'self', 'value', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_6/attention/self/value/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_6/attention/self/value/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_6', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_6/attention/self/value/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_6/attention/self/value/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_6', 'intermediate', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_6/intermediate/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_6/intermediate/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_6', 'intermediate', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_6/intermediate/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_6/intermediate/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_6', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_6/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_6/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_6', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_6/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_6/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_6', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_6/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_6/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_6', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_6/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_6/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_7/attention/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_7/attention/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_7/attention/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_7/attention/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_7/attention/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_7/attention/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_7/attention/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_7/attention/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_7', 'attention', 'self', 'key', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_7/attention/self/key/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_7/attention/self/key/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_7', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_7/attention/self/key/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_7/attention/self/key/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_7', 'attention', 'self', 'query', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_7/attention/self/query/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_7/attention/self/query/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_7', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_7/attention/self/query/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_7/attention/self/query/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_7', 'attention', 'self', 'value', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_7/attention/self/value/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_7/attention/self/value/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_7', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_7/attention/self/value/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_7/attention/self/value/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_7', 'intermediate', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_7/intermediate/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_7/intermediate/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_7', 'intermediate', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_7/intermediate/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_7/intermediate/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_7', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_7/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_7/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_7', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_7/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_7/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_7', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_7/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_7/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_7', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_7/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_7/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_8/attention/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_8/attention/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_8/attention/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_8/attention/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_8/attention/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_8/attention/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_8/attention/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_8/attention/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_8', 'attention', 'self', 'key', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_8/attention/self/key/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_8/attention/self/key/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_8', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_8/attention/self/key/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_8/attention/self/key/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_8', 'attention', 'self', 'query', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_8/attention/self/query/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_8/attention/self/query/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_8', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_8/attention/self/query/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_8/attention/self/query/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_8', 'attention', 'self', 'value', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_8/attention/self/value/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_8/attention/self/value/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_8', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_8/attention/self/value/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_8/attention/self/value/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_8', 'intermediate', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_8/intermediate/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_8/intermediate/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_8', 'intermediate', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_8/intermediate/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_8/intermediate/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_8', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_8/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_8/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_8', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_8/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_8/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_8', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_8/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_8/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_8', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_8/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_8/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_9/attention/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_9/attention/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_9/attention/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_9/attention/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_9/attention/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_9/attention/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_9/attention/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_9/attention/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_9', 'attention', 'self', 'key', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_9/attention/self/key/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_9/attention/self/key/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_9', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_9/attention/self/key/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_9/attention/self/key/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_9', 'attention', 'self', 'query', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_9/attention/self/query/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_9/attention/self/query/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_9', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_9/attention/self/query/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_9/attention/self/query/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_9', 'attention', 'self', 'value', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_9/attention/self/value/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_9/attention/self/value/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_9', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_9/attention/self/value/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_9/attention/self/value/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_9', 'intermediate', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_9/intermediate/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_9/intermediate/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_9', 'intermediate', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_9/intermediate/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_9/intermediate/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_9', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_9/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_9/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_9', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_9/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_9/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_9', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_9/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_9/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['electra', 'encoder', 'layer_9', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_9/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping electra/encoder/layer_9/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'embeddings_project', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/embeddings_project/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/embeddings_project/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'embeddings_project', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/embeddings_project/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/embeddings_project/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_0/attention/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_0/attention/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_0/attention/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_0/attention/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_0/attention/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_0/attention/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_0/attention/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_0/attention/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_0', 'attention', 'self', 'key', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_0/attention/self/key/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_0/attention/self/key/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_0', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_0/attention/self/key/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_0/attention/self/key/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_0', 'attention', 'self', 'query', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_0/attention/self/query/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_0/attention/self/query/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_0', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_0/attention/self/query/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_0/attention/self/query/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_0', 'attention', 'self', 'value', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_0/attention/self/value/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_0/attention/self/value/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_0', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_0/attention/self/value/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_0/attention/self/value/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_0', 'intermediate', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_0/intermediate/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_0/intermediate/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_0', 'intermediate', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_0/intermediate/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_0/intermediate/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_0', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_0/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_0/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_0', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_0/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_0/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_0', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_0/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_0/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_0', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_0/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_0/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_1/attention/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_1/attention/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_1/attention/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_1/attention/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_1/attention/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_1/attention/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_1/attention/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_1/attention/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_1', 'attention', 'self', 'key', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_1/attention/self/key/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_1/attention/self/key/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_1', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_1/attention/self/key/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_1/attention/self/key/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_1', 'attention', 'self', 'query', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_1/attention/self/query/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_1/attention/self/query/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_1', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_1/attention/self/query/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_1/attention/self/query/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_1', 'attention', 'self', 'value', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_1/attention/self/value/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_1/attention/self/value/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_1', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_1/attention/self/value/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_1/attention/self/value/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_1', 'intermediate', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_1/intermediate/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_1/intermediate/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_1', 'intermediate', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_1/intermediate/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_1/intermediate/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_1', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_1/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_1/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_1', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_1/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_1/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_1', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_1/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_1/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_1', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_1/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_1/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_10/attention/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_10/attention/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_10/attention/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_10/attention/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_10/attention/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_10/attention/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_10/attention/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_10/attention/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_10', 'attention', 'self', 'key', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_10/attention/self/key/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_10/attention/self/key/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_10', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_10/attention/self/key/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_10/attention/self/key/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_10', 'attention', 'self', 'query', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_10/attention/self/query/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_10/attention/self/query/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_10', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_10/attention/self/query/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_10/attention/self/query/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_10', 'attention', 'self', 'value', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_10/attention/self/value/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_10/attention/self/value/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_10', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_10/attention/self/value/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_10/attention/self/value/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_10', 'intermediate', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_10/intermediate/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_10/intermediate/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_10', 'intermediate', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_10/intermediate/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_10/intermediate/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_10', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_10/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_10/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_10', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_10/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_10/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_10', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_10/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_10/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_10', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_10/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_10/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_11/attention/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_11/attention/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_11/attention/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_11/attention/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_11/attention/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_11/attention/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_11/attention/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_11/attention/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_11', 'attention', 'self', 'key', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_11/attention/self/key/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_11/attention/self/key/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_11', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_11/attention/self/key/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_11/attention/self/key/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_11', 'attention', 'self', 'query', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_11/attention/self/query/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_11/attention/self/query/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_11', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_11/attention/self/query/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_11/attention/self/query/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_11', 'attention', 'self', 'value', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_11/attention/self/value/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_11/attention/self/value/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_11', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_11/attention/self/value/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_11/attention/self/value/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_11', 'intermediate', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_11/intermediate/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_11/intermediate/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_11', 'intermediate', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_11/intermediate/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_11/intermediate/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_11', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_11/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_11/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_11', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_11/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_11/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_11', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_11/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_11/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_11', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_11/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_11/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_2/attention/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_2/attention/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_2/attention/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_2/attention/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_2/attention/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_2/attention/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_2/attention/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_2/attention/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_2', 'attention', 'self', 'key', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_2/attention/self/key/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_2/attention/self/key/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_2', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_2/attention/self/key/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_2/attention/self/key/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_2', 'attention', 'self', 'query', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_2/attention/self/query/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_2/attention/self/query/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_2', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_2/attention/self/query/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_2/attention/self/query/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_2', 'attention', 'self', 'value', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_2/attention/self/value/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_2/attention/self/value/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_2', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_2/attention/self/value/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_2/attention/self/value/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_2', 'intermediate', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_2/intermediate/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_2/intermediate/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_2', 'intermediate', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_2/intermediate/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_2/intermediate/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_2', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_2/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_2/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_2', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_2/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_2/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_2', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_2/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_2/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_2', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_2/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_2/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_3/attention/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_3/attention/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_3/attention/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_3/attention/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_3/attention/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_3/attention/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_3/attention/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_3/attention/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_3', 'attention', 'self', 'key', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_3/attention/self/key/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_3/attention/self/key/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_3', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_3/attention/self/key/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_3/attention/self/key/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_3', 'attention', 'self', 'query', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_3/attention/self/query/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_3/attention/self/query/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_3', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_3/attention/self/query/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_3/attention/self/query/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_3', 'attention', 'self', 'value', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_3/attention/self/value/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_3/attention/self/value/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_3', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_3/attention/self/value/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_3/attention/self/value/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_3', 'intermediate', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_3/intermediate/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_3/intermediate/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_3', 'intermediate', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_3/intermediate/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_3/intermediate/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_3', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_3/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_3/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_3', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_3/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_3/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_3', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_3/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_3/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_3', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_3/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_3/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_4/attention/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_4/attention/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_4/attention/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_4/attention/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_4/attention/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_4/attention/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_4/attention/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_4/attention/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_4', 'attention', 'self', 'key', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_4/attention/self/key/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_4/attention/self/key/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_4', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_4/attention/self/key/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_4/attention/self/key/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_4', 'attention', 'self', 'query', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_4/attention/self/query/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_4/attention/self/query/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_4', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_4/attention/self/query/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_4/attention/self/query/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_4', 'attention', 'self', 'value', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_4/attention/self/value/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_4/attention/self/value/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_4', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_4/attention/self/value/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_4/attention/self/value/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_4', 'intermediate', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_4/intermediate/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_4/intermediate/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_4', 'intermediate', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_4/intermediate/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_4/intermediate/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_4', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_4/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_4/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_4', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_4/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_4/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_4', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_4/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_4/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_4', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_4/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_4/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_5/attention/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_5/attention/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_5/attention/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_5/attention/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_5/attention/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_5/attention/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_5/attention/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_5/attention/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_5', 'attention', 'self', 'key', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_5/attention/self/key/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_5/attention/self/key/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_5', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_5/attention/self/key/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_5/attention/self/key/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_5', 'attention', 'self', 'query', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_5/attention/self/query/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_5/attention/self/query/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_5', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_5/attention/self/query/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_5/attention/self/query/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_5', 'attention', 'self', 'value', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_5/attention/self/value/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_5/attention/self/value/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_5', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_5/attention/self/value/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_5/attention/self/value/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_5', 'intermediate', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_5/intermediate/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_5/intermediate/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_5', 'intermediate', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_5/intermediate/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_5/intermediate/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_5', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_5/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_5/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_5', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_5/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_5/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_5', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_5/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_5/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_5', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_5/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_5/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_6/attention/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_6/attention/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_6/attention/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_6/attention/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_6/attention/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_6/attention/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_6/attention/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_6/attention/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_6', 'attention', 'self', 'key', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_6/attention/self/key/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_6/attention/self/key/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_6', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_6/attention/self/key/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_6/attention/self/key/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_6', 'attention', 'self', 'query', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_6/attention/self/query/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_6/attention/self/query/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_6', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_6/attention/self/query/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_6/attention/self/query/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_6', 'attention', 'self', 'value', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_6/attention/self/value/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_6/attention/self/value/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_6', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_6/attention/self/value/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_6/attention/self/value/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_6', 'intermediate', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_6/intermediate/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_6/intermediate/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_6', 'intermediate', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_6/intermediate/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_6/intermediate/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_6', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_6/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_6/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_6', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_6/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_6/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_6', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_6/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_6/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_6', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_6/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_6/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_7/attention/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_7/attention/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_7/attention/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_7/attention/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_7/attention/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_7/attention/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_7/attention/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_7/attention/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_7', 'attention', 'self', 'key', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_7/attention/self/key/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_7/attention/self/key/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_7', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_7/attention/self/key/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_7/attention/self/key/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_7', 'attention', 'self', 'query', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_7/attention/self/query/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_7/attention/self/query/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_7', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_7/attention/self/query/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_7/attention/self/query/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_7', 'attention', 'self', 'value', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_7/attention/self/value/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_7/attention/self/value/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_7', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_7/attention/self/value/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_7/attention/self/value/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_7', 'intermediate', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_7/intermediate/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_7/intermediate/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_7', 'intermediate', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_7/intermediate/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_7/intermediate/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_7', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_7/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_7/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_7', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_7/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_7/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_7', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_7/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_7/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_7', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_7/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_7/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_8/attention/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_8/attention/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_8/attention/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_8/attention/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_8/attention/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_8/attention/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_8/attention/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_8/attention/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_8', 'attention', 'self', 'key', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_8/attention/self/key/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_8/attention/self/key/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_8', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_8/attention/self/key/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_8/attention/self/key/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_8', 'attention', 'self', 'query', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_8/attention/self/query/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_8/attention/self/query/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_8', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_8/attention/self/query/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_8/attention/self/query/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_8', 'attention', 'self', 'value', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_8/attention/self/value/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_8/attention/self/value/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_8', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_8/attention/self/value/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_8/attention/self/value/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_8', 'intermediate', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_8/intermediate/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_8/intermediate/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_8', 'intermediate', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_8/intermediate/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_8/intermediate/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_8', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_8/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_8/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_8', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_8/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_8/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_8', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_8/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_8/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_8', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_8/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_8/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_9/attention/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_9/attention/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_9/attention/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_9/attention/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_9/attention/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_9/attention/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_9/attention/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_9/attention/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_9', 'attention', 'self', 'key', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_9/attention/self/key/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_9/attention/self/key/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_9', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_9/attention/self/key/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_9/attention/self/key/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_9', 'attention', 'self', 'query', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_9/attention/self/query/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_9/attention/self/query/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_9', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_9/attention/self/query/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_9/attention/self/query/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_9', 'attention', 'self', 'value', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_9/attention/self/value/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_9/attention/self/value/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_9', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_9/attention/self/value/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_9/attention/self/value/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_9', 'intermediate', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_9/intermediate/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_9/intermediate/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_9', 'intermediate', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_9/intermediate/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_9/intermediate/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_9', 'output', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_9/output/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_9/output/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_9', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_9/output/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_9/output/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_9', 'output', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_9/output/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_9/output/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator', 'encoder', 'layer_9', 'output', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_9/output/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator/encoder/layer_9/output/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator_predictions', 'LayerNorm', 'beta']\n",
            "INFO:model.modeling_electra:Skipping generator_predictions/LayerNorm/beta/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator_predictions/LayerNorm/beta/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator_predictions', 'LayerNorm', 'gamma']\n",
            "INFO:model.modeling_electra:Skipping generator_predictions/LayerNorm/gamma/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator_predictions/LayerNorm/gamma/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator_predictions', 'dense', 'bias']\n",
            "INFO:model.modeling_electra:Skipping generator_predictions/dense/bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator_predictions/dense/bias/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator_predictions', 'dense', 'kernel']\n",
            "INFO:model.modeling_electra:Skipping generator_predictions/dense/kernel/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator_predictions/dense/kernel/adam_v\n",
            "INFO:model.modeling_electra:Initialize PyTorch weight ['generator_predictions', 'output_bias']\n",
            "INFO:model.modeling_electra:Skipping generator_predictions/output_bias/adam_m\n",
            "INFO:model.modeling_electra:Skipping generator_predictions/output_bias/adam_v\n",
            "INFO:model.modeling_electra:Skipping global_step\n",
            "Save PyTorch model to data/models/electra-spanish//pytorch_model.bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nN1HUyV9t_FI"
      },
      "source": [
        "**Use ELECTRA with `transformers`**\n",
        "\n",
        "After converting the model checkpoint to PyTorch format, we can start to use our pre-trained ELECTRA model on downstream tasks with the `transformers` library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrgjRUew2i_6"
      },
      "source": [
        "import torch\n",
        "from transformers import ElectraForPreTraining, ElectraTokenizerFast\n",
        "\n",
        "discriminator = ElectraForPreTraining.from_pretrained(MODEL_DIR)\n",
        "tokenizer = ElectraTokenizerFast.from_pretrained(DATA_DIR, do_lower_case=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lfy3IlEq2oDk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3ca722ad-d380-46df-a83d-740b0969f4eb"
      },
      "source": [
        "sentence = \"Los pÃ¡jaros estÃ¡n cantando\" # The birds are singing\n",
        "fake_sentence = \"Los pÃ¡jaros estÃ¡n hablando\" # The birds are speaking \n",
        "\n",
        "fake_tokens = tokenizer.tokenize(fake_sentence, add_special_tokens=True)\n",
        "fake_inputs = tokenizer.encode(fake_sentence, return_tensors=\"pt\")\n",
        "discriminator_outputs = discriminator(fake_inputs)\n",
        "predictions = discriminator_outputs[0] > 0\n",
        "\n",
        "[print(\"%7s\" % token, end=\"\") for token in fake_tokens]\n",
        "print(\"\\n\")\n",
        "[print(\"%7s\" % int(prediction), end=\"\") for prediction in predictions.tolist()];"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  [CLS]    Los    paj ##aros  estan  habla  ##ndo  [SEP]\n",
            "\n",
            "      1      0      0      0      0      0      0      0"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKVKso6O3IRC"
      },
      "source": [
        "Our model was trained for only 100 steps so the predictions are not accurate. The fully-trained ELECTRA-small for Spanish can be loaded as below:\n",
        "\n",
        "```python\n",
        "discriminator = ElectraForPreTraining.from_pretrained(\"skimai/electra-small-spanish\")\n",
        "tokenizer = ElectraTokenizerFast.from_pretrained(\"skimai/electra-small-spanish\", do_lower_case=False)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjJz-7T2_v-x"
      },
      "source": [
        "## 5. Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TxoYuDwAASv"
      },
      "source": [
        "In this article, we have walked through the ELECTRA paper to understand why ELECTRA is the most efficient transformer pre-training approach at the moment. At a small scale, ELECTRA-small can be trained on one GPU for 4 days to outperform GPT on the GLUE benchmark. At a large scale, ELECTRA-large sets a new state-of-the-art for SQuAD 2.0.\n",
        "\n",
        "We then actually train an ELECTRA model on Spanish texts and convert Tensorflow checkpoint to PyTorch and use the model with the `transformers` library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aptXQo8lBtnf"
      },
      "source": [
        "## References\n",
        "- [1] [ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators](https://openreview.net/pdf?id=r1xMH1BtvB)\n",
        "- [2] [google-research/electra](https://github.com/google-research/electra) - the official GitHub repository of the original paper\n",
        "- [3] [electra_pytorch](https://github.com/lonePatient/electra_pytorch) - a PyTorch implementation of ELECTRA"
      ]
    }
  ]
}