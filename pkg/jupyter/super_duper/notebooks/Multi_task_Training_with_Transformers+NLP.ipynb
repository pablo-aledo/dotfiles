{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multi-task Training with Transformers+NLP",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bo7kpNZnRzoB"
      },
      "source": [
        "# Multi-task Training with Hugging Face Transformers and NLP\n",
        "\n",
        "### Or: A recipe for multi-task training with Transformers' Trainer and NLP datasets\n",
        "\n",
        "\n",
        "\n",
        "Hugging Face has been building a lot of exciting new NLP functionality lately. The newly released [NLP](https://github.com/huggingface/nlp) provides a wide coverage of task data sets and metrics, as well as a simple interface for processing and caching the inputs extremely efficiently. They have also recently introduced a [Trainer](https://github.com/huggingface/transformers/blob/master/src/transformers/trainer.py) class to the Transformers library that handles all of the training and validation logic.\n",
        "\n",
        "However, one feature that is not currently supported in Hugging Face's current offerings is *multi-task training*. While there has been some discussion about the best way to support multi-task training ([1](https://github.com/huggingface/transformers/issues/4340), [2](https://github.com/huggingface/nlp/issues/217)), the community has not yet settled on a convention for doing so. Multi-task training has been shown to improve task performance ([1](https://www.aclweb.org/anthology/P19-1441/), [2](https://arxiv.org/abs/1910.10683)) and is a common experimental setting for NLP researchers.\n",
        "\n",
        "In this Colab notebook, we will show how to use both the new NLP library as well as the Trainer for a **multi-task** training scheme.\n",
        "\n",
        "So let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n90H9I0cMQvY"
      },
      "source": [
        "## Library setup\n",
        "\n",
        "First up, we will install the *NLP* and *Transformers* libraries. \n",
        "\n",
        "<font color='red'>**Note: After running the following cell, you will need to restart your runtime for the installation to work properly.**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlICaYzQan59"
      },
      "source": [
        "#!pip install git+https://github.com/huggingface/nlp\n",
        "!pip install transformers==2.11.0\n",
        "!pip install nlp==0.2.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejhYiFELazOd"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "import nlp\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXdgg0ucNGvj"
      },
      "source": [
        "## Fetching our data\n",
        "\n",
        "To showcase our multi-task functionality, we will choose tasks of different formats:\n",
        "\n",
        "* STS-B: A two-sentece textual similarity scoring task. (Prediction is a real number between 1 and 5)\n",
        "* RTE: A two-sentence natural language entailment task. (Prediction is one of two classes)\n",
        "* Commonsense QA: A multiple-choice question-answering task. (Each example consists of 5 seperate text inputs, prediction is which one of the 5 choices is correct)\n",
        "\n",
        "In particular, notice that unlike STS-B and RTE, Commonsense QA consists of feeding *multiple* inputs into the transformer model. Many other tasks have weirder formats too, so our setup needs to be flexible enough to accomodate very different kinds of tasks.\n",
        "\n",
        "Now, actually getting the task data is super simple. We can simply call the `nlp.load_dataset` method, which automatically downloads the data and prepares it for use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pntb5EqgapA1"
      },
      "source": [
        "dataset_dict = {\n",
        "    \"stsb\": nlp.load_dataset('glue', name=\"stsb\"),\n",
        "    \"rte\": nlp.load_dataset('glue', name=\"rte\"),\n",
        "    \"commonsense_qa\": nlp.load_dataset('commonsense_qa'),\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFTXc2iVOizO"
      },
      "source": [
        "We can show one example from each task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiP4yQMPOQVz"
      },
      "source": [
        "for task_name, dataset in dataset_dict.items():\n",
        "    print(task_name)\n",
        "    print(dataset_dict[task_name][\"train\"][0])\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQ39AbTAPAUi"
      },
      "source": [
        "## Creating a Multi-task Model\n",
        "\n",
        "Next up, we are going to create a multi-task model. \n",
        "\n",
        "Typically, a multi-task model in the age of BERT works by having a shared BERT-style encoder transformer, and different task heads for each task.\n",
        "\n",
        "![Multi-Task 1](https://drive.google.com/uc?id=1TCdyyoHInbiZtSOUmyJN1miCj1iysygU)\n",
        "\n",
        "We could try to implement this directly in code, but there are two downsides to this approach:\n",
        "\n",
        "1. Hugging Face's Transformers has implementations for single-task models, but not modular task heads. This means we will need to do a lot of our own leg work to write our own task heads.\n",
        "2. This format assumes that the input is processed the same way in the encoder for every task. Already, Commonsense QA is problematic for this approach, since it requires the encoder to process *multiple* input sequences for a single example. Other tasks may similarly break this abstraction.\n",
        "\n",
        "Instead, we are going to do something **radically different**. We are going to create separate models for each task, but we are going make them share the same encoder. \n",
        "\n",
        "![Multi-Task 2](https://drive.google.com/uc?id=1xmghPPO5RC-TnpYP4_PpZ-TRfJF33S6p)\n",
        "\n",
        "This will serve the same goal as having the encoder be jointly trained across multiple tasks, but still retain the independent implementations of each model. As such, we can use the existing task-model implementations in Transformers, such as `RobertaForSequenceClassification` and `RobertaForMultipleChoice`.\n",
        "\n",
        "Importantly, the shared encoder ensures that during training, all updates will update the same encoder weighs, and also **does not consume any additional GPU memory**.\n",
        "\n",
        "First, we define our `MultitaskModel` class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVX5hFlzmLka"
      },
      "source": [
        "class MultitaskModel(transformers.PreTrainedModel):\n",
        "    def __init__(self, encoder, taskmodels_dict):\n",
        "        \"\"\"\n",
        "        Setting MultitaskModel up as a PretrainedModel allows us\n",
        "        to take better advantage of Trainer features\n",
        "        \"\"\"\n",
        "        super().__init__(transformers.PretrainedConfig())\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.taskmodels_dict = nn.ModuleDict(taskmodels_dict)\n",
        "\n",
        "    @classmethod\n",
        "    def create(cls, model_name, model_type_dict, model_config_dict):\n",
        "        \"\"\"\n",
        "        This creates a MultitaskModel using the model class and config objects\n",
        "        from single-task models. \n",
        "\n",
        "        We do this by creating each single-task model, and having them share\n",
        "        the same encoder transformer.\n",
        "        \"\"\"\n",
        "        shared_encoder = None\n",
        "        taskmodels_dict = {}\n",
        "        for task_name, model_type in model_type_dict.items():\n",
        "            model = model_type.from_pretrained(\n",
        "                model_name, \n",
        "                config=model_config_dict[task_name],\n",
        "            )\n",
        "            if shared_encoder is None:\n",
        "                shared_encoder = getattr(model, cls.get_encoder_attr_name(model))\n",
        "            else:\n",
        "                setattr(model, cls.get_encoder_attr_name(model), shared_encoder)\n",
        "            taskmodels_dict[task_name] = model\n",
        "        return cls(encoder=shared_encoder, taskmodels_dict=taskmodels_dict)\n",
        "\n",
        "    @classmethod\n",
        "    def get_encoder_attr_name(cls, model):\n",
        "        \"\"\"\n",
        "        The encoder transformer is named differently in each model \"architecture\".\n",
        "        This method lets us get the name of the encoder attribute\n",
        "        \"\"\"\n",
        "        model_class_name = model.__class__.__name__\n",
        "        if model_class_name.startswith(\"Bert\"):\n",
        "            return \"bert\"\n",
        "        elif model_class_name.startswith(\"Roberta\"):\n",
        "            return \"roberta\"\n",
        "        elif model_class_name.startswith(\"Albert\"):\n",
        "            return \"albert\"\n",
        "        else:\n",
        "            raise KeyError(f\"Add support for new model {model_class_name}\")\n",
        "\n",
        "    def forward(self, task_name, **kwargs):\n",
        "        return self.taskmodels_dict[task_name](**kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zSZsp8Cb7gd"
      },
      "source": [
        "As described above, the `MultitaskModel` class consists of only two components - the shared \"encoder\", a dictionary to the individual task models. Now, we can simply create the corresponding task models by supplying the invidual model classes and model configs. We will use Transformers' AutoModels to further automate the choice of model class given a model architecture (in our case, let's use `roberta-base`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_sosFINo24B"
      },
      "source": [
        "model_name = \"roberta-base\"\n",
        "multitask_model = MultitaskModel.create(\n",
        "    model_name=model_name,\n",
        "    model_type_dict={\n",
        "        \"stsb\": transformers.AutoModelForSequenceClassification,\n",
        "        \"rte\": transformers.AutoModelForSequenceClassification,\n",
        "        \"commonsense_qa\": transformers.AutoModelForMultipleChoice,\n",
        "    },\n",
        "    model_config_dict={\n",
        "        \"stsb\": transformers.AutoConfig.from_pretrained(model_name, num_labels=1),\n",
        "        \"rte\": transformers.AutoConfig.from_pretrained(model_name, num_labels=2),\n",
        "        \"commonsense_qa\": transformers.AutoConfig.from_pretrained(model_name),\n",
        "    },\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxSAQ6q4O-uL"
      },
      "source": [
        "To confirm that all three task-models use the same encoder, we can check the data pointers of the respective encoders. In this case, we'll check that the word embeddings in each model all point to the same memory location."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrtS3ZeSsoZw"
      },
      "source": [
        "if model_name.startswith(\"roberta-\"):\n",
        "    print(multitask_model.encoder.embeddings.word_embeddings.weight.data_ptr())\n",
        "    print(multitask_model.taskmodels_dict[\"stsb\"].roberta.embeddings.word_embeddings.weight.data_ptr())\n",
        "    print(multitask_model.taskmodels_dict[\"rte\"].roberta.embeddings.word_embeddings.weight.data_ptr())\n",
        "    print(multitask_model.taskmodels_dict[\"commonsense_qa\"].roberta.embeddings.word_embeddings.weight.data_ptr())\n",
        "else:\n",
        "    print(\"Exercise for the reader: add a check for other model architectures =)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PujQR2HkPTRk"
      },
      "source": [
        "## Processing our task data\n",
        "\n",
        "We have created a dictionary of NLP datasets above, but we need to do a little more work to convert the respective task data into model inputs.\n",
        "\n",
        "We'll start by first getting the tokenizer corresponding to our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0n96ifPukDkb"
      },
      "source": [
        "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5BubjFwPySD"
      },
      "source": [
        "Next, we'll write some short functions to convert from raw text to tokenized text inputs. \n",
        "\n",
        "* Both STS-B and RTE and two-sentence input tasks, so we will concatenate them with the corresponding special tokens. (The tokenizer's `batch_encode_plus` method handles this for us.) So, the input might look like: \n",
        "\n",
        "```\n",
        "['<s>', 'This', 'is', 'my', 'premise', '.', '</s>', '</s>', 'This', 'is', 'my', 'hypothesis', '.', '</s>']\n",
        "```\n",
        "\n",
        "* CommonsenseQA, is a multiple choice task. A single example consists of a question, a five possible answer choices. We will feed the model inputs concatenated like `QUESTION + CHOICE_1`, `QUESTION + CHOICE_2` and so on. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSeBYKCublmo"
      },
      "source": [
        "max_length = 128\n",
        "\n",
        "def convert_to_stsb_features(example_batch):\n",
        "    inputs = list(zip(example_batch['sentence1'], example_batch['sentence2']))\n",
        "    features = tokenizer.batch_encode_plus(\n",
        "        inputs, max_length=max_length, pad_to_max_length=True\n",
        "    )\n",
        "    features[\"labels\"] = example_batch[\"label\"]\n",
        "    return features\n",
        "\n",
        "def convert_to_rte_features(example_batch):\n",
        "    inputs = list(zip(example_batch['sentence1'], example_batch['sentence2']))\n",
        "    features = tokenizer.batch_encode_plus(\n",
        "        inputs, max_length=max_length, pad_to_max_length=True\n",
        "    )\n",
        "    features[\"labels\"] = example_batch[\"label\"]\n",
        "    return features\n",
        "\n",
        "def convert_to_commonsense_qa_features(example_batch):\n",
        "    num_examples = len(example_batch[\"question\"])\n",
        "    num_choices = len(example_batch[\"choices\"][0][\"text\"])\n",
        "    features = {}\n",
        "    for example_i in range(num_examples):\n",
        "        choices_inputs = tokenizer.batch_encode_plus(\n",
        "            list(zip(\n",
        "                [example_batch[\"question\"][example_i]] * num_choices,\n",
        "                example_batch[\"choices\"][example_i][\"text\"],\n",
        "            )),\n",
        "            max_length=max_length, pad_to_max_length=True,\n",
        "        )\n",
        "        for k, v in choices_inputs.items():\n",
        "            if k not in features:\n",
        "                features[k] = []\n",
        "            features[k].append(v)\n",
        "    labels2id = {char: i for i, char in enumerate(\"ABCDE\")}\n",
        "    # Dummy answers for test\n",
        "    if example_batch[\"answerKey\"][0]:\n",
        "        features[\"labels\"] = [labels2id[ans] for ans in example_batch[\"answerKey\"]]\n",
        "    else:\n",
        "        features[\"labels\"] = [0] * num_examples    \n",
        "    return features\n",
        "\n",
        "convert_func_dict = {\n",
        "    \"stsb\": convert_to_stsb_features,\n",
        "    \"rte\": convert_to_rte_features,\n",
        "    \"commonsense_qa\": convert_to_commonsense_qa_features,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eULIAQ9WRYXn"
      },
      "source": [
        "Now that we have defined the above functions, we can use `dataset.map` method available in the NLP library to apply the functions over our entire datasets. The NLP library that handles the mapping efficiently and caches the features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcLnS85Hkhbf"
      },
      "source": [
        "columns_dict = {\n",
        "    \"stsb\": ['input_ids', 'attention_mask', 'labels'],\n",
        "    \"rte\": ['input_ids', 'attention_mask', 'labels'],\n",
        "    \"commonsense_qa\": ['input_ids', 'attention_mask', 'labels'],\n",
        "}\n",
        "\n",
        "features_dict = {}\n",
        "for task_name, dataset in dataset_dict.items():\n",
        "    features_dict[task_name] = {}\n",
        "    for phase, phase_dataset in dataset.items():\n",
        "        features_dict[task_name][phase] = phase_dataset.map(\n",
        "            convert_func_dict[task_name],\n",
        "            batched=True,\n",
        "            load_from_cache_file=False,\n",
        "        )\n",
        "        print(task_name, phase, len(phase_dataset), len(features_dict[task_name][phase]))\n",
        "        features_dict[task_name][phase].set_format(\n",
        "            type=\"torch\", \n",
        "            columns=columns_dict[task_name],\n",
        "        )\n",
        "        print(task_name, phase, len(phase_dataset), len(features_dict[task_name][phase]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x33Yu15nSurv"
      },
      "source": [
        "As a recap:\n",
        "\n",
        "* We have created our multi-task model by fusing several single-task Transformer models\n",
        "* We have created a (cached) dictionary of featurized inputs for each of our tasks, using NLP dataset\n",
        "\n",
        "Next up, we need to \n",
        "\n",
        "1. Set up our data loading\n",
        "2. Set up our Trainer \n",
        "3. Start training!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4N7IF9hTR7m"
      },
      "source": [
        "## Preparing a multi-task data loader and Trainer\n",
        "\n",
        "Setting up a multi-task data loader should be simple in principle - we simply need to sample from multiple single-task data loaders with some probability, and feed each batch to the multi-task model above. Of course, along with each batch, we also need to tell the model what task it is for, so `MultitaskModel` knows to use the right corresponding task-model.\n",
        "\n",
        "However, because we want to use the built-in `Trainer` class in Transformers, this gets a little tricky, since the `Trainer` expects a single data loader, and expects a very specific format of per-batch data. This slice of code is somewhat of a hack around that constraint. (This can become a lot more streamlined with some tweaks to the Trainer code from the Hugging Face folks =))\n",
        "\n",
        "We need to define a `MultitaskDataloader` that combines several data loaders into a single \"data loader\" - not so different from our multi-task model above! This `MultitaskDataloader` should do what we described: sample from different single-task data loaders, and yield a task batch and the corresponding task name (we're going to add the `task_name` to the batch data).\n",
        "\n",
        "We will also need to override the `get_train_dataloader` method of the `Trainer` to play well with our `MultitaskDataloader`. We do this with a `MultitaskTrainer`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdUbpAIZzWce"
      },
      "source": [
        "import dataclasses\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from transformers.training_args import is_tpu_available\n",
        "from transformers.trainer import get_tpu_sampler\n",
        "from transformers.data.data_collator import DataCollator, InputDataClass\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from torch.utils.data.sampler import RandomSampler\n",
        "from typing import List, Union, Dict\n",
        "\n",
        "\n",
        "class NLPDataCollator(DataCollator):\n",
        "    \"\"\"\n",
        "    Extending the existing DataCollator to work with NLP dataset batches\n",
        "    \"\"\"\n",
        "    def collate_batch(self, features: List[Union[InputDataClass, Dict]]) -> Dict[str, torch.Tensor]:\n",
        "        first = features[0]\n",
        "        if isinstance(first, dict):\n",
        "          # NLP data sets current works presents features as lists of dictionary\n",
        "          # (one per example), so we  will adapt the collate_batch logic for that\n",
        "          if \"labels\" in first and first[\"labels\"] is not None:\n",
        "              if first[\"labels\"].dtype == torch.int64:\n",
        "                  labels = torch.tensor([f[\"labels\"] for f in features], dtype=torch.long)\n",
        "              else:\n",
        "                  labels = torch.tensor([f[\"labels\"] for f in features], dtype=torch.float)\n",
        "              batch = {\"labels\": labels}\n",
        "          for k, v in first.items():\n",
        "              if k != \"labels\" and v is not None and not isinstance(v, str):\n",
        "                  batch[k] = torch.stack([f[k] for f in features])\n",
        "          return batch\n",
        "        else:\n",
        "          # otherwise, revert to using the default collate_batch\n",
        "          return DefaultDataCollator().collate_batch(features)\n",
        "\n",
        "\n",
        "class StrIgnoreDevice(str):\n",
        "    \"\"\"\n",
        "    This is a hack. The Trainer is going call .to(device) on every input\n",
        "    value, but we need to pass in an additional `task_name` string.\n",
        "    This prevents it from throwing an error\n",
        "    \"\"\"\n",
        "    def to(self, device):\n",
        "        return self\n",
        "\n",
        "\n",
        "class DataLoaderWithTaskname:\n",
        "    \"\"\"\n",
        "    Wrapper around a DataLoader to also yield a task name\n",
        "    \"\"\"\n",
        "    def __init__(self, task_name, data_loader):\n",
        "        self.task_name = task_name\n",
        "        self.data_loader = data_loader\n",
        "\n",
        "        self.batch_size = data_loader.batch_size\n",
        "        self.dataset = data_loader.dataset\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_loader)\n",
        "    \n",
        "    def __iter__(self):\n",
        "        for batch in self.data_loader:\n",
        "            batch[\"task_name\"] = StrIgnoreDevice(self.task_name)\n",
        "            yield batch\n",
        "\n",
        "\n",
        "class MultitaskDataloader:\n",
        "    \"\"\"\n",
        "    Data loader that combines and samples from multiple single-task\n",
        "    data loaders.\n",
        "    \"\"\"\n",
        "    def __init__(self, dataloader_dict):\n",
        "        self.dataloader_dict = dataloader_dict\n",
        "        self.num_batches_dict = {\n",
        "            task_name: len(dataloader) \n",
        "            for task_name, dataloader in self.dataloader_dict.items()\n",
        "        }\n",
        "        self.task_name_list = list(self.dataloader_dict)\n",
        "        self.dataset = [None] * sum(\n",
        "            len(dataloader.dataset) \n",
        "            for dataloader in self.dataloader_dict.values()\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return sum(self.num_batches_dict.values())\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"\n",
        "        For each batch, sample a task, and yield a batch from the respective\n",
        "        task Dataloader.\n",
        "\n",
        "        We use size-proportional sampling, but you could easily modify this\n",
        "        to sample from some-other distribution.\n",
        "        \"\"\"\n",
        "        task_choice_list = []\n",
        "        for i, task_name in enumerate(self.task_name_list):\n",
        "            task_choice_list += [i] * self.num_batches_dict[task_name]\n",
        "        task_choice_list = np.array(task_choice_list)\n",
        "        np.random.shuffle(task_choice_list)\n",
        "        dataloader_iter_dict = {\n",
        "            task_name: iter(dataloader) \n",
        "            for task_name, dataloader in self.dataloader_dict.items()\n",
        "        }\n",
        "        for task_choice in task_choice_list:\n",
        "            task_name = self.task_name_list[task_choice]\n",
        "            yield next(dataloader_iter_dict[task_name])    \n",
        "\n",
        "class MultitaskTrainer(transformers.Trainer):\n",
        "\n",
        "    def get_single_train_dataloader(self, task_name, train_dataset):\n",
        "        \"\"\"\n",
        "        Create a single-task data loader that also yields task names\n",
        "        \"\"\"\n",
        "        if self.train_dataset is None:\n",
        "            raise ValueError(\"Trainer: training requires a train_dataset.\")\n",
        "        if is_tpu_available():\n",
        "            train_sampler = get_tpu_sampler(train_dataset)\n",
        "        else:\n",
        "            train_sampler = (\n",
        "                RandomSampler(train_dataset)\n",
        "                if self.args.local_rank == -1\n",
        "                else DistributedSampler(train_dataset)\n",
        "            )\n",
        "\n",
        "        data_loader = DataLoaderWithTaskname(\n",
        "            task_name=task_name,\n",
        "            data_loader=DataLoader(\n",
        "              train_dataset,\n",
        "              batch_size=self.args.train_batch_size,\n",
        "              sampler=train_sampler,\n",
        "              collate_fn=self.data_collator.collate_batch,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        if is_tpu_available():\n",
        "            data_loader = pl.ParallelLoader(\n",
        "                data_loader, [self.args.device]\n",
        "            ).per_device_loader(self.args.device)\n",
        "        return data_loader\n",
        "\n",
        "    def get_train_dataloader(self):\n",
        "        \"\"\"\n",
        "        Returns a MultitaskDataloader, which is not actually a Dataloader\n",
        "        but an iterable that returns a generator that samples from each \n",
        "        task Dataloader\n",
        "        \"\"\"\n",
        "        return MultitaskDataloader({\n",
        "            task_name: self.get_single_train_dataloader(task_name, task_dataset)\n",
        "            for task_name, task_dataset in self.train_dataset.items()\n",
        "        })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AtQfkWxVUSJ"
      },
      "source": [
        "## Time to train!\n",
        "\n",
        "Okay, we have done all the hard work, now it is time for it to pay off. We can now simply create our `MultitaskTrainer`, and start training! \n",
        "\n",
        "(This takes about ~45 minutes for me on Colab, but it will depend on the GPU you are allocated.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4YUxdIZz3_i"
      },
      "source": [
        "train_dataset = {\n",
        "    task_name: dataset[\"train\"] \n",
        "    for task_name, dataset in features_dict.items()\n",
        "}\n",
        "trainer = MultitaskTrainer(\n",
        "    model=multitask_model,\n",
        "    args=transformers.TrainingArguments(\n",
        "        output_dir=\"./models/multitask_model\",\n",
        "        overwrite_output_dir=True,\n",
        "        learning_rate=1e-5,\n",
        "        do_train=True,\n",
        "        num_train_epochs=3,\n",
        "        # Adjust batch size if this doesn't fit on the Colab GPU\n",
        "        per_device_train_batch_size=8,  \n",
        "        save_steps=3000,\n",
        "    ),\n",
        "    data_collator=NLPDataCollator(),\n",
        "    train_dataset=train_dataset,\n",
        ")\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBQQVj67j7kn"
      },
      "source": [
        "All done! Now, we can evaluate our multi-task model on all three tasks. In this case, we can simply use single-task data loaders, since we are evaluating each task individually.\n",
        "\n",
        "We will use the (private) `_prediction_loop` method from the Trainer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk6aj8UmBV9Q"
      },
      "source": [
        "preds_dict = {}\n",
        "for task_name in [\"rte\", \"stsb\", \"commonsense_qa\"]:\n",
        "    eval_dataloader = DataLoaderWithTaskname(\n",
        "        task_name,\n",
        "        trainer.get_eval_dataloader(eval_dataset=features_dict[task_name][\"validation\"])\n",
        "    )\n",
        "    print(eval_dataloader.data_loader.collate_fn)\n",
        "    preds_dict[task_name] = trainer._prediction_loop(\n",
        "        eval_dataloader, \n",
        "        description=f\"Validation: {task_name}\",\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzHyYue7rnBz"
      },
      "source": [
        "Now that we have all the predictions, let's go ahead and score them. The NLP library also has built-in metrics for the GLUE tasks (which includes STS-B and RTE), but not for Commonsense QA. Thankfully, Commonsense QA's evaluation metric is simple accuracy, which we can compute easily."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vXMkkvZJuKo"
      },
      "source": [
        "# Evalute RTE\n",
        "nlp.load_metric('glue', name=\"rte\").compute(\n",
        "    np.argmax(preds_dict[\"rte\"].predictions, axis=1),\n",
        "    preds_dict[\"rte\"].label_ids,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYAqVC6OJuPX"
      },
      "source": [
        "# Evalute STS-B\n",
        "nlp.load_metric('glue', name=\"stsb\").compute(\n",
        "    preds_dict[\"stsb\"].predictions.flatten(),\n",
        "    preds_dict[\"stsb\"].label_ids,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWKTZxcjFPnS"
      },
      "source": [
        "# Evalute Commonsense QA\n",
        "np.mean(\n",
        "    np.argmax(preds_dict[\"commonsense_qa\"].predictions, axis=1)\n",
        "    == preds_dict[\"commonsense_qa\"].label_ids\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lxh5vgHor47-"
      },
      "source": [
        "You should expect scores of approximately:\n",
        "\n",
        "* RTE: ~0.74\n",
        "* STS-B: ~0.89/0.89\n",
        "* Commonsense QA: ~0.60\n",
        "\n",
        "These aren't award winning scores, nor are our tasks chosen for multi-task training synergy, but hopefully we have demonstrated how to do multi-task training with some of Hugging Face's latest offerings!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xW8bnTgCsx5c"
      },
      "source": [
        "# An advertisement: Come check out jiant!\n",
        "\n",
        "While the above recipe works, we saw what some of the frictions were: handling multi-task data loading, coercing the Trainer to work with multi-task inputs, and handling the featurization for each of the tasks.\n",
        "\n",
        "If you are interested in more streamlined multi-task (or even single-task) fine-tuning work, we are building [jiant](https://jiant.info/), an NLP research-oriented library, built directly on the Transformers, where multi-task training is a first-class feature. `jiant` aims to facilitate cutting-edge NLP transfer learning research through broad task coverage and modular components, and we highly recommend using `jiant` for streamlined multi-task training workflows.\n",
        "\n",
        "(If you've previously worked with `jiant`, we are currently undertaking [a complete rewrite](https://github.com/jiant-dev/jiant) to better support current research needs and engineering workflows.)\n",
        "\n",
        "Click [here](https://jiant.info/) to learn more, or attend our system demo presentation at [ACL 2020](https://acl2020.org/program/accepted/#system-demonstrations)."
      ]
    }
  ]
}