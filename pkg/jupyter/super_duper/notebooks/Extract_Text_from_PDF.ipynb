{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Extract_Text_from_PDF.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2zFif1zCNRR"
      },
      "source": [
        "# Extracting Text from PDF Files\n",
        "\n",
        "Let's look at how to extract text from a PDF file, using the [`pdfx`](https://www.metachris.com/pdfx/) library in Python.\n",
        "\n",
        "First we need to install the library:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTEuwmzhCNRU"
      },
      "source": [
        "!pip install pdfx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMFBjxJcCNRV"
      },
      "source": [
        "Next, let's work with an example from the corpus in the [Rich Context leaderboard competition](https://github.com/Coleridge-Initiative/rclc/blob/master/corpus.ttl) â€“ a machine learning competition about parsing named entities from PDFs of open access research publications.\n",
        "\n",
        "The following snippets in [TTL format](https://en.wikipedia.org/wiki/Turtle_(syntax)) show a research paper `publication-7aa3d69253e37668541c` hosted on [EuropePMC](https://europepmc.org/) that has a known link to a dataset `dataset-0a7b604ab2e52411d45a` hosted by the [Centers for Disease Control and Prevention](https://wwwn.cdc.gov/nchs/nhanes/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XADsy2UvCNRV"
      },
      "source": [
        "```\n",
        ":publication-7aa3d69253e37668541c\n",
        "  rdf:type :ResearchPublication ;\n",
        "  foaf:page \"http://europepmc.org/articles/PMC3001474\"^^xsd:anyURI ;\n",
        "  dct:publisher \"PLoS One\" ;\n",
        "  dct:title \"VKORC1 common variation and bone mineral density in the Third National Health and Nutrition Examination Survey\" ;\n",
        "  dct:identifier \"10.1371/journal.pone.0015088\" ;\n",
        "  :openAccess \"http://europepmc.org/articles/PMC3001474?pdf=render\"^^xsd:anyURI ;\n",
        "  cito:citesAsDataSource :dataset-0a7b604ab2e52411d45a ;\n",
        ".\n",
        "\n",
        ":dataset-0a7b604ab2e52411d45a\n",
        "  rdf:type :Dataset ;\n",
        "  foaf:page \"https://wwwn.cdc.gov/nchs/nhanes/\"^^xsd:anyURI ;\n",
        "  dct:publisher \"Centers for Disease Control and Prevention\" ;\n",
        "  dct:title \"National Health and Nutrition Examination Survey\" ;\n",
        "  dct:alternative \"NHANES\" ;\n",
        "  dct:alternative \"NHANES I\" ;\n",
        "  dct:alternative \"NHANES II\" ;\n",
        "  dct:alternative \"NHANES III\" ;\n",
        ".\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_XVVhKGCNRW"
      },
      "source": [
        "The paper is:\n",
        "\n",
        "  * [\"VKORC1 common variation and bone mineral density in the Third National Health and Nutrition Examination Survey\"](http://europepmc.org/articles/PMC3001474); Dana C. Crawford, Kristin Brown-Gentry, Mark J. Rieder; _PLoS One_. 2010; 5(12): e15088.\n",
        "\n",
        "We'll used `pdfx` to download the PDF file directly from the open access URL:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxMJ64uKCNRW"
      },
      "source": [
        "import pdfx\n",
        "\n",
        "pdf = pdfx.PDFx(\"http://europepmc.org/articles/PMC3001474?pdf=render\")\n",
        "\n",
        "pdf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONAOSKofCNRX"
      },
      "source": [
        "Next, use the `get_text()` function to extract the text from the `pdf` object:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hdu2mtWjCNRZ"
      },
      "source": [
        "text = pdf.get_text()\n",
        "text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGdDeCBqCNRa"
      },
      "source": [
        "Now we can use `spaCy` to parse that text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Umln6WXdCNRa"
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DsBsiC9CNRb"
      },
      "source": [
        "Let's look at a dataframe of the parsed tokens:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab7CW4fZCNRc"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "cols = (\"text\", \"lemma\", \"POS\", \"explain\", \"stopword\")\n",
        "rows = []\n",
        "\n",
        "for t in doc:\n",
        "    row = [t.text, t.lemma_, t.pos_, spacy.explain(t.pos_), t.is_stop]\n",
        "    rows.append(row)\n",
        "\n",
        "df = pd.DataFrame(rows, columns=cols)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiG3Zw_gCNRd"
      },
      "source": [
        "The parsed text shows lots of characters that could be cleaned up, but for this demo, let's run *named entity resolution* in `spaCy` to extract the entities:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVOY6qaZCNRd"
      },
      "source": [
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqzvDNTjCNRe"
      },
      "source": [
        "Great, that identified multiple mentions of the _NHANES_ dataset:\n",
        "\n",
        "  * `the Third National Health and Nutrition Examination Survey` _ORG_\n",
        "  * `NHANES III` _PERSON_\n",
        "  \n",
        "The default labels aren't correct, but we could [update the Named Entity Recognizer](https://spacy.io/usage/training#ner) in `spaCy` to fix that."
      ]
    }
  ]
}