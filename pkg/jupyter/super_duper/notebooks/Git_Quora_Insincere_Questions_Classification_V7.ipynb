{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Git Quora Insincere Questions Classification_V7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1K-0-sx2usif",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d7e7bfb-b7fd-44a3-8f53-637fefbf0236"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "   \n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "print(tf.__version__)\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbT4sDDGOioj"
      },
      "source": [
        "# Loading and pre-preparation data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikGHSGNLxxGs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d5a6ddf1-3a0e-4fe6-ef22-c3617ec3e726"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEOfuJYE14LA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "66e83c04-1788-4a7a-94ec-8b4f362a47db"
      },
      "source": [
        "! ls \"/content/drive/My Drive/quora_data\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "glove.840B.300d\t\t\tparagram_300_sl999     test_data.txt\n",
            "GoogleNews-vectors-negative300\tsample_submission.csv  train.csv\n",
            "insincere.txt\t\t\tsincere.txt\t       wiki-news-300d-1M\n",
            "my_submission.csv\t\ttest.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYgWMi_9szrH"
      },
      "source": [
        "import pandas as pd \n",
        "train_data = pd.read_csv('/content/drive/My Drive/quora_data/train.csv')\n",
        "test_data = pd.read_csv('/content/drive/My Drive/quora_data/test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYCv_jFStsvZ"
      },
      "source": [
        "puncts = [\n",
        "    ',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&',\n",
        "    '/', '[', ']', '%', '=', '#', '*', '+', '\\\\', '•', '~', '@', '£',\n",
        "    '·', '_', '{', '}', '©', '^', '®', '`', '→', '°', '€', '™', '›',\n",
        "    '♥', '←', '×', '§', '″', '′', 'Â', '█', 'à', '…', '“', '★', '”',\n",
        "    '–', '●', 'â', '►', '−', '¢', '¬', '░', '¶', '↑', '±',  '▾',\n",
        "    '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '▒', '：', '⊕', '▼',\n",
        "    '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲',\n",
        "    'è', '¸', 'Ã', '⋅', '‘', '∞', '∙', '）', '↓', '、', '│', '（', '»',\n",
        "    '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø',\n",
        "    '¹', '≤', '‡', '₹', '´'\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLzSUAdQv7nc"
      },
      "source": [
        "abbreviations = {\n",
        "    \"ain't\": \"is not\",\n",
        "    \"aren't\": \"are not\",\n",
        "    \"can't\": \"cannot\",\n",
        "    \"'cause\": \"because\",\n",
        "    \"could've\": \"could have\",\n",
        "    \"couldn't\": \"could not\",\n",
        "    \"didn't\": \"did not\",\n",
        "    \"doesn't\": \"does not\",\n",
        "    \"don't\": \"do not\",\n",
        "    \"hadn't\": \"had not\",\n",
        "    \"hasn't\": \"has not\",\n",
        "    \"haven't\": \"have not\",\n",
        "    \"he'd\": \"he would\",\n",
        "    \"he'll\": \"he will\",\n",
        "    \"he's\": \"he is\",\n",
        "    \"how'd\": \"how did\",\n",
        "    \"how'd'y\": \"how do you\",\n",
        "    \"how'll\": \"how will\",\n",
        "    \"how's\": \"how is\",\n",
        "    \"I'd\": \"I would\",\n",
        "    \"I'd've\": \"I would have\",\n",
        "    \"I'll\": \"I will\",\n",
        "    \"I'll've\": \"I will have\",\n",
        "    \"I'm\": \"I am\",\n",
        "    \"I've\": \"I have\",\n",
        "    \"i'd\": \"i would\",\n",
        "    \"i'd've\": \"i would have\",\n",
        "    \"i'll\": \"i will\",\n",
        "    \"i'll've\": \"i will have\",\n",
        "    \"i'm\": \"i am\",\n",
        "    \"i've\": \"i have\",\n",
        "    \"isn't\": \"is not\",\n",
        "    \"it'd\": \"it would\",\n",
        "    \"it'd've\": \"it would have\",\n",
        "    \"it'll\": \"it will\",\n",
        "    \"it'll've\": \"it will have\",\n",
        "    \"it's\": \"it is\",\n",
        "    \"let's\": \"let us\",\n",
        "    \"ma'am\": \"madam\",\n",
        "    \"mayn't\": \"may not\",\n",
        "    \"might've\": \"might have\",\n",
        "    \"mightn't\": \"might not\",\n",
        "    \"mightn't've\": \"might not have\",\n",
        "    \"must've\": \"must have\",\n",
        "    \"mustn't\": \"must not\",\n",
        "    \"mustn't've\": \"must not have\",\n",
        "    \"needn't\": \"need not\",\n",
        "    \"needn't've\": \"need not have\",\n",
        "    \"o'clock\": \"of the clock\",\n",
        "    \"oughtn't\": \"ought not\",\n",
        "    \"oughtn't've\": \"ought not have\",\n",
        "    \"shan't\": \"shall not\",\n",
        "    \"sha'n't\": \"shall not\",\n",
        "    \"shan't've\": \"shall not have\",\n",
        "    \"she'd\": \"she would\",\n",
        "    \"she'd've\": \"she would have\",\n",
        "    \"she'll\": \"she will\",\n",
        "    \"she'll've\": \"she will have\",\n",
        "    \"she's\": \"she is\",\n",
        "    \"should've\": \"should have\",\n",
        "    \"shouldn't\": \"should not\",\n",
        "    \"shouldn't've\": \"should not have\",\n",
        "    \"so've\": \"so have\",\n",
        "    \"so's\": \"so as\",\n",
        "    \"this's\": \"this is\",\n",
        "    \"that'd\": \"that would\",\n",
        "    \"that'd've\": \"that would have\",\n",
        "    \"that's\": \"that is\",\n",
        "    \"there'd\": \"there would\",\n",
        "    \"there'd've\": \"there would have\",\n",
        "    \"there's\": \"there is\",\n",
        "    \"here's\": \"here is\",\n",
        "    \"they'd\": \"they would\",\n",
        "     \"they'd've\": \"they would have\",\n",
        "    \"they'll\": \"they will\",\n",
        "    \"they'll've\": \"they will have\",\n",
        "    \"they're\": \"they are\",\n",
        "    \"they've\": \"they have\",\n",
        "    \"to've\": \"to have\",\n",
        "    \"wasn't\": \"was not\",\n",
        "    \"we'd\": \"we would\",\n",
        "    \"we'd've\": \"we would have\",\n",
        "    \"we'll\": \"we will\",\n",
        "    \"we'll've\": \"we will have\",\n",
        "    \"we're\": \"we are\",\n",
        "    \"we've\": \"we have\",\n",
        "    \"weren't\": \"were not\",\n",
        "    \"what'll\": \"what will\",\n",
        "    \"what'll've\": \"what will have\",\n",
        "    \"what're\": \"what are\",\n",
        "    \"what's\": \"what is\",\n",
        "    \"what've\": \"what have\",\n",
        "    \"when's\": \"when is\",\n",
        "    \"when've\": \"when have\",\n",
        "    \"where'd\": \"where did\",\n",
        "    \"where's\": \"where is\",\n",
        "    \"where've\": \"where have\",\n",
        "     \"who'll\": \"who will\",\n",
        "    \"who'll've\": \"who will have\",\n",
        "    \"who's\": \"who is\",\n",
        "    \"who've\": \"who have\",\n",
        "    \"why's\": \"why is\",\n",
        "    \"why've\": \"why have\",\n",
        "    \"will've\": \"will have\",\n",
        "    \"won't\": \"will not\",\n",
        "    \"won't've\": \"will not have\",\n",
        "    \"would've\": \"would have\",\n",
        "    \"wouldn't\": \"would not\",\n",
        "    \"wouldn't've\": \"would not have\",\n",
        "    \"y'all\": \"you all\",\n",
        "    \"y'all'd\": \"you all would\",\n",
        "    \"y'all'd've\": \"you all would have\",\n",
        "    \"y'all're\": \"you all are\",\n",
        "    \"y'all've\": \"you all have\",\n",
        "    \"you'd\": \"you would\",\n",
        "    \"you'd've\": \"you would have\",\n",
        "    \"you'll\": \"you will\",\n",
        "    \"you'll've\": \"you will have\",\n",
        "    \"you're\": \"you are\",\n",
        "    \"you've\": \"you have\",\n",
        "    \"who'd\": \"who would\",\n",
        "    \"who're\": \"who are\",\n",
        "    \"'re\": \" are\",\n",
        "    \"tryin'\": \"trying\",\n",
        "    \"doesn'\": \"does not\",\n",
        "    'howdo': 'how do',\n",
        "    'whatare': 'what are',\n",
        "    'howcan': 'how can',\n",
        "    'howmuch': 'how much',\n",
        "    'howmany': 'how many',\n",
        "    'whydo': 'why do',\n",
        "    'doI': 'do I',\n",
        "    'theBest': 'the best',\n",
        "    'howdoes': 'how does',\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gljc4m_Wt50S"
      },
      "source": [
        "def clean(df):\n",
        "    df = clean_lower(df)\n",
        "    #df = clean_unicode(df)\n",
        "    df = clean_math(df)\n",
        "    df = clean_abbreviation(df, abbreviations)\n",
        "    #df = clean_spells(df, spells)\n",
        "    #df = clean_language(df)\n",
        "    df = clean_puncts(df, puncts)\n",
        "    df = clean_space(df)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syl1nHBZxJ8r"
      },
      "source": [
        "def clean_lower(df):\n",
        "    df[\"question_text\"] = df[\"question_text\"].apply(lambda x: x.lower())\n",
        "    return df\n",
        "\n",
        "def clean_puncts(df, puncts):\n",
        "    df['question_text'] = df['question_text'].apply(lambda x: _clean_puncts(x, puncts))\n",
        "    return df\n",
        "    \n",
        "def _clean_puncts(x, puncts):\n",
        "    x = str(x)\n",
        "    # added space around puncts after replace\n",
        "    for punct in puncts:\n",
        "        if punct in x:\n",
        "            x = x.replace(punct, f' {punct} ')\n",
        "    return x\n",
        "def clean_abbreviation(df, abbreviations):\n",
        "    compiled_abbreviation = re.compile('(%s)' % '|'.join(abbreviations.keys()))\n",
        "    def replace(match):\n",
        "        return abbreviations[match.group(0)]\n",
        "    df['question_text'] = df[\"question_text\"].apply(\n",
        "        lambda x: _clean_abreviation(x, compiled_abbreviation, replace)\n",
        "    )\n",
        "    return df\n",
        "    \n",
        "def _clean_abreviation(x, compiled_re, replace):\n",
        "    return compiled_re.sub(replace, x)\n",
        "\n",
        "def clean_space(df):\n",
        "    compiled_re = re.compile(r\"\\s+\")\n",
        "    df['question_text'] = df[\"question_text\"].apply(lambda x: _clean_space(x, compiled_re))\n",
        "    return df\n",
        "def _clean_space(x, compiled_re):\n",
        "    return compiled_re.sub(\" \", x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8yWkEcaJAI3"
      },
      "source": [
        "def clean_math(df):\n",
        "    math_puncts = 'θπα÷⁴≠β²¾∫≥⇒¬∠＝∑Φ√½¼'\n",
        "    math_puncts_long = [r'\\\\frac', r'\\[math\\]', r'\\[/math\\]', r'\\\\lim']\n",
        "    compiled_math = re.compile('(%s)' % '|'.join(math_puncts))\n",
        "    compiled_math_long = re.compile('(%s)' % '|'.join(math_puncts_long))\n",
        "    df['question_text'] = df['question_text'].apply(lambda x: _clean_math(x, compiled_math_long))\n",
        "    df['question_text'] = df['question_text'].apply(lambda x: _clean_math(x, compiled_math))\n",
        "    return df\n",
        "\n",
        "def _clean_math(x, compiled_re):\n",
        "    return compiled_re.sub(' <math> ', x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVL1W0epzCqD"
      },
      "source": [
        "from multiprocessing import Pool\n",
        "import re\n",
        "\n",
        "num_cores = 2\n",
        "def df_parallelize_run(df, func, num_cores=2):\n",
        "    df_split = np.array_split(df, num_cores)\n",
        "    pool = Pool(num_cores)\n",
        "    df = pd.concat(pool.map(func, df_split))\n",
        "    pool.close()\n",
        "    pool.join()\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0mp9YmAx4oI"
      },
      "source": [
        "train_data = df_parallelize_run(train_data, clean)\n",
        "test_data = df_parallelize_run(test_data, clean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dvxz4oCs-21d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c4c3174b-2e21-4247-a941-96fbb53d85da"
      },
      "source": [
        "print(\"Train shape : \", train_data.shape)\n",
        "print(\"Test shape : \", test_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train shape :  (1306122, 3)\n",
            "Test shape :  (375806, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aao8vD19ywxD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ead10c1a-f2e4-432a-d08c-5920d5d1d971"
      },
      "source": [
        "train_data.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['qid', 'question_text', 'target'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuU7XRC5wR0E"
      },
      "source": [
        "train_data= train_data.drop(['qid'], axis=1)\n",
        "test_data= test_data.drop(['qid'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMvImAvuzP0l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d377481f-9cfd-4ba5-a45b-98ba705d49a2"
      },
      "source": [
        "train_data.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "question_text    0\n",
              "target           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_ZRqXBlnmxM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "01347be4-cff9-47a8-9019-f3ebc1a71bf0"
      },
      "source": [
        "test_data.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "question_text    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4EWeIknzL5w"
      },
      "source": [
        "#from collections import defaultdict\n",
        "train1_data = train_data[train_data[\"target\"]==1]\n",
        "train0_data = train_data[train_data[\"target\"]==0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJNMvovpzakQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a6dc3104-39bf-47a3-cdf3-399492149368"
      },
      "source": [
        "sincere_data = train0_data.drop([\"target\"], axis=1)\n",
        "insincere_data = train1_data.drop([\"target\"], axis=1)\n",
        "type(sincere_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmocQIpGYYBr"
      },
      "source": [
        "#Split data to two classes:\n",
        "\n",
        "\n",
        "> 1. Sincere data >>> 0\n",
        "2. Insincere data >>> 1 \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8uNONjFL8fM"
      },
      "source": [
        "#Sincere_class\n",
        "#with open('sincere.txt', \"w\") as f3:\n",
        "#      [ f3.write((row['question_text'])+'\\n') for index, row in sincere_data.iterrows()]\n",
        "#f3.close()\n",
        "\n",
        "#Insincere_class\n",
        "#with open('insincere.txt', \"w\") as f4:\n",
        "#      [ f4.write((row['question_text'])+'\\n') for index, row in insincere_data.iterrows()]\n",
        "#f4.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OW7q3tD2RNln"
      },
      "source": [
        "#!head \"/content/drive/My Drive/quora_data/test_data.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXCouFfIoRed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "ea925987-c298-4f2d-fc9e-b8c1dba48425"
      },
      "source": [
        "!head '/content/drive/My Drive/quora_data/sincere.txt'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "how did quebec nationalists see their province as a nation in the 1960s ? \n",
            "do you have an adopted dog , how would you encourage people to adopt and not shop ? \n",
            "why does velocity affect time ? does velocity affect space geometry ? \n",
            "how did otto von guericke used the magdeburg hemispheres ? \n",
            "can i convert montra helicon d to a mountain bike by just changing the tyres ? \n",
            "is gaza slowly becoming auschwitz , dachau or treblinka for palestinians ? \n",
            "why does quora automatically ban conservative opinions when reported , but does not do the same for liberal views ? \n",
            "is it crazy if i wash or wipe my groceries off ? germs are everywhere . \n",
            "is there such a thing as dressing moderately , and if so , how is that different than dressing modestly ? \n",
            "is it just me or have you ever been in this phase wherein you became ignorant to the people you once loved , completely disregarding their feelings / lives so you get to have something go your way and feel temporarily at ease . how did things change ? \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79ght2d-obbo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "281c09a6-de12-4dde-91cd-ceecb8473a3d"
      },
      "source": [
        "!head '/content/drive/My Drive/quora_data/insincere.txt'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "has the united states become the largest dictatorship in the world ? \n",
            "which babies are more sweeter to their parents ? dark skin babies or light skin babies ? \n",
            "if blacks support school choice and mandatory sentencing for criminals why do not they vote republican ? \n",
            "i am gay boy and i love my cousin ( boy ) . he is sexy , but i dont know what to do . he is hot , and i want to see his di * * . what should i do ? \n",
            "which races have the smallest penis ? \n",
            "why do females find penises ugly ? \n",
            "how do i marry an american woman for a green card ? how much do they charge ? \n",
            "why do europeans say they are the superior race , when in fact it took them over 2 , 000 years until mid 19th century to surpass china ' s largest economy ? \n",
            "did julius caesar bring a tyrannosaurus rex on his campaigns to frighten the celts into submission ? \n",
            "in what manner has republican backing of ' states rights ' been hypocritical and what ways have they actually restricted the ability of states to make their own laws ? \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mgon285606vv"
      },
      "source": [
        "#!cp -R /content/sincere.txt \"/content/drive/My Drive/quora_data\"\n",
        "#!cp -R /content/insincere.txt \"/content/drive/My Drive/quora_data\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaKmNEYsEVbT"
      },
      "source": [
        "! head \"/content/drive/My Drive/quora_data/sincere.txt\" -n 20000 > sincere_small.txt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e72wmMyMMHh1"
      },
      "source": [
        "! head \"/content/drive/My Drive/quora_data/insincere.txt\" -n 50000 > insincere_small.txt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KL1-wD1L9FBY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c978ef40-df4b-4f57-fd51-91a061f4fe40"
      },
      "source": [
        "DIRECTORY_URL = '/content/'\n",
        "FILE_NAMES = ['sincere_small.txt', 'insincere_small.txt']\n",
        "\n",
        "for name in FILE_NAMES:\n",
        "  text_dir = DIRECTORY_URL+name\n",
        "  print(text_dir)\n",
        "  \n",
        "parent_dir = os.path.dirname(text_dir)\n",
        "\n",
        "parent_dir\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/sincere_small.txt\n",
            "/content/insincere_small.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNt-dG6689UG"
      },
      "source": [
        "def labeler(example, index):\n",
        "  return example, tf.cast(index, tf.int64)  \n",
        "\n",
        "labeled_data_sets = []\n",
        "\n",
        "for i, file_name in enumerate(FILE_NAMES):\n",
        "  lines_dataset = tf.data.TextLineDataset(os.path.join(parent_dir, file_name))\n",
        "  labeled_dataset = lines_dataset.map(lambda ex: labeler(ex, i))\n",
        "  labeled_data_sets.append(labeled_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJasZLMY-XIW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "768d7ef0-92db-4d0a-b653-c3527712fcdd"
      },
      "source": [
        "labeled_data_sets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<MapDataset shapes: ((), ()), types: (tf.string, tf.int64)>,\n",
              " <MapDataset shapes: ((), ()), types: (tf.string, tf.int64)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e_fK_pC-pMo"
      },
      "source": [
        "BUFFER_SIZE = 50000\n",
        "#BUFFER_SIZE = 5000\n",
        "BATCH_SIZE = 64\n",
        "#TAKE_SIZE = 5000\n",
        "TAKE_SIZE = 2000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWb_xna5-s_4"
      },
      "source": [
        "all_labeled_data = labeled_data_sets[0]\n",
        "for labeled_dataset in labeled_data_sets[1:]:\n",
        "  all_labeled_data = all_labeled_data.concatenate(labeled_dataset)\n",
        "  \n",
        "all_labeled_data = all_labeled_data.shuffle(\n",
        "    BUFFER_SIZE, reshuffle_each_iteration=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJWGaG39-1AH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "45c1341b-f4a1-4dab-f6f4-9cfdf18ed6c3"
      },
      "source": [
        "for ex in all_labeled_data.take(5):\n",
        "  print(ex)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: id=10697273, shape=(), dtype=string, numpy=b'what is the minimum user base required for quora to launch in another language ? '>, <tf.Tensor: id=10697274, shape=(), dtype=int64, numpy=0>)\n",
            "(<tf.Tensor: id=10697275, shape=(), dtype=string, numpy=b'why most of guys lie to get sex from girls ? '>, <tf.Tensor: id=10697276, shape=(), dtype=int64, numpy=1>)\n",
            "(<tf.Tensor: id=10697277, shape=(), dtype=string, numpy=b'why is a man with no testicles frowned upon by both men & women ? '>, <tf.Tensor: id=10697278, shape=(), dtype=int64, numpy=1>)\n",
            "(<tf.Tensor: id=10697279, shape=(), dtype=string, numpy=b'what should i do as i want to travel japan ? '>, <tf.Tensor: id=10697280, shape=(), dtype=int64, numpy=0>)\n",
            "(<tf.Tensor: id=10697281, shape=(), dtype=string, numpy=b'why do iranian people get offended when they are mistaken as arab ? do not they speak arabic language ? '>, <tf.Tensor: id=10697282, shape=(), dtype=int64, numpy=1>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7nV8DiGkb_G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c4e8fdf1-d4d7-4ffc-d401-04d105344f69"
      },
      "source": [
        "type(all_labeled_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.ShuffleDataset"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Plkd7_8__Dy1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e86cfb3e-726b-4b73-f029-343eb3f480d8"
      },
      "source": [
        "tokenizer = tfds.features.text.Tokenizer()\n",
        "\n",
        "vocabulary_set = set()\n",
        "for text_tensor, _ in all_labeled_data:\n",
        "  some_tokens = tokenizer.tokenize(text_tensor.numpy())\n",
        "  vocabulary_set.update(some_tokens)\n",
        "\n",
        "vocab_size = len(vocabulary_set)\n",
        "vocab_size "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39749"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN8S6uzcVuGF"
      },
      "source": [
        "Note: The Tokenization process takes long time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIts4B37_SUS"
      },
      "source": [
        "encoder = tfds.features.text.TokenTextEncoder(vocabulary_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M51T2G33ZM-_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d188e817-2348-4187-dbe1-525233da0c6b"
      },
      "source": [
        "example_text = next(iter(all_labeled_data))[0].numpy()\n",
        "print(example_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'what is the minimum user base required for quora to launch in another language ? '\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1utzpPGz_vjh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "402b226a-ec88-4751-f382-03abe24d3e50"
      },
      "source": [
        "encoded_example = encoder.encode(example_text)\n",
        "print(encoded_example)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[13200, 14300, 26682, 34874, 22165, 31995, 19065, 20070, 15830, 22073, 24087, 2332, 18968, 35668]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNB7Lu-w_vTy"
      },
      "source": [
        "def encode(text_tensor, label):\n",
        "  encoded_text = encoder.encode(text_tensor.numpy())\n",
        "  return encoded_text, label\n",
        "\n",
        "def encode_map_fn(text, label):\n",
        "  return tf.py_function(encode, inp=[text, label], Tout=(tf.int64, tf.int64))\n",
        "\n",
        "all_encoded_data = all_labeled_data.map(encode_map_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zYH0Hk0VJH1"
      },
      "source": [
        "#Preparing Test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UM8A8khw8Yh"
      },
      "source": [
        "lineList = [line.rstrip('\\n') for line in open('/content/drive/My Drive/quora_data/test_data.txt')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHUe-09ydyeA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7278084e-c5e2-4af4-e3b2-059c5d0251be"
      },
      "source": [
        "len(lineList)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "375806"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkpnWCgEca18"
      },
      "source": [
        "def pad_to_size(vec, size):\n",
        "  zeros = [0] * (size - len(vec))\n",
        "  vec.extend(zeros)\n",
        "  return vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zVl56zcaKJj"
      },
      "source": [
        "train_data = all_encoded_data.skip(TAKE_SIZE).shuffle(BUFFER_SIZE)\n",
        "train_data = train_data.padded_batch(BATCH_SIZE, padded_shapes=([-1],[]))\n",
        "\n",
        "val_data = all_encoded_data.take(TAKE_SIZE)\n",
        "val_data = val_data.padded_batch(BATCH_SIZE, padded_shapes=([-1],[]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQGAGbnsCUJz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7d686876-b6fd-4884-a910-928972a24535"
      },
      "source": [
        "sample_text, sample_labels = next(iter(val_data))\n",
        "\n",
        "sample_labels.numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
              "       1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukttS6JqCm20"
      },
      "source": [
        "vocab_size += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JkBkOi7N_bk"
      },
      "source": [
        "# First Model using RNN (Recurrent neural networks)\n",
        " \n",
        "> 1. One LSTM layer.\n",
        "2. Two LSTM layer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAneJVO4CpB3"
      },
      "source": [
        "model = tf.keras.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROVm1MPKBOdJ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6N6fZGcRCtnO"
      },
      "source": [
        "model.add(tf.keras.layers.Embedding(vocab_size, 64))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr6KnWl5Yho4"
      },
      "source": [
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3DWY33ZCxLe"
      },
      "source": [
        " # One or more dense layers.\n",
        "# Edit the list in the `for` line to experiment with layer sizes.\n",
        "for units in [64, 64]:\n",
        "  model.add(tf.keras.layers.Dense(units, activation='relu'))\n",
        "\n",
        "# Output layer. The first argument is the number of labels.\n",
        "model.add(tf.keras.layers.Dense(2, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZOdQn32oCFD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "30ffec37-a16d-40f4-f9fb-9f22e05a9095"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, None, 64)          2544000   \n",
            "_________________________________________________________________\n",
            "bidirectional_7 (Bidirection (None, 128)               66048     \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 2,622,594\n",
            "Trainable params: 2,622,594\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7qTNq6uCzuL"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPywrjZFC3_F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "0a6495e2-8c57-4fbc-8aa4-36c00da2a068"
      },
      "source": [
        "history= model.fit(train_data, epochs=3, validation_data=val_data)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1063/1063 [==============================] - 100s 94ms/step - loss: 0.2890 - accuracy: 0.8830 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1063/1063 [==============================] - 88s 83ms/step - loss: 0.1925 - accuracy: 0.9292 - val_loss: 0.3030 - val_accuracy: 0.8825\n",
            "Epoch 3/3\n",
            "1063/1063 [==============================] - 88s 83ms/step - loss: 0.1468 - accuracy: 0.9475 - val_loss: 0.3919 - val_accuracy: 0.8650\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cOTFp90O-P0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "717f5e33-7c4a-4d8b-e21c-21b8ebc7a52f"
      },
      "source": [
        "eval_loss, eval_acc = model.evaluate(val_data)\n",
        "\n",
        "print('\\nEval loss: {:.3f}, Eval accuracy: {:.3f}'.format(eval_loss, eval_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 4s 115ms/step - loss: 0.3919 - accuracy: 0.8650\n",
            "\n",
            "Eval loss: 0.392, Eval accuracy: 0.865\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFoSID_WO0NY"
      },
      "source": [
        "# Second Model (Two LSTM layers):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD7_ZNU_kKI3"
      },
      "source": [
        "model_2= tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(encoder.vocab_size, 64),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOOVF8TXkmLd"
      },
      "source": [
        "model_2.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDjGPZBJksaq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "aaa54408-5e6d-43c6-8d57-f47c6b88eb00"
      },
      "source": [
        "history = model_2.fit(train_data, epochs=3,\n",
        "                    validation_data=val_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1063/1063 [==============================] - 125s 118ms/step - loss: 0.3010 - accuracy: 0.8816 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1063/1063 [==============================] - 110s 104ms/step - loss: 0.1989 - accuracy: 0.9300 - val_loss: 0.3212 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1063/1063 [==============================] - 110s 104ms/step - loss: 0.1462 - accuracy: 0.9497 - val_loss: 0.3286 - val_accuracy: 0.8770\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fwY_MvdnCL3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e31a45a2-2864-48eb-9073-bdb294c963d4"
      },
      "source": [
        "eval_loss, eval_acc = model_2.evaluate(val_data)\n",
        "\n",
        "print('\\nEval loss: {:.3f}, Eval accuracy: {:.3f}'.format(eval_loss, eval_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 4s 128ms/step - loss: 0.3286 - accuracy: 0.8770\n",
            "\n",
            "Eval loss: 0.329, Eval accuracy: 0.877\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4PsudloPWcG"
      },
      "source": [
        "def prepare_test(sen, pad=True):\n",
        "  encoded_sample_pred_text = encoder.encode(sen)\n",
        "  if pad:\n",
        "    encoded_sample_pred_text = pad_to_size(encoded_sample_pred_text, 64)\n",
        "    \n",
        "  encoded_sample_pred_text = tf.cast(encoded_sample_pred_text, tf.int64)\n",
        "  return (encoded_sample_pred_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqFhYuKiD44r"
      },
      "source": [
        "test_data = [prepare_test(sen=lineList[i], pad=True) for i in range(len(lineList))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saEMx8rB9hz5"
      },
      "source": [
        "def get_label(prediction):\n",
        "  if prediction[0][0] > prediction[0][1]:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWrcKU9f9vGF"
      },
      "source": [
        "def predict_senetneces_v2(sen, pad):\n",
        "  encoded_sample_pred_text = encoder.encode(sen)\n",
        "  if pad:\n",
        "    encoded_sample_pred_text = pad_to_size(encoded_sample_pred_text, 64)\n",
        "    \n",
        "  encoded_sample_pred_text = tf.cast(encoded_sample_pred_text, tf.int64)\n",
        "  predictions = model.predict(tf.expand_dims(encoded_sample_pred_text, 0))\n",
        "\n",
        "  return (predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHTWdwkeOcyb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "912fdc6a-03e8-488f-ac7d-5aa819af5c74"
      },
      "source": [
        "test1= \"why does velocity affect time?\"\n",
        "pred_test= predict_senetneces_v2(test1, pad= False)\n",
        "pred_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9776342 , 0.02236583]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZi7wWxzXGx0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "948e827e-1762-476a-e323-d0b975e84fda"
      },
      "source": [
        "get_label(pred_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCLhXrFCgTKH"
      },
      "source": [
        "test2= \"White people and black people \"\n",
        "pred_test2= predict_senetneces_v2(test2, pad= False)\n",
        "pred_test2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEFLeiZLgzrK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c857f0c6-7aab-4386-92c2-7088c3c88cbf"
      },
      "source": [
        "get_label(pred_test2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pjQc9VK936X"
      },
      "source": [
        "predictions = [predict_senetneces_v2(sen=lineList[i], pad=True) for i in range(len(lineList[:10000]))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd5p_uBkOu29"
      },
      "source": [
        "predictions[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP7FwVypnEQ_"
      },
      "source": [
        "pred_label=[get_label(prediction=prediction) for prediction in predictions]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QQgvLqhxDul",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f382d05d-0d32-4453-bc12-156ea5699565"
      },
      "source": [
        "sample_text, sample_labels = next(iter(val_data))\n",
        "\n",
        "sample_labels.numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
              "       1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HImpfT-Wwdqu"
      },
      "source": [
        "y_val=[]\n",
        "for val in sample_labels.numpy():\n",
        "    y_val.append(val)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9t1yxBRL5MIb"
      },
      "source": [
        "def get_label2(prediction):\n",
        "  if prediction[0] > prediction[1]:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVXZTagDsGz2"
      },
      "source": [
        "y_pred= model.predict(val_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPJ_aP9B43Nl"
      },
      "source": [
        "y_pred=[get_label2(y) for y in y_pred]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNjSthYMnDcE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "814e0131-250c-4030-99f5-4b8c2d445acb"
      },
      "source": [
        "print(y_pred[:100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFI0pvTuSD4e"
      },
      "source": [
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLQ7gTouSMrt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "af04cf51-7a98-4e93-be2c-135cf874c138"
      },
      "source": [
        "score = f1_score(y_pred[:64], y_val)\n",
        "score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9411764705882352"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 271
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a56wkE_zOF0u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}