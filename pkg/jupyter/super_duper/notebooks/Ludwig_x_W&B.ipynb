{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ludwig x W&B.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YuWG703vf6O"
      },
      "source": [
        "#Deep Learning for Developers with Ludwig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVGL9YQcvpA9"
      },
      "source": [
        "<a href=\"https://imgur.com/exy6IQj\"><img src=\"https://i.imgur.com/exy6IQj.jpg\" title=\"source: imgur.com\" /></a>\n",
        "\n",
        "Ludwig is a toolbox built on top of TensorFlow that allows users to train and test deep learning models without the need to write code.\n",
        "\n",
        "All you need to provide is a dataset file containing your data, a list of columns to use as inputs, and a list of columns to use as outputs, Ludwig will do the rest. Simple commands can be used to train models both locally and in a distributed way, and to use them to predict new data.\n",
        "\n",
        "A programmatic API is also available in order to use Ludwig from your python code. A suite of visualization tools allows you to analyze models' training and test performance and to compare them.\n",
        "\n",
        "### Why use W&B\n",
        "\n",
        "Think of W&B like GitHub for machine learning models — save machine learning experiments to your private, hosted dashboard. Experiment quickly with the confidence that all the versions of your models are saved for you, no matter where you're running your scripts.\n",
        "\n",
        "W&B lightweight integrations works with any Python script, and all you need to do is sign up for a free W&B account to start tracking and visualizing your models.\n",
        "\n",
        "We've instrumented the the Ludwig repo to automatically log training and evaluation metrics to W&B at each logging step.\n",
        "\n",
        "### Using W&B with Ludwig\n",
        "To use Ludwig’s new Weights and Biases integration, just add the `–wandb` parameter to your ludwig commands. This will allow training and experiments to be tracked and interacted with on the corresponding Weights and Biases page.\n",
        "\n",
        "And here an example:\n",
        "`ludwig train --dataset <DATASET_PATH> --config_file <CONFIG_FILE_PATH> --wandb`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymCLdZvUwmX8"
      },
      "source": [
        "# Installation and demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdI2UgZbEePT"
      },
      "source": [
        "! pip install git+http://github.com/uber/ludwig.git -qq\n",
        "! pip install ludwig[serve] -qq\n",
        "! pip install wandb -qq "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62KTErutC2SN"
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8HIcSwSwtLs"
      },
      "source": [
        "### Text Classification\n",
        "\n",
        "Text classification also known as text tagging or text categorization is the process of categorizing text into organized groups. By using Natural Language Processing (NLP), text classifiers can automatically analyze text and then assign a set of pre-defined tags or categories based on its content.\n",
        "\n",
        "Unstructured text is everywhere, such as emails, chat conversations, websites, and social media but it’s hard to extract value from this data unless it’s organized in a certain way. Doing so used to be a difficult and expensive process since it required spending time and resources to manually sort the data or creating handcrafted rules that are difficult to maintain. \n",
        "\n",
        "Let's build a text classifier using ludwig.\n",
        "\n",
        "### Kaggle's AGNews Dataset\n",
        "AG is a collection of more than 1 million news articles. News articles have been gathered from more than 2000  news sources by ComeToMyHead in more than 1 year of activity. ComeToMyHead is an academic news search engine which has been running since July, 2004. The dataset is provided by the academic comunity for research purposes in data mining (clustering, classification, etc), information retrieval (ranking, search, etc), xml, data compression, data streaming, and any other non-commercial activity. For more information, please refer to the link http://www.di.unipi.it/~gulli/AG_corpus_of_news_articles.html .\n",
        "\n",
        "The articles are divided into 4 classes:\n",
        "```\n",
        "World\n",
        "Sports\n",
        "Business\n",
        "Sci/Tech\n",
        "```\n",
        "Let's download the dataset. The dataset from kaggle has been pre-processed and uploaded to W&B as dataset artifact. It can be downloaded using the API that comes associated with each artifact."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4gOi3oBLKmA"
      },
      "source": [
        "import wandb\n",
        "run = wandb.init()\n",
        "\n",
        "artifact = run.use_artifact('authors/Classification/AGNews:v0', type='dataset')\n",
        "artifact_dir = artifact.download()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5lgKtjJL2Jr"
      },
      "source": [
        "# Move the files to /content\n",
        "!mv /content/artifacts/AGNews:v0/final_train.csv  /content/\n",
        "!mv /content/artifacts/AGNews:v0/final_test.csv  /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jC1PZ7AA1RjC"
      },
      "source": [
        "id_to_label = {\n",
        "   1: 'World', 2: 'Sports', 3: 'Business', 4: 'Sci/Tech'\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNi-TB-kzJyk"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_csv = pd.read_csv(\"final_train.csv\")\n",
        "train_csv.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNoybfJ-o5-y"
      },
      "source": [
        "## Experiment Tracking\n",
        "Ludwig comes with native support for weights and biases which enables you to log the metrics while experimenting witht model training so that you don't lose your progress. These metrics can be viewed in you W&B dashboard. To enable W&B logging you need to pass an additional `--wandb` argument for training.\n",
        "By default you are given 3 choices during runtime:\n",
        "\n",
        "* (1) Create a W&B account\n",
        "* (2) Use an existing W&B account\n",
        "* (3) Don't visualize my results\n",
        "\n",
        "After selecting option 2, you'll be redirected to authentication page, after which the training and logging starts.\n",
        "[Here's the dashboard](https://app.wandb.ai/authors/experiment/runs/yjra94mp?workspace=user-cayush) for the following run\n",
        "\n",
        "## Train \n",
        "This command lets you train a model from your data. You can call it with:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-jIkcuk0K17"
      },
      "source": [
        "!ludwig train --dataset final_train.csv --config \\\n",
        "\"{ input_features: [{name: Title, type: text}, {name: Description, type: text}], \\\n",
        "   output_features: [{name: ClassIndex, type: category}] }\" \\\n",
        " -g 0 --wandb --experiment_name \"Classification\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hhIq3A5tBF_"
      },
      "source": [
        "You get all of these detailed insights about the training process in the W&B dashboard:\n",
        "\n",
        "\n",
        "\n",
        "*  ## Training and system usage Metrics\n",
        "\n",
        "<a href=\"https://imgur.com/PT1FE4V\"><img src=\"https://i.imgur.com/PT1FE4V.gif\" title=\"source: imgur.com\" /></a>\n",
        "\n",
        "* ## Tensorboard Metrics\n",
        "<a href=\"https://imgur.com/uZzSe9J\"><img src=\"https://i.imgur.com/uZzSe9J.gif\" title=\"source: imgur.com\" /></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCbRBLU9-jZL"
      },
      "source": [
        "## Predict\n",
        "This command lets you use a previously trained model to predict on new data. You can call it with:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFC-Sud4-iDh"
      },
      "source": [
        "!ludwig predict --dataset final_test.csv \\\n",
        "--model_path results/Classification_run/model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcAO2hc--W-l"
      },
      "source": [
        "On performing prediction, you get the following files in both csv and npy format:\n",
        "* Class Index predictions \n",
        "* Class Index probalities for each class\n",
        "* Highest Class Index probability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVh_5RmZRlck"
      },
      "source": [
        "prediction = pd.read_csv('results/ClassIndex_predictions.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxMNj_v1R1aQ"
      },
      "source": [
        "# Check on some random examples\n",
        "test_dataset = pd.read_csv('final_test.csv')\n",
        "index = [100,900,575,1100,1500]\n",
        "for i in index:\n",
        "  print(test_dataset.iloc[i], '\\n Prediction -> ', id_to_label[prediction.iloc[i][0]], '\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GD8RTS4UcZ_"
      },
      "source": [
        "## Evaluate\n",
        "This command lets you use a previously trained model to predict on new data and evaluate the performance of the prediction compared to ground truth. You can call it with:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gUKSUzhVH1f"
      },
      "source": [
        "!ludwig evaluate --dataset final_test.csv \\\n",
        "--model_path results/Classification_run/model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3zYHD_7Aac7"
      },
      "source": [
        "Running evaluation saves the evaluation metrics in the results folder in json format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU5JijKD5xm7"
      },
      "source": [
        "# Visualize\n",
        "Ludwig comes with many visualization options. If you want to look at the learning curves of your model for instance, run:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP_B8am553_g"
      },
      "source": [
        "!ludwig visualize \\\n",
        "--visualization learning_curves \\\n",
        "--training_statistics results/Classification_run/training_statistics.json \\\n",
        "--output_directory results/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5RF54kyB29t"
      },
      "source": [
        "using `--output_directory ` argument saves the outputs in the desired directory instead of directly displaying them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTmmfv2Rg0YF"
      },
      "source": [
        "## Serving\n",
        "This command lets you load a pre-trained model and serve it on an http server. It uses port 8000 by default.\n",
        "Once the server is up and running, you can pass the parameters defined the model configuration as inputs. \n",
        "Example:\n",
        "```\n",
        "curl http://0.0.0.0:8000/predict -X POST -F 'Title=Science' -F 'Description=Techology'\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHluQ0jUVOoC"
      },
      "source": [
        "!ludwig serve --model_path results/Classification_run/model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTRIEjoRFDNK"
      },
      "source": [
        "# Save model artifact\n",
        "Wandb allows you to save your datasets, models and entire directories along with a graph that represents the relation b/w the runs and the logged files. These logged files/directories are termed as Artifacts.  As Ludwig's trained models consist of multiple files, we'll log the entire directory using artifacts.\n",
        "\n",
        "Here's an example artifacts graph\n",
        "\n",
        "\n",
        "<a href=\"https://imgur.com/Y6H4QXZ\"><img src=\"https://i.imgur.com/Y6H4QXZ.png\" title=\"source: imgur.com\" /></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaLyQ8S0AXBP"
      },
      "source": [
        "import wandb\n",
        "run = wandb.init(project='Classification',name='Artifact_model')\n",
        "artifact = wandb.Artifact('News_classifier', type='model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI3Xb1RSaopX"
      },
      "source": [
        "artifact.add_dir('results/Classification_run/model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzDxHKcra0ci"
      },
      "source": [
        "run.log_artifact(artifact)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUqR8LBfa9jL"
      },
      "source": [
        "### Load the saved artifact\n",
        "The saved artifacts can be accessed using the API that automatically gets generated once you upload the artifact. You can then perform transfer learning, prediction or even deploy the models downloaded using artifacts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tt8S-02nC8-d"
      },
      "source": [
        "# Other Features\n",
        "There are many other useful commands supported by Ludwig CLI such as:\n",
        "```\n",
        "hyperopt: Perform hyperparameter optimization\n",
        "collect_summary: Prints names of weights and layers activations to use with other collect commands\n",
        "collect_weights: Collects tensors containing a pretrained model weights\n",
        "collect_activations: Collects tensors for each datapoint using a pretrained model\n",
        "export_savedmodel: Exports Ludwig models to SavedModel\n",
        "export_neuropod: Exports Ludwig models to Neuropod\n",
        "preprocess: Preprocess data and saves it into HDF5 and JSON format\n",
        "synthesize_dataset: Creates synthetic data for tesing purposes\n",
        "```\n",
        "To know more about these features please visit the [official Ludwig docs](https://ludwig-ai.github.io/ludwig-docs/user_guide/) "
      ]
    }
  ]
}