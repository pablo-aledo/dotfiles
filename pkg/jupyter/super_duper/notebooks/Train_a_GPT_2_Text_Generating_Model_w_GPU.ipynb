{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train a GPT-2 Text-Generating Model w/ GPU",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7LoMj4GA4n_"
      },
      "source": [
        "#  Train a GPT-2 Text-Generating Model w/ GPU For Free \n",
        "\n",
        "by [Max Woolf](http://minimaxir.com)\n",
        "\n",
        "*Last updated: February 14th, 2021*\n",
        "\n",
        "Retrain an advanced text generating neural network on any text dataset **for free on a GPU using Collaboratory** using `gpt-2-simple`!\n",
        "\n",
        "For more about `gpt-2-simple`, you can visit [this GitHub repository](https://github.com/minimaxir/gpt-2-simple). You can also read my [blog post](https://minimaxir.com/2019/09/howto-gpt2/) for more information how to use this notebook!\n",
        "\n",
        "\n",
        "To get started:\n",
        "\n",
        "1. Copy this notebook to your Google Drive to keep it and save your changes. (File -> Save a Copy in Drive)\n",
        "2. Make sure you're running the notebook in Google Chrome.\n",
        "3. Run the cells below:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBkpRgBCBS2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1582c747-ba18-4ddb-ddc9-1c3668c04a44"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj2IJLHP3KwE"
      },
      "source": [
        "## GPU\n",
        "\n",
        "Colaboratory uses either a Nvidia T4 GPU or an Nvidia K80 GPU. The T4 is slightly faster than the old K80 for training GPT-2, and has more memory allowing you to train the larger GPT-2 models and generate more text.\n",
        "\n",
        "You can verify which GPU is active by running the cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUmTooTW3osf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e20abb13-ae13-4631-8a18-17f3a32f46b8"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Feb 14 20:24:25 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wXB05bPDYxS"
      },
      "source": [
        "## Downloading GPT-2\n",
        "\n",
        "If you're retraining a model on new text, you need to download the GPT-2 model first. \n",
        "\n",
        "There are three released sizes of GPT-2:\n",
        "\n",
        "* `124M` (default): the \"small\" model, 500MB on disk.\n",
        "* `355M`: the \"medium\" model, 1.5GB on disk.\n",
        "* `774M`: the \"large\" model, cannot currently be finetuned with Colaboratory but can be used to generate text from the pretrained model (see later in Notebook)\n",
        "* `1558M`: the \"extra large\", true model. Will not work if a K80/P4 GPU is attached to the notebook. (like `774M`, it cannot be finetuned).\n",
        "\n",
        "Larger models have more knowledge, but take longer to finetune and longer to generate text. You can specify which base model to use by changing `model_name` in the cells below.\n",
        "\n",
        "The next cell downloads it from Google Cloud Storage and saves it in the Colaboratory VM at `/models/<model_name>`.\n",
        "\n",
        "This model isn't permanently saved in the Colaboratory VM; you'll have to redownload it if you want to retrain it at a later time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8wSlgXoDPCR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d97b26cf-eb8c-4c22-d83b-4df8fa5f6ca4"
      },
      "source": [
        "gpt2.download_gpt2(model_name=\"124M\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 489Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 1.07Mit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 311Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:39, 12.8Mit/s]\n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 265Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 1.37Mit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 1.60Mit/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8KXuKWzQSsN"
      },
      "source": [
        "## Mounting Google Drive\n",
        "\n",
        "The best way to get input text to-be-trained into the Colaboratory VM, and to get the trained model *out* of Colaboratory, is to route it through Google Drive *first*.\n",
        "\n",
        "Running this cell (which will only work in Colaboratory) will mount your personal Google Drive in the VM, which later cells can use to get data in/out. (it will ask for an auth code; that auth is not saved anywhere)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puq4iC6vUAHc"
      },
      "source": [
        "gpt2.mount_gdrive()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT__brhBCvJu"
      },
      "source": [
        "## Uploading a Text File to be Trained to Colaboratory\n",
        "\n",
        "In the Colaboratory Notebook sidebar on the left of the screen, select *Files*. From there you can upload files:\n",
        "\n",
        "![alt text](https://i.imgur.com/TGcZT4h.png)\n",
        "\n",
        "Upload **any smaller text file**  (<10 MB) and update the file name in the cell below, then run the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OFnPCLADfll"
      },
      "source": [
        "file_name = \"shakespeare.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeeSKtNWUedE"
      },
      "source": [
        "If your text file is larger than 10MB, it is recommended to upload that file to Google Drive first, then copy that file from Google Drive to the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z6okFD8VKtS"
      },
      "source": [
        "gpt2.copy_file_from_gdrive(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdpZQXknFNY3"
      },
      "source": [
        "## Finetune GPT-2\n",
        "\n",
        "The next cell will start the actual finetuning of GPT-2. It creates a persistent TensorFlow session which stores the training config, then runs the training for the specified number of `steps`. (to have the finetuning run indefinitely, set `steps = -1`)\n",
        "\n",
        "The model checkpoints will be saved in `/checkpoint/run1` by default. The checkpoints are saved every 500 steps (can be changed) and when the cell is stopped.\n",
        "\n",
        "The training might time out after 4ish hours; make sure you end training and save the results so you don't lose them!\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files.\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.finetune`:\n",
        "\n",
        "\n",
        "*  **`restore_from`**: Set to `fresh` to start training from the base GPT-2, or set to `latest` to restart training from an existing checkpoint.\n",
        "* **`sample_every`**: Number of steps to print example output\n",
        "* **`print_every`**: Number of steps to print training progress.\n",
        "* **`learning_rate`**:  Learning rate for the training. (default `1e-4`, can lower to `1e-5` if you have <1MB input data)\n",
        "*  **`run_name`**: subfolder within `checkpoint` to save the model. This is useful if you want to work with multiple models (will also need to specify  `run_name` when loading the model)\n",
        "* **`overwrite`**: Set to `True` if you want to continue finetuning an existing model (w/ `restore_from='latest'`) without creating duplicate copies. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeXshJM-Cuaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2fec22c-a013-46d1-b5c4-133d56f9ec7f"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='124M',\n",
        "              steps=1000,\n",
        "              restore_from='fresh',\n",
        "              run_name='run1',\n",
        "              print_every=10,\n",
        "              sample_every=200,\n",
        "              save_every=500\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.75s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 338025 tokens\n",
            "Training...\n",
            "[10 | 18.82] loss=3.77 avg=3.77\n",
            "[20 | 31.29] loss=3.49 avg=3.63\n",
            "[30 | 43.73] loss=3.38 avg=3.54\n",
            "[40 | 56.17] loss=3.41 avg=3.51\n",
            "[50 | 68.62] loss=3.31 avg=3.47\n",
            "[60 | 81.07] loss=3.50 avg=3.47\n",
            "[70 | 93.52] loss=3.17 avg=3.43\n",
            "[80 | 105.95] loss=3.23 avg=3.40\n",
            "[90 | 118.40] loss=3.17 avg=3.37\n",
            "[100 | 130.86] loss=3.10 avg=3.35\n",
            "[110 | 143.31] loss=3.24 avg=3.34\n",
            "[120 | 155.79] loss=2.99 avg=3.30\n",
            "[130 | 168.24] loss=2.93 avg=3.27\n",
            "[140 | 180.68] loss=3.07 avg=3.26\n",
            "[150 | 193.12] loss=3.07 avg=3.24\n",
            "[160 | 205.57] loss=3.05 avg=3.23\n",
            "[170 | 218.01] loss=2.87 avg=3.21\n",
            "[180 | 230.45] loss=2.88 avg=3.19\n",
            "[190 | 242.89] loss=3.01 avg=3.18\n",
            "[200 | 255.34] loss=2.77 avg=3.16\n",
            "======== SAMPLE 1 ========\n",
            " leads, that thou, with\n",
            "great patience, doe well, and not with a frown.\n",
            "\n",
            "TRANIO:\n",
            "Thy grace, thy goodness, thou hast, to-day struck a mark\n",
            "of love for the world;\n",
            "And thou with most patience, to-morrow\n",
            "seeks at home to a monastery.\n",
            "\n",
            "BAPTISTA:\n",
            "And by this, what we see may have good effect\n",
            "by giving a better light.\n",
            "\n",
            "CAMILLO:\n",
            "Ay, and here she doth, if you pardon me,\n",
            "I do repent your love.\n",
            "\n",
            "TRANIO:\n",
            "Thou art a prophet, and in thy speech\n",
            "and the words thy character is, there follows\n",
            "nothing in truth. Thou shalt marry:\n",
            "What, in Romeo, will I do, unless you\n",
            "have a brother?\n",
            "\n",
            "CLAUDIO:\n",
            "Why, I have never a brother\n",
            "To marry with me. I cannot, but,\n",
            "And can never, marry with any one.\n",
            "\n",
            "TRANIO:\n",
            "You do mean, and here she doth, if you have\n",
            "an unclean handkerchief, as it were the\n",
            "water of one green crab shoots forth.\n",
            "You may think as thou art that I have made\n",
            "such a grave in my life: but, by the\n",
            "honesty of the actor, the scene is out\n",
            "for my grave.\n",
            "\n",
            "CAMILLO:\n",
            "Ay, sir, and here she doth, if I have any\n",
            "danger to thee. Yes, it must be so. But,\n",
            "you are sure, sir, the danger I bear thy\n",
            "finger with thy peril to me is great: though\n",
            "not as great as thou conceive'st, yet that you may\n",
            "feel it. Thou hast an unclean handkerchief.\n",
            "\n",
            "TRANIO:\n",
            "I' faith, sir, I have seen it, sir: but thou\n",
            "not be a gentleman, but an ape; being a\n",
            "gentleman, as a fellow ape, and one whose\n",
            "kindness and kindness may be known to those\n",
            "that call thee their friend.\n",
            "\n",
            "CLAUDIO:\n",
            "Hush, no more!\n",
            "\n",
            "TRANIO:\n",
            "You know me not well.\n",
            "\n",
            "CLAUDIO:\n",
            "Sir, no more:\n",
            "I am the captain and captain of this vessel;\n",
            "I will send letters to all the crew.\n",
            "\n",
            "TRANIO:\n",
            "And I will give thanks.\n",
            "\n",
            "CLAUDIO:\n",
            "My brother is a priest, sir; let me be\n",
            "master of the way to that sacrament.\n",
            "\n",
            "TRANIO:\n",
            "And I am of the most holy order: that is,\n",
            "to instruct all the people.\n",
            "\n",
            "CLAUDIO:\n",
            "Why, sir, I will go with you.\n",
            "\n",
            "TRANIO:\n",
            "And I will let thee do it:\n",
            "for all is safe there on shore, sir.\n",
            "\n",
            "CLAUDIO:\n",
            "You are dangerous to me, sir, too much as thou\n",
            "impure in thyself.\n",
            "\n",
            "TRANIO:\n",
            "So true, being so bold as to do wrong.\n",
            "\n",
            "CLAUDIO:\n",
            "Mistress, I will be thy servant: sir,\n",
            "I will take the helm and be ready for your\n",
            "fortune.\n",
            "\n",
            "TRANIO:\n",
            "Obey me, Master Tranio.\n",
            "\n",
            "CLAUDIO:\n",
            "Obey me, sir!\n",
            "\n",
            "TRANIO:\n",
            "How?\n",
            "\n",
            "LEONTES:\n",
            "Obey me, sir.\n",
            "\n",
            "TRANIO:\n",
            "Obey me, sir!\n",
            "\n",
            "LEONTES:\n",
            "And so with good reason\n",
            "I give myself my title and give place to\n",
            "A hundred men.\n",
            "\n",
            "TRANIO:\n",
            "That's too great a scale.\n",
            "\n",
            "ANGELO:\n",
            "Obey me, sir! I am but a lad!\n",
            "\n",
            "CLAUDIO:\n",
            "My good lord, I will do as you tell me, my\n",
            "virtue and charity to thee,\n",
            "in your name: and that I do, trust mine heart\n",
            "to you: but, as I have already said, to do\n",
            "as thou dost, I will follow my conscience,--\n",
            "The conscience of the man that I trusted\n",
            "was, that it is an oath to me to be\n",
            "thorough, noble, honest, brave, and true,\n",
            "for thyself and the honour of thyself, if I have\n",
            "not done my honour--that I may not be as\n",
            "somewhere between to-day and-night as I had\n",
            "long since been, I will, I pray, follow not\n",
            "my conscience.\n",
            "\n",
            "ANGELO:\n",
            "That's a foul word, that will have to grow again.\n",
            "\n",
            "TRANIO:\n",
            "So be it indeed.\n",
            "\n",
            "ANGELO:\n",
            "O my good lord! my conscience! as if that\n",
            "happen'd\n",
            "\n",
            "[210 | 276.91] loss=2.73 avg=3.13\n",
            "[220 | 289.35] loss=2.78 avg=3.12\n",
            "[230 | 301.79] loss=2.72 avg=3.10\n",
            "[240 | 314.25] loss=2.90 avg=3.09\n",
            "[250 | 326.68] loss=2.95 avg=3.08\n",
            "[260 | 339.13] loss=2.65 avg=3.06\n",
            "[270 | 351.59] loss=2.78 avg=3.05\n",
            "[280 | 364.03] loss=2.57 avg=3.03\n",
            "[290 | 376.47] loss=2.52 avg=3.01\n",
            "[300 | 388.90] loss=2.76 avg=3.00\n",
            "[310 | 401.35] loss=2.45 avg=2.98\n",
            "[320 | 413.81] loss=2.54 avg=2.96\n",
            "[330 | 426.25] loss=2.29 avg=2.94\n",
            "[340 | 438.70] loss=2.47 avg=2.92\n",
            "[350 | 451.14] loss=2.53 avg=2.91\n",
            "[360 | 463.58] loss=2.67 avg=2.90\n",
            "[370 | 476.03] loss=2.32 avg=2.88\n",
            "[380 | 488.48] loss=2.35 avg=2.87\n",
            "[390 | 500.93] loss=2.27 avg=2.85\n",
            "[400 | 513.37] loss=2.26 avg=2.83\n",
            "======== SAMPLE 1 ========\n",
            " Rutra.\n",
            "\n",
            "RICHARD:\n",
            "A wise sir,\n",
            "For that the Lord doth bid him do; but me,\n",
            "You must be in earnest to him.\n",
            "\n",
            "KING RICHARD III:\n",
            "I do, and I will undertake\n",
            "To be the man that bids him do it for me.\n",
            "Now, by our office, I am honourable; but\n",
            "By what I have done, my honour requires\n",
            "Dilute the man's honour. A wise man,\n",
            "By the wisdom of the man that is accused,\n",
            "Would be fit to die for't; therefore,\n",
            "What good is it to die for't?\n",
            "\n",
            "KING RICHARD III:\n",
            "The man in earnest, being honourable,\n",
            "Will do it for himself.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Good madam, I would be bold to do you offence;\n",
            "But by my life you would know it is lawful,\n",
            "Unto another's life.\n",
            "\n",
            "KING RICHARD III:\n",
            "I must be plain,\n",
            "The man by my life will do it for himself.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Ay, madam, ay, if you can.\n",
            "\n",
            "KING RICHARD III:\n",
            "That's my right:\n",
            "You must be plain,\n",
            "But know that it is no good you do't.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Ay, madam, for your life.\n",
            "\n",
            "KING RICHARD III:\n",
            "But I am not the man to do't:\n",
            "And by their lives I am not the man to,\n",
            "Unless I should be that one of them\n",
            "Did it for his life.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Ay, madam.\n",
            "\n",
            "KING RICHARD III:\n",
            "Say you so?\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "No, madam.\n",
            "\n",
            "KING RICHARD III:\n",
            "What?\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "For 'twixt your husband and me.\n",
            "\n",
            "KING RICHARD III:\n",
            "No man shall sit in my husband's seat,\n",
            "Unless he say amen to it.\n",
            "\n",
            "DUKE:\n",
            "Lord, the duke calls you for a while?\n",
            "\n",
            "KING RICHARD III:\n",
            "Yes, but he'll call you back when.\n",
            "\n",
            "DUKE:\n",
            "Lord Duke of York come?\n",
            "\n",
            "KING RICHARD III:\n",
            "\n",
            "DUKE:\n",
            "\n",
            "DUKE:\n",
            "\n",
            "DUKE:\n",
            "He is near at hand, you may say.\n",
            "\n",
            "KING RICHARD III:\n",
            "No matter, Lord Duke; his words are enough for right.\n",
            "\n",
            "DUKE:\n",
            "I am too old, I see, to be of service to him;\n",
            "And I would not be king, therefore, if\n",
            "My husband were the king and my lord the Duke.\n",
            "\n",
            "Lord Duke:\n",
            "My lord, no matter, Duke:\n",
            "No matter, Duke.\n",
            "\n",
            "KING RICHARD III:\n",
            "Then, sweet madam, let me speak with you.\n",
            "\n",
            "DUKE:\n",
            "As we would speak ourselves, so shall you.\n",
            "\n",
            "QUEEN MARGARET:\n",
            "My lord, this fellow is as old as we are.\n",
            "We do desire to go see the trial and\n",
            "speech of the young offenders.\n",
            "\n",
            "KING RICHARD III:\n",
            "What shall we here do?\n",
            "\n",
            "QUEEN MARGARET:\n",
            "We will go see the trial and\n",
            "speech of the young offenders.\n",
            "\n",
            "KING RICHARD III:\n",
            "Then, gracious sovereign, let me speak, Lady Marlborough:\n",
            "This fellow will he the young murderer,\n",
            "If I shall be come to know him then his name.\n",
            "The young man that I murder in the hope\n",
            "I shall slay shall be so much young as to warrant\n",
            "The time, place, and deed of my killing.\n",
            "\n",
            "QUEEN MARGARET:\n",
            "Then make no fear of him;\n",
            "He is of good report and is still living.\n",
            "\n",
            "KING RICHARD III:\n",
            "'Tis but his age that worries me most.\n",
            "This fellow is a knave that knows me well.\n",
            "This fellow knows me well, is known in England;\n",
            "I will venture to him, as it seems the king;\n",
            "And do swear him before a holy man;\n",
            "As well his brother and our fair aunt,\n",
            "The queen's dear wife, as his, brother,\n",
            "Will make us to confess his true love.\n",
            "\n",
            "KING RICHARD III:\n",
            "Tullus and Caius and all that follow\n",
            "Before the Earl of Wiltshire, and all of us,\n",
            "Can come to him and swear his justice.\n",
            "\n",
            "QUEEN MARGARET:\n",
            "Lord, it is a grievous error\n",
            "To swear before a holy man.\n",
            "\n",
            "\n",
            "\n",
            "[410 | 534.10] loss=2.12 avg=2.81\n",
            "[420 | 546.54] loss=2.48 avg=2.80\n",
            "[430 | 559.02] loss=2.08 avg=2.78\n",
            "[440 | 571.47] loss=2.40 avg=2.77\n",
            "[450 | 583.90] loss=1.94 avg=2.75\n",
            "[460 | 596.34] loss=1.78 avg=2.72\n",
            "[470 | 608.81] loss=1.82 avg=2.70\n",
            "[480 | 621.26] loss=1.82 avg=2.67\n",
            "[490 | 633.71] loss=1.93 avg=2.65\n",
            "[500 | 646.14] loss=1.66 avg=2.63\n",
            "Saving checkpoint/run1/model-500\n",
            "[510 | 661.51] loss=1.70 avg=2.61\n",
            "[520 | 673.94] loss=1.88 avg=2.59\n",
            "[530 | 686.37] loss=1.98 avg=2.57\n",
            "[540 | 698.81] loss=1.96 avg=2.56\n",
            "[550 | 711.24] loss=1.81 avg=2.54\n",
            "[560 | 723.69] loss=1.16 avg=2.51\n",
            "[570 | 736.13] loss=1.30 avg=2.48\n",
            "[580 | 748.56] loss=1.19 avg=2.45\n",
            "[590 | 761.02] loss=1.66 avg=2.43\n",
            "[600 | 773.46] loss=1.63 avg=2.42\n",
            "======== SAMPLE 1 ========\n",
            " your heart 'breathe,\n",
            "If you have any to entreat;\n",
            "That's my counsel; but why not you?\n",
            "I'll tell you your face; and give you your tale\n",
            "My mother breathed in marriage: that's it.\n",
            "\n",
            "DUKE OF YORK:\n",
            "Ah sir! how much longer this age,\n",
            "As you are our age, lasts; for we\n",
            "Hath marr'd it, and more are coming.\n",
            "Let me make my last, your last.\n",
            "\n",
            "DUCHESS OF YORK:\n",
            "My son, how woo'd are you, my son?\n",
            "\n",
            "DUKE OF YORK:\n",
            "Wife, thou must at once.\n",
            "\n",
            "DUCHESS OF YORK:\n",
            "What woo'd are you? wilt thou die?\n",
            "I tell thee, be happy till there be another.\n",
            "\n",
            "DUKE OF YORK:\n",
            "If by some accident my wooed daughter, whom\n",
            "Ere you be gone, shall have that gift which she\n",
            "Must beg for me.\n",
            "\n",
            "DUCHESS OF YORK:\n",
            "O, let her die, and I shall not;\n",
            "For then she must live, she shall never shall die.\n",
            "If 'twere any thing but joy in thee,\n",
            "Leave no woo man out, for it is but a\n",
            "Pseudopubilism: 'tis a very jealous\n",
            "That doth keep wooing.\n",
            "\n",
            "RICHARD:\n",
            "Why, Richard, is it not a shame\n",
            "That you are made so great a king?\n",
            "To be made a king is a joy,\n",
            "And no joy in being made such a king;\n",
            "For being made a king is a joy to\n",
            "be happy. But say, what talk you of that?\n",
            "\n",
            "GEORGE:\n",
            "My mind is changed; if Warwick be my king,\n",
            "My head should then not be changed.\n",
            "\n",
            "RICHARD:\n",
            "The happy man doth win the unhappy woman,\n",
            "And make a king. But is my head changed\n",
            "For that reason?\n",
            "\n",
            "GEORGE:\n",
            "No.\n",
            "\n",
            "RICHARD:\n",
            "Do you then talk of a change, Richard?\n",
            "\n",
            "RICHARD:\n",
            "If indeed my head be changed for joy, my mind\n",
            "Becomes joyful by this. But in what?\n",
            "\n",
            "GEORGE:\n",
            "Ay, such a one as the queen in Cupid's time,\n",
            "When she was first begot; for then 'Twas news,\n",
            "That the worm was made good, to make 'twertween.\n",
            "\n",
            "RICHARD:\n",
            "Ay, now, so done, madam, that the love\n",
            "Of Richard thy son and the queen had both found\n",
            "A happy home together: yet is 't true\n",
            "That Margaret and her husband were begot\n",
            "To be secure in some harbour;\n",
            "That is, to breed them here in England,\n",
            "When this land is now in Richard's power\n",
            "To have their babies here in England.\n",
            "\n",
            "GEORGE:\n",
            "But, madam,\n",
            "That should so chance; now in England's court\n",
            "Who should not be so fearful.\n",
            "\n",
            "BUSHY:\n",
            "What's that?\n",
            "\n",
            "GEORGE:\n",
            "That you say is true; and I doubt not but\n",
            "The fear is too great for any country\n",
            "To put upon our lists. But, madam,\n",
            "When your head is changed, what's the matter then\n",
            "With you and your wife, that look upon you\n",
            "Like that you were a baby then?\n",
            "\n",
            "BUSHY:\n",
            "A little sheepled down the middle,\n",
            "To mock our gracious lordship.\n",
            "\n",
            "RICHMOND:\n",
            "No matter what, I blame your fear;\n",
            "I know you well, and know well what's to do.\n",
            "But what's the matter?\n",
            "\n",
            "BUSHY:\n",
            "O, let it be as easy as it is,\n",
            "To have your head repass'd and your face\n",
            "Mangled with bands, to have your hair\n",
            "Pitched in electrocuted sun,\n",
            "To keep your face as it is, as it were,\n",
            "So you from being able to walk and speak.\n",
            "\n",
            "RICHMOND:\n",
            "No, no, a mask is mock'd up for that,\n",
            "That like a man you cannot use fair,\n",
            "That thinks himself in any dress, in garments,\n",
            "And would not but be disguised in't,\n",
            "To be seen by your wife, seeing your head,\n",
            "As it were changed in any of your house,\n",
            "As it were, mock'd and done all fair.\n",
            "And so, madam, out! I say unto you, Warwick\n",
            "Hath changed his mind upon these terms,\n",
            "And shall be fought with you, if you avoid\n",
            "The dangerous prompter and avoid the speech.\n",
            "O thou valiant prince! take this book upon thy hands,\n",
            "That when you sleep feel no pain, when you fall asleep,\n",
            "Your pains are\n",
            "\n",
            "[610 | 794.26] loss=1.41 avg=2.39\n",
            "[620 | 806.71] loss=1.20 avg=2.37\n",
            "[630 | 819.17] loss=1.54 avg=2.35\n",
            "[640 | 831.60] loss=1.10 avg=2.32\n",
            "[650 | 844.06] loss=1.01 avg=2.30\n",
            "[660 | 856.51] loss=1.42 avg=2.28\n",
            "[670 | 868.93] loss=0.88 avg=2.25\n",
            "[680 | 881.38] loss=1.48 avg=2.23\n",
            "[690 | 893.84] loss=1.35 avg=2.22\n",
            "[700 | 906.28] loss=0.83 avg=2.19\n",
            "[710 | 918.71] loss=1.02 avg=2.17\n",
            "[720 | 931.14] loss=0.88 avg=2.14\n",
            "[730 | 943.58] loss=1.04 avg=2.12\n",
            "[740 | 956.02] loss=0.92 avg=2.10\n",
            "[750 | 968.48] loss=0.97 avg=2.08\n",
            "[760 | 980.93] loss=1.01 avg=2.06\n",
            "[770 | 993.36] loss=0.91 avg=2.04\n",
            "[780 | 1005.82] loss=0.85 avg=2.01\n",
            "[790 | 1018.26] loss=0.64 avg=1.99\n",
            "[800 | 1030.71] loss=0.90 avg=1.97\n",
            "======== SAMPLE 1 ========\n",
            ":\n",
            "\n",
            "FLORIZEL:\n",
            "A woman\n",
            "To speak so fair a slanderous indictment of my youth!\n",
            "I am frail, my bones are out, my strength too brittle,\n",
            "Therefore I charge you, in your own city,\n",
            "Repair you this bed; reposing your grace\n",
            "In that which you wrong me with, this contrary.\n",
            "\n",
            "KATHARINA:\n",
            "I have a brother,\n",
            "And heir to the Catholic crown I would to him.\n",
            "\n",
            "PRINCE EDWARD:\n",
            "He is young and frail, but come you fairly in time:\n",
            "if slander can steal from a frail body, clothe him\n",
            "and make him strong and fresh by working his heart out.\n",
            "The time will come that slander should infect a frail soul.\n",
            "Hence you'll be glad to have him put to death.\n",
            "\n",
            "KATHARINA:\n",
            "He is old and frail, but come you fairly in time.\n",
            "if slander can lick the heavenly bodies clean, clothe him\n",
            "and make them strong and fresh by their different bearing,\n",
            "bring him over to this very method, let him,\n",
            "if the time come that slander should insinuate itself,\n",
            "let him from his proper place purge himself\n",
            "with distilled water, so to speak, to make up the night.\n",
            "\n",
            "Servant:\n",
            "Amen.\n",
            "\n",
            "ANGELO:\n",
            "Bid them all this night to come to the supper.\n",
            "\n",
            "Lord:\n",
            "Here is the duke of conservato's pleasure.\n",
            "\n",
            "All:\n",
            "The ladies are come.\n",
            "\n",
            "LEONTES:\n",
            "Good night to you all.\n",
            "\n",
            "First Lord:\n",
            "Go, cheerly, make them quick at work, and have them ready;\n",
            "For I will be with you at leisure. My liege,\n",
            "You are welcome; go, cheerly.\n",
            "\n",
            "GLOUCESTER:\n",
            "A witch, a fiend!\n",
            "\n",
            "KING RICHARD II:\n",
            "Come hither, Richard, the queen hath given thanks.\n",
            "Bear with me now, I say thanks.\n",
            "Bear with me, I say nay.\n",
            "\n",
            "First Lord:\n",
            "God in holy mother, peace, my very daughter!\n",
            "\n",
            "KING RICHARD II:\n",
            "A witch, a fiend!\n",
            "\n",
            "Second Lord:\n",
            "God in holy mother, peace, my very daughter!\n",
            "\n",
            "GLOUCESTER:\n",
            "A little while before;\n",
            "for, I will coz, all unheir my melancholy looks.\n",
            "A little while before, lord chamberlain.\n",
            "Go tell these lords and commons that once again,\n",
            "I am come to take possession of their castles.\n",
            "\n",
            "BUCKINGHAM:\n",
            "Lord Northumberland, he means not to lose.\n",
            "\n",
            "GLOUCESTER:\n",
            "He looks as though he's for returning castleward.\n",
            "\n",
            "KING RICHARD II:\n",
            "What, with whom, my Lord of Salisbury?\n",
            "\n",
            "BUCKINGHAM:\n",
            "Who, my Lord of Buckingham?\n",
            "\n",
            "GLOUCESTER:\n",
            "My Lord of Salisbury.\n",
            "\n",
            "KING RICHARD II:\n",
            "From him that hath power over nature,\n",
            "From him that hath left the crown, and all,\n",
            "My gracious and most noble king, being he,\n",
            "Would seem an unnatural king at times of war.\n",
            "\n",
            "BUCKINGHAM:\n",
            "Why, Lord Northumberland, are they all the king?\n",
            "\n",
            "GLOUCESTER:\n",
            "Both:\n",
            "Both, my gracious lord, hath he forfeited his crown?\n",
            "\n",
            "KING RICHARD II:\n",
            "Ay, for taking it back from Nature.\n",
            "\n",
            "BUCKINGHAM:\n",
            "He hath forfeited it both, my gracious lord.\n",
            "\n",
            "GLOUCESTER:\n",
            "So hath he.\n",
            "\n",
            "KING RICHARD II:\n",
            "He hath even taken it back from the crown.\n",
            "\n",
            "BUCKINGHAM:\n",
            "Why does his gracious hand wring so, my gracious lord?\n",
            "\n",
            "GLOUCESTER:\n",
            "To give back again what he did at Tewksbury.\n",
            "\n",
            "KING RICHARD II:\n",
            "To give back, and give wisely.\n",
            "What have we here? let us contemplate this for a while;\n",
            "After what we have talked of, here in York might we find\n",
            "A noble land. But scarce let there be much talk of battle.\n",
            "I am the messenger; but who sends me?\n",
            "\n",
            "Lord Marshal:\n",
            "The king, my lord, sends.\n",
            "\n",
            "KING RICHARD II:\n",
            "Islington is crest'd at eight years of age.\n",
            "\n",
            "GLOUCESTER:\n",
            "His age, at least, till I see his outward face.\n",
            "\n",
            "KING RICHARD II:\n",
            "Boy, this must be the first time I've had encounter\n",
            "With an aged gentleman.\n",
            "But was it worth while, if he were living?\n",
            "\n",
            "BUCKINGHAM:\n",
            "He hath a volume\n",
            "\n",
            "[810 | 1051.14] loss=0.95 avg=1.95\n",
            "[820 | 1063.59] loss=0.86 avg=1.93\n",
            "[830 | 1076.04] loss=0.58 avg=1.91\n",
            "[840 | 1088.47] loss=0.82 avg=1.89\n",
            "[850 | 1100.91] loss=0.42 avg=1.86\n",
            "[860 | 1113.35] loss=0.41 avg=1.84\n",
            "[870 | 1125.79] loss=0.37 avg=1.81\n",
            "[880 | 1138.23] loss=0.48 avg=1.79\n",
            "[890 | 1150.68] loss=0.71 avg=1.77\n",
            "[900 | 1163.13] loss=0.59 avg=1.75\n",
            "[910 | 1175.58] loss=0.33 avg=1.73\n",
            "[920 | 1188.04] loss=0.59 avg=1.71\n",
            "[930 | 1200.48] loss=0.43 avg=1.69\n",
            "[940 | 1212.92] loss=0.33 avg=1.67\n",
            "[950 | 1225.36] loss=0.63 avg=1.65\n",
            "[960 | 1237.82] loss=0.33 avg=1.63\n",
            "[970 | 1250.26] loss=0.34 avg=1.61\n",
            "[980 | 1262.69] loss=0.51 avg=1.59\n",
            "[990 | 1275.17] loss=0.33 avg=1.57\n",
            "[1000 | 1287.61] loss=0.49 avg=1.55\n",
            "Saving checkpoint/run1/model-1000\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXSuTNERaw6K"
      },
      "source": [
        "After the model is trained, you can copy the checkpoint folder to your own Google Drive.\n",
        "\n",
        "If you want to download it to your personal computer, it's strongly recommended you copy it there first, then download from Google Drive. The checkpoint folder is copied as a `.rar` compressed file; you can download it and uncompress it locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHdTL8NDbAh3"
      },
      "source": [
        "gpt2.copy_checkpoint_to_gdrive(run_name='run1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQJgV_b4bmzd"
      },
      "source": [
        "You're done! Feel free to go to the **Generate Text From The Trained Model** section to generate text based on your retrained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pel-uBULXO2L"
      },
      "source": [
        "## Load a Trained Model Checkpoint\n",
        "\n",
        "Running the next cell will copy the `.rar` checkpoint file from your Google Drive into the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCcx5u7sbPTD"
      },
      "source": [
        "gpt2.copy_checkpoint_from_gdrive(run_name='run1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTa6zf3e_9gV"
      },
      "source": [
        "The next cell will allow you to load the retrained model checkpoint + metadata necessary to generate text.\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fxL77nvAMAX"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name='run1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJwpF_ACONp"
      },
      "source": [
        "## Generate Text From The Trained Model\n",
        "\n",
        "After you've trained the model or loaded a retrained model from checkpoint, you can now generate text. `generate` generates a single text from the loaded model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RNY6RBI9LmL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae2ea4f1-9831-4250-b1eb-dcbd12e0d6f7"
      },
      "source": [
        "gpt2.generate(sess, run_name='run1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Romeo was a gentleman,\n",
            "A gentleman of gentle complexion,\n",
            "A gentleman in gentle discourse,\n",
            "A gentleman in gentle words,\n",
            "A gentleman in gentle discourse,\n",
            "To smile at gentle Polixenes,\n",
            "And smile again at gentle Menenius.\n",
            "\n",
            "MENENIUS:\n",
            "A gentle discourse,\n",
            "And a very mild one indeed,\n",
            "For such a subject as ours,\n",
            "To smooth the wrinkles of the brow.\n",
            "\n",
            "First Senator:\n",
            "Our subjects,\n",
            "We are pleased to send you on your first pleasure,\n",
            "After your first pleasure we have well proceeded.\n",
            "\n",
            "VOLUMNIA:\n",
            "I think, sir, about the wine, sir, and the rest,\n",
            "Would you advise each of them in their turn to bring\n",
            "The wine to them?\n",
            "\n",
            "CORIOLANUS:\n",
            "Yea, sir; I'll be in patience;\n",
            "And let you bequeath the wine to your wine,\n",
            "If you so desire.\n",
            "\n",
            "MENENIUS:\n",
            "Would you prescribe any thing?\n",
            "\n",
            "CORIOLANUS:\n",
            "I will in person,\n",
            "Wherein the physician is well acquainted.\n",
            "\n",
            "MENENIUS:\n",
            "Well, no more: you have arrived at the right\n",
            "Till you have acquainted me with Valentinus.\n",
            "\n",
            "CORIOLANUS:\n",
            "The very first pleasure I had in your daughter,\n",
            "To see her at the first pleasure;\n",
            "For her beauty was the first pleasure;\n",
            "For her beauty was the last pleasure.\n",
            "I have often noted, that before I came\n",
            "To know her true love, that she was not newly born,\n",
            "My first pleasure was seeing her first,\n",
            "Before my first pleasure: and so, after,\n",
            "Were it not for her first kiss, she would have first\n",
            "Upon her, to kiss upon her, an instant.\n",
            "And so she did; and so did I for the\n",
            "three whole hours we spent together;\n",
            "Before she came to know me; before I could\n",
            "Tell her I was a man, she would have\n",
            "all alone, in a dream, till I came to know her.\n",
            "And so she did; and so did I for the\n",
            "three hours we spent together.\n",
            "\n",
            "VOLUMNIA:\n",
            "So with Marcius and for the rest of the company.\n",
            "\n",
            "CORIOLANUS:\n",
            "What is your opinion, gentle senator, of the\n",
            "separation of the scepter and the key?\n",
            "\n",
            "CORIOLANUS:\n",
            "That it was the better for Marcius and the\n",
            "assembly; for the scepter was within the\n",
            "time of his coming to the senate chamber; and the\n",
            "assembly was the great and shining wench.\n",
            "\n",
            "CORIOLANUS:\n",
            "That it was the better for him and the assembly.\n",
            "\n",
            "VOLUMNIA:\n",
            "That it was the better for him and the assembly.\n",
            "The assembly was a well-heal'd, well-balanced,\n",
            "renown'd, and in very worthy condition.\n",
            "He was not of great appetite, being\n",
            "not in the way of obeisance.\n",
            "\n",
            "CORIOLANUS:\n",
            "I would have thought, sir, that he had spent his\n",
            "concession of his annual tax, as it were, upon\n",
            "sip, wine, and other lawful means; for, he\n",
            "thought himself, he might have purchased a kingdom by\n",
            "using the revenue of the state.\n",
            "\n",
            "VOLUMNIA:\n",
            "He hath spent his annual revenue; so, in\n",
            "his opinion, he divides the sum of three parts\n",
            "of corn into good, good, and bad plots; divides them\n",
            "so that the good portion is richer than the\n",
            "bad portion, and so divides the plot of corn, that\n",
            "the evil portion may be fouler than the sum\n",
            "I hath spent.\n",
            "\n",
            "CORIOLANUS:\n",
            "Let me have more than I have, or that is much.\n",
            "\n",
            "VOLUMNIA:\n",
            "But how is it divided? by plot.\n",
            "\n",
            "CORIOLANUS:\n",
            "By good portion.\n",
            "\n",
            "VOLUMNIA:\n",
            "By evil portion.\n",
            "\n",
            "CORIOLANUS:\n",
            "By worst portion.\n",
            "\n",
            "VOLUMNIA:\n",
            "By worst plot.\n",
            "\n",
            "CORIOLANUS:\n",
            "By slave plot.\n",
            "\n",
            "VOLUMNIA:\n",
            "By slave plot! the better for the worse.\n",
            "I would the gods had smothered this plot!\n",
            "Thou wouldst have heaved a man to the bed of hell,\n",
            "swallowed him, made him cry, spake with him, cried\n",
            "'What is the consequence of this'? By plot! by worst!\n",
            "Thou wouldst have made a finer slave, a\n",
            "better shrew than this Angelo, a finer caitiff\n",
            "than this Prince Florizel, a finer stag than\n",
            "this Mercury, a finer sun; a finer star, a\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF4-PqF0Fl7R"
      },
      "source": [
        "If you're creating an API based on your model and need to pass the generated text elsewhere, you can do `text = gpt2.generate(sess, return_as_list=True)[0]`\n",
        "\n",
        "You can also pass in a `prefix` to the generate function to force the text to start with a given character sequence and generate text from there (good if you add an indicator when the text starts).\n",
        "\n",
        "You can also generate multiple texts at a time by specifing `nsamples`. Unique to GPT-2, you can pass a `batch_size` to generate multiple samples in parallel, giving a massive speedup (in Colaboratory, set a maximum of 20 for `batch_size`).\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.generate` and friends:\n",
        "\n",
        "*  **`length`**: Number of tokens to generate (default 1023, the maximum)\n",
        "* **`temperature`**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
        "* **`top_k`**: Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n",
        "* **`top_p`**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)\n",
        "* **`truncate`**: Truncates the input text until a given sequence, excluding that sequence (e.g. if `truncate='<|endoftext|>'`, the returned text will include everything before the first `<|endoftext|>`). It may be useful to combine this with a smaller `length` if the input texts are short.\n",
        "*  **`include_prefix`**: If using `truncate` and `include_prefix=False`, the specified `prefix` will not be included in the returned text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DKMc0fiej4N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c294c08d-3659-4aa2-851b-5ba12c397a1e"
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              length=250,\n",
        "              temperature=0.7,\n",
        "              prefix=\"LORD\",\n",
        "              nsamples=5,\n",
        "              batch_size=5\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LORD WILLOUGHBY:\n",
            "And, Lord Marshal, to the Tower.\n",
            "\n",
            "KING RICHARD III:\n",
            "As near the time when we were born,\n",
            "Let not our graces enter into this story,\n",
            "For God's sake, the whole truth shall stand:\n",
            "The selfsame night God gave the sun,\n",
            "Let angels, and stars enter, and the four cardinal directions,\n",
            "Be satisfied, that the power thereof is determined:\n",
            "For we are ere now the prime of corn,\n",
            "Or of harvest, harvest being done,\n",
            "Caught in the vice of night, and fall asleep.\n",
            "O Clifford, how we lay to bed! Clifford, I am loath\n",
            "To sleep under this false bed of roses:\n",
            "I think, to mellow out this bed, I may by a jest\n",
            "Be naked and naked and naked! If night be pall'd,\n",
            "All self-portents must fall asleep;\n",
            "Unless, God forbid, thou art not in bed.\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "I am, and therefore, as thou suspect'st, O.K.\n",
            "Where there is no strength in the dark,\n",
            "Never will I rest, till thou bring me\n",
            "====================\n",
            "LORD WILLOUGHBY:\n",
            "The morn to pray is vain;\n",
            "Nor doth it offend the holy church,\n",
            "Nor any holy man. Come, go with me;\n",
            "I will not linger behind.\n",
            "\n",
            "ANGELO:\n",
            "Will you go with us to the prison,\n",
            "Or are you banished i' the town?\n",
            "\n",
            "PROSPERO:\n",
            "What is the matter\n",
            "That inquiring minds learn how there comes\n",
            "To solitary confession and carouse\n",
            "Of its own accord so rarely majestical\n",
            "And seldom of such meritoriousness?\n",
            "\n",
            "ANGELO:\n",
            "What is the matter?\n",
            "\n",
            "PROSPERO:\n",
            "Go you along; thou'rt damnable.\n",
            "\n",
            "ANGELO:\n",
            "I will not go with thee, unless thou go'st\n",
            "To geld a brace of draymen and use them\n",
            "For digging iron. Will you go along?\n",
            "\n",
            "PROSPERO:\n",
            "No, not with thee: I am with thee, stick\n",
            "Your neck out for the best bawd.\n",
            "\n",
            "ANGELO:\n",
            "Thou art the first bawd in the way:\n",
            "Take him to prison, and try him thine own\n",
            "====================\n",
            "LORD STANLEY:\n",
            "You have not forthrunne me.\n",
            "\n",
            "HERMIONE:\n",
            "Go in to him, Marshal.\n",
            "\n",
            "LEONTES:\n",
            "Where is the other Warwick, that we\n",
            "Have named for him?\n",
            "\n",
            "HERMIONE:\n",
            "He is hastily arrived, good sir,\n",
            "From the most hospitable succor: his gracious wife\n",
            "Shall be your goodbye, to make speedy exchange\n",
            "Of late; for Warwick, being gone, is fled,\n",
            "To hold up such favours as you can find\n",
            "Containing him welcome.\n",
            "\n",
            "LEONTES:\n",
            "Where's Warwick? speak with him.\n",
            "\n",
            "HERMIONE:\n",
            "There shall be none that speak so well against him.\n",
            "I have heard it said, and many a wise man\n",
            "Hath she lived, that it is better to be wrongful\n",
            "Than the under-minded men in general: but it is better\n",
            "To be wrongful than wrong yourself to be mew'd,\n",
            "Or in any thing else be mew'd mew'd.\n",
            "I am ashamed, that men of state are never\n",
            "Of what we mean to look for, but we speak\n",
            "To show a\n",
            "====================\n",
            "LORD WILLOUGHBY:\n",
            "Here comes his sword to kill me.\n",
            "\n",
            "CATESBY:\n",
            "I thought your majesty\n",
            "Would have bid the Duke of Norfolk,\n",
            "Who hath not been seen before, present\n",
            "Before she went to the feast.\n",
            "\n",
            "KING RICHARD III:\n",
            "Well, say you, Duke of Norfolk,\n",
            "Join with him and three hundred thousand others;\n",
            "Let her come and join with him;\n",
            "Sound the first-rate sword, and he shall join with her;\n",
            "And, after her, shall she become a king.\n",
            "\n",
            "NORTHUMBERLAND:\n",
            "Well said, my sovereign:\n",
            "Join with her; let her join with him;\n",
            "This shall be such a sword as she to him.\n",
            "\n",
            "KING RICHARD III:\n",
            "So said, my sovereign.\n",
            "\n",
            "NORTHUMBERLAND:\n",
            "And so shall she join with him.\n",
            "\n",
            "KING RICHARD III:\n",
            "So said, her majesty.\n",
            "\n",
            "NORTHUMBERLAND:\n",
            "And so shall she join with him.\n",
            "\n",
            "KING RICHARD III:\n",
            "Brother, your grace is come to Sandyshire from France.\n",
            "\n",
            "DUKE OF YORK:\n",
            "Where did you\n",
            "====================\n",
            "LORD WILLOUGHBY:\n",
            "That beastly wretch,\n",
            "Whose head and horns resemble the horns of a bear,\n",
            "While he himself is obscured in shadows;\n",
            "And thus we chain him up and hang him:\n",
            "The sentence for the ordering the rebels\n",
            "In this foul act of war is, for the time he lived\n",
            "I doubt not but the Lord Protector would\n",
            "Require the head and horns of that beastly wretch\n",
            "To carve a glorious figure in their own territories:\n",
            "And for this same they slandered both their fathers,\n",
            "And all the rest in their sleep. But, O, my soul,\n",
            "I see where thou conterest me and what I mean,\n",
            "By striking him to the ground that tread'st not upon you,\n",
            "And that will not hence: I am for thee, love.\n",
            "Thy deathly scar calls shall be drown'd out\n",
            "In the clean air that bears your name; thy banishment\n",
            "Will be sudden and in the flame of his flames:\n",
            "Where he stands before the fire, poor soul, die:\n",
            "His execution shall be sudden, and in the flame\n",
            "Of his flames his flames: hence shall thy souls rest,\n",
            "And never hear from thee\n",
            "====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjjEN2Tafhl2"
      },
      "source": [
        "For bulk generation, you can generate a large amount of text to a file and sort out the samples locally on your computer. The next cell will generate a generated text file with a unique timestamp.\n",
        "\n",
        "You can rerun the cells as many times as you want for even more generated texts!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa6p6arifSL0"
      },
      "source": [
        "gen_file = 'gpt2_gentext_{:%Y%m%d_%H%M%S}.txt'.format(datetime.utcnow())\n",
        "\n",
        "gpt2.generate_to_file(sess,\n",
        "                      destination_path=gen_file,\n",
        "                      length=500,\n",
        "                      temperature=0.7,\n",
        "                      nsamples=100,\n",
        "                      batch_size=20\n",
        "                      )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-LRex8lfv1g"
      },
      "source": [
        "# may have to run twice to get file to download\n",
        "files.download(gen_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQAN3M6RT7Kj"
      },
      "source": [
        "## Generate Text From The Pretrained Model\n",
        "\n",
        "If you want to generate text from the pretrained model, not a finetuned model, pass `model_name` to `gpt2.load_gpt2()` and `gpt2.generate()`.\n",
        "\n",
        "This is currently the only way to generate text from the 774M or 1558M models with this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsUd_jHgUZnD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "4e0c8a3f-3527-41c4-e3fe-3357f3f8f6c2"
      },
      "source": [
        "model_name = \"774M\"\n",
        "\n",
        "gpt2.download_gpt2(model_name=model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 354Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 131Mit/s]                                                    \n",
            "Fetching hparams.json: 1.05Mit [00:00, 279Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 3.10Git [00:23, 131Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 380Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 2.10Mit [00:00, 226Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 199Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAe4NpKNUj2C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "b09bfe1d-2ff8-4b8a-fffb-273d28d5d4ae"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.load_gpt2(sess, model_name=model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0828 18:37:58.571830 139905369159552 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading pretrained model models/774M/model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xInIZKaU104",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        },
        "outputId": "56348e28-7d08-45e3-c859-f26c0efd066d"
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              model_name=model_name,\n",
        "              prefix=\"The secret of life is\",\n",
        "              length=100,\n",
        "              temperature=0.7,\n",
        "              top_p=0.9,\n",
        "              nsamples=5,\n",
        "              batch_size=5\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The secret of life is that it's really easy to make it complicated,\" said Bill Nye, the host of the popular science show \"Bill Nye the Science Guy.\" \"And this is one of the reasons why we all need to be smarter about science, because we can't keep up with the amazing things that are going on all the time.\"\n",
            "\n",
            "While Nye is correct that \"everything that's going on all the time\" is making the world a better place, he misses the point. This is not\n",
            "====================\n",
            "The secret of life is in the rhythm of the universe. It's not a mystery. It's not a mystery to me. It's the nature of the universe. It's the beauty of the universe. It's the way the universe works. It's the way the universe is. It's the way the universe is going to work. It's the way the universe is. It's the way the universe is. It's the way the universe is. It's the way the universe is. It's the way\n",
            "====================\n",
            "The secret of life is in the universe.\n",
            "\n",
            "\n",
            "-\n",
            "\n",
            "The Red Devil\n",
            "\n",
            "It's the end of the world as we know it, and the only thing that can save us is a band of super-powered individuals known as the Red Devil.\n",
            "\n",
            "\n",
            "The Red Devil is a group of super-powered individuals who are seeking the secret of life and the only way they know how to do it is by taking on the roles of a variety of different super-powered individuals, each of which has their own\n",
            "====================\n",
            "The secret of life is in the mixing of the elements, and it is the mixing of the elements that makes life possible.\"\n",
            "\n",
            "But in the world of food science, the idea of a \"complex\" or \"complexity\" is almost entirely imaginary.\n",
            "\n",
            "As a scientist, I'm fascinated by the question of how life first began.\n",
            "\n",
            "It's the question that drives my work and the work of the scientists who work on it.\n",
            "\n",
            "My current research is exploring how microbes work in the first moments\n",
            "====================\n",
            "The secret of life is the journey of life, the search for the truth.\n",
            "\n",
            "4.4.2. The last thing you know\n",
            "\n",
            "There is nothing more important than the last thing you know.\n",
            "\n",
            "4.4.3. The little things that make all the difference\n",
            "\n",
            "The little things that make all the difference.\n",
            "\n",
            "4.4.4. The truth is the best teacher\n",
            "\n",
            "The truth is the best teacher.\n",
            "\n",
            "4.4.5. The truth is what\n",
            "====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig-KVgkCDCKD"
      },
      "source": [
        "# Etcetera\n",
        "\n",
        "If the notebook has errors (e.g. GPU Sync Fail), force-kill the Colaboratory virtual machine and restart it with the command below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIHiVP53FnsX"
      },
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmTXWNUygS5E"
      },
      "source": [
        "# LICENSE\n",
        "\n",
        "MIT License\n",
        "\n",
        "Copyright (c) 2019 Max Woolf\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    }
  ]
}