{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Try_mrm8488_xquad_finetuned_uncased_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTFfiD2JdN5B"
      },
      "source": [
        "# Colab to try the model [mrm8488/bert-multi-uncased-finetuned-xquadv1](https://huggingface.co/mrm8488/bert-multi-uncased-finetuned-xquadv1)\n",
        "\n",
        "## A fined tuned version of BERT base **multilingual** uncased on [XQUAD](https://github.com/deepmind/xquad/blob/master/README.md) dataset (```multilingual Q&A```) using [huggingface/transformers](https://github.com/huggingface/transformers)\n",
        "\n",
        "Supported Languages (11):\n",
        "```\n",
        "- Arabic: `ar`\n",
        "- German: `de`\n",
        "- Greek: `el`\n",
        "- English: `en`\n",
        "- Spanish: `es`\n",
        "- Hindi: `hi`\n",
        "- Russian: `ru`\n",
        "- Thai: `th`\n",
        "- Turkish: `tr`\n",
        "- Vietnamese: `vi`\n",
        "- Chinese: `zh`\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70UYUF6Ob7vI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "99a9403b-acf7-45f0-db50-63609c6b5c02"
      },
      "source": [
        "!pip install -q transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 501kB 4.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 870kB 23.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0MB 38.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.7MB 51.9MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCoInXk-cFTY"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "qa_pipeline = pipeline(\n",
        "    \"question-answering\",\n",
        "    model=\"mrm8488/bert-multi-uncased-finetuned-xquadv1\",\n",
        "    tokenizer=\"mrm8488/bert-multi-uncased-finetuned-xquadv1\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyObybtDcbF0"
      },
      "source": [
        "### Spanish"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zBho6MOccb-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "2e82b1a5-4379-4fc5-ff89-ea70f3e654f7"
      },
      "source": [
        "qa_pipeline({\n",
        "    'context': \"Manuel Romero ha estado colaborando activamente últimamente en el repositorio de hugginface/transformers\",\n",
        "    'question': \"¿Quién ha estado colaborando de forma activa en hugginface/transformers?\"\n",
        "    \n",
        "})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 190.70it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 6069.90it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'Manuel Romero', 'end': 13, 'score': 0.6817649967337047, 'start': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyRFfgFRch4H"
      },
      "source": [
        "### English"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVtxQNB1ceiv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "9e495259-8ab6-4dbc-db1d-92e3760c6c73"
      },
      "source": [
        "qa_pipeline({\n",
        "    'context': \"Manuel Romero has been working hardly in the repository hugginface/transformers lately\",\n",
        "    'question': \"Who has been working hard for hugginface/transformers lately?\"\n",
        "    \n",
        "})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 183.84it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 6482.70it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'Manuel Romero', 'end': 13, 'score': 0.715519859329504, 'start': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMj7oF5Dcmbu"
      },
      "source": [
        "### German"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbgyuzsNclEF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "fb9a18cb-19f8-4e38-d67c-8b721896519f"
      },
      "source": [
        "qa_pipeline({\n",
        "    'context': \"Manuel Romero hat in letzter Zeit kaum im Hugginface / Transformers-Repository gearbeitet\",\n",
        "    'question': \"Für welches Repository hat Manuel Romero in letzter Zeit gearbeitet?\"\n",
        "    \n",
        "})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 247.61it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 7025.63it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'Hugginface / Transformers-Repository',\n",
              " 'end': 78,\n",
              " 'score': 0.5922690127954304,\n",
              " 'start': 42}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3veaGBmJcunH"
      },
      "source": [
        "### French"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHJVI7KQctcl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "f1e1415e-767f-407c-e46e-74ac0a70f84c"
      },
      "source": [
        "qa_pipeline({\n",
        "    'context': \"Manuel Romero a travaillé à peine dans le référentiel hugginface / transformers ces derniers temps\",\n",
        "    'question': \"Pour quel référentiel a travaillé Manuel Romero récemment?\"\n",
        "    \n",
        "})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 184.61it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 1733.90it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'hugginface / transformers',\n",
              " 'end': 79,\n",
              " 'score': 0.6488578824417459,\n",
              " 'start': 54}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8sNsjNtc3Il"
      },
      "source": [
        "### Russian"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVn_8yhdc1jb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "ebb9ca2b-d077-4233-86e6-4bbd17fd6860"
      },
      "source": [
        "qa_pipeline({\n",
        "    'context': \"Мануэль Ромеро в последнее время почти не работал в репозитории hugginface / transformers\",\n",
        "    'question': \"Кто в последнее время усердно работал над обнимашками / трансформерами?\"\n",
        "    \n",
        "})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 239.94it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 411.17it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'Мануэль Ромеро',\n",
              " 'end': 14,\n",
              " 'score': 0.6974524093281502,\n",
              " 'start': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz6FS8nAc-Dv"
      },
      "source": [
        "### Hindi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd84mWGcc8cU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "020c9c0a-f84a-4655-e4f8-2e5584175c7e"
      },
      "source": [
        "# context: Coronavirus is seeding panic in the West because it expands so fast.\n",
        "# question: What is seeding the panic in the West?\n",
        "qa_pipeline({\n",
        "    'context': \"कोरोनावायरस पश्चिम में घबराहट का कारण है क्योंकि यह इतनी तेजी से फैलता है\",\n",
        "    'question': \"पश्चिम में दहशत का बीजारोपण क्या है?\"\n",
        "    \n",
        "})\n",
        "# output: Coronavirus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 464.85it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 1018.78it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'कोरोनावायरस', 'end': 11, 'score': 0.6570828916920277, 'start': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cui4YwhudD0n"
      },
      "source": [
        "### Chinese"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpLzs_NHdCzD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "752dbba9-7444-4ddc-88c3-d4ab178dbf22"
      },
      "source": [
        "# context: coronavirus is seeding the confusion in Europe because it spreads so fast. A lot of public events are being suspended.\n",
        "# question: Where does coronavirus cause confusion?\n",
        "qa_pipeline({\n",
        "    'context': \"冠状病毒在欧洲引起了混乱，因为它的传播速度如此之快。 许多公共活动都被暂停。\",\n",
        "    'question': \"冠状病毒在哪里引起混乱？\"\n",
        "    \n",
        "})\n",
        "# output: Coronavirus has caused confusion in Europe because it spreads so fast."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 212.64it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 6393.76it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': '冠状病毒在欧洲引起了混乱，因为它的传播速度如此之快。',\n",
              " 'end': 26,\n",
              " 'score': 0.7257830859596304,\n",
              " 'start': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-c8u9XxOe5UU"
      },
      "source": [
        "## Bonus: do it in a FORM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGA6yPiFe-JW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "725d47f2-e735-4190-bbc1-c93dab3f2fdc"
      },
      "source": [
        "#@title Q&A Form\n",
        "# example in armenian\n",
        "# context: Recently, Manuel Romero has been actively collaborating on the hugginface / transformers repository\n",
        "# question: Who actively collaborates on hugginface / transformers?\n",
        "context = 'Վերջերս Մանուել Ռոմերոն ակտիվորեն համագործակցում է hugginface / transformers պահոցում' #@param {type:\"string\"}\n",
        "question = 'Ո՞վ է ակտիվորեն համագործակցում hugginface / տրանսֆորմատորներում' #@param {type:\"string\"}\n",
        "\n",
        "qa_pipeline({\n",
        "    'context': context,\n",
        "    'question': question\n",
        "    \n",
        "})\n",
        "\n",
        "# output: Manuel Romero"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 172.00it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 2796.20it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'Մանուել Ռոմերոն',\n",
              " 'end': 23,\n",
              " 'score': 0.6901003019312313,\n",
              " 'start': 8}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z519bHq6Apv"
      },
      "source": [
        "### Do you want to try the cased version?\n",
        "<img src=\"https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667\" alt=\"Open In Colab\" data-canonical-src=\"https://colab.research.google.com/assets/colab-badge.svg\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iX2EItPs7FJk"
      },
      "source": [
        "### Do you have any question? Send my an [email](https://mrm8488.github.io#contact) or [AMA](https://github.com/mrm8488/ama) or Follow me on [Twitter](https://twitter.com/mrm8488)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFvmXLP1fHsS"
      },
      "source": [
        "> Created by [Manuel Romero/@mrm8488](https://twitter.com/mrm8488)"
      ]
    }
  ]
}