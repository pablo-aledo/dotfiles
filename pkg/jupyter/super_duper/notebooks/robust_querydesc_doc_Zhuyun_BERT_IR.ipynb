{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "robust querydesc-doc Zhuyun BERT IR",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkTLZ3I4_7c_"
      },
      "source": [
        "# BERT finetuning tasks in 5 minutes with Cloud TPU\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\" >\n",
        " <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wtjs1QDb3DX"
      },
      "source": [
        "**BERT**, or **B**idirectional **E**mbedding **R**epresentations from **T**ransformers, is a new method of pre-training language representations which obtains state-of-the-art results on a wide array of Natural Language Processing (NLP) tasks. The academic paper can be found here: https://arxiv.org/abs/1810.04805.\n",
        "\n",
        "This Colab demonstates using a free Colab Cloud TPU to fine-tune sentence and sentence-pair classification tasks built on top of pretrained BERT models.\n",
        "\n",
        "**Note:**  You will need a GCP (Google Compute Engine) account and a GCS (Google Cloud \n",
        "Storage) bucket for this Colab to run.\n",
        "\n",
        "Please follow the [Google Cloud TPU quickstart](https://cloud.google.com/tpu/docs/quickstart) for how to create GCP account and GCS bucket. You have [$300 free credit](https://cloud.google.com/free/) to get started with any GCP product. You can learn more about Cloud TPU at https://cloud.google.com/tpu/docs.\n",
        "\n",
        "Once you finish the setup, let's start!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycHMh-bhC-vX"
      },
      "source": [
        "**Firstly**, we need to set up Colab TPU running environment, verify a TPU device is succesfully connected and upload credentials to TPU for GCS bucket usage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "191zq3ZErihP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "5043c533-ab71-44b9-8578-2e03df3d23d9"
      },
      "source": [
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.23.109.42:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 3369616037017264270),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 2622471493146608794),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 1798304136644219600),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 10581187294090197416),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 12329653481336770435),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 14528859872554398856),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 17707723227843171150),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 3881497008498220576),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 8157979055802369997),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 3291712269752196463),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 5835223111330970448)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0825 17:59:53.579113 140009157400448 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFJrTvzMw6tf"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUBP35oCDmbF"
      },
      "source": [
        "**Secondly**, prepare and import BERT modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wzwke0sxS6W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "ab1d2b33-5827-464b-aa5a-f0b445d34c90"
      },
      "source": [
        "import sys\n",
        "!rm -r bert_repo6\n",
        "!test -d bert_repo6 || git clone https://github.com/AdeDZY/SIGIR19-BERT-IR bert_repo6\n",
        "if not 'bert_repo6' in sys.path:\n",
        "  sys.path += ['bert_repo6']\n",
        "if not '.' in sys.path:\n",
        "  sys.path += ['.']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert_repo6'...\n",
            "remote: Enumerating objects: 72, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/72)\u001b[K\rremote: Counting objects:   2% (2/72)\u001b[K\rremote: Counting objects:   4% (3/72)\u001b[K\rremote: Counting objects:   5% (4/72)\u001b[K\rremote: Counting objects:   6% (5/72)\u001b[K\rremote: Counting objects:   8% (6/72)\u001b[K\rremote: Counting objects:   9% (7/72)\u001b[K\rremote: Counting objects:  11% (8/72)\u001b[K\rremote: Counting objects:  12% (9/72)\u001b[K\rremote: Counting objects:  13% (10/72)\u001b[K\rremote: Counting objects:  15% (11/72)\u001b[K\rremote: Counting objects:  16% (12/72)\u001b[K\rremote: Counting objects:  18% (13/72)\u001b[K\rremote: Counting objects:  19% (14/72)\u001b[K\rremote: Counting objects:  20% (15/72)\u001b[K\rremote: Counting objects:  22% (16/72)\u001b[K\rremote: Counting objects:  23% (17/72)\u001b[K\rremote: Counting objects:  25% (18/72)\u001b[K\rremote: Counting objects:  26% (19/72)\u001b[K\rremote: Counting objects:  27% (20/72)\u001b[K\rremote: Counting objects:  29% (21/72)\u001b[K\rremote: Counting objects:  30% (22/72)\u001b[K\rremote: Counting objects:  31% (23/72)\u001b[K\rremote: Counting objects:  33% (24/72)\u001b[K\rremote: Counting objects:  34% (25/72)\u001b[K\rremote: Counting objects:  36% (26/72)\u001b[K\rremote: Counting objects:  37% (27/72)\u001b[K\rremote: Counting objects:  38% (28/72)\u001b[K\rremote: Counting objects:  40% (29/72)\u001b[K\rremote: Counting objects:  41% (30/72)\u001b[K\rremote: Counting objects:  43% (31/72)\u001b[K\rremote: Counting objects:  44% (32/72)\u001b[K\rremote: Counting objects:  45% (33/72)\u001b[K\rremote: Counting objects:  47% (34/72)\u001b[K\rremote: Counting objects:  48% (35/72)\u001b[K\rremote: Counting objects:  50% (36/72)\u001b[K\rremote: Counting objects:  51% (37/72)\u001b[K\rremote: Counting objects:  52% (38/72)\u001b[K\rremote: Counting objects:  54% (39/72)\u001b[K\rremote: Counting objects:  55% (40/72)\u001b[K\rremote: Counting objects:  56% (41/72)\u001b[K\rremote: Counting objects:  58% (42/72)\u001b[K\rremote: Counting objects:  59% (43/72)\u001b[K\rremote: Counting objects:  61% (44/72)\u001b[K\rremote: Counting objects:  62% (45/72)\u001b[K\rremote: Counting objects:  63% (46/72)\u001b[K\rremote: Counting objects:  65% (47/72)\u001b[K\rremote: Counting objects:  66% (48/72)\u001b[K\rremote: Counting objects:  68% (49/72)\u001b[K\rremote: Counting objects:  69% (50/72)\u001b[K\rremote: Counting objects:  70% (51/72)\u001b[K\rremote: Counting objects:  72% (52/72)\u001b[K\rremote: Counting objects:  73% (53/72)\u001b[K\rremote: Counting objects:  75% (54/72)\u001b[K\rremote: Counting objects:  76% (55/72)\u001b[K\rremote: Counting objects:  77% (56/72)\u001b[K\rremote: Counting objects:  79% (57/72)\u001b[K\rremote: Counting objects:  80% (58/72)\u001b[K\rremote: Counting objects:  81% (59/72)\u001b[K\rremote: Counting objects:  83% (60/72)\u001b[K\rremote: Counting objects:  84% (61/72)\u001b[K\rremote: Counting objects:  86% (62/72)\u001b[K\rremote: Counting objects:  87% (63/72)\u001b[K\rremote: Counting objects:  88% (64/72)\u001b[K\rremote: Counting objects:  90% (65/72)\u001b[K\rremote: Counting objects:  91% (66/72)\u001b[K\rremote: Counting objects:  93% (67/72)\u001b[K\rremote: Counting objects:  94% (68/72)\u001b[K\rremote: Counting objects:  95% (69/72)\u001b[K\rremote: Counting objects:  97% (70/72)\u001b[K\rremote: Counting objects:  98% (71/72)\u001b[K\rremote: Counting objects: 100% (72/72)\u001b[K\rremote: Counting objects: 100% (72/72), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 72 (delta 34), reused 36 (delta 15), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (72/72), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRhM1Zc3uurM"
      },
      "source": [
        "sys.path = ['',\n",
        " '/env/python',\n",
        " '/usr/lib/python36.zip',\n",
        " '/usr/lib/python3.6',\n",
        " '/usr/lib/python3.6/lib-dynload',\n",
        " '/usr/local/lib/python3.6/dist-packages',\n",
        " '/usr/lib/python3/dist-packages',\n",
        " '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n",
        " '/root/.ipython',\n",
        " '.',\n",
        " 'bert_repo6']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_G1me7e7wBCR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "40e01bd1-c6ad-4c13-9402-b79f173cfc73"
      },
      "source": [
        "sys.path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '/env/python',\n",
              " '/usr/lib/python36.zip',\n",
              " '/usr/lib/python3.6',\n",
              " '/usr/lib/python3.6/lib-dynload',\n",
              " '/usr/local/lib/python3.6/dist-packages',\n",
              " '/usr/lib/python3/dist-packages',\n",
              " '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n",
              " '/root/.ipython',\n",
              " '.',\n",
              " 'bert_repo6']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDFZNHKk2ksX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "38c4d66e-9ba2-45cb-d164-33ebb90674ef"
      },
      "source": [
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import collections\n",
        "import csv\n",
        "import os\n",
        "import modeling\n",
        "import optimization\n",
        "import tokenization\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import json\n",
        "from run_qe_classifier import *\n",
        "import random\n",
        "import re\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0825 18:00:01.416598 140009157400448 deprecation_wrapper.py:119] From bert_repo6/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfr2rQ3e3cZl"
      },
      "source": [
        "FOLD=2 #@param {type:\"integer\"}\n",
        "QUERY_FIELD=\"desc\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl4yhhXMZHXa"
      },
      "source": [
        "class MyRobust04Processor(DataProcessor):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.max_test_depth = 100\n",
        "        self.max_train_depth = 1000\n",
        "        self.n_folds = 5\n",
        "        self.fold = FOLD\n",
        "        self.q_fields = QUERY_FIELD.split(' ')\n",
        "        tf.logging.info(\"Using query fields {}\".format(' '.join(self.q_fields)))\n",
        "\n",
        "        self.train_folds = [(self.fold + i) % self.n_folds + 1 for i in range(self.n_folds - 1)]\n",
        "        self.dev_fold = (self.fold + self.n_folds - 2) % self.n_folds + 1\n",
        "        self.test_folds = (self.fold + self.n_folds - 1) % self.n_folds + 1\n",
        "        tf.logging.info(\"Train Folds: {}\".format(str(self.train_folds)))\n",
        "        tf.logging.info(\"Dev Fold: {}\".format(str(self.dev_fold)))\n",
        "        tf.logging.info(\"Test Fold: {}\".format(str(self.test_folds)))\n",
        "\n",
        "    def get_train_examples(self, data_dir):\n",
        "        examples = []\n",
        "        train_files = [\"{}.trec.with_json\".format(i) for i in self.train_folds]\n",
        "\n",
        "        qrel_file = tf.gfile.Open(os.path.join(data_dir, \"qrels\"))\n",
        "        qrels = self._read_qrel(qrel_file)\n",
        "        tf.logging.info(\"Qrel size: {}\".format(len(qrels)))\n",
        "\n",
        "        query_file = tf.gfile.Open(os.path.join(data_dir, \"queries.json\"))\n",
        "        qid2queries = self._read_queries(query_file)\n",
        "        tf.logging.info(\"Loaded {} queries.\".format(len(qid2queries)))\n",
        "        n_rel = 0\n",
        "\n",
        "        for file_name in train_files:\n",
        "            train_file = tf.gfile.Open(os.path.join(data_dir, file_name))\n",
        "            for i, line in enumerate(train_file):\n",
        "                #if random.random() > 0.33:\n",
        "                #  continue\n",
        "                items = line.strip().split('#')\n",
        "                trec_line = items[0]\n",
        "\n",
        "                qid, _, docid, r, _, _ = trec_line.strip().split(' ')\n",
        "                assert qid in qid2queries, \"QID {} not found\".format(qid)\n",
        "                q_json_dict = qid2queries[qid]\n",
        "                q_text_list = [tokenization.convert_to_unicode(q_json_dict[field]) for field in self.q_fields]\n",
        "\n",
        "                json_dict = json.loads('#'.join(items[1:]))\n",
        "                body_words = json_dict[\"doc\"][\"body\"].split(' ')\n",
        "                truncated_body = ' '.join(body_words[0: min(250, len(body_words))])\n",
        "                d = tokenization.convert_to_unicode(truncated_body)\n",
        "\n",
        "                r = int(r)\n",
        "                if r > self.max_train_depth:\n",
        "                    continue\n",
        "                label = tokenization.convert_to_unicode(\"0\")\n",
        "                if (qid, docid) in qrels or (qid, docid.split('_')[0]) in qrels:\n",
        "                    label = tokenization.convert_to_unicode(\"1\")\n",
        "                    n_rel += 1\n",
        "                guid = \"train-%s-%s\" % (qid, docid)\n",
        "                examples.append(\n",
        "                    InputExample(guid=guid, text_a_list=q_text_list, text_b=d, label=label)\n",
        "                )\n",
        "            train_file.close()\n",
        "        random.shuffle(examples)\n",
        "        tf.logging.info(\"{} relevant\".format(n_rel))\n",
        "        return examples\n",
        "\n",
        "    def get_dev_examples(self, data_dir):\n",
        "        examples = []\n",
        "        dev_file = tf.gfile.Open(os.path.join(data_dir, \"{}.trec.with_json\".format(self.dev_folds)))\n",
        "        qrel_file = tf.gfile.Open(os.path.join(data_dir, \"qrels\"))\n",
        "        qrels = self._read_qrel(qrel_file)\n",
        "        tf.logging.info(\"Qrel size: {}\".format(len(qrels)))\n",
        "\n",
        "        query_file = tf.gfile.Open(os.path.join(data_dir, \"queries.json\"))\n",
        "        qid2queries = self._read_queries(query_file)\n",
        "        tf.logging.info(\"Loaded {} queries.\".format(len(qid2queries)))\n",
        "        \n",
        "        flag = False\n",
        "        for i, line in enumerate(dev_file):\n",
        "            items = line.strip().split('#')\n",
        "            trec_line = items[0]\n",
        "\n",
        "            qid, _, docid, r, _, _ = trec_line.strip().split(' ')\n",
        "            assert qid in qid2queries, \"QID {} not found\".format(qid)\n",
        "            q_json_dict = qid2queries[qid]\n",
        "            q_text_list = [tokenization.convert_to_unicode(q_json_dict[field]) for field in self.q_fields]\n",
        "\n",
        "            json_dict = json.loads('#'.join(items[1:]))\n",
        "            body_words = json_dict[\"doc\"][\"body\"].split(' ')\n",
        "            truncated_body = ' '.join(body_words[0: min(250, len(body_words))])\n",
        "            d = tokenization.convert_to_unicode(truncated_body)\n",
        "            \n",
        "            r = int(r)\n",
        "            if r > self.max_test_depth:\n",
        "                continue\n",
        "            label = tokenization.convert_to_unicode(\"0\")\n",
        "            if (qid, docid) in qrels or (qid, docid.split('_')[0]) in qrels:\n",
        "                label = tokenization.convert_to_unicode(\"1\")\n",
        "                flag = True\n",
        "            guid = \"dev-%s-%s\" % (qid, docid)\n",
        "            examples.append(\n",
        "                InputExample(guid=guid, text_a_list=q_text_list, text_b=d, label=label)\n",
        "            )\n",
        "        dev_file.close()\n",
        "        if not flag:\n",
        "            tf.logging.warning(\"No relevant document is labeled!\")\n",
        "        return examples\n",
        "\n",
        "    def get_test_examples(self, data_dir):\n",
        "        examples = []\n",
        "        dev_file = tf.gfile.Open(os.path.join(data_dir, \"{}.trec.with_json\".format(self.test_folds)))\n",
        "        qrel_file = tf.gfile.Open(os.path.join(data_dir, \"qrels\"))\n",
        "        qrels = self._read_qrel(qrel_file)\n",
        "        tf.logging.info(\"Qrel size: {}\".format(len(qrels)))\n",
        "\n",
        "        query_file = tf.gfile.Open(os.path.join(data_dir, \"queries.json\"))\n",
        "        qid2queries = self._read_queries(query_file)\n",
        "        tf.logging.info(\"Loaded {} queries.\".format(len(qid2queries)))\n",
        "\n",
        "        for i, line in enumerate(dev_file):\n",
        "            items = line.strip().split('#')\n",
        "            trec_line = items[0]\n",
        "\n",
        "            qid, _, docid, r, _, _ = trec_line.strip().split(' ')\n",
        "            assert qid in qid2queries, \"QID {} not found\".format(qid)\n",
        "            q_json_dict = qid2queries[qid]\n",
        "            q_text_list = [tokenization.convert_to_unicode(q_json_dict[field]) for field in self.q_fields]\n",
        "\n",
        "            json_dict = json.loads('#'.join(items[1:]))\n",
        "            body_words = json_dict[\"doc\"][\"body\"].split(' ')\n",
        "            truncated_body = ' '.join(body_words[0: min(250, len(body_words))])\n",
        "            d = tokenization.convert_to_unicode(truncated_body)\n",
        "\n",
        "            r = int(r)\n",
        "            if r > self.max_test_depth:\n",
        "                continue\n",
        "            label = tokenization.convert_to_unicode(\"0\")\n",
        "            if (qid, docid) in qrels or (qid, docid.split('_')[0]) in qrels:\n",
        "                label = tokenization.convert_to_unicode(\"1\")\n",
        "            guid = \"test-%s-%s\" % (qid, docid)\n",
        "            examples.append(\n",
        "                InputExample(guid=guid, text_a_list=q_text_list, text_b=d, label=label)\n",
        "            )\n",
        "        dev_file.close()\n",
        "        return examples\n",
        "\n",
        "    def _read_qrel(self, qrel_file):\n",
        "        qrels = set()\n",
        "        for line in qrel_file:\n",
        "            qid, _, docid, rel = line.strip().split(' ')\n",
        "            rel = int(rel)\n",
        "            if rel > 0:\n",
        "                qrels.add((qid, docid))\n",
        "        return qrels\n",
        "\n",
        "    def _read_queries(self, query_file):\n",
        "        qid2queries = {}\n",
        "        for i, line in enumerate(query_file):\n",
        "            json_dict = json.loads(line)\n",
        "            qid = json_dict[\"qid\"]\n",
        "            qid2queries[qid] = json_dict\n",
        "            if i < 3:\n",
        "              tf.logging.info(\"Example Q: {}\".format(json_dict))\n",
        "        return qid2queries\n",
        "   \n",
        "    def get_labels(self):\n",
        "        return [\"0\", \"1\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRu1aKO1D7-Z"
      },
      "source": [
        "**Thirdly**, prepare for training:\n",
        "\n",
        "*  Specify task and download training data.\n",
        "*  Specify BERT pretrained model\n",
        "*  Specify GS bucket, create output directory for model checkpoints and eval results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYkaAlJNfhul",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "434372fd-d695-4dd3-b6b7-311dd222f98c"
      },
      "source": [
        "TASK = 'robust-descinit-doc' #@param {type:\"string\"}\n",
        "\n",
        "# Available pretrained model checkpoints:\n",
        "#   uncased_L-12_H-768_A-12: uncased BERT base model\n",
        "#   uncased_L-24_H-1024_A-16: uncased BERT large model\n",
        "#   cased_L-12_H-768_A-12: cased BERT large model\n",
        "BERT_MODEL = 'uncased_L-12_H-768_A-12' #@param {type:\"string\"}\n",
        "BERT_PRETRAINED_DIR = 'gs://cloud-tpu-checkpoints/bert/' + BERT_MODEL\n",
        "print('***** BERT pretrained directory: {} *****'.format(BERT_PRETRAINED_DIR))\n",
        "!gsutil ls $BERT_PRETRAINED_DIR\n",
        "\n",
        "BUCKET = 'bertir' #@param {type:\"string\"}\n",
        "assert BUCKET, 'Must specify an existing GCS bucket name'\n",
        "OUTPUT_DIR = 'gs://{}/bert/models/{}-fold{}'.format(BUCKET, TASK, FOLD)\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n",
        "\n",
        "DATA_DIR = \"robust/cv_descinit/\" #@param {type:\"string\"}\n",
        "TASK_DATA_DIR = 'gs://{}/{}'.format(BUCKET, DATA_DIR) \n",
        "\n",
        "!gsutil ls $TASK_DATA_DIR\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** BERT pretrained directory: gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12 *****\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_config.json\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_model.ckpt.index\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_model.ckpt.meta\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/checkpoint\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/vocab.txt\n",
            "***** Model output directory: gs://bertir/bert/models/robust-descinit-doc-fold2 *****\n",
            "gs://bertir/robust/cv_descinit/1.trec.with_json\n",
            "gs://bertir/robust/cv_descinit/2.trec.with_json\n",
            "gs://bertir/robust/cv_descinit/3.trec.with_json\n",
            "gs://bertir/robust/cv_descinit/4.trec.with_json\n",
            "gs://bertir/robust/cv_descinit/5.trec.with_json\n",
            "gs://bertir/robust/cv_descinit/qrels\n",
            "gs://bertir/robust/cv_descinit/queries.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hcpfl4N2EdOk"
      },
      "source": [
        "**Now, let's play!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu2dQ_TId-uH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "1266f191-c1fa-4292-9b34-1911bf7814ba"
      },
      "source": [
        "# Setup task specific model and TPU running config.\n",
        "\n",
        "import modeling\n",
        "import optimization\n",
        "import tokenization\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0' \n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "\n",
        "# Model Hyper Parameters\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "EVAL_BATCH_SIZE = 8\n",
        "PREDICT_BATCH_SIZE = 32\n",
        "\n",
        "LEARNING_RATE = 1e-5\n",
        "NUM_TRAIN_EPOCHS = 1.0\n",
        "WARMUP_PROPORTION = 0.1\n",
        "MAX_SEQCONCAT_LENGTH = 256\n",
        "\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 20000\n",
        "ITERATIONS_PER_LOOP = 1000\n",
        "NUM_TPU_CORES = 8\n",
        "VOCAB_FILE = os.path.join(BERT_PRETRAINED_DIR, 'vocab.txt')\n",
        "CONFIG_FILE = os.path.join(BERT_PRETRAINED_DIR, 'bert_config.json')\n",
        "INIT_CHECKPOINT = os.path.join(BERT_PRETRAINED_DIR, 'bert_model.ckpt')\n",
        "DO_LOWER_CASE = BERT_MODEL.startswith('uncased')\n",
        "\n",
        "\n",
        "processor = MyRobust04Processor()\n",
        "label_list = processor.get_labels()\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file=VOCAB_FILE, do_lower_case=DO_LOWER_CASE)\n",
        "\n",
        "tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "run_config = tf.contrib.tpu.RunConfig(\n",
        "    cluster=tpu_cluster_resolver,\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        iterations_per_loop=ITERATIONS_PER_LOOP,\n",
        "        num_shards=NUM_TPU_CORES,\n",
        "        per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n",
        "\n",
        "#\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I0825 18:00:40.569850 140009157400448 <ipython-input-8-61c55fbbf5b3>:9] Using query fields desc\n",
            "I0825 18:00:40.573701 140009157400448 <ipython-input-8-61c55fbbf5b3>:14] Train Folds: [3, 4, 5, 1]\n",
            "I0825 18:00:40.575356 140009157400448 <ipython-input-8-61c55fbbf5b3>:15] Dev Fold: 1\n",
            "I0825 18:00:40.576762 140009157400448 <ipython-input-8-61c55fbbf5b3>:16] Test Fold: 2\n",
            "W0825 18:00:40.577953 140009157400448 deprecation_wrapper.py:119] From bert_repo6/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQl1UDtRMcZM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "ed922f4a-c5e3-43fd-c6ab-480610f91aca"
      },
      "source": [
        "train_examples = processor.get_train_examples(TASK_DATA_DIR)\n",
        "num_train_steps = int(len(train_examples) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "model_fn = model_fn_builder(\n",
        "    bert_config=modeling.BertConfig.from_json_file(CONFIG_FILE),\n",
        "    num_labels=len(label_list),\n",
        "    init_checkpoint=INIT_CHECKPOINT,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    num_train_steps=num_train_steps,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    use_tpu=True,\n",
        "    use_one_hot_embeddings=True)\n",
        "\n",
        "estimator = tf.contrib.tpu.TPUEstimator(\n",
        "    use_tpu=True,\n",
        "    model_fn=model_fn,\n",
        "    config=run_config,\n",
        "    train_batch_size=TRAIN_BATCH_SIZE,\n",
        "    eval_batch_size=EVAL_BATCH_SIZE,\n",
        "    predict_batch_size=PREDICT_BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Qrel size: 17412\n",
            "INFO:tensorflow:Example Q: {'title': 'Islamic Revolution', 'qid': '669', 'question': 'what is Islamic Revolution', 'narr': 'Relevant documents must discuss the reasons that relations between the Islamic world and the United States have deteriorated.', 'desc_short': 'causes Islamic Revolution relative relations US', 'desc': 'What were the causes for the Islamic Revolution relative to relations with the U.S.?'}\n",
            "INFO:tensorflow:Example Q: {'title': 'poverty, disease', 'qid': '668', 'question': 'what is the relation ship between poverty and disease', 'narr': 'Documents that do not link poverty to diseases directly but mention a link between poverty and health care are relevant. Documents that simply mention poverty and disease but do not draw a connection are not relevant.', 'desc_short': 'relationship poverty disease', 'desc': 'What is the relationship between poverty and disease?'}\n",
            "INFO:tensorflow:Example Q: {'title': 'unmarried-partner households', 'qid': '667', 'question': 'what is unmarried-partner households', 'narr': 'Reference to any laws pertaining to such households as well as same sex households are relevant.', 'desc_short': 'increasing trend creation unmarried partner households US', 'desc': 'the increasing trend toward creation of unmarried-partner households in the U.S.'}\n",
            "INFO:tensorflow:Loaded 250 queries.\n",
            "INFO:tensorflow:7870 relevant\n",
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f0d1c251a60>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://bertir/bert/models/robust-descinit-doc-fold2', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 20000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      value: \"10.48.223.82:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0d1c589748>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.48.223.82:8470', '_evaluation_master': 'grpc://10.48.223.82:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f0d1c2bb550>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U_c8s2AvhgL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        },
        "outputId": "0494b688-64db-4b70-cfbd-3eb31e44d3a0"
      },
      "source": [
        "# Train the model.\n",
        "train_file = os.path.join(OUTPUT_DIR, \"train.tf_record\")\n",
        "train_features = file_based_convert_examples_to_features(\n",
        "    train_examples, label_list, MAX_SEQCONCAT_LENGTH, tokenizer, train_file)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 200000\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: train-304-FR940214-2-00015\n",
            "INFO:tensorflow:tokens: [CLS] com ##pile a list of mammals that are considered to be endangered , identify their habitat and , if possible , specify what threatens them . [SEP] department of defense army department , office of the secretary availability for the final program ##matic environmental impact statement for joint training exercise ro ##ving sands at fort bliss , texas and new mexico and white sands missile range , new mexico agency : department of the army , dod . action : notice of availability . summary : interested parties are here ##by notified that the district engineer , u . s . army corps of engineers , fort worth district , has prepared a final program ##matic environmental impact statement ( f ##pe ##is ) for the u . s . army forces command ( for ##sco ##m ) regarding joint training exercise ro ##ving sands ( rs ) proposed to be conducted at fort bliss and white sands missile range . this e ##is addresses the next five rs exercises as well as potential uses of rs sites by 3rd armored cavalry regiment and 11th air defense artillery ( ada ) brigade . [SEP]\n",
            "INFO:tensorflow:input_ids: 101 4012 22090 1037 2862 1997 11993 2008 2024 2641 2000 2022 10193 1010 6709 2037 6552 1998 1010 2065 2825 1010 20648 2054 17016 2068 1012 102 2533 1997 3639 2390 2533 1010 2436 1997 1996 3187 11343 2005 1996 2345 2565 12644 4483 4254 4861 2005 4101 2731 6912 20996 6455 13457 2012 3481 13670 1010 3146 1998 2047 3290 1998 2317 13457 7421 2846 1010 2047 3290 4034 1024 2533 1997 1996 2390 1010 26489 1012 2895 1024 5060 1997 11343 1012 12654 1024 4699 4243 2024 2182 3762 19488 2008 1996 2212 3992 1010 1057 1012 1055 1012 2390 3650 1997 6145 1010 3481 4276 2212 1010 2038 4810 1037 2345 2565 12644 4483 4254 4861 1006 1042 5051 2483 1007 2005 1996 1057 1012 1055 1012 2390 2749 3094 1006 2005 9363 2213 1007 4953 4101 2731 6912 20996 6455 13457 1006 12667 1007 3818 2000 2022 4146 2012 3481 13670 1998 2317 13457 7421 2846 1012 2023 1041 2483 11596 1996 2279 2274 12667 11110 2004 2092 2004 4022 3594 1997 12667 4573 2011 3822 10612 5945 3483 1998 6252 2250 3639 4893 1006 15262 1007 4250 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: train-408-FT931-4836\n",
            "INFO:tensorflow:tokens: [CLS] what tropical storms ( hurricanes and typhoon ##s ) have caused significant property damage and loss of life ? [SEP] un ##i store ##brand , the norwegian ins ##urer , yesterday revealed a big loss in 1992 due to a nk ##r ##2 . 63 ##bn ( dollars 37 ##3 ##m ) write - down on the group ' s 28 per cent stake in ska ##ndi ##a for ##sa ##k - rings , sweden ' s biggest ins ##urer . un ##i reported a consolidated pre - tax loss of nk ##r ##3 . 38 ##bn against a profit of nk ##r ##47 ##1 ##m in 1991 . last august , un ##i collapsed into the hands of public administrators after failing to service nk ##r ##3 . 6 ##bn in short - term debt acc ##rued to finance a failed raid on ska ##ndi ##a . un ##i said it would strive to dispose of the nk ##r ##4 . 7 ##bn ska ##ndi ##a stake as soon as possible . group net operating income rose slightly last year to nk ##r ##20 . 48 ##bn from nk ##r ##19 . 54 ##bn as operating costs remained largely the same at nk ##r ##4 . 07 ##bn . mr per ter ##je vol ##d , chief executive , said that , considering the difficult times which the group had experienced , the results achieved by the life and non - life divisions were acceptable . ' we are pleased to note that [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2054 5133 12642 1006 17035 1998 15393 2015 1007 2031 3303 3278 3200 4053 1998 3279 1997 2166 1029 102 4895 2072 3573 23544 1010 1996 5046 16021 27595 1010 7483 3936 1037 2502 3279 1999 2826 2349 2000 1037 25930 2099 2475 1012 6191 24700 1006 6363 4261 2509 2213 1007 4339 1011 2091 2006 1996 2177 1005 1055 2654 2566 9358 8406 1999 24053 16089 2050 2005 3736 2243 1011 7635 1010 4701 1005 1055 5221 16021 27595 1012 4895 2072 2988 1037 10495 3653 1011 4171 3279 1997 25930 2099 2509 1012 4229 24700 2114 1037 5618 1997 25930 2099 22610 2487 2213 1999 2889 1012 2197 2257 1010 4895 2072 7798 2046 1996 2398 1997 2270 15631 2044 7989 2000 2326 25930 2099 2509 1012 1020 24700 1999 2460 1011 2744 7016 16222 28551 2000 5446 1037 3478 8118 2006 24053 16089 2050 1012 4895 2072 2056 2009 2052 29453 2000 27764 1997 1996 25930 2099 2549 1012 1021 24700 24053 16089 2050 8406 2004 2574 2004 2825 1012 2177 5658 4082 3318 3123 3621 2197 2095 2000 25930 2099 11387 1012 4466 24700 2013 25930 2099 16147 1012 5139 24700 2004 4082 5366 2815 4321 1996 2168 2012 25930 2099 2549 1012 5718 24700 1012 2720 2566 28774 6460 5285 2094 1010 2708 3237 1010 2056 2008 1010 6195 1996 3697 2335 2029 1996 2177 2018 5281 1010 1996 3463 4719 2011 1996 2166 1998 2512 1011 2166 5908 2020 11701 1012 1005 2057 2024 7537 2000 3602 2008 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: train-639-LA121890-0104\n",
            "INFO:tensorflow:tokens: [CLS] what factors contributed to the growth of consumer on - line shopping ? [SEP] the government has taken the fun out of the year - end tax dodge . years ago , avoiding taxes could be exciting . it caused people to invest in wind farms , cattle ranch ##es and oil wells . some would hire their 3 - year - olds and pay them ex ##or ##bit ##ant salaries . others might claim their dogs as dependent ##s . ok , so some of it was shady . at least it was interesting . now , because of tax legislation passed by congress and strict ##er rules enforced by the internal revenue service , the choices are less lucrative - - and far less dice ##y . you can give money to charity , prep ##ay a few bills , sell some investments and put money away for retirement . still , the chance of dramatically reducing your tax is slight . \" people who tell you they can solve all your year - end tax problems are probably going to charge you more in fees than they ' ll save you in tax , \" sighed gregg ritchie , partner with the accounting firm of k ##pm ##g peat mar ##wick . in fact , because of new tax rules that go into effect next year , you might want to avoid tax avoidance altogether this year . \" normally you would want to def ##er income and accelerate de ##duction [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2054 5876 5201 2000 1996 3930 1997 7325 2006 1011 2240 6023 1029 102 1996 2231 2038 2579 1996 4569 2041 1997 1996 2095 1011 2203 4171 11898 1012 2086 3283 1010 9992 7773 2071 2022 10990 1012 2009 3303 2111 2000 15697 1999 3612 8623 1010 7125 8086 2229 1998 3514 7051 1012 2070 2052 10887 2037 1017 1011 2095 1011 19457 1998 3477 2068 4654 2953 16313 4630 20566 1012 2500 2453 4366 2037 6077 2004 7790 2015 1012 7929 1010 2061 2070 1997 2009 2001 22824 1012 2012 2560 2009 2001 5875 1012 2085 1010 2138 1997 4171 6094 2979 2011 3519 1998 9384 2121 3513 16348 2011 1996 4722 6599 2326 1010 1996 9804 2024 2625 21115 1011 1011 1998 2521 2625 18740 2100 1012 2017 2064 2507 2769 2000 5952 1010 17463 4710 1037 2261 8236 1010 5271 2070 10518 1998 2404 2769 2185 2005 5075 1012 2145 1010 1996 3382 1997 12099 8161 2115 4171 2003 7263 1012 1000 2111 2040 2425 2017 2027 2064 9611 2035 2115 2095 1011 2203 4171 3471 2024 2763 2183 2000 3715 2017 2062 1999 9883 2084 2027 1005 2222 3828 2017 1999 4171 1010 1000 5489 18281 20404 1010 4256 2007 1996 9529 3813 1997 1047 9737 2290 23366 9388 7184 1012 1999 2755 1010 2138 1997 2047 4171 3513 2008 2175 2046 3466 2279 2095 1010 2017 2453 2215 2000 4468 4171 24685 10462 2023 2095 1012 1000 5373 2017 2052 2215 2000 13366 2121 3318 1998 23306 2139 16256 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: train-608-FBIS4-24690\n",
            "INFO:tensorflow:tokens: [CLS] find articles that discuss the pro ##s and con ##s of taxi ##ng u . s . social security benefits . [SEP] bf ##n [ by ni ##u hui shu ##an ( 36 ##6 ##2 258 ##5 263 ##3 ) and su shu ##mei ( 56 ##85 321 ##9 273 ##4 ) : \" the social safety situation of the whole province is basically stable \" ] [ text ] in order to realistic ##ally guarantee political and social stability in our province , the provincial people ' s congress standing committee organized a law enforcement inspection group with li yong ##jin as the leader and zhang z ##hen ##hua ##n , gao yong ##tang , and zhou xi ##nr ##en as the deputy leaders to travel to shi ##jia ##zh ##uan ##g city , bao ##ding city , tang ##shan city , and qin ##hua ##ng ##da ##o city on 5 - 13 may to respectively inspect their situations in implementing the \" decision of the national people ' s congress standing committee on strengthening comprehensive management of social safety , \" and the \" he ##bei provincial regulation on comprehensive management of social safety . \" the inspection group held that our province has done much work in implementing the \" decision \" and the \" regulation , \" and achieved noticeable results in the comprehensive management of social safety . the whole province , from the urban to the rural areas , has witnessed a basically stable social safety situation and [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2424 4790 2008 6848 1996 4013 2015 1998 9530 2015 1997 10095 3070 1057 1012 1055 1012 2591 3036 6666 1012 102 28939 2078 1031 2011 9152 2226 17504 18454 2319 1006 4029 2575 2475 24398 2629 25246 2509 1007 1998 10514 18454 26432 1006 5179 27531 24030 2683 25371 2549 1007 1024 1000 1996 2591 3808 3663 1997 1996 2878 2874 2003 10468 6540 1000 1033 1031 3793 1033 1999 2344 2000 12689 3973 11302 2576 1998 2591 9211 1999 2256 2874 1010 1996 4992 2111 1005 1055 3519 3061 2837 4114 1037 2375 7285 10569 2177 2007 5622 18999 14642 2004 1996 3003 1998 9327 1062 10222 14691 2078 1010 17377 18999 26067 1010 1998 14367 8418 16118 2368 2004 1996 4112 4177 2000 3604 2000 11895 26541 27922 13860 2290 2103 1010 25945 4667 2103 1010 9745 9688 2103 1010 1998 19781 14691 3070 2850 2080 2103 2006 1019 1011 2410 2089 2000 4414 22459 2037 8146 1999 14972 1996 1000 3247 1997 1996 2120 2111 1005 1055 3519 3061 2837 2006 16003 7721 2968 1997 2591 3808 1010 1000 1998 1996 1000 2002 19205 4992 7816 2006 7721 2968 1997 2591 3808 1012 1000 1996 10569 2177 2218 2008 2256 2874 2038 2589 2172 2147 1999 14972 1996 1000 3247 1000 1998 1996 1000 7816 1010 1000 1998 4719 17725 3463 1999 1996 7721 2968 1997 2591 3808 1012 1996 2878 2874 1010 2013 1996 3923 2000 1996 3541 2752 1010 2038 9741 1037 10468 6540 2591 3808 3663 1998 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: train-361-FT933-16036\n",
            "INFO:tensorflow:tokens: [CLS] discuss clothing sweat ##sho ##ps . [SEP] when tor ##ay , japan ' s biggest textiles company , opens a pounds 50 ##m factory in the uk tomorrow there will be the usual ribbon - cutting and rice wine . but behind the ra ##zz ##mata ##zz lies a deep pe ##ssi ##mism in the industry . like many leading western industrial ##ised countries , japan has seen the production of textiles and clothing drift to countries with lower wages elsewhere in asia . unlike its western counterparts , however , the japanese government seems unwilling to protect domestic companies with trade barriers against imports . an executive at te ##iji ##n , japan ' s second - largest synthetic fibre textiles company , blame ##s the lack of domestic protection on the us and the ec , both of which are pressing japan to cut its trade surplus , set to reach dollars 150 ##bn this year . ' the government has problems with the trade surplus . we believe that the ( domestic ) textile and clothing industries will be sacrificed , ' he said . but japan ' s textiles companies are not prepared to be martyrs in the trade war . unable to beat the import ##ers on home territory , they are engaged in an unprecedented diversion of investment abroad . overseas , they can take advantage of a combination of lower labour costs , lower transport costs to local customers and access to local markets that have import [SEP]\n",
            "INFO:tensorflow:input_ids: 101 6848 5929 7518 22231 4523 1012 102 2043 17153 4710 1010 2900 1005 1055 5221 18762 2194 1010 7480 1037 7038 2753 2213 4713 1999 1996 2866 4826 2045 2097 2022 1996 5156 10557 1011 6276 1998 5785 4511 1012 2021 2369 1996 10958 13213 21022 13213 3658 1037 2784 21877 18719 26725 1999 1996 3068 1012 2066 2116 2877 2530 3919 5084 3032 1010 2900 2038 2464 1996 2537 1997 18762 1998 5929 11852 2000 3032 2007 2896 12678 6974 1999 4021 1012 4406 2049 2530 14562 1010 2174 1010 1996 2887 2231 3849 15175 2000 4047 4968 3316 2007 3119 13500 2114 17589 1012 2019 3237 2012 8915 27821 2078 1010 2900 1005 1055 2117 1011 2922 12553 20962 18762 2194 1010 7499 2015 1996 3768 1997 4968 3860 2006 1996 2149 1998 1996 14925 1010 2119 1997 2029 2024 7827 2900 2000 3013 2049 3119 15726 1010 2275 2000 3362 6363 5018 24700 2023 2095 1012 1005 1996 2231 2038 3471 2007 1996 3119 15726 1012 2057 2903 2008 1996 1006 4968 1007 12437 1998 5929 6088 2097 2022 20268 1010 1005 2002 2056 1012 2021 2900 1005 1055 18762 3316 2024 2025 4810 2000 2022 18945 1999 1996 3119 2162 1012 4039 2000 3786 1996 12324 2545 2006 2188 3700 1010 2027 2024 5117 1999 2019 15741 20150 1997 5211 6917 1012 6931 1010 2027 2064 2202 5056 1997 1037 5257 1997 2896 4428 5366 1010 2896 3665 5366 2000 2334 6304 1998 3229 2000 2334 6089 2008 2031 12324 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:Writing example 10000 of 200000\n",
            "INFO:tensorflow:Writing example 20000 of 200000\n",
            "INFO:tensorflow:Writing example 30000 of 200000\n",
            "INFO:tensorflow:Writing example 40000 of 200000\n",
            "INFO:tensorflow:Writing example 50000 of 200000\n",
            "INFO:tensorflow:Writing example 60000 of 200000\n",
            "INFO:tensorflow:Writing example 70000 of 200000\n",
            "INFO:tensorflow:Writing example 80000 of 200000\n",
            "INFO:tensorflow:Writing example 90000 of 200000\n",
            "INFO:tensorflow:Writing example 100000 of 200000\n",
            "INFO:tensorflow:Writing example 110000 of 200000\n",
            "INFO:tensorflow:Writing example 120000 of 200000\n",
            "INFO:tensorflow:Writing example 130000 of 200000\n",
            "INFO:tensorflow:Writing example 140000 of 200000\n",
            "INFO:tensorflow:Writing example 150000 of 200000\n",
            "INFO:tensorflow:Writing example 160000 of 200000\n",
            "INFO:tensorflow:Writing example 170000 of 200000\n",
            "INFO:tensorflow:Writing example 180000 of 200000\n",
            "INFO:tensorflow:Writing example 190000 of 200000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBotBeY2SmOF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5868
        },
        "outputId": "282b0a59-ac33-4842-92e8-1bb1d6f09b6e"
      },
      "source": [
        "train_file = os.path.join(OUTPUT_DIR, \"train.tf_record\")\n",
        "\n",
        "print('***** Started training at {} *****'.format(datetime.datetime.now()))\n",
        "print('  Batch size = {}'.format(TRAIN_BATCH_SIZE))\n",
        "tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
        "train_input_fn = file_based_input_fn_builder(\n",
        "    input_file=train_file,\n",
        "    seq_length=MAX_SEQCONCAT_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=True)\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "print('***** Finished training at {} *****'.format(datetime.datetime.now()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Started training at 2019-02-17 22:31:27.056560 *****\n",
            "  Batch size = 16\n",
            "INFO:tensorflow:  Num steps = 12500\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.48.223.82:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 30147252720118779)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 5943998631476698115)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 6996880061535684028)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 8869860106319317431)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 9648826225144127634)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 8183343211811544839)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 9017370592501583399)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 14197139647162520709)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 6523081069847528375)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 6437766214945267913)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 12312129282703901937)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From bert_repo6/run_qe_classifier.py:671: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "WARNING:tensorflow:From bert_repo6/run_qe_classifier.py:651: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:1720: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
            "INFO:tensorflow:*** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (2, 256)\n",
            "INFO:tensorflow:  name = input_mask, shape = (2, 256)\n",
            "INFO:tensorflow:  name = is_real_example, shape = (2,)\n",
            "INFO:tensorflow:  name = label_ids, shape = (2,)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (2, 256)\n",
            "WARNING:tensorflow:From bert_repo6/modeling.py:359: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From bert_repo6/modeling.py:673: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = output_weights:0, shape = (2, 768)\n",
            "INFO:tensorflow:  name = output_bias:0, shape = (2,)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into gs://bertir/bert/models/robust-descinit-doc-fold2/model.ckpt.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Installing graceful shutdown hook.\n",
            "INFO:tensorflow:Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "INFO:tensorflow:Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 7 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.002480302, step = 1000\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.0035083757, step = 2000 (66.336 sec)\n",
            "INFO:tensorflow:global_step/sec: 15.0747\n",
            "INFO:tensorflow:examples/sec: 241.195\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 3.7903695, step = 3000 (60.729 sec)\n",
            "INFO:tensorflow:global_step/sec: 16.4667\n",
            "INFO:tensorflow:examples/sec: 263.467\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.00029360162, step = 4000 (61.282 sec)\n",
            "INFO:tensorflow:global_step/sec: 16.318\n",
            "INFO:tensorflow:examples/sec: 261.088\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.00023701639, step = 5000 (60.813 sec)\n",
            "INFO:tensorflow:global_step/sec: 16.4438\n",
            "INFO:tensorflow:examples/sec: 263.1\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.00068673975, step = 6000 (61.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 16.3556\n",
            "INFO:tensorflow:examples/sec: 261.689\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.00012438741, step = 7000 (61.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 16.3419\n",
            "INFO:tensorflow:examples/sec: 261.47\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.00021740227, step = 8000 (60.793 sec)\n",
            "INFO:tensorflow:global_step/sec: 16.4492\n",
            "INFO:tensorflow:examples/sec: 263.187\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 9.869681e-05, step = 9000 (60.756 sec)\n",
            "INFO:tensorflow:global_step/sec: 16.4596\n",
            "INFO:tensorflow:examples/sec: 263.354\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.00023979631, step = 10000 (61.236 sec)\n",
            "INFO:tensorflow:global_step/sec: 16.3302\n",
            "INFO:tensorflow:examples/sec: 261.283\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.0030450176, step = 11000 (60.845 sec)\n",
            "INFO:tensorflow:global_step/sec: 16.4355\n",
            "INFO:tensorflow:examples/sec: 262.967\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.0010376909, step = 12000 (61.248 sec)\n",
            "INFO:tensorflow:global_step/sec: 16.3267\n",
            "INFO:tensorflow:examples/sec: 261.227\n",
            "INFO:tensorflow:Enqueue next (500) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (500) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.0003310985, step = 12500 (31.012 sec)\n",
            "INFO:tensorflow:global_step/sec: 16.1227\n",
            "INFO:tensorflow:examples/sec: 257.964\n",
            "INFO:tensorflow:Saving checkpoints for 12500 into gs://bertir/bert/models/robust-descinit-doc-fold2/model.ckpt.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:Loss for final step: 0.0003310985.\n",
            "INFO:tensorflow:training_loop marked as finished\n",
            "***** Finished training at 2019-02-17 22:46:41.654223 *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMoAi_LYLBRm"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDgZbmLnUaLf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "2a54d6df-cad3-4ece-9964-7356cc0c337a"
      },
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "predict_examples = processor.get_test_examples(TASK_DATA_DIR)\n",
        "num_actual_predict_examples = len(predict_examples)\n",
        "assert num_actual_predict_examples > 0\n",
        "predict_batch_size = 32\n",
        "while len(predict_examples) % predict_batch_size != 0:\n",
        "  predict_examples.append(PaddingInputExample())\n",
        "\n",
        "predict_file = os.path.join(OUTPUT_DIR, \"predict.tf_record\")\n",
        "file_based_convert_examples_to_features(predict_examples, label_list,\n",
        "                                        MAX_SEQCONCAT_LENGTH, tokenizer,\n",
        "                                        predict_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Qrel size: 17412\n",
            "INFO:tensorflow:Example Q: {'title': 'Islamic Revolution', 'qid': '669', 'question': 'what is Islamic Revolution', 'narr': 'Relevant documents must discuss the reasons that relations between the Islamic world and the United States have deteriorated.', 'desc_short': 'causes Islamic Revolution relative relations US', 'desc': 'What were the causes for the Islamic Revolution relative to relations with the U.S.?'}\n",
            "INFO:tensorflow:Example Q: {'title': 'poverty, disease', 'qid': '668', 'question': 'what is the relation ship between poverty and disease', 'narr': 'Documents that do not link poverty to diseases directly but mention a link between poverty and health care are relevant. Documents that simply mention poverty and disease but do not draw a connection are not relevant.', 'desc_short': 'relationship poverty disease', 'desc': 'What is the relationship between poverty and disease?'}\n",
            "INFO:tensorflow:Example Q: {'title': 'unmarried-partner households', 'qid': '667', 'question': 'what is unmarried-partner households', 'narr': 'Reference to any laws pertaining to such households as well as same sex households are relevant.', 'desc_short': 'increasing trend creation unmarried partner households US', 'desc': 'the increasing trend toward creation of unmarried-partner households in the U.S.'}\n",
            "INFO:tensorflow:Loaded 250 queries.\n",
            "INFO:tensorflow:Writing example 0 of 5024\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: test-332-FT933-6679\n",
            "INFO:tensorflow:tokens: [CLS] this query is looking for investigations that have targeted evade ##rs of u . s . income tax . [SEP] tom wins ##hip , investigations manager of the inland revenue compliance unit in sl ##ough , believes that most people are basically honest and willing to pay their taxes . ' we are not in the business of putting people out of business . we just want people to join our club and be contributors , ' he says . his team of four officers is one of the few branches of the civil service that can show a financial return on its activities . for every pounds 1 spent , it collects pounds 5 from tax evade ##rs . ' people are app ##re ##hen ##sive of us but we do generally try to be understanding , ' he says . ' we don ' t seek to crush people to death . after all nobody likes paying tax and we don ' t get a discount because we work here . ' wins ##hip ' s team pursue ##s unpaid schedule d taxes - those level ##led on the self - employed . sl ##ough has between 8 , 000 and 9 , 000 people registered to pay schedule d , and the office investigates about 1 , 000 separate cases of suspected eva ##sion in that tax category every year . ' many of our inquiries arise from telephone calls from informant ##s and anonymous letters , ' says beverley stain [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2023 23032 2003 2559 2005 9751 2008 2031 9416 26399 2869 1997 1057 1012 1055 1012 3318 4171 1012 102 3419 5222 5605 1010 9751 3208 1997 1996 9514 6599 12646 3131 1999 22889 10593 1010 7164 2008 2087 2111 2024 10468 7481 1998 5627 2000 3477 2037 7773 1012 1005 2057 2024 2025 1999 1996 2449 1997 5128 2111 2041 1997 2449 1012 2057 2074 2215 2111 2000 3693 2256 2252 1998 2022 16884 1010 1005 2002 2758 1012 2010 2136 1997 2176 3738 2003 2028 1997 1996 2261 5628 1997 1996 2942 2326 2008 2064 2265 1037 3361 2709 2006 2049 3450 1012 2005 2296 7038 1015 2985 1010 2009 17427 7038 1019 2013 4171 26399 2869 1012 1005 2111 2024 10439 2890 10222 12742 1997 2149 2021 2057 2079 3227 3046 2000 2022 4824 1010 1005 2002 2758 1012 1005 2057 2123 1005 1056 6148 2000 10188 2111 2000 2331 1012 2044 2035 6343 7777 7079 4171 1998 2057 2123 1005 1056 2131 1037 19575 2138 2057 2147 2182 1012 1005 5222 5605 1005 1055 2136 7323 2015 23850 6134 1040 7773 1011 2216 2504 3709 2006 1996 2969 1011 4846 1012 22889 10593 2038 2090 1022 1010 2199 1998 1023 1010 2199 2111 5068 2000 3477 6134 1040 1010 1998 1996 2436 28062 2055 1015 1010 2199 3584 3572 1997 6878 9345 10992 1999 2008 4171 4696 2296 2095 1012 1005 2116 1997 2256 27050 13368 2013 7026 4455 2013 28694 2015 1998 10812 4144 1010 1005 2758 29057 21101 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: test-332-FBIS4-44451\n",
            "INFO:tensorflow:tokens: [CLS] this query is looking for investigations that have targeted evade ##rs of u . s . income tax . [SEP] cs ##o [ article by fan hai ##jian ( 540 ##0 318 ##9 101 ##7 ) and gen ##g jian ##yu ##n ( 510 ##5 169 ##6 00 ##6 ##1 ) : \" what does 15 . 4 billion yuan tell us - - a look into the nationwide inspection of tax revenue , financial affairs , and commodity prices \" ] [ text ] the 1993 inspection of tax revenue , financial affairs and commodity prices in china revealed numerous violations of laws and regulations totaling 15 . 4 billion yuan , of which 10 billion yuan were recovered for the nation ' s treasury , a result which pleased us all . but while we may re ##jo ##ice over the success , we cannot help but be somewhat concerned , what does the 15 . 4 billion yuan really tell us ? a series of shocking figures according to a report furnished by an authoritative source , analysis of the total monetary amount of tax and financial revenue violations uncovered in the 1993 inspection indicates that : - - by method of inspection , 6 . 57 billion yuan or 42 . 8 percent came from internal inspection by the enterprises and work units , and 8 . 79 billion yuan or 57 . 2 percent from outside inspection . the amounts of violations in the two categories are 2 . [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2023 23032 2003 2559 2005 9751 2008 2031 9416 26399 2869 1997 1057 1012 1055 1012 3318 4171 1012 102 20116 2080 1031 3720 2011 5470 15030 27685 1006 20263 2692 27003 2683 7886 2581 1007 1998 8991 2290 29214 10513 2078 1006 23475 2629 18582 2575 4002 2575 2487 1007 1024 1000 2054 2515 2321 1012 1018 4551 11237 2425 2149 1011 1011 1037 2298 2046 1996 9053 10569 1997 4171 6599 1010 3361 3821 1010 1998 19502 7597 1000 1033 1031 3793 1033 1996 2857 10569 1997 4171 6599 1010 3361 3821 1998 19502 7597 1999 2859 3936 3365 13302 1997 4277 1998 7040 21798 2321 1012 1018 4551 11237 1010 1997 2029 2184 4551 11237 2020 6757 2005 1996 3842 1005 1055 9837 1010 1037 2765 2029 7537 2149 2035 1012 2021 2096 2057 2089 2128 5558 6610 2058 1996 3112 1010 2057 3685 2393 2021 2022 5399 4986 1010 2054 2515 1996 2321 1012 1018 4551 11237 2428 2425 2149 1029 1037 2186 1997 16880 4481 2429 2000 1037 3189 19851 2011 2019 23949 3120 1010 4106 1997 1996 2561 12194 3815 1997 4171 1998 3361 6599 13302 14486 1999 1996 2857 10569 7127 2008 1024 1011 1011 2011 4118 1997 10569 1010 1020 1012 5401 4551 11237 2030 4413 1012 1022 3867 2234 2013 4722 10569 2011 1996 9926 1998 2147 3197 1010 1998 1022 1012 6535 4551 11237 2030 5401 1012 1016 3867 2013 2648 10569 1012 1996 8310 1997 13302 1999 1996 2048 7236 2024 1016 1012 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: test-332-LA072789-0069\n",
            "INFO:tensorflow:tokens: [CLS] this query is looking for investigations that have targeted evade ##rs of u . s . income tax . [SEP] a controversial procedure under which tax cheat ##s could pay back taxes and avoid criminal prosecution is a long - established part of internal revenue service practice nationwide and is well known among attorneys specializing in tax disputes , legal experts said wednesday . the informal practice is described in official irs manual ##s - - and thus is sanctioned by the agency - - and made available to anyone , not just those with close relationships with irs officials , the experts said . these views contrast sharply with characterization ##s made by congressional investigators this week probing allegations of misconduct at irs offices in los angeles and elsewhere . investigators contend ##ed that these arrangements , involving the los angeles office in particular , involved favor ##itis ##m and were not approved by national irs headquarters . \" it ' s legal , there ' s no question about it , \" said roger olsen , a los angeles tax attorney and former assistant u . s . attorney general in charge of all federal tax prosecution ##s between 1981 and 1987 . \" if you go to tax seminars , the subject is widely di ##sse ##minated . it ' s not a secret , \" said eugene d . silver ##man , a los angeles tax attorney and a former attorney with the irs and justice department . \" i [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2023 23032 2003 2559 2005 9751 2008 2031 9416 26399 2869 1997 1057 1012 1055 1012 3318 4171 1012 102 1037 6801 7709 2104 2029 4171 21910 2015 2071 3477 2067 7773 1998 4468 4735 11537 2003 1037 2146 1011 2511 2112 1997 4722 6599 2326 3218 9053 1998 2003 2092 2124 2426 16214 14055 1999 4171 11936 1010 3423 8519 2056 9317 1012 1996 11900 3218 2003 2649 1999 2880 25760 6410 2015 1011 1011 1998 2947 2003 14755 2011 1996 4034 1011 1011 1998 2081 2800 2000 3087 1010 2025 2074 2216 2007 2485 6550 2007 25760 4584 1010 1996 8519 2056 1012 2122 5328 5688 9249 2007 23191 2015 2081 2011 7740 14766 2023 2733 28664 9989 1997 23337 2012 25760 4822 1999 3050 3349 1998 6974 1012 14766 27481 2098 2008 2122 7565 1010 5994 1996 3050 3349 2436 1999 3327 1010 2920 5684 13706 2213 1998 2020 2025 4844 2011 2120 25760 4075 1012 1000 2009 1005 1055 3423 1010 2045 1005 1055 2053 3160 2055 2009 1010 1000 2056 5074 18997 1010 1037 3050 3349 4171 4905 1998 2280 3353 1057 1012 1055 1012 4905 2236 1999 3715 1997 2035 2976 4171 11537 2015 2090 3261 1998 3055 1012 1000 2065 2017 2175 2000 4171 17239 1010 1996 3395 2003 4235 4487 11393 26972 1012 2009 1005 1055 2025 1037 3595 1010 1000 2056 8207 1040 1012 3165 2386 1010 1037 3050 3349 4171 4905 1998 1037 2280 4905 2007 1996 25760 1998 3425 2533 1012 1000 1045 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:label: 1 (id = 1)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: test-332-FBIS4-53968\n",
            "INFO:tensorflow:tokens: [CLS] this query is looking for investigations that have targeted evade ##rs of u . s . income tax . [SEP] bf ##n [ text ] tokyo , may 24 ky ##od ##o - - simultaneous implementation of a hike in the consumption tax and an income tax cut would have an adverse impact on private consumption , prime minister ts ##uto ##mu hat ##a said tuesday [ 24 may ] . if the government were to implement a consumption tax hike and income tax cut \" without a time differential , it would only discourage consumption , \" hat ##a told the house of representatives budget committee . \" it is utterly un ##thi ##nka ##ble to implement a tax hike alone from now on , \" hat ##a said in response to a query from japanese communist party inter ##pel ##lat ##or ka ##zu ##o shi ##i , who pressed hat ##a to clarify whether the government will hike the consumption tax . the tax rate is currently 3 percent . hat ##a hinted that the government will implement another tax cut in advance of a consumption tax hike , saying that a time la ##g between the two \" is con ##ce ##iva ##ble . \" \" the ratio of consumption - related taxes to total state revenue ( in japan ) is the lowest among the ( 24 ) member states of the organization for economic cooperation and development , \" he said . the japanese ratio stands at 19 . [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2023 23032 2003 2559 2005 9751 2008 2031 9416 26399 2869 1997 1057 1012 1055 1012 3318 4171 1012 102 28939 2078 1031 3793 1033 5522 1010 2089 2484 18712 7716 2080 1011 1011 17424 7375 1997 1037 21857 1999 1996 8381 4171 1998 2019 3318 4171 3013 2052 2031 2019 15316 4254 2006 2797 8381 1010 3539 2704 24529 16161 12274 6045 2050 2056 9857 1031 2484 2089 1033 1012 2065 1996 2231 2020 2000 10408 1037 8381 4171 21857 1998 3318 4171 3013 1000 2302 1037 2051 11658 1010 2009 2052 2069 28085 8381 1010 1000 6045 2050 2409 1996 2160 1997 4505 5166 2837 1012 1000 2009 2003 12580 4895 15222 25804 3468 2000 10408 1037 4171 21857 2894 2013 2085 2006 1010 1000 6045 2050 2056 1999 3433 2000 1037 23032 2013 2887 4750 2283 6970 11880 20051 2953 10556 9759 2080 11895 2072 1010 2040 4508 6045 2050 2000 25037 3251 1996 2231 2097 21857 1996 8381 4171 1012 1996 4171 3446 2003 2747 1017 3867 1012 6045 2050 21795 2008 1996 2231 2097 10408 2178 4171 3013 1999 5083 1997 1037 8381 4171 21857 1010 3038 2008 1037 2051 2474 2290 2090 1996 2048 1000 2003 9530 3401 11444 3468 1012 1000 1000 1996 6463 1997 8381 1011 3141 7773 2000 2561 2110 6599 1006 1999 2900 1007 2003 1996 7290 2426 1996 1006 2484 1007 2266 2163 1997 1996 3029 2005 3171 6792 1998 2458 1010 1000 2002 2056 1012 1996 2887 6463 4832 2012 2539 1012 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: test-332-FT933-6681\n",
            "INFO:tensorflow:tokens: [CLS] this query is looking for investigations that have targeted evade ##rs of u . s . income tax . [SEP] as the uk ' s fruit - picking season gets under way , the pretty apple orchards of kent and sussex are teaming with what the inland revenue calls the ' ghosts ' and ' moonlight ##ers ' who make up britain ' s bloom ##ing hidden economy . these phantom employees , for whom the revenue has no records , work not just in agriculture , but as waiter ##s , cleaner ##s , sales ##men , mini - cab drivers and decor ##ators . they have one thing in common : not a penny of their earnings finds its way to the exchequer . their combined efforts make up the uk ' s informal or hidden economy - legitimate economic activity that is not declared for tax . for a government that is looking at all areas of public spending to find possible cuts or extra revenue , the informal sector would appear to provide rich picking ##s . mr peter lille ##y , social security secretary , has raised his cabinet profile with a summer campaign aimed at saving pounds 1b ##n by stopping the ' selfish crimes ' of social security fraud ##sters . stepping up efforts to crack down on tax eva ##sion would seem the logical co ##roll ##ary . but the absence of accurate figures on the size of the black economy - by definition the transactions [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2023 23032 2003 2559 2005 9751 2008 2031 9416 26399 2869 1997 1057 1012 1055 1012 3318 4171 1012 102 2004 1996 2866 1005 1055 5909 1011 8130 2161 4152 2104 2126 1010 1996 3492 6207 22976 1997 5982 1998 9503 2024 27025 2007 2054 1996 9514 6599 4455 1996 1005 11277 1005 1998 1005 11986 2545 1005 2040 2191 2039 3725 1005 1055 13426 2075 5023 4610 1012 2122 11588 5126 1010 2005 3183 1996 6599 2038 2053 2636 1010 2147 2025 2074 1999 5237 1010 2021 2004 15610 2015 1010 20133 2015 1010 4341 3549 1010 7163 1011 9298 6853 1998 25545 18926 1012 2027 2031 2028 2518 1999 2691 1024 2025 1037 10647 1997 2037 16565 4858 2049 2126 2000 1996 28889 1012 2037 4117 4073 2191 2039 1996 2866 1005 1055 11900 2030 5023 4610 1011 11476 3171 4023 2008 2003 2025 4161 2005 4171 1012 2005 1037 2231 2008 2003 2559 2012 2035 2752 1997 2270 5938 2000 2424 2825 7659 2030 4469 6599 1010 1996 11900 4753 2052 3711 2000 3073 4138 8130 2015 1012 2720 2848 22479 2100 1010 2591 3036 3187 1010 2038 2992 2010 5239 6337 2007 1037 2621 3049 6461 2012 7494 7038 26314 2078 2011 7458 1996 1005 14337 6997 1005 1997 2591 3036 9861 15608 1012 9085 2039 4073 2000 8579 2091 2006 4171 9345 10992 2052 4025 1996 11177 2522 28402 5649 1012 2021 1996 6438 1997 8321 4481 2006 1996 2946 1997 1996 2304 4610 1011 2011 6210 1996 11817 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRC2z8LcKxNv"
      },
      "source": [
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "#predict_file=\"gs://bertir/bert/models/marco/predict.tf_record\"\n",
        "#num_actual_predict_examples = 999240\n",
        "tf.logging.info(\"***** Running prediction*****\")\n",
        "#tf.logging.info(\"  Num examples = %d (%d actual, %d padding)\",\n",
        "#                    len(predict_examples), num_actual_predict_examples,\n",
        "#                    len(predict_examples) - num_actual_predict_examples)\n",
        "tf.logging.info(\"  Batch size = %d\", PREDICT_BATCH_SIZE)\n",
        "\n",
        "predict_drop_remainder = True \n",
        "predict_input_fn = file_based_input_fn_builder(\n",
        "        input_file=predict_file,\n",
        "        seq_length=MAX_SEQCONCAT_LENGTH,\n",
        "        is_training=False,\n",
        "        drop_remainder=predict_drop_remainder)\n",
        "\n",
        "result = estimator.predict(input_fn=predict_input_fn)\n",
        "\n",
        "output_predict_file = os.path.join(OUTPUT_DIR, \"test_results.tsv\")\n",
        "with tf.gfile.GFile(output_predict_file, \"w\") as writer:\n",
        "  num_written_lines = 0\n",
        "  tf.logging.info(\"***** Predict results *****\")\n",
        "  for (i, prediction) in enumerate(result):\n",
        "    probabilities = prediction[\"probabilities\"]\n",
        "    if i >= num_actual_predict_examples:\n",
        "      break\n",
        "    output_line = \"\\t\".join(\n",
        "            str(class_probability)\n",
        "            for class_probability in probabilities) + \"\\n\"\n",
        "    writer.write(output_line)\n",
        "    num_written_lines += 1\n",
        "    if num_written_lines % 100000 == 0:\n",
        "      print(num_written_lines)\n",
        "assert num_written_lines == num_actual_predict_examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lqHzLU8LBad"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoXRtSPZvdiS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "52c4e089-74c5-4ba9-ecbb-73a470d7a364"
      },
      "source": [
        "# Eval the model.\n",
        "eval_examples = processor.get_dev_examples(TASK_DATA_DIR)\n",
        "eval_features = run_classifier.convert_examples_to_features(\n",
        "    eval_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "print('***** Started evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "print('  Num examples = {}'.format(len(eval_examples)))\n",
        "print('  Batch size = {}'.format(EVAL_BATCH_SIZE))\n",
        "# Eval will be slightly WRONG on the TPU because it will truncate\n",
        "# the last batch.\n",
        "eval_steps = int(len(eval_examples) / EVAL_BATCH_SIZE)\n",
        "eval_input_fn = run_classifier.input_fn_builder(\n",
        "    features=eval_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=True)\n",
        "result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)\n",
        "print('***** Finished evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "output_eval_file = os.path.join(OUTPUT_DIR, \"eval_results.txt\")\n",
        "with tf.gfile.GFile(output_eval_file, \"w\") as writer:\n",
        "  print(\"***** Eval results *****\")\n",
        "  for key in sorted(result.keys()):\n",
        "    print('  {} = {}'.format(key, str(result[key])))\n",
        "    writer.write(\"%s = %s\\n\" % (key, str(result[key])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-8f3170d2c22c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meval_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dev_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTASK_DATA_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m eval_features = run_classifier.convert_examples_to_features(\n\u001b[1;32m      3\u001b[0m     eval_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'***** Started evaluation at {} *****'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'  Num examples = {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-0eec902fe2a7>\u001b[0m in \u001b[0;36mget_dev_examples\u001b[0;34m(self, data_dir)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_dev_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mexamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mdev_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{}.trec.with_json\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdev_folds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mqrel_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"qrels\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mqrels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_qrel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqrel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'MyClueWebProcessor' object has no attribute 'dev_folds'"
          ]
        }
      ]
    }
  ]
}