{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Sentiment_Analyst_Test_v4.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4vmy9UGGDE_"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQ7p1I-xbfE-"
      },
      "source": [
        "## Connect to Google Drive\n",
        "\n",
        "First thing first, connect this Google Colab project to Google Drive.\n",
        "\n",
        "Run the code below to connect them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbrBwJm6Kad_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "a4c106fe-1b4f-470a-c748-85913d2cae0d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BPlLtZhAg40"
      },
      "source": [
        "## Load the Data from *.csv* Source\n",
        "\n",
        "Here we use **Hotel Reviews** data from Kaggle as our dataset. You can download it [here](https://https://www.kaggle.com/anu0012/hotel-review). After that, upload the .csv file to any directory in your personal Google Drive.\n",
        "</br>\n",
        "\n",
        "The hotel review data from the link provided above consists of *train.csv* and *test.csv*. But, in this project we will be using the **latter** only\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "To acces the data in the .csv file, copy the path of that .csv file and store it in a variable called `data` using the code provided below.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-12T02:28:26.067339Z",
          "start_time": "2019-01-12T02:28:25.657870Z"
        },
        "id": "L1CIqN0PGDFv"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Raihan's Google Drive directory\n",
        "# data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Datasets/hotelReview_train.csv')\n",
        "\n",
        "# Ibnu's Google Drive directory\n",
        "# data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Hotel Review/train.csv')\n",
        "\n",
        "# Local directory\n",
        "data = pd.read_csv('hotel_review_train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SPTfBMOGDGF"
      },
      "source": [
        "## Displaying the Data\n",
        "\n",
        "After the data has been sucessfully read, we can display different aspects of the data programmatically."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8INTYS7DaCF2"
      },
      "source": [
        "Below is a snippet code to output the numbers of (row, column)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-12T02:28:26.167477Z",
          "start_time": "2019-01-12T02:28:26.161840Z"
        },
        "id": "yQ-oclyEGDGU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e18a9705-e5f3-416d-dab6-2b08564eb77e"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38932, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI6Pt4m-aKFe"
      },
      "source": [
        "Below is a snippet code to output a `n` random of row(s)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-12T02:28:26.940688Z",
          "start_time": "2019-01-12T02:28:26.920105Z"
        },
        "id": "1JfN1FAVGDHO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "03679aae-5039-48ff-fffd-d3f9991508b1"
      },
      "source": [
        "data.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User_ID</th>\n",
              "      <th>Description</th>\n",
              "      <th>Browser_Used</th>\n",
              "      <th>Device_Used</th>\n",
              "      <th>Is_Response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1642</th>\n",
              "      <td>id11968</td>\n",
              "      <td>My husband and I plus two of our friends (anot...</td>\n",
              "      <td>Firefox</td>\n",
              "      <td>Mobile</td>\n",
              "      <td>not happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22265</th>\n",
              "      <td>id32591</td>\n",
              "      <td>After reading reviews, I thought this was goin...</td>\n",
              "      <td>Mozilla Firefox</td>\n",
              "      <td>Mobile</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1932</th>\n",
              "      <td>id12258</td>\n",
              "      <td>This is a reliable, consistent hotel. Not spec...</td>\n",
              "      <td>Google Chrome</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27233</th>\n",
              "      <td>id37559</td>\n",
              "      <td>This hotel is located right next to a trolley ...</td>\n",
              "      <td>Google Chrome</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>not happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18930</th>\n",
              "      <td>id29256</td>\n",
              "      <td>This hotel is the perfect place to stay while ...</td>\n",
              "      <td>IE</td>\n",
              "      <td>Tablet</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       User_ID  ... Is_Response\n",
              "1642   id11968  ...   not happy\n",
              "22265  id32591  ...       happy\n",
              "1932   id12258  ...       happy\n",
              "27233  id37559  ...   not happy\n",
              "18930  id29256  ...       happy\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8l8nCONvaupM"
      },
      "source": [
        "Below is a snippet code to output the data descriptively"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-12T02:28:27.373486Z",
          "start_time": "2019-01-12T02:28:27.163266Z"
        },
        "id": "vkTqUOqZGDHl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "261fca4e-3581-4086-b15a-3a4bb5637b4a"
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User_ID</th>\n",
              "      <th>Description</th>\n",
              "      <th>Browser_Used</th>\n",
              "      <th>Device_Used</th>\n",
              "      <th>Is_Response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>38932</td>\n",
              "      <td>38932</td>\n",
              "      <td>38932</td>\n",
              "      <td>38932</td>\n",
              "      <td>38932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>38932</td>\n",
              "      <td>38932</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>id24260</td>\n",
              "      <td>My husband and I love to stay at the JW Marrio...</td>\n",
              "      <td>Firefox</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7367</td>\n",
              "      <td>15026</td>\n",
              "      <td>26521</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        User_ID  ... Is_Response\n",
              "count     38932  ...       38932\n",
              "unique    38932  ...           2\n",
              "top     id24260  ...       happy\n",
              "freq          1  ...       26521\n",
              "\n",
              "[4 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hhanrDUa2gw"
      },
      "source": [
        "Below is a snippet code to output the count of target value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-12T02:28:28.080686Z",
          "start_time": "2019-01-12T02:28:28.069031Z"
        },
        "id": "4zl7RNS8GDIG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "92548428-5c3c-407b-c357-230acbd3af65"
      },
      "source": [
        "data['Is_Response'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "happy        26521\n",
              "not happy    12411\n",
              "Name: Is_Response, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vihuVKhZGDKt"
      },
      "source": [
        "In this project, we'll only use the column of `Description` and `Is_Response` only. \n",
        "\n",
        "We'll also store all of the `Description` data to a variable named `attribute` and the `Is_Response` as `target`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2X2A2sRGDK8"
      },
      "source": [
        "# Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jp66TON1biaf"
      },
      "source": [
        "## Column Handling\n",
        "\n",
        "First we will get rid of unused columns which are irrelevant for this project's Sentiment Analysis. Those columns are `User_ID`, `Browser_Used`, and `Device_Used`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ31385-cBDX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "outputId": "8007c8a3-b426-4abe-c38c-ab5e0fa79254"
      },
      "source": [
        "data.drop(columns = ['User_ID', 'Browser_Used', 'Device_Used'], inplace = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-c4cba12f1ea3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'User_ID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Browser_Used'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Device_Used'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4115\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4116\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4117\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4118\u001b[0m         )\n\u001b[1;32m   4119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3912\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3913\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3914\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3944\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3945\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3946\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3947\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5338\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5340\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} not found in axis\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5341\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5342\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['User_ID' 'Browser_Used' 'Device_Used'] not found in axis\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmY4RKLscEWd"
      },
      "source": [
        "Next we will change the `Is_Response` column values from \"happy\" and \"not happy\" to \"positive\" and \"negative\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvYLTjhbc7gO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "c54b9aa8-7ada-4d67-9d9b-d225d3e295de"
      },
      "source": [
        "data['Is_Response'] = data['Is_Response'].map({'happy' : 'positive', 'not happy' : 'negative'})\n",
        "\n",
        "data.sample(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>Is_Response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>32912</th>\n",
              "      <td>Positives: Great Building, Artwork, uniforms, ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17626</th>\n",
              "      <td>This place is ok. Service is what you'd expect...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16888</th>\n",
              "      <td>My husband booked for us to go to NY for my --...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Description Is_Response\n",
              "32912  Positives: Great Building, Artwork, uniforms, ...    negative\n",
              "17626  This place is ok. Service is what you'd expect...    negative\n",
              "16888  My husband booked for us to go to NY for my --...    positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zd1830MpGDXL"
      },
      "source": [
        "## Text Cleaning\n",
        "\n",
        "We will clean the text by removing any punctuations. In addition, this steps also removes any twitter username (@username...) and websites link (http... and www...). The processes above are done using Regular Expression method to search for matching texts.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-12T07:44:52.829360Z",
          "start_time": "2019-01-12T07:44:52.814348Z"
        },
        "id": "fFcPeo3HGDXR"
      },
      "source": [
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "\n",
        "tokenizer = WordPunctTokenizer()\n",
        "twitter_handle = r'@[A-Za-z0-9_]+'                         # remove twitter handle (@username)\n",
        "url_handle = r'http[^ ]+'                                  # remove website URLs that start with 'https?://'\n",
        "combined_handle = r'|'.join((twitter_handle, url_handle))  # join\n",
        "www_handle = r'www.[^ ]+'                                  # remove website URLs that start with 'www.'\n",
        "punctuation_handle = r'\\W+'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DhBYZ0Ng_XQ"
      },
      "source": [
        "\n",
        "We will also get rid of \"stopwords\". Stopwords are the most common words in a language that adds no semantic meaning to a sentece; there is no single universal list of stop words used by all natural language processing tools, and indeed not all tools even use such a list. \n",
        "\n",
        "<img height=300 src=https://onlinemediamasters.com/wp-content/uploads/2015/11/Stop-Words.jpg >\n",
        "</img>\n",
        "\n",
        "This stopwords we use will be in English and can be downloaded [here](http://xpo6.com/download-stop-word-list/). \n",
        "\n",
        "Download \"Text file of stop words for download\" Then add at the first line \"stopword\". The idea is to trick the `read_csv` function to read a column with a header named \"stopword\".\n",
        "\n",
        "Then upload it somewhere on your Google Drive. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ndrL7yNhxk4"
      },
      "source": [
        "# Ibnu's Google Drive directory\n",
        "# stopwords = set(pd.read_csv('/content/drive/My Drive/Colab Notebooks/Hotel Review/stop-word-list.txt', sep='\\n', header=0).stopword)\n",
        "\n",
        "# Raihan's Google Drive directory\n",
        "# stopwords = set(pd.read_csv('/content/drive/My Drive/Colab Notebooks/Stopword/stopword_en.txt', sep='\\n', header=0).stopword)\n",
        "\n",
        "# Local direcotry\n",
        "stopwords = set(pd.read_csv('stopword_en.txt', sep='\\n', header=0).stopword)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_KA6x_nh0mn"
      },
      "source": [
        "Define a function called `process_text` to process the text using the methods listed above. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-12T07:45:30.662530Z",
          "start_time": "2019-01-12T07:45:30.652253Z"
        },
        "code_folding": [],
        "id": "LU_mpn5xGDYG"
      },
      "source": [
        "def process_text(text):\n",
        "    soup = BeautifulSoup(text, 'lxml')\n",
        "    souped = soup.get_text()\n",
        "\n",
        "    try:\n",
        "        text = souped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
        "    except:\n",
        "        text = souped\n",
        "\n",
        "    cleaned_text = re.sub(punctuation_handle, \" \",(re.sub(www_handle, '', re.sub(combined_handle, '', text)).lower()))\n",
        "    cleaned_text = ' '.join([word for word in cleaned_text.split() if word not in stopwords])\n",
        "\n",
        "    return (\" \".join([word for word in tokenizer.tokenize(cleaned_text) if len(word) > 1])).strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzD7QUlCieUn"
      },
      "source": [
        "Below is an input-based example to test the above text cleaning method. Try it~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-12T07:45:31.359526Z",
          "start_time": "2019-01-12T07:45:31.355559Z"
        },
        "id": "cvint9L5GDYp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "9478b433-5a53-4fc4-ccb5-6d87d79f5436"
      },
      "source": [
        "example_text = \"hahaha if above a ----'-' www.adasd apakah SAYA ingin pergi pada tanggal 15 bulan februari besok ? tidak karena hari kemarin @twitter suka main https://www.twitter.com\"\n",
        "\n",
        "process_text(example_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hahaha apakah saya ingin pergi pada tanggal 15 bulan februari besok tidak karena hari kemarin suka main'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hV-aW8M4rnnQ"
      },
      "source": [
        "Then we will create a new column in our data named `clean_text` to store the cleaned text. \n",
        "\n",
        "We will process every row in variable `attribute`, which is the raw text from the .csv data. Then concate the new attribute `clean_text` to the original data file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-12T04:52:30.859912Z",
          "start_time": "2019-01-12T04:52:12.479129Z"
        },
        "id": "EQ-B4aA8GDa-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "8fc915c2-c492-4771-e392-4c2568b5855f"
      },
      "source": [
        "cleaned_text = []\n",
        "\n",
        "for text in data.Description:\n",
        "    cleaned_text.append(process_text(text))\n",
        "\n",
        "clean_text = pd.DataFrame({'clean_text' : cleaned_text})\n",
        "data = pd.concat([data, clean_text], axis = 1)\n",
        "\n",
        "data.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>Is_Response</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2979</th>\n",
              "      <td>I visited Washington, DC for one night-one day...</td>\n",
              "      <td>negative</td>\n",
              "      <td>visited washington dc night day march chose ho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32090</th>\n",
              "      <td>The Peninsula Hotel remains my favorite city h...</td>\n",
              "      <td>positive</td>\n",
              "      <td>peninsula hotel remains favorite city hotel ve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9157</th>\n",
              "      <td>We had a delightful stay at this hotel. The lo...</td>\n",
              "      <td>positive</td>\n",
              "      <td>delightful stay hotel location walking distanc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31880</th>\n",
              "      <td>I came to the Sax last month for a conference,...</td>\n",
              "      <td>positive</td>\n",
              "      <td>came sax month conference did fine job room sp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26662</th>\n",
              "      <td>I had the most wonderful stay at The Parc --. ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>wonderful stay parc recommended sister amazing...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Description  ...                                         clean_text\n",
              "2979   I visited Washington, DC for one night-one day...  ...  visited washington dc night day march chose ho...\n",
              "32090  The Peninsula Hotel remains my favorite city h...  ...  peninsula hotel remains favorite city hotel ve...\n",
              "9157   We had a delightful stay at this hotel. The lo...  ...  delightful stay hotel location walking distanc...\n",
              "31880  I came to the Sax last month for a conference,...  ...  came sax month conference did fine job room sp...\n",
              "26662  I had the most wonderful stay at The Parc --. ...  ...  wonderful stay parc recommended sister amazing...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgknLcBFcJAO"
      },
      "source": [
        "## Splitting Train Data\n",
        "\n",
        "Here we are going set the variable `attribute` to hold the movie review texts, and variable `target` to hold the conclusion [ positive ; negative ] of the moview review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-12T02:29:35.560355Z",
          "start_time": "2019-01-12T02:29:34.449802Z"
        },
        "id": "GlDVoO5sGDNd"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "attribute = data.clean_text\n",
        "target = data.Is_Response"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-15Apv3GDTQ"
      },
      "source": [
        "We will split entire data set into four variables; `attribute_train`, `attribute_test`, `target_train`, `target_test`, with the ratio of 9:1 ( train : test ). \n",
        "\n",
        "The ratio is then converted to `0.1` as a parameter to tell the test data size is gonna be 10% data of the train data\n",
        "\n",
        "After that, we display the four variables to see how much data is distributed amongst the variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-12T02:42:13.095947Z",
          "start_time": "2019-01-12T02:42:13.052219Z"
        },
        "id": "Bkn4xOrJGDUV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "346159de-056c-482f-8341-e5aad5b0935c"
      },
      "source": [
        "attribute_train, attribute_test, target_train, target_test = train_test_split(attribute, target, test_size = 0.1, random_state = 225)\n",
        "\n",
        "print('attribute_train :', len(attribute_train))\n",
        "print('attribute_test  :', len(attribute_test))\n",
        "print('target_train :', len(target_train))\n",
        "print('target_test  :', len(target_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "attribute_train : 35038\n",
            "attribute_test  : 3894\n",
            "target_train : 35038\n",
            "target_test  : 3894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AhgutQtGDe9"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sxsr271btF_6"
      },
      "source": [
        "## Defining the Model\n",
        "\n",
        "We will train the model of this project by Vectorizing using **TF-IDF** and the Classifier using **Logistic Regression** \n",
        "\n",
        "We choose so because it is ...  *(insert reason here)*\n",
        "\n",
        "Other options for Vectorizers are `CountVectorizer` and `HashingVectorizer`. And as for Classifiers, there are : \n",
        "\n",
        "1.   sklearn.ensemble `RandomForestClassifier`,\n",
        "2.   sklearn.naive_bayes `BernoulliNB`,\n",
        "3.   sklearn.svm `SVC`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-12T03:56:09.911553Z",
          "start_time": "2019-01-12T03:56:09.907616Z"
        },
        "id": "AmOeBYilGDfU"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "tvec = TfidfVectorizer()\n",
        "clf2 = LogisticRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oj7LN5UFGDhF"
      },
      "source": [
        "## Create Model Pipeline\n",
        "\n",
        "The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters. Here, the parameters are our Vectorizer and Classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-11T19:26:00.894924Z",
          "start_time": "2019-01-11T19:26:00.891324Z"
        },
        "id": "Os7lqezaGDhM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "outputId": "d7574da2-69e0-432c-f673-250674d86e31"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "model = Pipeline([('vectorizer',tvec)\n",
        "                 ,('classifier',clf2)])\n",
        "\n",
        "model.fit(attribute_train, target_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorizer',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('classifier',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='warn', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='warn', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2DDo746yNGF"
      },
      "source": [
        "Below is a phrase to be used as an example to test the model above, which outputs the verdict of what the predicted sentiment is. Try it~\n",
        "\n",
        "[Here](https://www.tripadvisor.com/Hotel_Review-g152515-d503041-Reviews-Hotel_Riu_Palace_Cabo_San_Lucas-Cabo_San_Lucas_Los_Cabos_Baja_California.html#REVIEWS) is another example of multiple hotel reviews from Trip Advisor that you can copy paste to the variable `example_text`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1XevTA3_bX5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e145d17a-2cba-4371-a37b-6c2aba3428e4"
      },
      "source": [
        "example_text = [\"I'm very happy now\"]\n",
        "example_result = model.predict(example_text)\n",
        "\n",
        "print(example_result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['positive']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SblpE83zGDif"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M40WyKmKzrnl"
      },
      "source": [
        "## Test with attribute_test\n",
        "\n",
        "We will perform a testing with `attribute_test` and then compare the actual result from `response_test`. \n",
        "\n",
        "After that, display the *confusion_matrix*, which is also known as an error matrix, a specific table layout that allows visualization of the performance of an algorithm\n",
        "\n",
        "<img height=\"200\" src=\"https://www.mathworks.com/matlabcentral/mlc-downloads/downloads/submissions/60900/versions/13/screenshot.png\" alt=\"Confusion Matrix\" />"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-12T02:09:31.637123Z",
          "start_time": "2019-01-12T02:09:31.631356Z"
        },
        "id": "s_uoYvp-GDip",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "51725eeb-d4a9-4492-9b62-6173db0371ca"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "verdict = model.predict(attribute_test)\n",
        "\n",
        "confusion_matrix(verdict, target_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 989,  147],\n",
              "       [ 334, 2424]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqjeYTd-35A5"
      },
      "source": [
        "Display the accuracy we got by comparing the test result of `verdict` and actual result of `target_test`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BanqV-XXXGtD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "21cfcf78-6984-451d-9929-59c46c8987c6"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "print(\"Accuracy : \", accuracy_score(verdict, target_test))\n",
        "print(\"Precision : \", precision_score(verdict, target_test, average = 'weighted'))\n",
        "print(\"Recall : \", recall_score(verdict, target_test, average = 'weighted'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy :  0.8764766307139189\n",
            "0.8858545002516267\n",
            "0.8764766307139189\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}