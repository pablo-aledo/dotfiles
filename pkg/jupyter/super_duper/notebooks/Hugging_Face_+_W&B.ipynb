{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hugging Face + W&B",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccHJqOajNN7l"
      },
      "source": [
        "#Hugging Face + Weights & Biases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKpiNY516JUf"
      },
      "source": [
        "### Introduction\n",
        "Visualize your [Hugging Face](https://github.com/huggingface/transformers) model's performance quickly with a seamless W&B integration. Compare hyperparameters, output metrics, and system stats like GPU utilization across your models. \n",
        "\n",
        "<img src=\"https://i.imgur.com/vnejHGh.png\" width=\"800\">\n",
        "\n",
        "**Why use W&B**\n",
        "\n",
        "Think of W&B like GitHub for machine learning modelsâ€” save machine learning experiments to your private, hosted dashboard. Experiment quickly with the confidence that all the versions of your models are saved for you, no matter where you're running your scripts.\n",
        "\n",
        "W&B lightweight integrations works with any Python script, and all you need to do is sign up for a free W&B account to start tracking and visualizing your models.\n",
        "\n",
        "In the Hugging Face Transformers repo, we've instrumented the Trainer to automatically log training and evaluation metrics to W&B at each logging step.\n",
        "\n",
        "Here's an in depth look at how the integration works: [Hugging Face + W&B Report](https://app.wandb.ai/jxmorris12/huggingface-demo/reports/Train-a-model-with-Hugging-Face-and-Weights-%26-Biases--VmlldzoxMDE2MTU)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pt71k9Ew6Qp6"
      },
      "source": [
        "### Install dependencies\n",
        "Install the Hugging Face and Weights & Biases libraries, and the GLUE dataset and training script for this tutorial.\n",
        "- [Hugging Face Transformers](https://github.com/huggingface/transformers): Natural language models and datasets\n",
        "- [Weights & Biases](https://docs.wandb.com/): Experiment tracking and visualization\n",
        "- [GLUE dataset](https://gluebenchmark.com/): A language understanding benchmark dataset\n",
        "- [GLUE script](https://github.com/huggingface/transformers/blob/master/examples/run_glue.py): Model training script for sequence classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUP7zxN2NKUi"
      },
      "source": [
        "!pip install transformers datasets -qq\n",
        "!pip install wandb -qq\n",
        "!wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/text-classification/run_glue.py -qq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjX-QzE257Zv"
      },
      "source": [
        "### [Sign up for a free account â†’](https://app.wandb.ai/login?signup=true)\n",
        "\n",
        "- **Unified dashboard**: Central repository for all your model metrics and predictions\n",
        "- **Lightweight**: No code changes required to integrate with Hugging Face\n",
        "- **Accessible**: Free for individuals and academic teams\n",
        "- **Secure**: All projects are private by default\n",
        "- **Trusted**: Used by machine learning teams at OpenAI, Toyota, GitHub, Lyft and more"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bv5DsG_bALsh"
      },
      "source": [
        "## API Key\n",
        "Once you've signed up, run the next cell and click on the link to get your API key and authenticate this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3FFmY4JqWdN"
      },
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEjCv5Tpm8KO"
      },
      "source": [
        "Optionally, we can set environment variables to customize W&B logging. See [documentation](https://docs.wandb.com/library/integrations/huggingface)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sGBcr-Tm_xW"
      },
      "source": [
        "# Optional: log both gradients and parameters\n",
        "%env WANDB_WATCH=all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNWjjJYhNQx3"
      },
      "source": [
        "## Train the model\n",
        "Next, call the downloaded training script [run_glue.py](https://huggingface.co/transformers/examples.html#glue) and see training automatically get tracked to the Weights & Biases dashboard. This script fine-tunes BERT on the Microsoft Research Paraphrase Corpusâ€” pairs of sentences with human annotations indicating whether they are semantically equivalent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pBSRh8kNRBi"
      },
      "source": [
        "%env WANDB_PROJECT=huggingface-demo\n",
        "%env TASK_NAME=MRPC\n",
        "\n",
        "!python run_glue.py \\\n",
        "  --model_name_or_path bert-base-uncased \\\n",
        "  --task_name MRPC \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --max_seq_length 256 \\\n",
        "  --per_device_train_batch_size 32 \\\n",
        "  --learning_rate 2e-4 \\\n",
        "  --num_train_epochs 3 \\\n",
        "  --output_dir /tmp/$TASK_NAME/ \\\n",
        "  --overwrite_output_dir \\\n",
        "  --logging_steps 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFGc9Qs3A7AY"
      },
      "source": [
        "## Visualize results in dashboard\n",
        "Click the link printed out above, or go to [wandb.ai](https://app.wandb.ai) to see your results stream in live. The link to see your run in the browser will appear after all the dependencies are loaded â€” look for the following output: \"**wandb**: ðŸš€ View run at [URL to your unique run]\"\n",
        "\n",
        "**Visualize Model Performance**\n",
        "It's easy to look across dozens of experiments, zoom in on interesting findings, and visualize highly dimensional data.\n",
        "\n",
        "![](https://gblobscdn.gitbook.com/assets%2F-Lqya5RvLedGEWPhtkjU%2F-M79Y5aLAFsMEcybMZcC%2F-M79YL90K1jiq-3jeQK-%2Fhf%20gif%2015.gif?alt=media&token=523d73f4-3f6c-499c-b7e8-ef5be0c10c2a)\n",
        "\n",
        "**Compare Architectures**\n",
        "Here's an example comparing [BERT vs DistilBERT](https://app.wandb.ai/jack-morris/david-vs-goliath/reports/Does-model-size-matter%3F-Comparing-BERT-and-DistilBERT-using-Sweeps--VmlldzoxMDUxNzU) â€” it's easy to see how different architectures effect the evaluation accuracy throughout training with automatic line plot visualizations.\n",
        "![](https://gblobscdn.gitbook.com/assets%2F-Lqya5RvLedGEWPhtkjU%2F-M79Y5aLAFsMEcybMZcC%2F-M79Ytpj6q6Jlv9RKZGT%2Fgif%20for%20comparing%20bert.gif?alt=media&token=e3dee5de-d120-4330-b4bd-2e2ddbb8315e)\n",
        "\n",
        "### What gets tracked\n",
        "Weights & Biases saves a new run for each experiment. Here's the information that gets saved by default:\n",
        "- **Hyperparameters**: Settings for your model are saved in Config\n",
        "- **Model Metrics**: Time series data of metrics streaming in are saved in Log\n",
        "- **Terminal Logs**: Command line outputs are saved and available in a tab\n",
        "- **System Metrics**: GPU and CPU utilization, memory, temperature etc.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ45eea3Cujc"
      },
      "source": [
        "## Resources\n",
        "- [Documentation](https://docs.wandb.com/huggingface): docs on the Weights & Biases and Hugging Face integration\n",
        "- Contact: Message us at contact@wandb.com with questions"
      ]
    }
  ]
}