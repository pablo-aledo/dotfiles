{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT for Text Extraction on DRCD dataset",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cba4ee198eb74eaa8759388ca0cfb888": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f0cbbd5f2f0a4bb58ed0317beb10323b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_407d9522b3944f12bd73564bb1b173ab",
              "IPY_MODEL_23aaa02429004233a799153d197df498"
            ]
          }
        },
        "f0cbbd5f2f0a4bb58ed0317beb10323b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "407d9522b3944f12bd73564bb1b173ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_799a86adb6ed4824bab6272718ef8468",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 109540,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 109540,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a13e4c1473654239bcfc3c72703557e7"
          }
        },
        "23aaa02429004233a799153d197df498": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_93f19ec734b641fab5fd372c9427adec",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 110k/110k [00:04&lt;00:00, 26.4kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dad3540871074120bf8ef364effeafa2"
          }
        },
        "799a86adb6ed4824bab6272718ef8468": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a13e4c1473654239bcfc3c72703557e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "93f19ec734b641fab5fd372c9427adec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dad3540871074120bf8ef364effeafa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "272e2586028c496daf7e174551f13f15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c8481ed1028746d68ad265b8e0be8e2c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f2c2a15b610f4616987770a954483782",
              "IPY_MODEL_7810e733c10a4bf1aec7412f4123f7b8"
            ]
          }
        },
        "c8481ed1028746d68ad265b8e0be8e2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f2c2a15b610f4616987770a954483782": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_890f7b3d27de4e3596ee6d58d074a9bc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ada56cf49acc43c0ad9b25b8d7ad27e6"
          }
        },
        "7810e733c10a4bf1aec7412f4123f7b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_90d53b42bd4f4c08bbd7aab7e8a13525",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29.0/29.0 [00:00&lt;00:00, 63.5B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8b27ae69914449d6b6a4253b46d50ea1"
          }
        },
        "890f7b3d27de4e3596ee6d58d074a9bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ada56cf49acc43c0ad9b25b8d7ad27e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "90d53b42bd4f4c08bbd7aab7e8a13525": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8b27ae69914449d6b6a4253b46d50ea1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f8bb1de6b3c463aae036844ccca40dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9406bf58f9644b4ebf84b65602c9d1f1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_43b8dd6fe76d492ba7ce0ebcb911fb7f",
              "IPY_MODEL_45ffd8ec66464640a0a25ad9fc8ca8ab"
            ]
          }
        },
        "9406bf58f9644b4ebf84b65602c9d1f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "43b8dd6fe76d492ba7ce0ebcb911fb7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c2acf78f21e44b90b94d0e914bcda70a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 268943,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 268943,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c3764641c27b4c078abd97bb43f8e08a"
          }
        },
        "45ffd8ec66464640a0a25ad9fc8ca8ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_eb812b120e65468da6eff8d396c74ad0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 269k/269k [00:00&lt;00:00, 952kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_888c71211ecc481f9e768101f3a9368b"
          }
        },
        "c2acf78f21e44b90b94d0e914bcda70a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c3764641c27b4c078abd97bb43f8e08a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eb812b120e65468da6eff8d396c74ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "888c71211ecc481f9e768101f3a9368b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X921eJm9YUMi"
      },
      "source": [
        "# 利用BERT模型及台達閱讀理解資料集(DRCD) 實作中文問答系統\n",
        "\n",
        "This notebook is inspired by Keras document code example - BERT (from HuggingFace Transformers) for Text Extraction.\n",
        "\n",
        "https://keras.io/examples/nlp/text_extraction_with_bert/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDXjzgwAcuOv"
      },
      "source": [
        "**Author:** [Vincent Wu](https://twitter.com/pleomax_wu)<br>\n",
        "**Contact:** pleomax0730@gmail.com<br>\n",
        "**Date created:** 2020/07/17<br>\n",
        "**Last modified:** 2021/05/20<br>\n",
        "**Description:** Fine tune pretrained BERT on DRCD."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7GJ5DPZZVdi"
      },
      "source": [
        "# Delta Reading Comprehension Dataset \n",
        "台達閱讀理解資料集 Delta Reading Comprehension Dataset (DRCD) 屬於通用領域繁體中文機器閱讀理解資料集。\n",
        "本資料集期望成為適用於遷移學習之標準中文閱讀理解資料集。\n",
        "本資料集從2,108篇維基條目中整理出10,014篇段落，並從段落中標註出30,000多個問題\n",
        "\n",
        "關於資料集之更詳細資訊請洽詢論文：\n",
        "For more information please refer to Paper https://arxiv.org/abs/1806.00920\n",
        "\n",
        "## Data format 資料格式\n",
        "\n",
        "- version : <String> 資料集版本\n",
        "- data : <Array>\n",
        "  - title : <String> : 文章標題\n",
        "  - id : <String> : 文章編號\n",
        "  - paragraphs : <Array>\n",
        "    - id : <String> : 文章編號_段落編號\n",
        "    - context : <String> : 段落內容\n",
        "    - qas : <Array>\n",
        "      - question : <String> : 問題內容\n",
        "      - id :<String> : 文章編號_段落編號_問題編號\n",
        "      - answers : <Arrays>\n",
        "        - answer_start : <int> text在文中位置\n",
        "        - id : <String> : \"1\"表示為人工標註的答案，\"2\"以上為人工答題的答案\n",
        "        - text : <string> : 答案內容\n",
        "\n",
        "**References:**\n",
        "\n",
        "- [BERT](https://arxiv.org/pdf/1810.04805.pdf)\n",
        "- [DRCD](https://arxiv.org/abs/1806.00920)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFPqbZzN9PAE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1750c8fe-a670-4a81-c9d1-659918b77872"
      },
      "source": [
        "!pip install -q transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.1MB 8.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3MB 37.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 901kB 54.0MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmcOywwqPqo3"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import string\n",
        "import numpy as np\n",
        "import logging\n",
        "import tensorflow as tf\n",
        "import time\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from transformers import BertTokenizer, TFBertModel, BertConfig, TFBertForQuestionAnswering\n",
        "from pprint import pprint\n",
        "from collections import Counter\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dxlt5T4FPrii"
      },
      "source": [
        "max_len = 384\n",
        "stride = 128                  # use stride(windowing) if tokenized_context + tokenized_question > max_len\n",
        "configuration = BertConfig()  # default paramters and configuration for BERT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAK8ewV-PuEe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232,
          "referenced_widgets": [
            "cba4ee198eb74eaa8759388ca0cfb888",
            "f0cbbd5f2f0a4bb58ed0317beb10323b",
            "407d9522b3944f12bd73564bb1b173ab",
            "23aaa02429004233a799153d197df498",
            "799a86adb6ed4824bab6272718ef8468",
            "a13e4c1473654239bcfc3c72703557e7",
            "93f19ec734b641fab5fd372c9427adec",
            "dad3540871074120bf8ef364effeafa2",
            "272e2586028c496daf7e174551f13f15",
            "c8481ed1028746d68ad265b8e0be8e2c",
            "f2c2a15b610f4616987770a954483782",
            "7810e733c10a4bf1aec7412f4123f7b8",
            "890f7b3d27de4e3596ee6d58d074a9bc",
            "ada56cf49acc43c0ad9b25b8d7ad27e6",
            "90d53b42bd4f4c08bbd7aab7e8a13525",
            "8b27ae69914449d6b6a4253b46d50ea1",
            "6f8bb1de6b3c463aae036844ccca40dc",
            "9406bf58f9644b4ebf84b65602c9d1f1",
            "43b8dd6fe76d492ba7ce0ebcb911fb7f",
            "45ffd8ec66464640a0a25ad9fc8ca8ab",
            "c2acf78f21e44b90b94d0e914bcda70a",
            "c3764641c27b4c078abd97bb43f8e08a",
            "eb812b120e65468da6eff8d396c74ad0",
            "888c71211ecc481f9e768101f3a9368b"
          ]
        },
        "outputId": "9c653967-b383-4e3f-f5e6-049896dbe1c7"
      },
      "source": [
        "# logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.ERROR)\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "\n",
        "# Save the pretrained tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-chinese\")\n",
        "save_path = \"bert_base_chinese/\"\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "tokenizer.save_pretrained(save_path)\n",
        "\n",
        "# Download the data\n",
        "train_data_url = \"https://raw.githubusercontent.com/DRCKnowledgeTeam/DRCD/master/DRCD_training.json\"\n",
        "train_path = keras.utils.get_file(\"train.json\", train_data_url)\n",
        "eval_data_url = \"https://github.com/DRCKnowledgeTeam/DRCD/blob/master/DRCD_dev.json?raw=true\"\n",
        "eval_path = keras.utils.get_file(\"eval.json\", eval_data_url)\n",
        "\n",
        "with open(train_path, \"r\", encoding=\"UTF-8\") as f:\n",
        "    raw_train_data = json.load(f)\n",
        "\n",
        "with open(eval_path, \"r\", encoding=\"UTF-8\") as f:\n",
        "    raw_eval_data = json.load(f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cba4ee198eb74eaa8759388ca0cfb888",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=109540.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "272e2586028c496daf7e174551f13f15",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f8bb1de6b3c463aae036844ccca40dc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=268943.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading data from https://raw.githubusercontent.com/DRCKnowledgeTeam/DRCD/master/DRCD_training.json\n",
            "15097856/15094666 [==============================] - 0s 0us/step\n",
            "Downloading data from https://github.com/DRCKnowledgeTeam/DRCD/blob/master/DRCD_dev.json?raw=true\n",
            "2187264/2184379 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHjZPBSYCHEB"
      },
      "source": [
        "# modified from ref: https://github.com/google-research/bert/blob/master/run_squad.py\n",
        "\n",
        "def check_is_max_context(spans, tokenized_ans):\n",
        "    best_score = None\n",
        "    best_span = None\n",
        "    true_start = None\n",
        "    true_end = None\n",
        "    tmp = []\n",
        "\n",
        "    for span in spans:\n",
        "        for idx, token in enumerate(span):\n",
        "            if span[idx:idx + len(tokenized_ans)] == tokenized_ans:\n",
        "                tmp.append(span)\n",
        "                tmp[-1].append([idx, idx + len(tokenized_ans) - 1])\n",
        "\n",
        "    for span in tmp:\n",
        "        start, end = span.pop()\n",
        "        num_left_context = len(span) - len(span[start:])\n",
        "        num_right_context = len(span) - len(span[:end + 1])\n",
        "        score = min(num_left_context, num_right_context) + 0.01 * len(span)\n",
        "        if best_score is None or score > best_score:\n",
        "            best_score = score\n",
        "            best_span = span\n",
        "            true_start = start\n",
        "            true_end = end\n",
        "\n",
        "    if best_score is None:\n",
        "        logging.debug(best_score)\n",
        "        logging.debug(spans)\n",
        "        logging.debug(tokenized_ans)\n",
        "        return None\n",
        "\n",
        "    return best_span, true_start, true_end"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw2EJ8KSGz9P"
      },
      "source": [
        "class SquadExample:\n",
        "    def __init__(self, question, context, start_char_idx, answer_text,\n",
        "                 all_answers):\n",
        "        self.question = question\n",
        "        self.context = context\n",
        "        self.start_char_idx = start_char_idx\n",
        "        self.answer_text = answer_text\n",
        "        self.all_answers = all_answers\n",
        "        self.skip = False\n",
        "\n",
        "    def preprocess(self):\n",
        "        context = self.context\n",
        "        question = self.question\n",
        "        answer_text = self.answer_text\n",
        "        start_char_idx = self.start_char_idx\n",
        "\n",
        "        # Find end character index of answer in context\n",
        "        end_char_idx = start_char_idx + len(answer_text)\n",
        "        if end_char_idx >= len(context):\n",
        "            self.skip = True\n",
        "            return\n",
        "\n",
        "        # Tokenize context\n",
        "        tokenized_context = tokenizer.encode(context)\n",
        "        context_no_special = tokenized_context[1:-1]\n",
        "\n",
        "        # Tokenize answer\n",
        "        tokenized_ans = tokenizer.encode(answer_text, add_special_tokens=False)\n",
        "\n",
        "        # Tokenize question\n",
        "        tokenized_question = tokenizer.encode(question)[1:]\n",
        "\n",
        "        if len(tokenized_context + tokenized_question) <= max_len:\n",
        "            start_token_idx = None\n",
        "            end_token_idx = None\n",
        "\n",
        "            # [CLS] context [SEP] question [SEP]\n",
        "            input_ids = tokenized_context + tokenized_question\n",
        "\n",
        "            # Find start and end token index for tokens from answer\n",
        "            for idx, token in enumerate(input_ids):\n",
        "                if input_ids[idx:idx + len(tokenized_ans)] == tokenized_ans:\n",
        "                    start, end = idx, idx + len(tokenized_ans) - 1\n",
        "                    start_token_idx = start\n",
        "                    end_token_idx = end\n",
        "                    \n",
        "            # 少數情況會造成 result 為 None，例如 \"90%\" 會被分詞為 [\"90\", \"%\"]，但正確答案為 [\"9\"]\n",
        "            if start_token_idx is None or end_token_idx is None:\n",
        "                self.skip = True\n",
        "                return\n",
        "\n",
        "            if len(tokenized_ans) == 1:\n",
        "                logging.debug(start_token_idx)\n",
        "                logging.debug(end_token_idx)\n",
        "                logging.debug(\"tokenized_ans:\", tokenized_ans)\n",
        "                logging.debug(\"tokenized_sub_context:\", input_ids[start_token_idx])\n",
        "                assert tokenized_ans[0] == input_ids[start_token_idx]\n",
        "            else:\n",
        "                logging.debug(start_token_idx)\n",
        "                logging.debug(end_token_idx)\n",
        "                logging.debug(\"tokenized_ans:\", tokenized_ans)\n",
        "                logging.debug(\"tokenized_sub_context:\", input_ids[start_token_idx:end_token_idx+1])\n",
        "                assert tokenized_ans == input_ids[\n",
        "                    start_token_idx:end_token_idx + 1]\n",
        "            \n",
        "            # Create token_type_ids, attention_mask\n",
        "            token_type_ids = [0] * len(tokenized_context) + [1] * len(tokenized_question)\n",
        "            attention_mask = [1] * len(input_ids)\n",
        "\n",
        "            # Padding            \n",
        "            padding_length = max_len - len(input_ids)\n",
        "            assert padding_length >= 0\n",
        "            input_ids = input_ids + ([0] * padding_length)\n",
        "            attention_mask = attention_mask + ([0] * padding_length)\n",
        "            token_type_ids = token_type_ids + ([0] * padding_length)            \n",
        "\n",
        "            self.input_ids = input_ids\n",
        "            self.token_type_ids = token_type_ids\n",
        "            self.attention_mask = attention_mask\n",
        "            self.start_token_idx = start_token_idx\n",
        "            self.end_token_idx = end_token_idx\n",
        "\n",
        "        else:\n",
        "            spans = []\n",
        "            for idx, token in enumerate(context_no_special):\n",
        "                if set(tokenized_ans).issubset(context_no_special[idx:idx +\n",
        "                                                                  stride - 2]):\n",
        "                    spans.append(context_no_special[idx:idx + stride - 2])\n",
        "            result = check_is_max_context(spans, tokenized_ans)\n",
        "            # 少數情況會造成 result 為 None，例如 \"90%\" 會被分詞為 [\"90\", \"%\"]，但正確答案為 [\"9\"]\n",
        "            if not result:\n",
        "                self.skip = True\n",
        "                return\n",
        "\n",
        "            final_span, start, end = result\n",
        "            final_span = [101] + final_span + [102]\n",
        "            # [CLS] context [SEP] question [SEP]\n",
        "            input_ids = final_span + tokenized_question\n",
        "\n",
        "            # Find start and end token index for tokens from answer\n",
        "            start_token_idx = start + 1  # \"[CLS]\" token offset\n",
        "            end_token_idx = end + 1\n",
        "\n",
        "            if len(tokenized_ans) == 1:\n",
        "                logging.debug(\"tokenized_ans:\", tokenized_ans)\n",
        "                logging.debug(\"tokenized_sub_context:\", input_ids[start_token_idx])\n",
        "                assert tokenized_ans[0] == input_ids[start_token_idx]\n",
        "            else:\n",
        "                logging.debug(\"tokenized_ans:\", tokenized_ans)\n",
        "                logging.debug(\"tokenized_sub_context:\", input_ids[start_token_idx:end_token_idx+1])\n",
        "                logging.debug(start_token_idx)\n",
        "                logging.debug(end_token_idx)\n",
        "                assert tokenized_ans == input_ids[start_token_idx:end_token_idx + 1]\n",
        "\n",
        "            # Create token_type_ids, attention_mask\n",
        "            token_type_ids = [0] * len(final_span) + [1] * len(tokenized_question)\n",
        "            attention_mask = [1] * len(input_ids)\n",
        "\n",
        "            # Padding            \n",
        "            padding_length = max_len - len(input_ids)\n",
        "            assert padding_length >= 0\n",
        "            input_ids = input_ids + ([0] * padding_length)\n",
        "            attention_mask = attention_mask + ([0] * padding_length)\n",
        "            token_type_ids = token_type_ids + ([0] * padding_length)            \n",
        "\n",
        "            self.input_ids = input_ids\n",
        "            self.token_type_ids = token_type_ids\n",
        "            self.attention_mask = attention_mask\n",
        "            self.start_token_idx = start_token_idx\n",
        "            self.end_token_idx = end_token_idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuFIiRHHPynG"
      },
      "source": [
        "def create_squad_examples(raw_data):\n",
        "    squad_examples = []\n",
        "    for item in raw_data[\"data\"]:\n",
        "        for para in item[\"paragraphs\"]:\n",
        "            context = para[\"context\"]\n",
        "            for qa in para[\"qas\"]:\n",
        "                question = qa[\"question\"]\n",
        "                answer_text = qa[\"answers\"][0][\"text\"]\n",
        "                all_answers = [_[\"text\"] for _ in qa[\"answers\"]]\n",
        "                start_char_idx = qa[\"answers\"][0][\"answer_start\"]\n",
        "                squad_eg = SquadExample(question, context, start_char_idx,\n",
        "                                        answer_text, all_answers)\n",
        "                squad_eg.preprocess()\n",
        "                squad_examples.append(squad_eg)\n",
        "    return squad_examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUF7SuOuPzt6"
      },
      "source": [
        "def create_inputs_targets(squad_examples):\n",
        "    dataset_dict = {\n",
        "        \"input_ids\": [],\n",
        "        \"token_type_ids\": [],\n",
        "        \"attention_mask\": [],\n",
        "        \"start_token_idx\": [],\n",
        "        \"end_token_idx\": [],\n",
        "    }\n",
        "    for example in squad_examples:\n",
        "        if example.skip == False:\n",
        "            for key in dataset_dict:\n",
        "                dataset_dict[key].append(getattr(example, key))\n",
        "    for key in dataset_dict:\n",
        "        dataset_dict[key] = np.asarray(dataset_dict[key])\n",
        "\n",
        "    x = [\n",
        "        dataset_dict[\"input_ids\"],\n",
        "        dataset_dict[\"token_type_ids\"],\n",
        "        dataset_dict[\"attention_mask\"],\n",
        "    ]\n",
        "    y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\n",
        "    return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mszPhce_DGJs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95183c36-149e-47c7-ad90-c6948b38d5c6"
      },
      "source": [
        "start_time = time.time()\n",
        "train_squad_examples = create_squad_examples(raw_train_data)\n",
        "end_time = time.time()\n",
        "print(f\"Took {end_time - start_time:.2f} seconds to preprocess raw train data.\")\n",
        "\n",
        "start_time = time.time()\n",
        "eval_squad_examples = create_squad_examples(raw_eval_data)\n",
        "end_time = time.time()\n",
        "print(f\"Took {end_time - start_time:.2f} seconds to preprocess raw eval data.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Took 184.96 seconds to preprocess raw train data.\n",
            "Took 26.42 seconds to preprocess raw eval data.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udxX5dR3AQnr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51d6919f-a25d-4a2e-af98-376c0e60aefc"
      },
      "source": [
        "x_train, y_train = create_inputs_targets(train_squad_examples)\n",
        "print(f\"{len(train_squad_examples)} training points created.\")\n",
        "print(f\"{len(x_train[0])} valid train samples with length {max_len}.\")\n",
        "print(f\"Dropped {len(train_squad_examples) - len(x_train[0])} invalid train samples.\")\n",
        "\n",
        "x_eval, y_eval = create_inputs_targets(eval_squad_examples)\n",
        "print(f\"{len(eval_squad_examples)} evaluation points created.\")\n",
        "print(f\"{len(x_eval[0])} valid samples with length {max_len}.\")\n",
        "print(f\"Dropped {len(eval_squad_examples) - len(x_eval[0])} invalid samples.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26936 training points created.\n",
            "26890 valid train samples with length 384.\n",
            "Dropped 46 invalid train samples.\n",
            "3524 evaluation points created.\n",
            "3520 valid samples with length 384.\n",
            "Dropped 4 invalid samples.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIulUhFRIWzq"
      },
      "source": [
        "def create_model():\n",
        "    ## BERT encoder\n",
        "    encoder = TFBertModel.from_pretrained(\"bert-base-chinese\")\n",
        "\n",
        "    ## QA Model\n",
        "    input_ids = layers.Input(shape=(max_len, ), dtype=tf.int32)\n",
        "    token_type_ids = layers.Input(shape=(max_len, ), dtype=tf.int32)\n",
        "    attention_mask = layers.Input(shape=(max_len, ), dtype=tf.int32)\n",
        "    embedding = encoder(\n",
        "        input_ids,\n",
        "        token_type_ids=token_type_ids,\n",
        "        attention_mask=attention_mask)[0]  # take sequence outputs (bsz, seq_len, hidden_size)\n",
        "\n",
        "    start_logits = layers.Dense(1, use_bias=False)(embedding)  # (bsz, seq_len, 1)\n",
        "    start_logits = layers.Flatten(name=\"start_logit\")(start_logits)  # (bsz, seq_len)\n",
        "\n",
        "    end_logits = layers.Dense(1, use_bias=False)(embedding)\n",
        "    end_logits = layers.Flatten(name=\"end_logit\")(end_logits)\n",
        "\n",
        "    # start_probs = layers.Activation(keras.activations.softmax, name=\"start\")(start_logits)\n",
        "    # end_probs = layers.Activation(keras.activations.softmax, name=\"end\")(end_logits)\n",
        "\n",
        "    model = keras.Model(\n",
        "        inputs=[input_ids, token_type_ids, attention_mask],\n",
        "        outputs=[start_logits, end_logits],\n",
        "    )\n",
        "    losses = {\n",
        "        \"start_logit\": keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        \"end_logit\": keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    }\n",
        "    optimizer = keras.optimizers.Adam(lr=3e-5)\n",
        "    model.compile(optimizer=optimizer, loss=losses)\n",
        "    return model\n",
        "\n",
        "\n",
        "model = create_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bunUNIZC9dj7"
      },
      "source": [
        "#  EM&F1參考\n",
        "中文\n",
        "https://github.com/ymcui/Chinese-XLNet/blob/0dcda8c4fe99f39317bb7af51f30469f65f8e577/src/cmrc2018_evaluate_drcd.py\n",
        "\n",
        "英文\n",
        "https://github.com/allenai/bi-att-flow/blob/master/squad/evaluate-v1.1.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HekxQ97MviCj"
      },
      "source": [
        "# remove punctuation\n",
        "def remove_punctuation(in_str):\n",
        "    in_str = str(in_str).lower().strip()\n",
        "    sp_char = [\n",
        "        '-', ':', '_', '*', '^', '/', '\\\\', '~', '`', '+', '=', '，', '。', '：',\n",
        "        '？', '！', '“', '”', '；', '’', '《', '》', '……', '·', '、', '「', '」', '（',\n",
        "        '）', '－', '～', '『', '』'\n",
        "    ]\n",
        "\n",
        "    out_segs = []\n",
        "    for char in in_str:\n",
        "        if char in sp_char or char in string.punctuation:\n",
        "            continue\n",
        "        else:\n",
        "            out_segs.append(char)\n",
        "    return ''.join(out_segs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JG_NbIoLWPcs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d806f06-5eba-4dbf-da98-63def9080944"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# split Chinese with English\n",
        "def mixed_segmentation(in_str, rm_punc=False):\n",
        "\tin_str = str(in_str).lower().strip()\n",
        "\tsegs_out = []\n",
        "\ttemp_str = \"\"\n",
        "\tsp_char = ['-',':','_','*','^','/','\\\\','~','`','+','=',\n",
        "\t\t\t   '，','。','：','？','！','“','”','；','’','《','》','……','·','、',\n",
        "\t\t\t   '「','」','（','）','－','～','『','』']\n",
        "\tfor char in in_str:\n",
        "\t\tif rm_punc and char in sp_char:\n",
        "\t\t\tcontinue\n",
        "\t\tif re.search(u\"[\\u4e00-\\u9fff]\", char) or char in sp_char:\n",
        "\t\t\tif temp_str != \"\":\n",
        "\t\t\t\tss = nltk.word_tokenize(temp_str)\n",
        "\t\t\t\tsegs_out.extend(ss)\n",
        "\t\t\t\ttemp_str = \"\"\n",
        "\t\t\tsegs_out.append(char)\n",
        "\t\telse:\n",
        "\t\t\ttemp_str += char\n",
        "\n",
        "\t#handling last part\n",
        "\tif temp_str != \"\":\n",
        "\t\tss = nltk.word_tokenize(temp_str)\n",
        "\t\tsegs_out.extend(ss)\n",
        "\n",
        "\treturn segs_out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4aRTfiRaAu4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4110f7f5-bc37-4b2e-f1ce-4db808a7659e"
      },
      "source": [
        "mixed_segmentation(remove_punctuation(\"today 天氣 真是棒rrr!！\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['today', '天', '氣', '真', '是', '棒', 'rrr']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoxU9C9kBhSE"
      },
      "source": [
        "def f1_score(prediction, ground_truth):\n",
        "    prediction_tokens = mixed_segmentation(prediction) # [char for char in prediction]\n",
        "    ground_truth_tokens = mixed_segmentation(ground_truth) # [char for char in ground_truth]\n",
        "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
        "    num_same = sum(common.values())\n",
        "    if num_same == 0:\n",
        "        return 0\n",
        "    precision = 1.0 * num_same / len(prediction_tokens)\n",
        "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    return f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vex06R18dYNX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7399760c-9906-4501-ac51-63a0d7b6e826"
      },
      "source": [
        "f1_score(prediction=\"today 天氣 真rrr\", ground_truth=\"today 天氣 真是棒\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7272727272727272"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cttGNUcu3EoL"
      },
      "source": [
        "class ExactMatch_F1(keras.callbacks.Callback):\n",
        "    \"\"\"\n",
        "    Each `SquadExample` object contains the character level offsets for each token\n",
        "    in its input paragraph. We use them to get back the span of text corresponding\n",
        "    to the tokens between our predicted start and end tokens.\n",
        "    All the ground-truth answers are also present in each `SquadExample` object.\n",
        "    We calculate the percentage of data points where the span of text obtained\n",
        "    from model predictions matches one of the ground-truth answers.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, x, y, squad_examples):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.squad_examples = squad_examples\n",
        "        \n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        pred_start, pred_end = self.model.predict(self.x)\n",
        "        em = 0\n",
        "        f1 = 0\n",
        "        examples_no_skip = [_ for _ in self.squad_examples if _.skip == False]\n",
        "        for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
        "            squad_eg = examples_no_skip[idx]\n",
        "            \n",
        "            start = np.argmax(start)\n",
        "            #print(\"\\nstart:\", start)\n",
        "            end = np.argmax(end)\n",
        "            #print(\"end:\", end)\n",
        "            if end < start:\n",
        "                pred_ans = \"\"\n",
        "            else:\n",
        "                pred_ans = \"\".join(tokenizer.convert_ids_to_tokens(squad_eg.input_ids[start:end+1], skip_special_tokens=True))\n",
        "            #print(\"predict answer span:\", pred_ans)\n",
        "            #print(\"true answer span:\", squad_eg.all_answers[0])\n",
        "\n",
        "            pred_ans = remove_punctuation(pred_ans)\n",
        "            true_ans = remove_punctuation(squad_eg.all_answers[0])\n",
        "\n",
        "            # 如果predict ans 是 true ans 的子集\n",
        "            if pred_ans in true_ans and pred_ans:\n",
        "                #print(\"pred is subset of true\")\n",
        "                em += 1\n",
        "            \n",
        "            f1 += f1_score(pred_ans, true_ans)\n",
        "\n",
        "        em = em / len(self.y[0])\n",
        "        f1 = f1 / len(self.y[0])\n",
        "        print(f\"\\nepoch={epoch+1}, exact match score={em:.2f}, F1 score={f1:.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93gNSJo2c9A1"
      },
      "source": [
        "# 訓練模型\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYHBEQM1BzaA"
      },
      "source": [
        "em_f1_callback = ExactMatch_F1(x_eval, y_eval, eval_squad_examples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJGtBp4FD2rs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "2bd9d70f-c509-4ea9-f3c7-832687538e6c"
      },
      "source": [
        "start_time = time.time()\n",
        "\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=3,  # For demonstration, 3 epochs are recommended\n",
        "    verbose=1,\n",
        "    batch_size=12,\n",
        "    callbacks=[em_f1_callback],\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Took {end_time - start_time} seconds to train our model.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2241/2241 [==============================] - ETA: 0s - loss: 1.8965 - start_logit_loss: 0.9368 - end_logit_loss: 0.9597\n",
            "epoch=1, exact match score=0.82, F1 score=0.88\n",
            "2241/2241 [==============================] - 4440s 2s/step - loss: 1.8965 - start_logit_loss: 0.9368 - end_logit_loss: 0.9597\n",
            "Epoch 2/3\n",
            "2241/2241 [==============================] - ETA: 0s - loss: 0.9003 - start_logit_loss: 0.4480 - end_logit_loss: 0.4523\n",
            "epoch=2, exact match score=0.85, F1 score=0.90\n",
            "2241/2241 [==============================] - 4436s 2s/step - loss: 0.9003 - start_logit_loss: 0.4480 - end_logit_loss: 0.4523\n",
            "Epoch 3/3\n",
            "2241/2241 [==============================] - ETA: 0s - loss: 0.5420 - start_logit_loss: 0.2668 - end_logit_loss: 0.2752\n",
            "epoch=3, exact match score=0.86, F1 score=0.90\n",
            "2241/2241 [==============================] - 4433s 2s/step - loss: 0.5420 - start_logit_loss: 0.2668 - end_logit_loss: 0.2752\n",
            "Took 13333.64521598816 seconds to train our model.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkuTb-fOIGXy"
      },
      "source": [
        "# Hugging Face"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJlbJQ5M0M7m",
        "outputId": "74bb2165-0d56-4d6c-e5de-34bc21f1218a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = \"/content/drive/MyDrive/qa_bert\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tYq563aKxEA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42bb6313-83bd-4d01-9f23-e1fbf7ee475f"
      },
      "source": [
        "qa_bert = TFBertForQuestionAnswering.from_pretrained(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForQuestionAnswering.\n",
            "\n",
            "All the layers of TFBertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/qa_bert.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForQuestionAnswering for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVsppGTXLolq"
      },
      "source": [
        "train_inputs = {\n",
        "        \"input_ids\": x_train[0][:],\n",
        "        \"token_type_ids\": x_train[1][:],\n",
        "        \"attention_mask\": x_train[2][:], \n",
        "        \"start_positions\": y_train[0][:],\n",
        "        \"end_positions\": y_train[1][:],\n",
        "}\n",
        "\n",
        "tf_train_dataset = tf.data.Dataset.from_tensor_slices(train_inputs).batch(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZRUBwkAmPdi"
      },
      "source": [
        "eval_inputs = {\n",
        "        \"input_ids\": x_eval[0][:],\n",
        "        \"token_type_ids\": x_eval[1][:],\n",
        "        \"attention_mask\": x_eval[2][:], \n",
        "        \"start_positions\": y_eval[0][:],\n",
        "        \"end_positions\": y_eval[1][:],\n",
        "}\n",
        "\n",
        "tf_eval_dataset = tf.data.Dataset.from_tensor_slices(eval_inputs).batch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdXsO4seNlIr"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(lr=3e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DvYoLxla-88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f93722b-d5c7-4455-9dd5-1172adf7fd82"
      },
      "source": [
        "epochs = 3\n",
        "\n",
        "for _ in tqdm(range(epochs)):\n",
        "    # pbar = tqdm(tf_train_dataset)\n",
        "    # for i, batch in enumerate(pbar):\n",
        "    for i, batch in enumerate(tf_train_dataset):\n",
        "        with tf.GradientTape() as tape:\n",
        "            outputs = qa_bert(batch)\n",
        "            loss_value = outputs.loss\n",
        "\n",
        "        grads = tape.gradient(loss_value, qa_bert.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, qa_bert.trainable_variables))\n",
        "\n",
        "        # pbar.set_description(f\"Loss: {loss_value.numpy()[0]:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [1:56:08<00:00, 2322.86s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNs_-Q_ymqio"
      },
      "source": [
        "examples_no_skip = [_ for _ in eval_squad_examples if _.skip == False]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4QChEwZoQ7f",
        "outputId": "d23893b0-06e0-4cd6-efc2-7c700eb1fc62"
      },
      "source": [
        "em = 0\n",
        "f1 = 0\n",
        "\n",
        "for i, batch in enumerate(tf_eval_dataset):\n",
        "    squad_eg = examples_no_skip[i]\n",
        "\n",
        "    outputs = qa_bert(batch)\n",
        "    start = np.argmax(outputs.start_logits)    \n",
        "    end = np.argmax(outputs.end_logits)\n",
        "\n",
        "\n",
        "    if end < start:\n",
        "        pred_ans = \"\"\n",
        "    else:\n",
        "        pred_ans = \"\".join(tokenizer.convert_ids_to_tokens(squad_eg.input_ids[start:end+1], skip_special_tokens=True))\n",
        "\n",
        "    pred_ans = remove_punctuation(pred_ans)\n",
        "    true_ans = remove_punctuation(squad_eg.all_answers[0])\n",
        "\n",
        "    if pred_ans in true_ans and pred_ans:\n",
        "        em += 1\n",
        "\n",
        "    f1 += f1_score(pred_ans, true_ans)\n",
        "\n",
        "em = em / len(tf_eval_dataset)\n",
        "f1 = f1 / len(tf_eval_dataset)\n",
        "print(f\"exact match score={em:.3f}, F1 score={f1:.3f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "exact match score=0.83, F1 score=0.86\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}