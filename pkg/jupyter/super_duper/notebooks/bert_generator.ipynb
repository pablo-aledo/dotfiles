{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "DeepPavlov",
      "language": "python",
      "name": "deeppavlov"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "bert_generator.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "earlKo22gSg8"
      },
      "source": [
        "In this notebook, we will take all the steps necessary to create a simple BERT-based pipeline for text generation using [Transformers](https://huggingface.co/transformers/index.html) and [DeepPavlov](https://deeppavlov.ai/) libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PwBdmifYWLh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4f9a49e4-8c89-4f79-a32a-3814d6380df6"
      },
      "source": [
        "!pip install deeppavlov==0.8.0 torch==1.4.0 transformers==2.8.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: deeppavlov==0.8.0 in /usr/local/lib/python3.6/dist-packages (0.8.0)\n",
            "Requirement already satisfied: torch==1.4.0 in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: transformers==2.8.0 in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: pyopenssl==19.1.0 in /usr/local/lib/python3.6/dist-packages (from deeppavlov==0.8.0) (19.1.0)\n",
            "Requirement already satisfied: pymorphy2==0.8 in /usr/local/lib/python3.6/dist-packages (from deeppavlov==0.8.0) (0.8)\n",
            "Requirement already satisfied: pandas==0.25.3 in /usr/local/lib/python3.6/dist-packages (from deeppavlov==0.8.0) (0.25.3)\n",
            "Requirement already satisfied: uvicorn==0.11.1 in /usr/local/lib/python3.6/dist-packages (from deeppavlov==0.8.0) (0.11.1)\n",
            "Requirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.6/dist-packages (from deeppavlov==0.8.0) (2.10.0)\n",
            "Requirement already satisfied: fuzzywuzzy==0.17.0 in /usr/local/lib/python3.6/dist-packages (from deeppavlov==0.8.0) (0.17.0)\n",
            "Requirement already satisfied: aio-pika==6.4.1 in /usr/local/lib/python3.6/dist-packages (from deeppavlov==0.8.0) (6.4.1)\n",
            "Requirement already satisfied: rusenttokenize==0.0.5 in /usr/local/lib/python3.6/dist-packages (from deeppavlov==0.8.0) (0.0.5)\n",
            "Requirement already satisfied: scikit-learn==0.21.2 in /usr/local/lib/python3.6/dist-packages (from deeppavlov==0.8.0) (0.21.2)\n",
            "Requirement already satisfied: pydantic==1.3 in /usr/local/lib/python3.6/dist-packages (from deeppavlov==0.8.0) (1.3)\n",
            "Requirement already satisfied: Cython==0.29.14 in /usr/local/lib/python3.6/dist-packages (from deeppavlov==0.8.0) (0.29.14)\n",
            "Requirement already satisfied: pytelegrambotapi==3.6.7 in /usr/local/lib/python3.6/dist-packages (from deeppavlov==0.8.0) (3.6.7)\n",
            "Requirement already satisfied: numpy==1.18.0 in /usr/local/lib/python3.6/dist-packages (from deeppavlov==0.8.0) (1.18.0)\n",
            "Requirement already satisfied: requests==2.22.0 in /usr/local/lib/python3.6/dist-packages (from deeppavlov==0.8.0) (2.22.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from deeppavlov==0.8.0) (1.4.1)\n",
            "Requirement already satisfied: nltk==3.4.5 in /usr/local/lib/python3.6/dist-packages (from deeppavlov==0.8.0) (3.4.5)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru in /usr/local/lib/python3.6/dist-packages (from deeppavlov==0.8.0) (2.4.404381.4453942)\n",
            "Requirement already satisfied: fastapi==0.47.1 in /usr/local/lib/python3.6/dist-packages (from deeppavlov==0.8.0) (0.47.1)\n",
            "Requirement already satisfied: tqdm==4.41.1 in /usr/local/lib/python3.6/dist-packages (from deeppavlov==0.8.0) (4.41.1)\n",
            "Requirement already satisfied: overrides==2.7.0 in /usr/local/lib/python3.6/dist-packages (from deeppavlov==0.8.0) (2.7.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.1.85)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.12.38)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.0.41)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (3.0.12)\n",
            "Requirement already satisfied: cryptography>=2.8 in /usr/local/lib/python3.6/dist-packages (from pyopenssl==19.1.0->deeppavlov==0.8.0) (2.8)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.6/dist-packages (from pyopenssl==19.1.0->deeppavlov==0.8.0) (1.12.0)\n",
            "Requirement already satisfied: dawg-python>=0.7 in /usr/local/lib/python3.6/dist-packages (from pymorphy2==0.8->deeppavlov==0.8.0) (0.7.2)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2==0.8->deeppavlov==0.8.0) (0.6.2)\n",
            "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from pymorphy2==0.8->deeppavlov==0.8.0) (2.4.393442.3710985)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.3->deeppavlov==0.8.0) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.3->deeppavlov==0.8.0) (2.6.1)\n",
            "Requirement already satisfied: httptools==0.0.13; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"pypy\" in /usr/local/lib/python3.6/dist-packages (from uvicorn==0.11.1->deeppavlov==0.8.0) (0.0.13)\n",
            "Requirement already satisfied: uvloop>=0.14.0; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"pypy\" in /usr/local/lib/python3.6/dist-packages (from uvicorn==0.11.1->deeppavlov==0.8.0) (0.14.0)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.6/dist-packages (from uvicorn==0.11.1->deeppavlov==0.8.0) (0.9.0)\n",
            "Requirement already satisfied: click==7.* in /usr/local/lib/python3.6/dist-packages (from uvicorn==0.11.1->deeppavlov==0.8.0) (7.0)\n",
            "Requirement already satisfied: websockets==8.* in /usr/local/lib/python3.6/dist-packages (from uvicorn==0.11.1->deeppavlov==0.8.0) (8.1)\n",
            "Requirement already satisfied: yarl in /usr/local/lib/python3.6/dist-packages (from aio-pika==6.4.1->deeppavlov==0.8.0) (1.4.2)\n",
            "Requirement already satisfied: aiormq<4,>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from aio-pika==6.4.1->deeppavlov==0.8.0) (3.2.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21.2->deeppavlov==0.8.0) (0.14.1)\n",
            "Requirement already satisfied: dataclasses>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from pydantic==1.3->deeppavlov==0.8.0) (0.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov==0.8.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov==0.8.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov==0.8.0) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov==0.8.0) (2.8)\n",
            "Requirement already satisfied: starlette<=0.12.9,>=0.12.9 in /usr/local/lib/python3.6/dist-packages (from fastapi==0.47.1->deeppavlov==0.8.0) (0.12.9)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.38 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (1.15.38)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.9.5)\n",
            "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.8->pyopenssl==19.1.0->deeppavlov==0.8.0) (1.14.0)\n",
            "Requirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.6/dist-packages (from yarl->aio-pika==6.4.1->deeppavlov==0.8.0) (4.7.5)\n",
            "Requirement already satisfied: pamqp==2.3.0 in /usr/local/lib/python3.6/dist-packages (from aiormq<4,>=3.2.0->aio-pika==6.4.1->deeppavlov==0.8.0) (2.3.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers==2.8.0) (0.15.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.8->pyopenssl==19.1.0->deeppavlov==0.8.0) (2.19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12h9NwGqYeCI"
      },
      "source": [
        "from typing import List, Optional, Collection\n",
        "\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "\n",
        "from deeppavlov import build_model\n",
        "from deeppavlov.core.common.registry import register\n",
        "from deeppavlov.core.models.component import Component"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-NWrmzAYWLm"
      },
      "source": [
        "Define a DeepPavlov component to pre-process input text for the BERT model.  \n",
        "[An existing TransformersBertPreprocessor class](https://github.com/deepmipt/DeepPavlov/blob/0.8.0/deeppavlov/models/preprocessors/transformers_preprocessor.py) does this and more but cannot work with paired texts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vnfw71EaYWLn"
      },
      "source": [
        "@register('bert_encoder')\n",
        "class TransformersBertEncoder(Component):\n",
        "    def __init__(self, pretrained_model: str = 'bert-base-uncased', **kwargs):\n",
        "        self.tokenizer: BertTokenizer = BertTokenizer.from_pretrained(pretrained_model)\n",
        "        \n",
        "    def __call__(self, texts_batch: List[str], text_pairs_batch: Optional[List[str]] = None):\n",
        "        if text_pairs_batch is not None:\n",
        "            data = list(zip(texts_batch, text_pairs_batch))\n",
        "        else:\n",
        "            data = texts_batch\n",
        "        \n",
        "        res = self.tokenizer.batch_encode_plus(data, pad_to_max_length=True, add_special_tokens=True, return_tensors='pt', return_attention_masks=True)\n",
        "        return res['input_ids'], res['attention_mask'], res['token_type_ids']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8JpgCEHYWLr"
      },
      "source": [
        "A simple BERT-based class to generate a follow up of an initial text.  \n",
        "It will sample tokens until `max_generated_tokens` is generated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcehZXH5YWLs"
      },
      "source": [
        "@register('bert_generator')\n",
        "class TransformersBertGenerator(Component):\n",
        "    def __init__(self, pretrained_model: str = 'bert-base-uncased',\n",
        "                 max_generated_tokens: int = 15,\n",
        "                 mask_token_id: int = 103, sep_token_id: int = 102, pad_token_id: int = 0, **kwargs):\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.model: BertForMaskedLM = BertForMaskedLM.from_pretrained(pretrained_model).to(self.device)\n",
        "        self.max_generated_tokens = max_generated_tokens\n",
        "        \n",
        "        self.mask_tensor = torch.tensor(mask_token_id, device=self.device)\n",
        "        self.sep_tensor = torch.tensor(sep_token_id, device=self.device)\n",
        "        self.pad_tensor = torch.tensor(pad_token_id, device=self.device)\n",
        "        \n",
        "    @staticmethod\n",
        "    def _sample(prediction_scores: torch.Tensor):\n",
        "        # return prediction_scores.argmax(dim=-1)\n",
        "        probas = torch.nn.functional.softmax(prediction_scores[:, 0], dim=-1)\n",
        "        return torch.multinomial(probas, num_samples=1)\n",
        "    \n",
        "    def __call__(self, input_ids: torch.Tensor, attention_masks: torch.Tensor, token_type_ids: torch.Tensor):\n",
        "        input_ids = input_ids.to(self.device)\n",
        "        attention_masks = attention_masks.to(self.device)\n",
        "        token_type_ids = token_type_ids.to(self.device)\n",
        "        \n",
        "        batch_size = torch.tensor(len(input_ids), device=self.device)\n",
        "        with torch.no_grad():\n",
        "            # indexes of all tokens that will be genertated\n",
        "            mask_indexes = torch.arange(self.max_generated_tokens, device=self.device).expand([batch_size, -1]) + attention_masks.sum(dim=1).unsqueeze(1) - 1\n",
        "            \n",
        "            # expand attention masks and token types matrixes to accomodate for addtitional tokens\n",
        "            attention_masks = torch.cat([attention_masks, torch.zeros([batch_size, self.max_generated_tokens], device=self.device, dtype=int)], dim=1)\n",
        "            attention_masks.scatter_(1, mask_indexes+1, 1)\n",
        "            token_type_ids = torch.cat([token_type_ids, torch.ones([batch_size, self.max_generated_tokens], device=self.device, dtype=int)], dim=1)\n",
        "            \n",
        "            # expand token ids matrixes with paddings\n",
        "            input_ids = torch.cat([input_ids, self.pad_tensor.expand(batch_size, self.max_generated_tokens)], dim=1)\n",
        "            # insert [MASK] and [SEP] tokens\n",
        "            input_ids.scatter_(1, mask_indexes, self.mask_tensor)\n",
        "            input_ids.scatter_(1, attention_masks.sum(dim=1).unsqueeze(1)-1, self.sep_tensor)\n",
        "            \n",
        "            # fill in masks one by one\n",
        "            for i in range(self.max_generated_tokens):\n",
        "                indexes = mask_indexes[:, i:i+1]\n",
        "                prediction_scores = self.model.forward(input_ids, attention_masks, token_type_ids)[0]\n",
        "                mask_predictions = prediction_scores.gather(1, indexes.unsqueeze(-1).expand((-1, -1, prediction_scores.shape[-1])))\n",
        "                input_ids.scatter_(1, indexes, self._sample(mask_predictions))\n",
        "        return input_ids.cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wudZz_x7YWLw"
      },
      "source": [
        "A component for decoding output ids into tokens for second sentences.  \n",
        "It will decode tokens until it meets a `'[SEP]'` token or one of the `stopwords`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJNJbowrYWLx"
      },
      "source": [
        "@register('bert_decoder')\n",
        "class TransformersBertDecoder(Component):\n",
        "    def __init__(self, tokenizer: BertTokenizer, stopwords: Collection[str] = ('.', '?', '!'), **kwargs):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.stopwords = set(stopwords)\n",
        "    \n",
        "    def __call__(self, ids_batch: List[List[int]]):\n",
        "        result = []\n",
        "        \n",
        "        for tokens_ids in ids_batch:\n",
        "            all_tokens = iter(self.tokenizer.convert_ids_to_tokens(tokens_ids))\n",
        "            # skip the first part\n",
        "            for token in all_tokens:\n",
        "                if token == '[SEP]':\n",
        "                    break\n",
        "            tokens = []\n",
        "            # take tokens until finding `[SEP]` or one of the stopwords\n",
        "            for token in all_tokens:\n",
        "                if token == '[SEP]':\n",
        "                    break\n",
        "                tokens.append(token)\n",
        "                if token in self.stopwords:\n",
        "                    break\n",
        "            result.append(' '.join(tokens).replace(' ##', '').replace('##', ''))\n",
        "            \n",
        "        return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BY_vLJi2YWL0"
      },
      "source": [
        "A DeepPavlov configuration for the whole pipeline.  \n",
        "Read the DeepPavlov documentation for more information on [what it is](http://docs.deeppavlov.ai/en/0.8.0/intro/configuration.html) and how to [access custom components](http://docs.deeppavlov.ai/en/0.8.0/devguides/registry.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiqFYie1YWL2"
      },
      "source": [
        "config = {\n",
        "    'chainer': {\n",
        "        'in': ['texts', 'suggestions'],\n",
        "        'pipe': [\n",
        "            {\n",
        "                'class_name': 'bert_encoder',\n",
        "                'id': 'encoder',\n",
        "                'pretrained_model': '{PRETRAINED_MODEL}',\n",
        "                'in': ['texts', 'suggestions'],\n",
        "                'out': ['input_ids', 'attention_masks', 'token_type_ids']\n",
        "            },\n",
        "            {\n",
        "                'class_name': 'bert_generator',\n",
        "                'pretrained_model': '{PRETRAINED_MODEL}',\n",
        "                'max_generated_tokens': 10,\n",
        "                'mask_token_id': '#encoder.tokenizer.mask_token_id',\n",
        "                'sep_token_id': '#encoder.tokenizer.sep_token_id',\n",
        "                'pad_token_id': '#encoder.tokenizer.pad_token_id',\n",
        "                'in': ['input_ids', 'attention_masks', 'token_type_ids'],\n",
        "                'out': ['output_ids']\n",
        "            },\n",
        "            {\n",
        "                'class_name': 'bert_decoder',\n",
        "                'tokenizer': '#encoder.tokenizer',\n",
        "                'stopwords': ['.', '!', '?'],\n",
        "                'in': ['output_ids'],\n",
        "                'out': ['result']\n",
        "            }\n",
        "        ],\n",
        "        'out': ['result']\n",
        "    },\n",
        "    'metadata': {\n",
        "        'variables': {\n",
        "            'PRETRAINED_MODEL': 'bert-base-uncased'\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rm4YNaFYYWL5"
      },
      "source": [
        "Initialize the model and test it on some inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X51xPziBYWL6"
      },
      "source": [
        "dp_model = build_model(config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xO0txctnYWL9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "527966c0-da80-422e-e4d9-7fc63d453c04"
      },
      "source": [
        "texts = [\n",
        "    'DeepPavlov is an open source conversational AI framework.',\n",
        "    'The inference can speed up multiple times if you switch from CPU to GPU usage.',\n",
        "    'It is a period of civil war.'\n",
        "]\n",
        "suggestions = [\n",
        "    'I think that it',\n",
        "    'No result is an expected behavior and it means',\n",
        "    'Rebel spaceships, striking from a hidden base, have won their first victory against'\n",
        "]\n",
        "\n",
        "results = dp_model(texts, suggestions)\n",
        "\n",
        "print(*zip(texts, results), sep='\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('DeepPavlov is an open source conversational AI framework.', 'i think that it is a base for the service in general .')\n",
            "('The inference can speed up multiple times if you switch from CPU to GPU usage.', 'no result is an expected behavior and it means no one will have the first planned event occurs .')\n",
            "('It is a period of civil war.', 'rebel spaceships , striking from a hidden base , have won their first victory against a force , and later , a revolutionary coalition .')\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}