{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Agnostic RoBERTa-based Natural Languageto SQL Query Generation",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZP5z9uZw6ZB"
      },
      "source": [
        "# Data Agnostic RoBERTa-based Natural Languageto SQL Query Generation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0NrrIE-ObTB"
      },
      "source": [
        "### IMPORTANT: Set the runtime accelerator to use a GPU otherwise the code will run into errors\n",
        "\n",
        "The code cell below will mount your Google Drive to the colab notebook so that you can use files directly from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXvZi6MFN6iX"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4TXgygQxLkW"
      },
      "source": [
        "The below cell creates a copy of the GitHub repository, It lets you use the functions from the repo without having to install it locally"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6b9_q4AuLxK"
      },
      "source": [
        "!rm -rf RoBERTa-NL2SQL\n",
        "\n",
        "GIT_PATH = \"https://github.com/DebadityaPal/RoBERTa-NL2SQL\"\n",
        "!git clone \"{GIT_PATH}\"\n",
        "%cd RoBERTa-NL2SQL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSKkk9GqPLxE"
      },
      "source": [
        "Downloading the dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjqHS8cYf-9q"
      },
      "source": [
        "!pip install records\n",
        "!pip install transformers==3.4.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iUhJAnyQCoD"
      },
      "source": [
        "Let us import the libraries that we will be using"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CX57A283PZXQ"
      },
      "source": [
        "import load_data\n",
        "import torch\n",
        "import json,argparse\n",
        "import load_model\n",
        "import roberta_training\n",
        "import corenlp_local\n",
        "import seq2sql_model_testing\n",
        "import seq2sql_model_training_functions\n",
        "import model_save_and_infer\n",
        "import dev_function\n",
        "import infer_functions\n",
        "import time\n",
        "import os\n",
        "import nltk\n",
        "\n",
        "from dbengine_sqlnet import DBEngine\n",
        "from torchsummary import summary\n",
        "from tqdm.notebook import tqdm\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2hT-7fIQSLm"
      },
      "source": [
        "The following cell will set the PyTorch device to a GPU which enables us to use it during runtime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUtONmvdQNkA"
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zga8cHAOk6UJ"
      },
      "source": [
        "## Loading Data From Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umnKobpIkyKT"
      },
      "source": [
        "path_wikisql = \"/content/drive/My Drive/RoBERTa NL2SQL\"\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "train_data, train_table, dev_data, dev_table, train_loader, dev_loader = load_data.get_data(path_wikisql, batch_size = BATCH_SIZE)\n",
        "test_data,test_table,test_loader = load_data.get_test_data(path_wikisql, batch_size = BATCH_SIZE)\n",
        "zero_data,zero_table,zero_loader = load_data.get_zero_data(path_wikisql, batch_size = BATCH_SIZE)    # Data to test Zero Shot Learning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLvAcCc6nMlZ"
      },
      "source": [
        "## Loading Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI33ulCynQvC"
      },
      "source": [
        "roberta_model, tokenizer, configuration = load_model.get_roberta_model()          # Loads the RoBERTa Model\n",
        "seq2sql_model = load_model.get_seq2sql_model(configuration.hidden_size)           # Loads the LSTM based submodels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7h6RO52RofAR"
      },
      "source": [
        "## Loading the Pre trained weights, skip the below cell if you want to train the model from scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oRugxqvopyG"
      },
      "source": [
        "path_roberta_pretrained = path_wikisql + \"/model_roberta_best.pt\"\n",
        "path_model_pretrained = path_wikisql + \"/model_best.pt\"\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    res = torch.load(path_roberta_pretrained)\n",
        "else:\n",
        "    res = torch.load(path_roberta_pretrained, map_location='cpu')\n",
        "\n",
        "roberta_model.load_state_dict(res['model_roberta'])\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    res = torch.load(path_model_pretrained)\n",
        "else:\n",
        "    res = torch.load(path_model_pretrained, map_location='cpu')\n",
        "\n",
        "seq2sql_model.load_state_dict(res['model'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaxHUOSKo5qP"
      },
      "source": [
        "## Loading the Model Optimizers\n",
        "\n",
        "##### RoBERTa: Adam Optimizer with learning rate = 0.00001\n",
        "##### SubModels: Adam Optimizer with learning rate = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsB3EqSyo5XW"
      },
      "source": [
        "model_optimizer, roberta_optimizer = load_model.get_optimizers(seq2sql_model , roberta_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__T0p8MopL_m"
      },
      "source": [
        "## Below we define a function that prints the metrics in a readable format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phNnnnqHpTkg"
      },
      "source": [
        "def print_result(epoch, acc, dname):\n",
        "    ave_loss, acc_sc, acc_sa, acc_wn, acc_wc, acc_wo, acc_wvi, acc_wv, acc_lx, acc_x = acc\n",
        "\n",
        "    print(f'{dname} results ------------')\n",
        "    print(\n",
        "        f\" Epoch: {epoch}, ave loss: {ave_loss}, acc_sc: {acc_sc:.3f}, acc_sa: {acc_sa:.3f}, acc_wn: {acc_wn:.3f}, \\\n",
        "        acc_wc: {acc_wc:.3f}, acc_wo: {acc_wo:.3f}, acc_wvi: {acc_wvi:.3f}, acc_wv: {acc_wv:.3f}, acc_lx: {acc_lx:.3f}, acc_x: {acc_x:.3f}\"\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5oo_S2cpant"
      },
      "source": [
        "## Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ooY4UPj3eDL"
      },
      "source": [
        "EPOCHS = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dMdLFfhpdFV"
      },
      "source": [
        "acc_lx_t_best = 0.693             # Creats checkpoint so that a worse model does not get saved\n",
        "epoch_best = 0                   \n",
        "for epoch in range(EPOCHS):\n",
        "    acc_train = dev_function.train( seq2sql_model, roberta_model, model_optimizer, roberta_optimizer, tokenizer, configuration, path_wikisql, train_loader)\n",
        "    acc_dev, results_dev, cnt_list = dev_function.test(seq2sql_model, roberta_model, model_optimizer, tokenizer, configuration, path_wikisql, dev_loader, mode=\"dev\")\n",
        "    print_result(epoch, acc_train, 'train')\n",
        "    print_result(epoch, acc_dev, 'dev')\n",
        "    acc_lx_t = acc_dev[-2]\n",
        "    if acc_lx_t > acc_lx_t_best:                  # IMPORTANT : Comment out this whole if block if you are using a shortcut to the original\n",
        "        acc_lx_t_best = acc_lx_t                  #             Drive Folder, otherwise an error will stop the execution of the code.\n",
        "        epoch_best = epoch                        #             You cannot edit the files in the original folder\n",
        "                                                  #             Download and Upload a separate copy to change the files.\n",
        "          \n",
        "        # save best model\n",
        "        state = {'model': seq2sql_model.state_dict()}\n",
        "        torch.save(state, os.path.join(path_wikisql, 'model_best.pt'))\n",
        "\n",
        "        state = {'model_roberta': roberta_model.state_dict()}\n",
        "        torch.save(state, os.path.join(path_wikisql, 'model_roberta_best.pt'))\n",
        "\n",
        "    print(f\" Best Dev lx acc: {acc_lx_t_best} at epoch: {epoch_best}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMN_dONS3rxO"
      },
      "source": [
        "## Testing The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2195kSWS4Bfw"
      },
      "source": [
        "acc_dev, results_dev, _ = dev_function.test(seq2sql_model, roberta_model, model_optimizer, tokenizer, configuration, path_wikisql, dev_loader, mode=\"dev\")\n",
        "acc_test, results_test, _ = dev_function.test(seq2sql_model, roberta_model, model_optimizer, tokenizer, configuration, path_wikisql, test_loader, mode=\"test\")\n",
        "acc_zero, results_zero, _ = dev_function.test(seq2sql_model, roberta_model, model_optimizer, tokenizer, configuration, path_wikisql, zero_loader, mode=\"test\")\n",
        "\n",
        "print_result('test', acc_dev, 'dev')\n",
        "print_result('test', acc_test, 'test')\n",
        "print_result('test', acc_zero, 'zero')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgJedL_b89Wd"
      },
      "source": [
        "## Test You Own Queries!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZ3EnkSu8jz8"
      },
      "source": [
        "nlu = \"Which year did the band release the Song 'Wake me Up'?\"\n",
        "\n",
        "# Specify the Table Schema\n",
        "table_id = '1-10015132-16'\n",
        "headers = ['Band', 'Song', 'Studio', 'Year', 'Awards']\n",
        "types = ['text', 'text', 'text', 'text', 'text']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5DYRbLO9Vz8"
      },
      "source": [
        "pr_sql_i =  infer_functions.infer(\n",
        "                nlu,\n",
        "                table_id, headers, types, tokenizer, \n",
        "                seq2sql_model, roberta_model, configuration, max_seq_length=222,\n",
        "                num_target_layers=2,\n",
        "                beam_size=4\n",
        "            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YchC_8xqOw-z"
      },
      "source": [
        "Use the cell below to delete the cloned repository, this will free up the space used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tpRXOpZMWsh"
      },
      "source": [
        "!rm -rf RoBERTa-NL2SQL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfp7iwrSMcq9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}