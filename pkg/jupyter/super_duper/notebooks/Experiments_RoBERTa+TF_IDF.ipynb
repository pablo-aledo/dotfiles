{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Experiments_RoBERTa+TF-IDF.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07b6b949f6a148d59bcef39cee3e77c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fb30347e7fe441bcb5ab7653ea1bac9f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_752cfdef7eec40cd8f34201e9d54d012",
              "IPY_MODEL_009209791281479fbcd240f3ebfb5954"
            ]
          }
        },
        "fb30347e7fe441bcb5ab7653ea1bac9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "752cfdef7eec40cd8f34201e9d54d012": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0ea2cdb682c7477c8b1c3b1adc566243",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5e2f6a052b8044c79e097f9db3f46c18"
          }
        },
        "009209791281479fbcd240f3ebfb5954": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_27925e9a9b4a4c3cb38e36db191481eb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:01&lt;00:00, 883kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_27a5bbd9f3de4ed08411521114318411"
          }
        },
        "0ea2cdb682c7477c8b1c3b1adc566243": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5e2f6a052b8044c79e097f9db3f46c18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "27925e9a9b4a4c3cb38e36db191481eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "27a5bbd9f3de4ed08411521114318411": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1cfb509850884a3a97561996ec91ba8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3be36a54cccd4623ada280deaded70d2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7fdb570b7e8d4709a7a6686cd4d57c65",
              "IPY_MODEL_3f0c2810564842438058c41d005398fd"
            ]
          }
        },
        "3be36a54cccd4623ada280deaded70d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7fdb570b7e8d4709a7a6686cd4d57c65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2d3d8678b433422395363d2f7537e9ad",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af93498e584b4131b77410ed0e9d340c"
          }
        },
        "3f0c2810564842438058c41d005398fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_91fabef68bf24fc38e69caa580f98f6e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 1.26MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0b67ce6ad9604aed9d52d6be2d1ad05c"
          }
        },
        "2d3d8678b433422395363d2f7537e9ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "af93498e584b4131b77410ed0e9d340c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91fabef68bf24fc38e69caa580f98f6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0b67ce6ad9604aed9d52d6be2d1ad05c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2b6db6195d144e4a3e848ad1757bfb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_829bf6e8a65d4800bfd7287d6007c113",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6a95671548194fbca06ec1414b7bbc04",
              "IPY_MODEL_707a75bbe4b941369233a16c829f8526"
            ]
          }
        },
        "829bf6e8a65d4800bfd7287d6007c113": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a95671548194fbca06ec1414b7bbc04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cb1df164f46942ba8b2a6a2f910763aa",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 482,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 482,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af726520a9a14ec084faaf659f864310"
          }
        },
        "707a75bbe4b941369233a16c829f8526": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0a39426b7f594e59a481505bcf9768e0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 482/482 [01:11&lt;00:00, 6.77B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_816082cb81da45f8a42dac691eab6b82"
          }
        },
        "cb1df164f46942ba8b2a6a2f910763aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "af726520a9a14ec084faaf659f864310": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0a39426b7f594e59a481505bcf9768e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "816082cb81da45f8a42dac691eab6b82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e940a261bfb4676aa5646d1fad7ebfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ae4795e9f23d47d382c726ab86965a9a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ce7dc62473734b9ca8086e59513271af",
              "IPY_MODEL_11066f3245804b359edef2938d1f11bc"
            ]
          }
        },
        "ae4795e9f23d47d382c726ab86965a9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce7dc62473734b9ca8086e59513271af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_94f62d80d26a4f6f9c96983b4bae1008",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1425941629,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1425941629,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e0dffc10db3d41c4bc5da781f621ce67"
          }
        },
        "11066f3245804b359edef2938d1f11bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_03350706a56841eba33d4b935a25ccb4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.43G/1.43G [01:10&lt;00:00, 20.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4a0d78ddc6614653ab8f52ee49d3075f"
          }
        },
        "94f62d80d26a4f6f9c96983b4bae1008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e0dffc10db3d41c4bc5da781f621ce67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "03350706a56841eba33d4b935a25ccb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4a0d78ddc6614653ab8f52ee49d3075f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-JLBdmyrir3",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "f0683cae-c8e9-4517-8e9b-be1f420d3c56"
      },
      "source": [
        "'''This file was used to experiment the RoBERTa and various ensemble models with RoBERTa on the given dataset.'''\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-af444bc4-1479-441d-bc8f-918d87a3b638\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-af444bc4-1479-441d-bc8f-918d87a3b638\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving RedditDevDataSrc.csv to RedditDevDataSrc.csv\n",
            "Saving RedditTestDataSrc.csv to RedditTestDataSrc.csv\n",
            "Saving RedditTrainDataSrc.csv to RedditTrainDataSrc.csv\n",
            "Saving TwitterDevDataSrc.csv to TwitterDevDataSrc.csv\n",
            "Saving TwitterTestDataSrc.csv to TwitterTestDataSrc.csv\n",
            "Saving TwitterTrainDataSrc.csv to TwitterTrainDataSrc.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6G6Vl7ZsJOE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9a894247-101b-4d77-c3a0-5a50ba7e8ad4"
      },
      "source": [
        "import tensorflow as tf\n",
        "# Getting GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgYrSE67sLva",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "939b440f-d4a4-4020-dd9a-0b7068eb9986"
      },
      "source": [
        "import torch\n",
        "# If a GPU is available\n",
        "if torch.cuda.is_available():    \n",
        "    #set device to GPU   \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If no GPU is available\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frFYhWeYsNx-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 760,
          "referenced_widgets": [
            "07b6b949f6a148d59bcef39cee3e77c8",
            "fb30347e7fe441bcb5ab7653ea1bac9f",
            "752cfdef7eec40cd8f34201e9d54d012",
            "009209791281479fbcd240f3ebfb5954",
            "0ea2cdb682c7477c8b1c3b1adc566243",
            "5e2f6a052b8044c79e097f9db3f46c18",
            "27925e9a9b4a4c3cb38e36db191481eb",
            "27a5bbd9f3de4ed08411521114318411",
            "1cfb509850884a3a97561996ec91ba8d",
            "3be36a54cccd4623ada280deaded70d2",
            "7fdb570b7e8d4709a7a6686cd4d57c65",
            "3f0c2810564842438058c41d005398fd",
            "2d3d8678b433422395363d2f7537e9ad",
            "af93498e584b4131b77410ed0e9d340c",
            "91fabef68bf24fc38e69caa580f98f6e",
            "0b67ce6ad9604aed9d52d6be2d1ad05c"
          ]
        },
        "outputId": "9bc84f14-b19f-47ef-ad30-4c78c19c68f2"
      },
      "source": [
        "#Importing necessary libraries\n",
        "!pip install transformers\n",
        "\n",
        "import re\n",
        "import scipy\n",
        "import pandas         as pd\n",
        "import io\n",
        "import numpy          as np\n",
        "import copy\n",
        "import seaborn        as sns\n",
        "\n",
        "import transformers\n",
        "from transformers                     import  RobertaModel, RobertaTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics                  import classification_report\n",
        "from sklearn.feature_extraction.text  import TfidfVectorizer\n",
        "\n",
        "from torch                            import nn, optim\n",
        "from torch.utils                      import data\n",
        "from sklearn.decomposition            import PCA\n",
        "\n",
        "#Seeding for deterministic results\n",
        "RANDOM_SEED = 64\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "   torch.cuda.manual_seed(RANDOM_SEED)\n",
        "   torch.cuda.manual_seed_all(RANDOM_SEED) \n",
        "   torch.backends.cudnn.deterministic = True  \n",
        "   torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "CLASS_NAMES = ['support', 'deny', 'query', 'comment']\n",
        "MAX_LENGTH = 200\n",
        "BATCH_SIZE = 4\n",
        "EPOCHS = 6\n",
        "HIDDEN_UNITS = 128\n",
        "\n",
        "tokenizer = transformers.RobertaTokenizer.from_pretrained('roberta-large')  #Use roberta-large or roberta-base"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 778kB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 8.5MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0MB 23.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 61.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=dc351f926249f1547ea646936277047730c3693fa88f8fe4cff76211ae1fe17c\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "07b6b949f6a148d59bcef39cee3e77c8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1cfb509850884a3a97561996ec91ba8d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1zp-jMcsWIz"
      },
      "source": [
        "#Converting labels to numbers\n",
        "def label_to_int(label):\n",
        "  if label   == 'support':\n",
        "    return 0\n",
        "  elif label == 'deny':\n",
        "    return 1\n",
        "  elif label == 'query':\n",
        "    return 2\n",
        "  elif label == 'comment':\n",
        "    return 3\n",
        "\n",
        "\n",
        "#Pre-processing Twitter and Reddit Posts to handle URLs and Mentions. \n",
        "#Replaces URLs with $URL$ and mentions with $MENTION$\n",
        "def processText(text):\n",
        "  text = re.sub(r\"(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?\", \"$URL$\",text.strip())\n",
        "  text = re.sub(r\"(@[A-Za-z0-9]+)\", \"$MENTION$\", text.strip())\n",
        "\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QImtZoCNsYrw"
      },
      "source": [
        "'''Processing all of Twitter and Reddit data frames to \n",
        "    1. Get rid of all NaN values\n",
        "    2. Remove columns not useful for the Model\n",
        "    3. Process text \n",
        "    4. Return a combined frame consisting of both Twitter and Reddit data'''\n",
        "\n",
        "    \n",
        "def processStanceData(twitterDf, RedditDf):\n",
        "  frames = [twitterDf, RedditDf]\n",
        "\n",
        "  resultDf = pd.concat(frames)                                                      #Concatenating twitter and reddit data\n",
        "  result1  = resultDf.replace(np.nan, '', regex=True)                               #Getting rid of NaN values\n",
        "\n",
        "  result1['labelvalue'] = result1.label_x.apply(label_to_int)                       #Converting labels to numbers\n",
        "  result1['SrcInre']    = result1['inreText'].str.cat(result1['sourceText'],sep=\" \")\n",
        "\n",
        "  data = result1[['text_x', 'id', 'inre_x', 'source_x' ,'label_x','SrcInre', 'labelvalue' ]].copy()\n",
        "\n",
        "\n",
        "  '''replyText           - the reply post (whose stance towards the target needs to be learnt)\n",
        "     replyTextId         - the ID of the reply post\n",
        "     previousText        - the text to which replyText was replied\n",
        "     sourceText          - the source post of the conversation thread\n",
        "     label               - the label value assigned to each post\n",
        "     previoysPlusSrctext - the concatenation of the previousText and the sourceText\n",
        "     labelValue          - the numberic value assigned to each label'''\n",
        "\n",
        "  data.columns = ['replyText', 'replyTextId', 'previousText', 'sourceText', 'label', 'previousPlusSrcText', 'labelValue']\n",
        "\n",
        "  data['pReplyText']           = data.replyText.apply(processText)\n",
        "  data['pPreviousPlusSrcText'] = data.previousPlusSrcText.apply(processText)\n",
        "  return data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4ARH8pisdYA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "71116769-2964-4756-8422-68e3c2a251aa"
      },
      "source": [
        "#Reading Twitter and Reddit data (train, dev and test) onto dataFrames\n",
        "twitterTrainDf  = pd.read_csv(io.StringIO(uploaded['TwitterTrainDataSrc.csv'].decode('utf-8')))\n",
        "redditTrainDf   = pd.read_csv(io.StringIO(uploaded['RedditTrainDataSrc.csv'].decode('utf-8')))\n",
        "\n",
        "twitterDevDf    = pd.read_csv(io.StringIO(uploaded['TwitterDevDataSrc.csv'].decode('utf-8')))\n",
        "redditDevDf     = pd.read_csv(io.StringIO(uploaded['RedditDevDataSrc.csv'].decode('utf-8')))\n",
        "\n",
        "twitterTestDf   = pd.read_csv(io.StringIO(uploaded['TwitterTestDataSrc.csv'].decode('utf-8')))\n",
        "redditTestDf    = pd.read_csv(io.StringIO(uploaded['RedditTestDataSrc.csv'].decode('utf-8')))\n",
        "\n",
        "#Processing Twitter and Reddit dataframe containig training data\n",
        "trainDf = processStanceData(twitterTrainDf, redditTrainDf)\n",
        "trainDf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>replyText</th>\n",
              "      <th>replyTextId</th>\n",
              "      <th>previousText</th>\n",
              "      <th>sourceText</th>\n",
              "      <th>label</th>\n",
              "      <th>previousPlusSrcText</th>\n",
              "      <th>labelValue</th>\n",
              "      <th>pReplyText</th>\n",
              "      <th>pPreviousPlusSrcText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mike Brown was staying with his grandmother fo...</td>\n",
              "      <td>498280126254428160</td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "      <td>support</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>Mike Brown was staying with his grandmother fo...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Witness: Police allegedly stopped Mike Brown a...</td>\n",
              "      <td>498430783699554305</td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "      <td>support</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>Witness: Police allegedly stopped Mike Brown a...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Line of police cars with high beams on greets ...</td>\n",
              "      <td>499366666300846081</td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "      <td>support</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>Line of police cars with high beams on greets ...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Currently the #FoxNews website has zero, repea...</td>\n",
              "      <td>499368931367608320</td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "      <td>support</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>Currently the #FoxNews website has zero, repea...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>St. Louis Co Police tell me ofcr shot a man wh...</td>\n",
              "      <td>499456140044824576</td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "      <td>support</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>St. Louis Co Police tell me ofcr shot a man wh...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>693</th>\n",
              "      <td>Quote:\\n\\n&amp;gt; I was opening Turnberry the day...</td>\n",
              "      <td>e2by4oh</td>\n",
              "      <td>e2bxvw0</td>\n",
              "      <td>8yktu5</td>\n",
              "      <td>deny</td>\n",
              "      <td>[deleted] Jon Sopel: Bizarre. @realDonaldTrump...</td>\n",
              "      <td>1</td>\n",
              "      <td>Quote:\\n\\n&amp;gt; I was opening Turnberry the day...</td>\n",
              "      <td>[deleted] Jon Sopel: Bizarre. $MENTION$ says h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>694</th>\n",
              "      <td>[deleted]</td>\n",
              "      <td>e2bynsb</td>\n",
              "      <td>e2by4oh</td>\n",
              "      <td>8yktu5</td>\n",
              "      <td>comment</td>\n",
              "      <td>Quote:\\n\\n&amp;gt; I was opening Turnberry the day...</td>\n",
              "      <td>3</td>\n",
              "      <td>[deleted]</td>\n",
              "      <td>Quote:\\n\\n&amp;gt; I was opening Turnberry the day...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>695</th>\n",
              "      <td>He said he was opening it the day before Brexi...</td>\n",
              "      <td>e2bz0mz</td>\n",
              "      <td>e2bynsb</td>\n",
              "      <td>8yktu5</td>\n",
              "      <td>comment</td>\n",
              "      <td>[deleted] Jon Sopel: Bizarre. @realDonaldTrump...</td>\n",
              "      <td>3</td>\n",
              "      <td>He said he was opening it the day before Brexi...</td>\n",
              "      <td>[deleted] Jon Sopel: Bizarre. $MENTION$ says h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>696</th>\n",
              "      <td>\"Well if you remember I was opening Turnberry ...</td>\n",
              "      <td>e2c1gqf</td>\n",
              "      <td>e2btp0f</td>\n",
              "      <td>8yktu5</td>\n",
              "      <td>comment</td>\n",
              "      <td>[deleted] Jon Sopel: Bizarre. @realDonaldTrump...</td>\n",
              "      <td>3</td>\n",
              "      <td>\"Well if you remember I was opening Turnberry ...</td>\n",
              "      <td>[deleted] Jon Sopel: Bizarre. $MENTION$ says h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>697</th>\n",
              "      <td>Yeah seems like he is either blatantly lying o...</td>\n",
              "      <td>e2c1n3o</td>\n",
              "      <td>e2bv4kg</td>\n",
              "      <td>8yktu5</td>\n",
              "      <td>comment</td>\n",
              "      <td>[This is the better tweet](https://twitter.com...</td>\n",
              "      <td>3</td>\n",
              "      <td>Yeah seems like he is either blatantly lying o...</td>\n",
              "      <td>[This is the better tweet]($URL$): he left the...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5217 rows Ã— 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             replyText  ...                               pPreviousPlusSrcText\n",
              "0    Mike Brown was staying with his grandmother fo...  ...                                                   \n",
              "1    Witness: Police allegedly stopped Mike Brown a...  ...                                                   \n",
              "2    Line of police cars with high beams on greets ...  ...                                                   \n",
              "3    Currently the #FoxNews website has zero, repea...  ...                                                   \n",
              "4    St. Louis Co Police tell me ofcr shot a man wh...  ...                                                   \n",
              "..                                                 ...  ...                                                ...\n",
              "693  Quote:\\n\\n&gt; I was opening Turnberry the day...  ...  [deleted] Jon Sopel: Bizarre. $MENTION$ says h...\n",
              "694                                          [deleted]  ...  Quote:\\n\\n&gt; I was opening Turnberry the day...\n",
              "695  He said he was opening it the day before Brexi...  ...  [deleted] Jon Sopel: Bizarre. $MENTION$ says h...\n",
              "696  \"Well if you remember I was opening Turnberry ...  ...  [deleted] Jon Sopel: Bizarre. $MENTION$ says h...\n",
              "697  Yeah seems like he is either blatantly lying o...  ...  [This is the better tweet]($URL$): he left the...\n",
              "\n",
              "[5217 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apfESmuDsh13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        },
        "outputId": "6d68d55e-690f-4a99-f571-8ee86cb4fead"
      },
      "source": [
        "#Processing Twitter and Reddit dataframe containig development data\n",
        "devDf = processStanceData(twitterDevDf, redditDevDf)\n",
        "devDf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>replyText</th>\n",
              "      <th>replyTextId</th>\n",
              "      <th>previousText</th>\n",
              "      <th>sourceText</th>\n",
              "      <th>label</th>\n",
              "      <th>previousPlusSrcText</th>\n",
              "      <th>labelValue</th>\n",
              "      <th>pReplyText</th>\n",
              "      <th>pPreviousPlusSrcText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Every 28 hours a black male is killed in the U...</td>\n",
              "      <td>498293668655423488</td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "      <td>support</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>Every 28 hours a black male is killed in the U...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>.@AP I demand you retract the lie that people ...</td>\n",
              "      <td>498486826269548545</td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "      <td>deny</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>.$MENTION$ I demand you retract the lie that p...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Police name the officer who shot #Ferguson tee...</td>\n",
              "      <td>500280249629036544</td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "      <td>support</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>Police name the officer who shot #Ferguson tee...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Police have named the cop who shot Michael Bro...</td>\n",
              "      <td>500298588992593920</td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "      <td>support</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>Police have named the cop who shot Michael Bro...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>At the war memorial in. Ottawa. A soldier has ...</td>\n",
              "      <td>524923293711998976</td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "      <td>support</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>At the war memorial in. Ottawa. A soldier has ...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431</th>\n",
              "      <td>That's pretty interesting. \\n\\nThey were talki...</td>\n",
              "      <td>e3ckunl</td>\n",
              "      <td>e3beeop</td>\n",
              "      <td>934q6t</td>\n",
              "      <td>comment</td>\n",
              "      <td>It turns out that iodine does decrease in tabl...</td>\n",
              "      <td>3</td>\n",
              "      <td>That's pretty interesting. \\n\\nThey were talki...</td>\n",
              "      <td>It turns out that iodine does decrease in tabl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>432</th>\n",
              "      <td>Is iodized salt not INCREDIBLY common in the USA?</td>\n",
              "      <td>e3cnfmf</td>\n",
              "      <td>934q6t</td>\n",
              "      <td>934q6t</td>\n",
              "      <td>comment</td>\n",
              "      <td>Iodine increases IQ and is an essential part o...</td>\n",
              "      <td>3</td>\n",
              "      <td>Is iodized salt not INCREDIBLY common in the USA?</td>\n",
              "      <td>Iodine increases IQ and is an essential part o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>433</th>\n",
              "      <td>Who does the website state you can only buy on...</td>\n",
              "      <td>e3cr1ps</td>\n",
              "      <td>e3ar20p</td>\n",
              "      <td>934q6t</td>\n",
              "      <td>comment</td>\n",
              "      <td>I take this daily, you'll notice a difference ...</td>\n",
              "      <td>3</td>\n",
              "      <td>Who does the website state you can only buy on...</td>\n",
              "      <td>I take this daily, you'll notice a difference ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>434</th>\n",
              "      <td>&amp;gt;Itâ€™s estimated that nearly one-third of th...</td>\n",
              "      <td>e3cz12q</td>\n",
              "      <td>e3apatz</td>\n",
              "      <td>934q6t</td>\n",
              "      <td>comment</td>\n",
              "      <td>Your title says that iodine is absent from alm...</td>\n",
              "      <td>3</td>\n",
              "      <td>&amp;gt;Itâ€™s estimated that nearly one-third of th...</td>\n",
              "      <td>Your title says that iodine is absent from alm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>go to the co-op. and bye some sea weed cracker...</td>\n",
              "      <td>e3d2zwn</td>\n",
              "      <td>e3bsdee</td>\n",
              "      <td>934q6t</td>\n",
              "      <td>comment</td>\n",
              "      <td>I had tried the drops sublingually, but they w...</td>\n",
              "      <td>3</td>\n",
              "      <td>go to the co-op. and bye some sea weed cracker...</td>\n",
              "      <td>I had tried the drops sublingually, but they w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1485 rows Ã— 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             replyText  ...                               pPreviousPlusSrcText\n",
              "0    Every 28 hours a black male is killed in the U...  ...                                                   \n",
              "1    .@AP I demand you retract the lie that people ...  ...                                                   \n",
              "2    Police name the officer who shot #Ferguson tee...  ...                                                   \n",
              "3    Police have named the cop who shot Michael Bro...  ...                                                   \n",
              "4    At the war memorial in. Ottawa. A soldier has ...  ...                                                   \n",
              "..                                                 ...  ...                                                ...\n",
              "431  That's pretty interesting. \\n\\nThey were talki...  ...  It turns out that iodine does decrease in tabl...\n",
              "432  Is iodized salt not INCREDIBLY common in the USA?  ...  Iodine increases IQ and is an essential part o...\n",
              "433  Who does the website state you can only buy on...  ...  I take this daily, you'll notice a difference ...\n",
              "434  &gt;Itâ€™s estimated that nearly one-third of th...  ...  Your title says that iodine is absent from alm...\n",
              "435  go to the co-op. and bye some sea weed cracker...  ...  I had tried the drops sublingually, but they w...\n",
              "\n",
              "[1485 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MFgrBAeskj_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "68152650-c86c-4370-89b7-14b915ff3303"
      },
      "source": [
        "#Processing Twitter and Reddit dataframe containig test data\n",
        "testDf = processStanceData(twitterTestDf, redditTestDf)\n",
        "testDf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>replyText</th>\n",
              "      <th>replyTextId</th>\n",
              "      <th>previousText</th>\n",
              "      <th>sourceText</th>\n",
              "      <th>label</th>\n",
              "      <th>previousPlusSrcText</th>\n",
              "      <th>labelValue</th>\n",
              "      <th>pReplyText</th>\n",
              "      <th>pPreviousPlusSrcText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Rep. Sheila Jackson Lee has no shame. I still ...</td>\n",
              "      <td>443938194715713536</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>support</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>Rep. Sheila Jackson Lee has no shame. I still ...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ICYMI: \"Rep Sheila Jackson Lee (D-Tx) Wants Hu...</td>\n",
              "      <td>774165935041093633</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>support</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>ICYMI: \"Rep Sheila Jackson Lee (D-Tx) Wants Hu...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Clinton camp delays Weather Channel ad buy aft...</td>\n",
              "      <td>784071228248109057</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>support</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>Clinton camp delays Weather Channel ad buy aft...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Clinton camp delays Weather Channel ad buy aft...</td>\n",
              "      <td>784118929799073793</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>support</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>Clinton camp delays Weather Channel ad buy aft...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Clinton camp delays Weather Channel ad buy aft...</td>\n",
              "      <td>784216706080178176</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>support</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>Clinton camp delays Weather Channel ad buy aft...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>756</th>\n",
              "      <td>Lawl. I'm assuming you're a troll. But if not,...</td>\n",
              "      <td>c5o445z</td>\n",
              "      <td>c5o2sto</td>\n",
              "      <td>xn2bn</td>\n",
              "      <td>comment</td>\n",
              "      <td>Doesn't mean it's not fake. You idiots voted a...</td>\n",
              "      <td>3</td>\n",
              "      <td>Lawl. I'm assuming you're a troll. But if not,...</td>\n",
              "      <td>Doesn't mean it's not fake. You idiots voted a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>757</th>\n",
              "      <td>not saying bush was the best, or palin was the...</td>\n",
              "      <td>c5o46c3</td>\n",
              "      <td>c5o445z</td>\n",
              "      <td>xn2bn</td>\n",
              "      <td>comment</td>\n",
              "      <td>Lawl. I'm assuming you're a troll. But if not,...</td>\n",
              "      <td>3</td>\n",
              "      <td>not saying bush was the best, or palin was the...</td>\n",
              "      <td>Lawl. I'm assuming you're a troll. But if not,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>758</th>\n",
              "      <td>^^^^^\\nthey would do that if someone hadn't se...</td>\n",
              "      <td>c5o47lt</td>\n",
              "      <td>c5nt4le</td>\n",
              "      <td>xn2bn</td>\n",
              "      <td>comment</td>\n",
              "      <td>When they bring up the college ID that shows h...</td>\n",
              "      <td>3</td>\n",
              "      <td>^^^^^\\nthey would do that if someone hadn't se...</td>\n",
              "      <td>When they bring up the college ID that shows h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>759</th>\n",
              "      <td>You are right about that, but we didn't know s...</td>\n",
              "      <td>c5o4cdk</td>\n",
              "      <td>c5o46c3</td>\n",
              "      <td>xn2bn</td>\n",
              "      <td>comment</td>\n",
              "      <td>not saying bush was the best, or palin was the...</td>\n",
              "      <td>3</td>\n",
              "      <td>You are right about that, but we didn't know s...</td>\n",
              "      <td>not saying bush was the best, or palin was the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>760</th>\n",
              "      <td>We...agree?? nice. reddit ftw</td>\n",
              "      <td>c5o4x2j</td>\n",
              "      <td>c5o4cdk</td>\n",
              "      <td>xn2bn</td>\n",
              "      <td>comment</td>\n",
              "      <td>You are right about that, but we didn't know s...</td>\n",
              "      <td>3</td>\n",
              "      <td>We...agree?? nice. reddit ftw</td>\n",
              "      <td>You are right about that, but we didn't know s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1827 rows Ã— 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             replyText  ...                               pPreviousPlusSrcText\n",
              "0    Rep. Sheila Jackson Lee has no shame. I still ...  ...                                                   \n",
              "1    ICYMI: \"Rep Sheila Jackson Lee (D-Tx) Wants Hu...  ...                                                   \n",
              "2    Clinton camp delays Weather Channel ad buy aft...  ...                                                   \n",
              "3    Clinton camp delays Weather Channel ad buy aft...  ...                                                   \n",
              "4    Clinton camp delays Weather Channel ad buy aft...  ...                                                   \n",
              "..                                                 ...  ...                                                ...\n",
              "756  Lawl. I'm assuming you're a troll. But if not,...  ...  Doesn't mean it's not fake. You idiots voted a...\n",
              "757  not saying bush was the best, or palin was the...  ...  Lawl. I'm assuming you're a troll. But if not,...\n",
              "758  ^^^^^\\nthey would do that if someone hadn't se...  ...  When they bring up the college ID that shows h...\n",
              "759  You are right about that, but we didn't know s...  ...  not saying bush was the best, or palin was the...\n",
              "760                      We...agree?? nice. reddit ftw  ...  You are right about that, but we didn't know s...\n",
              "\n",
              "[1827 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hF32c5TJsn7R"
      },
      "source": [
        "#Creates a dataset which will be used to feed to RoBERTa\n",
        "class StanceDataset(data.Dataset):\n",
        "\n",
        "  def __init__(self, firstSeq, secondSeq, TextSrcInre, labelValue,  tokenizer, max_len):\n",
        "    self.firstSeq    = firstSeq      #First input sequence that will be supplied to RoBERTa\n",
        "    self.secondSeq   = secondSeq     #Second input sequence that will be supplied to RoBERTa\n",
        "    self.TextSrcInre = TextSrcInre   #Concatenation of reply+ previous+ src text to get features from 1 training example\n",
        "    self.labelValue  = labelValue    #label value for each training example in the dataset\n",
        "    self.tokenizer   = tokenizer     #tokenizer that will be used to tokenize input sequences (Uses BERT-tokenizer here)\n",
        "    self.max_len     = max_len       #Maximum length of the tokens from the input sequence that BERT needs to attend to\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.labelValue)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    firstSeq    = str(self.firstSeq[item])\n",
        "    secondSeq   = str(self.secondSeq[item])\n",
        "    TextSrcInre = str(self.TextSrcInre[item])\n",
        "    \n",
        "    #Encoding the first and the second sequence to a form accepted by RoBERTa\n",
        "    #RoBERTa does not use token_type_ids to distinguish the first sequence from the second sequnece.\n",
        "    encoding = tokenizer.encode_plus(\n",
        "        firstSeq,\n",
        "        secondSeq,\n",
        "        max_length = self.max_len,\n",
        "        add_special_tokens= True,\n",
        "        truncation = True,\n",
        "        pad_to_max_length = True,\n",
        "        return_attention_mask = True,\n",
        "        return_tensors = 'pt'\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        'firstSeq' : firstSeq,\n",
        "        'secondSeq' : secondSeq,\n",
        "        'TextSrcInre': TextSrcInre,\n",
        "        'input_ids': encoding['input_ids'].flatten(),\n",
        "        'attention_mask': encoding['attention_mask'].flatten(),\n",
        "        'labelValue'  : torch.tensor(self.labelValue[item], dtype=torch.long)\n",
        "    }\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QivInecFsomT"
      },
      "source": [
        "#Creates a data loader\n",
        "def createDataLoader(dataframe, tokenizer, max_len, batch_size):\n",
        "  ds = StanceDataset(\n",
        "      firstSeq    = dataframe.pReplyText.to_numpy(),\n",
        "      secondSeq   = dataframe.pPreviousPlusSrcText.to_numpy(),\n",
        "      TextSrcInre = dataframe.TextSrcInre.to_numpy(),\n",
        "      labelValue  = dataframe.labelValue.to_numpy(),\n",
        "      tokenizer   = tokenizer,\n",
        "      max_len     = max_len\n",
        "  )\n",
        "\n",
        "  return data.DataLoader(\n",
        "      ds,\n",
        "      batch_size  = batch_size,\n",
        "      shuffle     = True,\n",
        "      num_workers = 4\n",
        "  )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWy-fUVOstCt"
      },
      "source": [
        "#Combining the reply, previous and source texts to get features for 1 training example\n",
        "trainDf['TextSrcInre'] = trainDf['pReplyText'].str.cat(trainDf['pPreviousPlusSrcText'],sep=\" \")\n",
        "devDf['TextSrcInre']   = devDf['pReplyText'].str.cat(devDf['pPreviousPlusSrcText'],sep=\" \")\n",
        "testDf['TextSrcInre']  = testDf['pReplyText'].str.cat(testDf['pPreviousPlusSrcText'],sep=\" \")\n",
        "\n",
        "\n",
        "#Creating data loader for training data\n",
        "trainDataLoader        = createDataLoader(trainDf, tokenizer, MAX_LENGTH, BATCH_SIZE)\n",
        "\n",
        "#Creating data loader for development data\n",
        "developmentDataLoader  = createDataLoader(devDf, tokenizer, MAX_LENGTH, BATCH_SIZE)\n",
        "\n",
        "#Creating data loader for test data\n",
        "testDataLoader         = createDataLoader(testDf, tokenizer, MAX_LENGTH, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9ndmG1btoKq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "bd9f49df-f957-4746-d519-fb4e0a2de3c7"
      },
      "source": [
        "#Instantiating the tf-idf vectorizer object\n",
        "tfidf = TfidfVectorizer(min_df = 10, max_df = 0.5, ngram_range=(1,2))\n",
        "\n",
        "xtrain = trainDf['TextSrcInre'].tolist()\n",
        "x_train_feats = tfidf.fit(xtrain)\n",
        "print(x_train_feats)\n",
        "print(len(x_train_feats.get_feature_names()))\n",
        "\n",
        "\n",
        "x_train_transform = x_train_feats.transform(xtrain)\n",
        "tfidf_transform_tensor = torch.tensor(scipy.sparse.csr_matrix.todense(x_train_transform)).float()\n",
        "print(x_train_transform.shape)\n",
        "\n",
        "\n",
        "pca = PCA(n_components=128)\n",
        "p = pca.fit(tfidf_transform_tensor)\n",
        "#print(p.shape)\n",
        "#print(p)\n",
        "X = p.transform(tfidf_transform_tensor)\n",
        "#torch.from_numpy(X.values)\n",
        "X = torch.from_numpy(X)\n",
        "#tfidf_transform_tensor_pca = torch.tensor(scipy.sparse.csr_matrix.todense(X)).float()\n",
        "#print(X.type())\n",
        "#print(X.shape)\n",
        "#print(X)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
            "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
            "                input='content', lowercase=True, max_df=0.5, max_features=None,\n",
            "                min_df=10, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
            "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
            "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
            "                tokenizer=None, use_idf=True, vocabulary=None)\n",
            "5814\n",
            "(5217, 5814)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeET7Siptyco"
      },
      "source": [
        "#This class defines the model that was used to pre-train a SNN on TF-IDF features\n",
        "class Tfidf_Nn(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Inputs to hidden layer linear transformation\n",
        "        self.hidden  = nn.Linear(len(tfidf.get_feature_names()), HIDDEN_UNITS)\n",
        "        # Output layer\n",
        "        self.output  =  nn.Linear(HIDDEN_UNITS, 4)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        \n",
        "        # Defining tanh activation and softmax output \n",
        "        self.tanh = nn.Tanh()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Pass the input tensor through each of our operations\n",
        "        x = self.hidden(x)\n",
        "        #print(x.shape)\n",
        "        y = self.tanh(x)\n",
        "        #print(y.shape)\n",
        "        z = self.dropout(y)\n",
        "        #print(z.shape)\n",
        "        z = self.output(z)\n",
        "        #print(z.shape)\n",
        "        z = self.softmax(z)\n",
        "        \n",
        "        #Returning the ouputs from the hidden layer and the final output layer\n",
        "        return  y, z\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZGZhYgbtz--",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "5151b3b1-045a-4c47-811d-ee32506d20e9"
      },
      "source": [
        "#Loading the already trained MLP model that was trained on TF-IDF features. \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "snnmodel = Tfidf_Nn()\n",
        "\n",
        "model_save_name = 'pre-trainedTfidf.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\"\n",
        "\n",
        "snnmodel.load_state_dict(torch.load(path))\n",
        "snnmodel.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tfidf_Nn(\n",
              "  (hidden): Linear(in_features=5814, out_features=128, bias=True)\n",
              "  (output): Linear(in_features=128, out_features=4, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (tanh): Tanh()\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMfWJLpssxRb"
      },
      "source": [
        "'''This class defines the model that will be used for \n",
        "training and testing on the dataset.\n",
        "\n",
        "Adapted from huggingFace\n",
        "This RoBERTa model from huggingface outputs the last hidden states\n",
        "and the pooled output by default. Pooled output is the classification \n",
        "token (1st token of the last hidden state) further processed by a Linear\n",
        "layer and a Tanh activation function.\n",
        "\n",
        "The pre-trained RoBERTa model is used as the primary model.\n",
        "This class experiments with RoBERTa and its ensemble with TF-IDF features. \n",
        "roberta-only :            No ensembling. This just fine-tunes the RoBERTa model. \n",
        "                          The pooled output is passed through a linear layer and \n",
        "                          softmax function is finally used for preictions. \n",
        "\n",
        "roberta-tfIdf :           This model conatenates the 1st token of last-hidden layer\n",
        "                          from RoBERTa with TF-IDF features. Various ways of this \n",
        "                          concatenation was experimented (using pooled output instead\n",
        "                          of 1st token of last hidden layer etc)\n",
        "\n",
        "roberta-pcaTfidf :        This model concatenates the pooled output from\n",
        "                          RoBERTa with the PCA transformed vector.\n",
        "\n",
        "roberta-preTrainedTfIdf : This model concatenates the pooled output from\n",
        "                          RoBERTa with the hidden layer output from a pre-trained\n",
        "                          SNN that was trained on TF-IDF features.\n",
        "\n",
        "Used dropout to prevent over-fitting.'''\n",
        "\n",
        "class StanceClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self,  n_classes):\n",
        "    super(StanceClassifier, self).__init__()\n",
        "    self.robertaModel              = RobertaModel.from_pretrained('roberta-large')    #use roberta-large or roberta-base\n",
        "    self.model_TFIDF               = snnmodel                                        #Pre-trained SNN trained with TF-IDF features\n",
        "\n",
        "    self.drop                      = nn.Dropout(p = 0.3)\n",
        "\n",
        "    self.output                    = nn.Linear(self.robertaModel.config.hidden_size, n_classes)\n",
        "\n",
        "    self.input_size_tfidf_only     = self.robertaModel.config.hidden_size + len(tfidf.get_feature_names())\n",
        "    self.input_size_tfidf_pca      = self.robertaModel.config.hidden_size + HIDDEN_UNITS\n",
        "    \n",
        "    self.dense                     = nn.Linear( self.input_size_tfidf_only,  self.input_size_tfidf_only)\n",
        "    self.out_proj                  = nn.Linear( self.input_size_tfidf_only, n_classes)\n",
        "    self.out_pca                   = nn.Linear( self.input_size_tfidf_pca, n_classes)\n",
        "\n",
        "    self.input_size_preTrain_tfidf = self.robertaModel.config.hidden_size +  HIDDEN_UNITS \n",
        "    self.out                       = nn.Linear(self.input_size_preTrain_tfidf, n_classes)\n",
        "    \n",
        "    self.softmax                   = nn.Softmax(dim = 1)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask, inputs_tfidf_feats, pca_transformed_feats, modelType):\n",
        "    \n",
        "    roberta_output     = self.robertaModel(\n",
        "        input_ids      = input_ids,               #Input sequence tokens\n",
        "        attention_mask = attention_mask )         #Mask to avoid performing attention on padding tokens\n",
        "    #print(roberta_output[1].shape)\n",
        "\n",
        "    if modelType   == 'roberta-only':\n",
        "      pooled_output = roberta_output[1]           #Using pooled output\n",
        "      output        = self.drop(pooled_output)\n",
        "      output        = self.output(output)\n",
        "\n",
        "    elif modelType == 'roberta-tfIdf':\n",
        "      soutput = roberta_output[1]#---------        experimenting with pooled output \n",
        "      #soutput = roberta_output[0][:, 0, :]        #taking <s> token (equivalent to [CLS] token in BERT)\n",
        "      x       = torch.cat((soutput, inputs_tfidf_feats) , dim=1)\n",
        "      x       = self.drop(x)\n",
        "      output  = self.out_proj(x)\n",
        "\n",
        "    elif modelType == 'roberta-pcaTfidf':\n",
        "      soutput = roberta_output[1]\n",
        "      x       = torch.cat((soutput, pca_transformed_feats) , dim=1)\n",
        "      x       = self.drop(x)\n",
        "      output  = self.out_pca(x)\n",
        "\n",
        "    elif modelType == 'roberta-TrainedTfIdf':\n",
        "      tfidf_hidddenLayer, tfidf_output = self.model_TFIDF(inputs_tfidf_feats)\n",
        "      #print(tfidf_hidddenLayer.shape)\n",
        "      #print(tfidf_output.shape)\n",
        "    \n",
        "      #Conactenating pooled output from RoBERTa with the hidden layer from the pre-trained SNN using TF-IDF features. \n",
        "      #pooled_output = torch.cat((roberta_output[1], tfidf_output) , dim=1)-------- Experimenting with Output of pre-trained SNN \n",
        "      pooled_output = torch.cat((roberta_output[1], tfidf_hidddenLayer) , dim=1)\n",
        "      output        = self.drop(pooled_output)\n",
        "      output        = self.out(output)\n",
        "    \n",
        "    return self.softmax(output)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8toH_ISooGBl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "3779da82-2a2a-4029-8f77-f92d7ff6e59c"
      },
      "source": [
        "'''from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "snnmodel = Tfidf_Nn()\n",
        "\n",
        "model_save_name = 'pre-trainedTfidf.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\"\n",
        "\n",
        "snnmodel.load_state_dict(torch.load(path))\n",
        "snnmodel.eval()\n",
        "model = StanceClassifier(len(CLASS_NAMES))\n",
        "\n",
        "#Loading fine-trained RoBERTa model on the same dataset\n",
        "model_save_name = 'RoBERTaLarge_TFIDFV2.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\"\n",
        "model.load_state_dict(torch.load(path))\n",
        "model.eval()\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "# = StanceClassifier(len(CLASS_NAMES))\n",
        "#model = model.to(device)\n",
        "print(model)\n",
        "\n",
        "print(snnmodel)'''\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'from google.colab import drive\\ndrive.mount(\\'/content/gdrive\\')\\nsnnmodel = Tfidf_Nn()\\n\\nmodel_save_name = \\'pre-trainedTfidf.pt\\'\\npath = F\"/content/gdrive/My Drive/{model_save_name}\"\\n\\nsnnmodel.load_state_dict(torch.load(path))\\nsnnmodel.eval()\\nmodel = StanceClassifier(len(CLASS_NAMES))\\n\\n#Loading fine-trained RoBERTa model on the same dataset\\nmodel_save_name = \\'RoBERTaLarge_TFIDFV2.pt\\'\\npath = F\"/content/gdrive/My Drive/{model_save_name}\"\\nmodel.load_state_dict(torch.load(path))\\nmodel.eval()\\nmodel = model.to(device)\\n\\n\\n# = StanceClassifier(len(CLASS_NAMES))\\n#model = model.to(device)\\nprint(model)\\n\\nprint(snnmodel)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmzNcXnMsx-p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "e2b6db6195d144e4a3e848ad1757bfb4",
            "829bf6e8a65d4800bfd7287d6007c113",
            "6a95671548194fbca06ec1414b7bbc04",
            "707a75bbe4b941369233a16c829f8526",
            "cb1df164f46942ba8b2a6a2f910763aa",
            "af726520a9a14ec084faaf659f864310",
            "0a39426b7f594e59a481505bcf9768e0",
            "816082cb81da45f8a42dac691eab6b82",
            "1e940a261bfb4676aa5646d1fad7ebfc",
            "ae4795e9f23d47d382c726ab86965a9a",
            "ce7dc62473734b9ca8086e59513271af",
            "11066f3245804b359edef2938d1f11bc",
            "94f62d80d26a4f6f9c96983b4bae1008",
            "e0dffc10db3d41c4bc5da781f621ce67",
            "03350706a56841eba33d4b935a25ccb4",
            "4a0d78ddc6614653ab8f52ee49d3075f"
          ]
        },
        "outputId": "42ac3655-e689-471b-8f86-4307563f70f7"
      },
      "source": [
        "#Instantiating a StanceClassifier object as our model and loading the model onto the GPU.\n",
        "model = StanceClassifier(len(CLASS_NAMES))\n",
        "model = model.to(device)\n",
        "#print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2b6db6195d144e4a3e848ad1757bfb4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=482.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e940a261bfb4676aa5646d1fad7ebfc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1425941629.0, style=ProgressStyle(descrâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3mQd06Ns0d9"
      },
      "source": [
        "'''Using the same optimiser as used in BERT paper\n",
        "with a different learning rate'''\n",
        "optimizer = AdamW(model.parameters(), \n",
        "                  lr = 2e-6, \n",
        "                  correct_bias= False)\n",
        "\n",
        "totalSteps = len(trainDataLoader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer,\n",
        "            num_warmup_steps=0,\n",
        "            num_training_steps = totalSteps\n",
        ")\n",
        "\n",
        "'''Using class-weights to accomodate heavily imbalanced data. \n",
        "These weights were learnt by running several experiments using \n",
        "other weights and the weights that produced the best results have\n",
        "finally been used here'''\n",
        "\n",
        "weights      = [8.0, 84.0, 8.0, 1.0]\n",
        "classWeights = torch.FloatTensor(weights)\n",
        "lossFunction = nn.CrossEntropyLoss(weight = classWeights).to(device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPJyrgGFs8TV"
      },
      "source": [
        "#This function is used for training the model. \n",
        "def train_epoch(\n",
        "  model,\n",
        "  dataLoader,\n",
        "  lossFunction,\n",
        "  optimizer,\n",
        "  device,\n",
        "  scheduler,\n",
        "  n_examples\n",
        "):\n",
        "\n",
        "  model = model.train()\n",
        "  losses = []\n",
        "  correctPredictions = 0\n",
        "\n",
        "  for d in dataLoader:\n",
        "    \n",
        "    input_ids              = d[\"input_ids\"].to(device)                           #Loading input ids to GPU\n",
        "    attention_mask         = d[\"attention_mask\"].to(device)                      #Loading attention mask to GPU\n",
        "    labelValues            = d[\"labelValue\"].to(device)                          #Loading label value to GPU\n",
        "    textSrcInre            = d[\"TextSrcInre\"]                                    \n",
        "    tfidf_transform        = x_train_feats.transform(textSrcInre)\n",
        "    tfidf_transform_tensor = torch.tensor(scipy.sparse.csr_matrix.todense(tfidf_transform)).float()   \n",
        "    pca_tensor             = p.transform(tfidf_transform_tensor)\n",
        "\n",
        "    pca_tensor = torch.from_numpy(pca_tensor).float()\n",
        "    pca_tensor = pca_tensor.to(device)\n",
        "    tfidf_transform_tensor = tfidf_transform_tensor.to(device)\n",
        "\n",
        "    #Getting the output from our model (Object of StanceClassification class) for train data\n",
        "    outputs = model(\n",
        "      input_ids             = input_ids,\n",
        "      attention_mask        = attention_mask,\n",
        "      inputs_tfidf_feats    = tfidf_transform_tensor,\n",
        "      pca_transformed_feats = pca_tensor,\n",
        "      modelType             = 'roberta-TrainedTfIdf'\n",
        "    )\n",
        "\n",
        "    #Determining the model predictions\n",
        "    _, predictionIndices = torch.max(outputs, dim=1)\n",
        "    loss = lossFunction(outputs, labelValues)\n",
        "\n",
        "    #Calculating the correct predictions for accuracy\n",
        "    correctPredictions += torch.sum(predictionIndices == labelValues)\n",
        "    losses.append(loss.item())\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return np.mean(losses), correctPredictions.double() / n_examples\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7kyxOzNs_33"
      },
      "source": [
        "#This function is used for evaluating the model on the development and test set\n",
        "def eval_model(\n",
        "    model, \n",
        "    dataLoader, \n",
        "    lossFunction,\n",
        "    device,\n",
        "    n_examples\n",
        "    ):\n",
        "  \n",
        "  model = model.eval()\n",
        "  losses = []\n",
        "  correctPredictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in dataLoader:\n",
        "\n",
        "      input_ids              = d[\"input_ids\"].to(device)                          #Loading input ids to GPU\n",
        "      attention_mask         = d[\"attention_mask\"].to(device)                     #Loading attention mask to GPU\n",
        "      labelValues            = d[\"labelValue\"].to(device)                         #Loading label values to GPU\n",
        "      textSrcInre            = d[\"TextSrcInre\"]\n",
        "      tfidf_transform        = x_train_feats.transform(textSrcInre)\n",
        "      tfidf_transform_tensor = torch.tensor(scipy.sparse.csr_matrix.todense(tfidf_transform)).float()    \n",
        "      \n",
        "      pca_tensor             = p.transform(tfidf_transform_tensor)\n",
        "\n",
        "      pca_tensor = torch.from_numpy(pca_tensor).float()\n",
        "      pca_tensor = pca_tensor.to(device)\n",
        "      tfidf_transform_tensor = tfidf_transform_tensor.to(device)\n",
        "\n",
        "      #Getting the softmax output from model for dev data\n",
        "      outputs = model(\n",
        "        input_ids             = input_ids,\n",
        "        attention_mask        = attention_mask,\n",
        "        inputs_tfidf_feats    = tfidf_transform_tensor,\n",
        "        pca_transformed_feats = pca_tensor,\n",
        "        modelType             = 'roberta-TrainedTfIdf'\n",
        "      )\n",
        "\n",
        "      #Determining the model predictions\n",
        "      _, predictionIndices = torch.max(outputs, dim=1)\n",
        "      loss = lossFunction(outputs, labelValues)\n",
        "\n",
        "      #Calculating the correct predictions for accuracy\n",
        "      correctPredictions += torch.sum(predictionIndices == labelValues)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return np.mean(losses), correctPredictions.double() / n_examples\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cm-MoWCftEQ4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "outputId": "a6a8befa-722b-415c-e29c-997e5ead3418"
      },
      "source": [
        "#fine tuning ROBERTa and validating it \n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  print(f'Epoch {epoch + 1}')\n",
        "  trainLoss, trainAccuracy = train_epoch(\n",
        "    model,\n",
        "    trainDataLoader,\n",
        "    lossFunction,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    len(trainDf)\n",
        "  )\n",
        "  \n",
        "  print(f'Training loss {trainLoss} Training accuracy {trainAccuracy}')\n",
        "\n",
        "  devLoss, devAccuracy = eval_model(\n",
        "    model,\n",
        "    developmentDataLoader,\n",
        "    lossFunction,\n",
        "    device,\n",
        "    len(devDf)\n",
        "  )\n",
        "\n",
        "  print(f'Development loss {devLoss} Development accuracy {devAccuracy}')\n",
        "  print()\n",
        "  \n",
        "  print()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "Training loss 1.298501740378895 Training accuracy 0.6289055012459267\n",
            "Development loss 1.2253233229601255 Development accuracy 0.7919191919191919\n",
            "\n",
            "\n",
            "Epoch 2\n",
            "Training loss 1.2555404903788219 Training accuracy 0.7230208932336591\n",
            "Development loss 1.2016303798844736 Development accuracy 0.8020202020202021\n",
            "\n",
            "\n",
            "Epoch 3\n",
            "Training loss 1.2344279885748795 Training accuracy 0.7243626605328732\n",
            "Development loss 1.1308476554770623 Development accuracy 0.818855218855219\n",
            "\n",
            "\n",
            "Epoch 4\n",
            "Training loss 1.190851000716403 Training accuracy 0.7400805060379528\n",
            "Development loss 1.1160803852222299 Development accuracy 0.8316498316498316\n",
            "\n",
            "\n",
            "Epoch 5\n",
            "Training loss 1.1655783090554892 Training accuracy 0.757715161970481\n",
            "Development loss 1.0835556969527276 Development accuracy 0.8154882154882155\n",
            "\n",
            "\n",
            "Epoch 6\n",
            "Training loss 1.1490712403794359 Training accuracy 0.7648073605520413\n",
            "Development loss 1.0594400346920054 Development accuracy 0.8195286195286196\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_wi9oVXtHR9"
      },
      "source": [
        "#This function gets the predictions from the model after it is trained.\n",
        "def get_predictions(model, data_loader):\n",
        "\n",
        "  model = model.eval()\n",
        "  review_texta = []\n",
        "  review_textb = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      textas                 = d[\"firstSeq\"]\n",
        "      textbs                 = d[\"secondSeq\"]\n",
        "      input_ids              = d[\"input_ids\"].to(device)\n",
        "      attention_mask         = d[\"attention_mask\"].to(device)\n",
        "      labels                 = d[\"labelValue\"].to(device)\n",
        "      textSrcInre            = d[\"TextSrcInre\"]\n",
        "      tfidf_transform        = tfidf.transform(textSrcInre)\n",
        "      tfidf_transform_tensor = torch.tensor(scipy.sparse.csr_matrix.todense(tfidf_transform)).float()\n",
        "\n",
        "      pca_tensor             =  p.transform(tfidf_transform_tensor)\n",
        "\n",
        "      pca_tensor = torch.from_numpy(pca_tensor).float()\n",
        "      pca_tensor = pca_tensor.to(device)\n",
        "      tfidf_transform_tensor = tfidf_transform_tensor.to(device)\n",
        "\n",
        "      #Getting the softmax output from model\n",
        "      outputs = model(\n",
        "        input_ids             = input_ids,\n",
        "        attention_mask        = attention_mask,\n",
        "        inputs_tfidf_feats    = tfidf_transform_tensor,\n",
        "        pca_transformed_feats = pca_tensor,\n",
        "        modelType             = 'roberta-TrainedTfIdf'\n",
        "      )\n",
        "\n",
        "      _, preds = torch.max(outputs, dim=1)     #Determining the model predictions\n",
        "\n",
        "      review_texta.extend(textas)\n",
        "      review_textb.extend(textbs)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(outputs)\n",
        "      real_values.extend(labels)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  \n",
        "  return review_texta, review_textb, predictions, prediction_probs, real_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hG_JcQt20reh"
      },
      "source": [
        "#Getting model predictions on dev dataset\n",
        "firstSeq_dev, secondSeq_dev, yHat_dev, predProbs_dev, yTest_dev = get_predictions(\n",
        "  model,\n",
        "  developmentDataLoader\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh219SUW0-Eh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "7d0876ba-44a7-4922-917b-fec848ea6de2"
      },
      "source": [
        "  #Printing classification report for dev dataset (Evaluating the model on Dev set)\n",
        "print(classification_report(yTest_dev, yHat_dev, target_names= CLASS_NAMES))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     support       0.48      0.31      0.38       102\n",
            "        deny       0.38      0.33      0.35        82\n",
            "       query       0.62      0.70      0.66       120\n",
            "     comment       0.89      0.91      0.90      1181\n",
            "\n",
            "    accuracy                           0.82      1485\n",
            "   macro avg       0.59      0.56      0.57      1485\n",
            "weighted avg       0.81      0.82      0.81      1485\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmraXgpo1TAg"
      },
      "source": [
        "#Saving the model onto the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "model_save_name = 'RoBERTaLarge_TFIDFV2.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmv7XMPZtIN3"
      },
      "source": [
        "#Getting model predictions on test dataset\n",
        "firstSeq_test, secondSeq_test, yHat_test, predProbs_test, yTest_test = get_predictions(\n",
        "  model,\n",
        "  testDataLoader\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRwqVzOk0y7x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "2e198a7c-90aa-4014-95a0-1f0b8f531130"
      },
      "source": [
        "#Printing classification report for test dataset (Evaluating the model on test set)\n",
        "print(classification_report(yTest_test, yHat_test, target_names= CLASS_NAMES))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     support       0.81      0.31      0.44       157\n",
            "        deny       0.68      0.53      0.60       101\n",
            "       query       0.60      0.57      0.58        93\n",
            "     comment       0.89      0.97      0.93      1476\n",
            "\n",
            "    accuracy                           0.87      1827\n",
            "   macro avg       0.74      0.59      0.64      1827\n",
            "weighted avg       0.86      0.87      0.85      1827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wYTempX1Gcj"
      },
      "source": [
        "#Saving the predictions onto a CSV file for error analysis\n",
        "zippedList =  list(zip(firstSeq_test, secondSeq_test, yHat_test, predProbs_test, yTest_test ))\n",
        "dfObj = pd.DataFrame(zippedList, columns = ['Texta' , 'Textb', 'Ypred', 'YpredsProbs', 'label'])\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('drive')\n",
        "\n",
        "dfObj.to_csv('dataPredsFromRoberta_TFIDFV2.csv')\n",
        "!cp dataPredsFromRoberta_TFIDFV2.csv \"drive/My Drive/\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}