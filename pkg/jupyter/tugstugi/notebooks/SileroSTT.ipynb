{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SileroSTT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNpFf5X1-R4b",
        "colab_type": "text"
      },
      "source": [
        "# Speech Recognition with Silero\n",
        "\n",
        "This notebook uses Silero from the project [snakers4/silero-models](https://github.com/snakers4/silero-models/) to transcribe English and German audio using microphone.\n",
        "\n",
        "For other deep-learning Colab notebooks, visit [tugstugi/dl-colab-notebooks](https://github.com/tugstugi/dl-colab-notebooks)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "antcD_Q3_d3X",
        "colab_type": "text"
      },
      "source": [
        "## Install snakers4/silero-models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnWntVYj6E63",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from os.path import exists, join, basename, splitext\n",
        "\n",
        "# checkout the project\n",
        "if not exists('silero-models'):\n",
        "  !git clone -q --depth 1 https://github.com/snakers4/silero-models\n",
        "\n",
        "  !pip install -q omegaconf torchaudio soundfile\n",
        "  !pip install -q https://github.com/tugstugi/dl-colab-notebooks/archive/colab_utils.zip\n",
        "%cd silero-models\n",
        "\n",
        "# silero imports\n",
        "import torch\n",
        "import random\n",
        "from glob import glob\n",
        "from omegaconf import OmegaConf\n",
        "from utils import (init_jit_model, \n",
        "                   split_into_batches,\n",
        "                   read_batch,\n",
        "                   prepare_model_input)\n",
        "\n",
        "device = torch.device('cpu')   # you can use any pytorch device\n",
        "models = OmegaConf.load('models.yml')\n",
        "\n",
        "# imports for uploading/recording\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import Audio, display, clear_output\n",
        "from dl_colab_notebooks.audio import record_audio, upload_audio\n",
        "import numpy as np\n",
        "from scipy.io import wavfile\n",
        "\n",
        "# wav to text method\n",
        "def wav_to_text(f='test.wav'):\n",
        "  batch = read_batch([f])\n",
        "  input = prepare_model_input(batch, device=device)\n",
        "  output = model(input)\n",
        "  return decoder(output[0].cpu())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZBYsyh9BGzm",
        "colab_type": "text"
      },
      "source": [
        "## Select Language"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svklf0Yc_80f",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@markdown { run: \"auto\" }\n",
        "\n",
        "language = \"English\" #@param [\"English\", \"German\", \"Spanish\"]\n",
        "print(language)\n",
        "if language == 'German':\n",
        "  model, decoder = init_jit_model(models.stt_models.de.latest.jit, device=device)\n",
        "elif language == \"Spanish\":\n",
        "  model, decoder = init_jit_model(models.stt_models.es.latest.jit, device=device)\n",
        "else:\n",
        "  model, decoder = init_jit_model(models.stt_models.en.latest.jit, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05aVmrwIBUMG",
        "colab_type": "text"
      },
      "source": [
        "## Transcribe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuZz9-Nv21SJ",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@markdown * Either record audio from microphone or upload audio from file (.mp3 or .wav) { run: \"auto\" }\n",
        "\n",
        "SAMPLE_RATE = 16000\n",
        "record_or_upload = \"Record\" #@param [\"Record\", \"Upload (.mp3 or .wav)\"]\n",
        "record_seconds =   10#@param {type:\"number\", min:1, max:10, step:1}\n",
        "\n",
        "def _recognize(audio):\n",
        "  display(Audio(audio, rate=SAMPLE_RATE, autoplay=True))\n",
        "  wavfile.write('test.wav', SAMPLE_RATE, (32767*audio).astype(np.int16))\n",
        "\n",
        "  transcription = wav_to_text()\n",
        "  print('\\n\\nTRANSCRIPTION:\\n')\n",
        "  print(transcription)\n",
        "\n",
        "\n",
        "def _record_audio(b):\n",
        "  clear_output()\n",
        "  audio = record_audio(record_seconds, sample_rate=SAMPLE_RATE)\n",
        "  _recognize(audio)\n",
        "def _upload_audio(b):\n",
        "  clear_output()\n",
        "  audio = upload_audio(sample_rate=SAMPLE_RATE)\n",
        "  _recognize(audio)\n",
        "\n",
        "if record_or_upload == \"Record\":\n",
        "  button = widgets.Button(description=\"Record Speech\")\n",
        "  button.on_click(_record_audio)\n",
        "  display(button)\n",
        "else:\n",
        "  _upload_audio(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}