{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepSORT_YOLOv3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbMjmfT5bZb6",
        "colab_type": "text"
      },
      "source": [
        "# Pedestrian Tracking with YOLOv3 and DeepSORT\n",
        "\n",
        "This is a pedestrian tracking demo using the open source project [ZQPei/deep_sort_pytorch](https://github.com/ZQPei/deep_sort_pytorch) which combines [DeepSORT](https://github.com/nwojke/deep_sort) with [YOLOv3](https://pjreddie.com/darknet/yolo/).\n",
        "\n",
        "For other deep-learning Colab notebooks, visit [tugstugi/dl-colab-notebooks](https://github.com/tugstugi/dl-colab-notebooks).\n",
        "\n",
        "## Install ZQPei/deep_sort_pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-swJb8AnUwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from os.path import exists, join, basename\n",
        "\n",
        "project_name = \"deep_sort_pytorch\"\n",
        "if not exists(project_name):\n",
        "  # clone and install\n",
        "  !git clone -q --recursive https://github.com/ZQPei/deep_sort_pytorch.git\n",
        "  \n",
        "import sys\n",
        "sys.path.append(project_name)\n",
        "\n",
        "import IPython\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uPYXRG3RQ8e",
        "colab_type": "text"
      },
      "source": [
        "## Download pretrained weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h15jd8tyoANM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yolo_pretrained_weight_dir = join(project_name, 'detector/YOLOv3/weight/')\n",
        "if not exists(join(yolo_pretrained_weight_dir, 'yolov3.weights')):\n",
        "  !cd {yolo_pretrained_weight_dir} && wget -q https://pjreddie.com/media/files/yolov3.weights\n",
        "    \n",
        "deepsort_pretrained_weight_dir = join(project_name, 'deep_sort/deep/checkpoint')\n",
        "if not exists(join(deepsort_pretrained_weight_dir, 'ckpt.t7')):\n",
        "  file_id = '1_qwTWdzT9dWNudpusgKavj_4elGgbkUN'\n",
        "  !cd {deepsort_pretrained_weight_dir} && curl -Lb ./cookie \"https://drive.google.com/uc?export=download&id={file_id}\" -o ckpt.t7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-OHRN2qSMnN",
        "colab_type": "text"
      },
      "source": [
        "## Track pedestrians\n",
        "\n",
        "First, download a test video from internet and show in the notebook:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHS89UbJoNfH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VIDEO_URL = 'http://www.robots.ox.ac.uk/ActiveVision/Research/Projects/2009bbenfold_headpose/Datasets/TownCentreXVID.avi'\n",
        "DURATION_S = 20  # process only the first 20 seconds\n",
        "\n",
        "\n",
        "\n",
        "video_file_name = 'video.mp4'\n",
        "if not exists(video_file_name):\n",
        "  !wget -q $VIDEO_URL\n",
        "  dowloaded_file_name = basename(VIDEO_URL)\n",
        "  # convert to MP4, because we can show only MP4 videos in the colab noteook\n",
        "  !ffmpeg -y -loglevel info -t $DURATION_S -i $dowloaded_file_name $video_file_name\n",
        "  \n",
        "\n",
        "def show_local_mp4_video(file_name, width=640, height=480):\n",
        "  import io\n",
        "  import base64\n",
        "  from IPython.display import HTML\n",
        "  video_encoded = base64.b64encode(io.open(file_name, 'rb').read())\n",
        "  return HTML(data='''<video width=\"{0}\" height=\"{1}\" alt=\"test\" controls>\n",
        "                        <source src=\"data:video/mp4;base64,{2}\" type=\"video/mp4\" />\n",
        "                      </video>'''.format(width, height, video_encoded.decode('ascii')))\n",
        " \n",
        "clear_output()\n",
        "show_local_mp4_video('video.mp4')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUmYyIrqSl1D",
        "colab_type": "text"
      },
      "source": [
        "Now, track the pedestrians on the downloaded video:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-j5tW6-PxSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd {project_name} && python yolov3_deepsort.py --ignore_display ../video.mp4 --save_path ../output.avi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Il1RKuhOSxCG",
        "colab_type": "text"
      },
      "source": [
        "Finally, we can visualize the result:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bG2UQsD7aAgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# first convert to mp4 to show in a Colab notebook\n",
        "!ffmpeg -y -loglevel panic -i output.avi output.mp4\n",
        "show_local_mp4_video('output.mp4', width=960, height=720)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}