{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "nsynth.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRmlJYze_29V"
      },
      "source": [
        "Copyright 2017 Google LLC.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Axg7pBLtt3V"
      },
      "source": [
        "# E-Z NSynth\n",
        "\n",
        "__Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders, ICML 2017__\n",
        "\n",
        "Jesse Engel, Cinjon Resnick, Adam Roberts, Sander Dieleman, Douglas Eck, Karen Simonyan, Mohammad Norouzi\n",
        "\n",
        "## Instructions\n",
        "* This colab notebook has everything you need to upload your own sounds and use NSynth models to reconstruct and interpolate between them.\n",
        "* You can use these sounds as samples in your own music a la [Andrew Huang Rocking Out with NSynth](https://www.youtube.com/watch?v=AaALLWQmCdI).\n",
        "* Make sure to use a kernel with a GPU attached by selecting: **Edit >> Notebook Settings >> Hardware Accelerator >> GPU** from the dropdown menu.\n",
        "* You can run this notebook without writing / seeing a line of code. Just click the triangular **\"Play\"** button on the left of each cell.\n",
        "* Start at the top and work your way to the bottom, clicking **\"Play\"** for each cell.\n",
        "* If you want to see the code, you can reveal with the menu on the upper right hand side of each cell.\n",
        "\n",
        "\n",
        "### Other Resources:\n",
        "* [Nat and Friends \"Behind the scenes\"](https://www.youtube.com/watch?v=BOoSy-Pg8is)\n",
        "* [Original Blog Post](https://magenta.tensorflow.org/nsynth)\n",
        "* [NSynth Instrument](https://magenta.tensorflow.org/nsynth-instrument)\n",
        "* [Jupyter Notebook Tutorial](https://magenta.tensorflow.org/nsynth-fastgen)\n",
        "* [ArXiv Paper](https://arxiv.org/abs/1704.01279)\n",
        "* [Github Code](https://github.com/tensorflow/magenta/tree/master/magenta/models/nsynth)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-2av9upRi0z"
      },
      "source": [
        "# Setup Environment\n",
        "\n",
        "We need to start downloading and choosing a pretrained NSynth model to use. Transfers several GBs, may take a minute or two. Just click Play..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "ZA7tNz2zAWvn"
      },
      "source": [
        "#@title Setup Environment\n",
        "#@test {\"output\": \"ignore\"}\n",
        "\n",
        "\n",
        "# Install magenta\n",
        "print('Installing Magenta...\\n')\n",
        "!pip install -qU magenta\n",
        "print('Installing ffmpeg...\\n')\n",
        "!echo \"Yes\" | apt-get install ffmpeg > /dev/null\n",
        "\n",
        "\n",
        "print('Downloading Pretrained Models...\\n')\n",
        "# Copy checkpoints from google cloud\n",
        "# Copying 1GB, takes a minute\n",
        "print('Getting Instruments Model...\\n')\n",
        "!gsutil -q -m cp -R gs://download.magenta.tensorflow.org/models/nsynth/wavenet-ckpt.tar /content/\n",
        "print('Getting Voices Model...\\n')\n",
        "!gsutil -q -m cp -R gs://download.magenta.tensorflow.org/models/nsynth/wavenet-voice-ckpt.tar.gz /content/\n",
        "!cd /content/\n",
        "!tar -xvf wavenet-ckpt.tar > /dev/null\n",
        "!tar -xvf wavenet-voice-ckpt.tar.gz > /dev/null\n",
        "\n",
        "\n",
        "print('Importing Modules...\\n')\n",
        "# Load modules and helper functions\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio\n",
        "%matplotlib inline\n",
        "\n",
        "from google.colab import files\n",
        "from magenta.models.nsynth import utils\n",
        "from magenta.models.nsynth.wavenet import fastgen\n",
        "from note_seq.notebook_utils import colab_play as play\n",
        "\n",
        "def upload(sample_length, sr):\n",
        "  '''Upload a .wav file.'''\n",
        "  filemap = files.upload()\n",
        "  file_list, audio_list = [], []\n",
        "  for key, value in filemap.items():\n",
        "    fname = os.path.join('/content/', key)\n",
        "    with open(fname, 'wb') as f:\n",
        "      f.write(value)\n",
        "    audio = utils.load_audio(fname, sample_length=sample_length, sr=sr)\n",
        "    file_list.append(fname)\n",
        "    audio_list.append(audio)\n",
        "  return file_list, audio_list\n",
        "\n",
        "download = files.download\n",
        "\n",
        "get_name = lambda f: os.path.splitext(os.path.basename(f))[0]\n",
        "\n",
        "print('Sucess!! Environment is now setup.')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyAT8mQhX1Gq"
      },
      "source": [
        "We have two pretrained models to choose from. One trained on the individual instrument notes of the [NSynth Dataset](https://magenta.tensorflow.org/datasets/nsynth) (\"Instruments\"), and another trained on a variety of voices in the wild for an art project (\"Voices\", mixture of singing and speaking). The Instruments model was trained on a larger quantity of data, so tends to generalize a bit better. Neither reconstructs audio perfectly, but both add their own unique character to sounds. Explore them both and see what you like!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "gSXXL26bLDCy"
      },
      "source": [
        "#@title Choose a Model { vertical-output: true, run: \"auto\" }\n",
        "Model = \"Instruments\" #@param [\"Instruments\", \"Voices\"] {type:\"string\"}\n",
        "ckpts = {'Instruments': '/content/wavenet-ckpt/model.ckpt-200000',\n",
        "         'Voices': '/content/wavenet-voice-ckpt/model.ckpt-200000'}\n",
        "\n",
        "ckpt_path = ckpts[Model]\n",
        "print('Using model pretrained on %s.' % Model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTAkswTOcgAp"
      },
      "source": [
        "# Load Sound Files\n",
        "\n",
        "Now it's time for you to load your own sound files for processing. You can use either `.wav` files or `.mp3` files, but in either case they will be converted to `.wav`. All files will be downsampled to 16kHz and cropped / silence padded to `Length` seconds as the input and output to the algorithm.\n",
        "\n",
        "Don't have sounds? You can downloaded free sounds from freesound.org For example:\n",
        "* https://freesound.org/people/MustardPlug/sounds/395058/\n",
        "* https://freesound.org/people/cms4f/sounds/159119/\n",
        "* https://freesound.org/people/juskiddink/sounds/60055/\n",
        "* https://freesound.org/people/Audeption/sounds/418526/\n",
        "* https://freesound.org/people/Jagadamba/sounds/255878/\n",
        "\n",
        "\n",
        "Keep in mind, with the cloud GPU synthesis takes around 4 minutes / 1 second of length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "CnSCiX0kA2-5"
      },
      "source": [
        "#@title Set Sound Length (in Seconds) { vertical-output: true, run: \"auto\" }\n",
        "Length = 2.0 #@param {type:\"number\"}\n",
        "SR = 16000\n",
        "SAMPLE_LENGTH = int(SR * Length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9IufW4mtPAU"
      },
      "source": [
        "Put all your sound files into a single folder and maker sure to select all the files you want to reconstruct / interpolate between. **(Ctrl/Cmd/Shift Click)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "mPwQYyYgBkdp"
      },
      "source": [
        "#@title Upload sound files (.wav, .mp3)\n",
        "\n",
        "try:\n",
        "  file_list, audio_list = upload(sample_length=SAMPLE_LENGTH, sr=SR)\n",
        "  names = [get_name(f) for f in file_list]\n",
        "  # Pad and peak normalize\n",
        "  for i in range(len(audio_list)):\n",
        "    audio_list[i] = audio_list[i] / np.abs(audio_list[i]).max()\n",
        "\n",
        "    if len(audio_list[i]) < SAMPLE_LENGTH:\n",
        "      padding = SAMPLE_LENGTH - len(audio_list[i])\n",
        "      audio_list[i] = np.pad(audio_list[i], (0, padding), 'constant')\n",
        "\n",
        "  audio_list = np.array(audio_list)\n",
        "except Exception as e:\n",
        "  print('Upload Cancelled')\n",
        "  print(e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQKDlAdW_qKn"
      },
      "source": [
        "# Encode\n",
        "\n",
        "Next we need to encode the audio. This should be relatively fast on a GPU, we will also create interpolations (the midpoints between each encoding) from which to re-synthesize audio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "SSr-7vuH_29l"
      },
      "source": [
        "#@title Generate Encodings\n",
        "audio = np.array(audio_list)\n",
        "z = fastgen.encode(audio, ckpt_path, SAMPLE_LENGTH)\n",
        "print('Encoded %d files' % z.shape[0])\n",
        "\n",
        "\n",
        "# Start with reconstructions\n",
        "z_list = [z_ for z_ in z]\n",
        "name_list = ['recon_' + name_ for name_ in names]\n",
        "\n",
        "# Add all the mean interpolations\n",
        "n = len(names)\n",
        "for i in range(n - 1):\n",
        "  for j in range(i + 1, n):\n",
        "    new_z = (z[i] + z[j]) / 2.0\n",
        "    new_name = 'interp_' + names[i] + '_X_'+ names[j]\n",
        "    z_list.append(new_z)\n",
        "    name_list.append(new_name)\n",
        "\n",
        "print(\"%d total: %d reconstructions and %d interpolations\" % (len(name_list), n, len(name_list) - n))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKR6CGUe_290"
      },
      "source": [
        "For fun, we can take a look at the encoding of our audio files. They are compressed representations of the audio but have some structure in their own right, (16 numbers, kind of like 16 channels of audio, so there are 16 different lines, colors are arbitrary). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "7Cawft23_290"
      },
      "source": [
        "#@title Visualize Audio and Encoding { vertical-output: true, run: \"auto\" }\n",
        "SoundFile = 0 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "file_number = SoundFile\n",
        "\n",
        "try:\n",
        "  print(names[file_number])\n",
        "  play(audio_list[file_number], sample_rate=SR)\n",
        "  # fig, axs = plt.subplots(2, 1, figsize=(12, 10))\n",
        "  plt.figure()\n",
        "  plt.plot(audio_list[file_number])\n",
        "  plt.title('Audio Signal')\n",
        "\n",
        "  plt.figure()\n",
        "  plt.plot(z_list[file_number])\n",
        "  plt.title('NSynth Encoding')\n",
        "except Exception as e:\n",
        "  print(e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGQfWut8U8QS"
      },
      "source": [
        "# Synthesize\n",
        "\n",
        "On the GPU, this should take about 4 minutes per 1 second of audio per a batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "3Eh71eovH4NZ"
      },
      "source": [
        "#@title Synthesize Interpolations\n",
        "print('Total Iterations to Complete: %d\\n' % SAMPLE_LENGTH)\n",
        "\n",
        "encodings = np.array(z_list)\n",
        "save_paths = ['/content/' + name + '.wav' for name in name_list]\n",
        "fastgen.synthesize(encodings,\n",
        "                   save_paths=save_paths,\n",
        "                   checkpoint_path=ckpt_path,\n",
        "                   samples_per_save=int(SAMPLE_LENGTH / 10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Cm4Yz4VvPyRX"
      },
      "source": [
        "#@title Download Interpolations\n",
        "for fname in save_paths:\n",
        "  print('Downloading: %s' % fname.split('/')[-1])\n",
        "  download(fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "ToDMo5PbC78w"
      },
      "source": [
        "#@title Listen to the outputs\n",
        "\n",
        "print(\"Originals:\\n\")\n",
        "for fname in file_list:\n",
        "  synth_audio = utils.load_audio(fname,\n",
        "                                 sample_length=SAMPLE_LENGTH,\n",
        "                                 sr=SR)\n",
        "  print(get_name(fname))\n",
        "  play(synth_audio, sample_rate=SR)\n",
        "\n",
        "for i, fname in enumerate(save_paths):\n",
        "  if i == 0:\n",
        "    print(\"Reconstructions:\\n\")\n",
        "  if i == len(file_list):\n",
        "    print(\"Interpolations:\\n\")\n",
        "  synth_audio = utils.load_audio(fname,\n",
        "                                 sample_length=SAMPLE_LENGTH,\n",
        "                                 sr=SR)\n",
        "  print(get_name(fname))\n",
        "  play(synth_audio, sample_rate=SR)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}