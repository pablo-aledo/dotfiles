{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Lucid Sonic Dreams - Tutorial Notebook",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSBBXrcy1ssE"
      },
      "source": [
        "# A. Set-Up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kBYttBTtlho"
      },
      "source": [
        "## A.1. Set-up GPU\n",
        "\n",
        "Navigate to **Runtime -> Change runtime type** and make sure **Hardware accelerator** is set to GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1OB-5oZxV0y"
      },
      "source": [
        "## A.2. Download Sample Audio Preview Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ldjd9LiHxZNG"
      },
      "source": [
        "## CHEMICAL LOVE - BASICALLY SATURDAY NIGHT ## \n",
        "\n",
        "! gdown --id 1aTWrzCvJyYcQ82PS6av3YJrtsON2_CUK\n",
        "\n",
        "## PANCAKE FEET - TENNYSSON ## \n",
        "\n",
        "! gdown --id 14MqCkuREr1TmuWaxZd8bnuhVlL_vCE9s\n",
        "\n",
        "## RASPBERRY - SAJE ## \n",
        "\n",
        "! gdown --id 1GqRi4VFEbw46e9RRvuGPtNc7TuOKFbjl\n",
        "\n",
        "## LUCID SONIC DREAMS DEMO TRACK ##\n",
        "\n",
        "# Main File\n",
        "! gdown --id 1Vc2yC2F5iO0ScC5F0CzF_YB1YPGI2uUP\n",
        "\n",
        "# Pulse File \n",
        "! gdown --id 1FY5MO6XqVu9abbdNQQY6C99RHxFGm36o\n",
        "\n",
        "# Class File\n",
        "! gdown --id 1-qwcs8_Va58YqkHMdXDm9uef-RcH01gh\n",
        "\n",
        "## SEA OF VOICES - PORTER ROBINSON ##\n",
        "\n",
        "# Instrumental (Main Audio)\n",
        "! gdown --id 13-kS5-3Tw2x9kEVfE3ZMkUN955nw73mN\n",
        "\n",
        "# Original (Output Audio)\n",
        "! gdown --id 1r0Mo-vtUIf2njqJ0h3hPJuQELcJ8K2Gu\n",
        "\n",
        "## UNFAITH - EKALI ## \n",
        "! gdown --id 1rgwrhtnVwK2Dom9pJ7p2CBF0j7F2vdkM\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PByrKtjcuMP8"
      },
      "source": [
        "## A.3. Install Lucid Sonic Dreams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50buTzTKOf6x"
      },
      "source": [
        "! pip install lucidsonicdreams"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63dO9FBu1Mv0"
      },
      "source": [
        "# B. Generate Sample Videos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AgAsUB54ej8"
      },
      "source": [
        "## B.1. Choosing a Style\n",
        "\n",
        "Styles can be selected using the **style** parameter, which takes in any of the following:\n",
        "\n",
        "*   A valid default style name provided by the package. Run **show_styles()** to print valid values. *Note: These styles are loaded from [this repository](https://github.com/justinpinkney/awesome-pretrained-stylegan2) by Justin Pinkney.*\n",
        "\n",
        "*   A path to a .pkl file that contains pre-trained StyleGAN weights\n",
        "\n",
        "*   A custom function that takes noise_batch and class_batch parameters and outputs a list of Pillow Images (see example in **B.5**)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak17n4mm81Hm"
      },
      "source": [
        "from lucidsonicdreams import show_styles \n",
        "\n",
        "# Show valid default style names. \n",
        "show_styles()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNnHbJgB2EWk"
      },
      "source": [
        "## B.2. Using Default Settings\n",
        "\n",
        "This package is set-up so that the only arguments required are the **file path to your audio track** and the **file name of the video output**. This code snippet outputs a 45-second, low-resolution preview of a video using the \"modern art\" style, and all the other default settings.\n",
        "\n",
        "The song used here is **Chemical Love by Basically Saturday Night**. You can watch the official music video [here](https://youtu.be/Gi7oQrtyjKI), or listen to them on [Spotify](https://open.spotify.com/artist/46tGdhXAQbTvxVOGgy0Fqu?si=E8mUjbWbR2uiiMR2MUc_4w)!\n",
        "\n",
        "Click [here](https://youtu.be/oGXfOmqFYTg) to view a full-length sample video without having to run the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7DkKcO9cfM_"
      },
      "source": [
        "from lucidsonicdreams import LucidSonicDream\n",
        "from google.colab import files\n",
        "\n",
        "L = LucidSonicDream(song = 'chemical_love.wav',\n",
        "                    style = 'abstract photos')\n",
        "\n",
        "L.hallucinate(file_name = 'chemical_love.mp4',\n",
        "              resolution = 360,\n",
        "              start = 30, \n",
        "              duration = 45)\n",
        "\n",
        "files.download(\"chemical_love.mp4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCo0pQkHANuA"
      },
      "source": [
        "## B.3. Tuning Parameters - How It Works"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuLiMg9CUXvG"
      },
      "source": [
        "There are **over 30 parameters** you can tune, offering tons of flexibility as to how you want your music to be visualized. This may seem like an overwhelming number, but things are easier to digest once you have a basic understanding of how the visualizer works.\n",
        "\n",
        "### So, how does it work? \n",
        "\n",
        "1. First, a batch of input vectors corresponding to output images is initialized. Linear interpolations between these vectors are produced, serving as the \"base\" vectors.\n",
        "2. Three components react to the audio: **Pulse**, **Motion**, and **Class**. These modify the \"base\" vectors accordingly.\n",
        "\n",
        "  *   **Pulse**, quite literally, refers to how the visuals \"pulse\" to the beat of the music. It is set to react to the audio's percussive elements by default. \n",
        "  *   **Motion** refers to how the visuals are \"pushed forward\" or \"sped up\" by the music, and is set to react to the audio's harmonic elements by default. \n",
        "  *   Finally, **Class** refers to the labels of objects shown in the generated images (e.g. in the case of the WikiArt style, classes can refer to Van Gogh, Andy Warhol, Da Vinci, etc). This is set to react to the audio's pitch, where each note controls the prominence of a class. *Note:* Among the default styles available, only WikiArt uses classes thus far.\n",
        "3. Finally, additional effects - such as contrast and flash - are added to the video. These are set to react to the audio's percussive elements by default.\n",
        "\n",
        "### The Parameters\n",
        "\n",
        "Now, the parameters can be easily understood by separating them into 7 categories: Initialization, Pulse, Motion, Class, Effects, Video, and Other. \n",
        "\n",
        "If this is still overwhelming, it's recommended that you start off by tuning **speed_fpm**, **pulse_react**, **motion_react** and **class_pitch_react**, and build from there. These parameters make the biggest difference.\n",
        "\n",
        "##### **Initialization**\n",
        "\n",
        "* **speed_fpm** (*Default: 12*) - FPM stands for \"Frames per Minute\". This determines how many images are initialized - the more there are, the faster the visuals morph. If **speed_fpm = 0**, then only one image is initialized, and that single image reacts to the audio. In this case, there will be no motion during silent parts of the audio.\n",
        "\n",
        "##### **Pulse Parameters**\n",
        "\n",
        "*   **pulse_react** (*Default: 0.5*) - The \"strength\" of the pulse. It is recommended to keep this between 0 and 2.\n",
        "*   **pulse_percussive** (*Default: True*) - If True while *pulse_harmonic* is False, pulse reacts to the audio's percussive elements.\n",
        "*   **pulse_harmonic** (*Default: False*) - If True while *pulse_percussive* is False, pulse reacts to the audio's harmonic elements.\n",
        "\n",
        "  *Note*: If both parameters are True or both parameters are False, pulse reacts to the \"entire\" unaltered audio.\n",
        "*   **pulse_audio** - Path to a separate audio file to be used to control pulse. This is recommended if you have access to an isolated drum/percussion track. If passed, *pulse_percussive* and *pulse_harmonic* are ignored. *Note:* this parameter is passed when defining the LucidSonicDream object.\n",
        "\n",
        "##### **Motion Parameters**\n",
        "\n",
        "*   **motion_react** (*0.5*), **motion_percussive** (*False*), **motion_harmonic** (*True*), and **motion_audio** - Simply the \"motion\" equivalents of the pulse parameters above. \n",
        "*   **motion_randomness** (*Default: 0.5*)- Degree of randomness of motion. Higher values will typically prevent the video from cycling through the same visuals repeatedly. Must range from 0 to 1.\n",
        "*   **truncation** (*Default: 1*) - Controls the variety of visuals generated. Lower values lead to lower variety. *Note*: A very low value will usually lead to \"jittery\" visuals. Must range from 0 to 1.\n",
        "\n",
        "##### **Class Parameters** \n",
        "\n",
        "*(Note: Most of these parameters were heavily inspired by the [Deep Music Visualizer](https://github.com/msieg/deep-music-visualizer) project by Matt Siegelman)*\n",
        "\n",
        "*   **classes** - List of at most 12 numerical object labels. If none, 12 labels are selected at random. \n",
        "*   **dominant_classes_first** (*Default: False*)- If True, the list passed to \"classes\" is sorted by prominence in descending order.\n",
        "*   **class_pitch_react** (*Default: 0.5*)- Class equivalent of pulse_react and motion_react. It is recommended to keep this between 0 and 2.\n",
        "*   **class_smooth_seconds** (*Default: 1*) - Number of seconds spent smoothly interpolating between each class vector. The higher the value, the less \"sudden\" the change of class.\n",
        "*   **class_complexity** (*Default: 1*) - Controls the \"complexity\" of images generated. Lower values tend to generate more simple and mundane images, while higher values tend to generate more intricate and bizzare objects. It is recommended to keep this between 0 and 1.\n",
        "*   **class_shuffle_seconds** (*Default: None*) - Controls the timestamps wherein the mapping of label to note is re-shuffled. This is recommended when the audio used has a limited range of pitches, but you wish for more classes to be shown. If the value passed is a number *n*, classes are shuffled every *n* seconds. If the value passed is a list of numbers, these numbers are used as timestamps (in seconds) wherein classes are shuffled.\n",
        "*   **class_shuffle_strength** (*Default: 0.5*) - Controls how drastically classes are re-shuffled. Only applies when class_shuffle_seconds is passed. It is recommended to keep this between 0 and 1.\n",
        "*   **class_audio** - Class equivalent of pulse_audio and motion_audio. Passed when defining the LucidSonicDream object. \n",
        "\n",
        "##### **Effects Parameters**\n",
        "\n",
        "*   **contrast_strength** (*Default: 0.5*) - Strength of default contrast effect. It is recommended to keep this between 0 and 1.\n",
        "*   **contrast_percussive** (*Default: True*) - If true, contrast reacts to the audio's percussive elements. Must range from 0 to 1.\n",
        "*   **contrast_audio** - Equivalent of previous \"audio\" arguments. Passed when defining the LucidSonicDream object.  \n",
        "\n",
        "  *Note*: If none of these arguments are passed, the contrast effect will not be applied. \n",
        "\n",
        "*   **flash_strength** (*0.5*), **flash_percussive** (*True*), and **flash_audio** - Equivalent of the previous three parameters, but for the a \"flash\" effect. It is recommended to keep these between 0 and 1. If none of these arguments are passed, the flash effect will not be applied. \n",
        "*   **custom_effects** - List of custom, user-defined effects to apply (See **B.4**)\n",
        "\n",
        "##### **Video Parameters**\n",
        "\n",
        "*   **resolution** - Self-explanatory. Low resolutions are recommended for \"trial\" renders. If none is passed, unaltered high-resolution images will be used.\n",
        "*   **start** (*Default: 0*) - Starting timestamp in seconds.\n",
        "*   **duration** - Video duration in seconds. If none is passed, full duration of audio will be used.\n",
        "*   **output_audio** - Final output audio of the video. Overwrites audio from \"song\" parameter if provided (See **B.5**)\n",
        "*   **fps** (*Default: 43*) - Video Frames Per Second. \n",
        "*   **save_frames** (*Default: False*) - If true, saved all individual video frames on disk.\n",
        "\n",
        "##### **Other**\n",
        "\n",
        "*   **batch_size** (*Default: 1*) - Determines how many vectors are simoultaneously fed to the model. Typically, larger batch sizes will output less clearly-defined images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ARd-chd2dCm"
      },
      "source": [
        "#### Example 1 \n",
        "\n",
        "This is a simple example whose appeal lies mostly in how it utilizes Motion.\n",
        "\n",
        "The song used here is **Pancake Feet by Tennysson**. As usual, you can watch the official music video [here](https://youtu.be/_ODm4UZGh7g), or listen to them on [Spotify](https://open.spotify.com/artist/3Nb8N20WChM0swo5qWTvm8?si=oUZ2uV7eQH2ieMucvL_vgA)!\n",
        "\n",
        "Click [here](https://youtu.be/ztWCMm9cExY) to view a full-length sample video without having to run the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTd6MslThkxX"
      },
      "source": [
        "L = LucidSonicDream('pancake_feet.mp3',\n",
        "                    style = 'modern art')\n",
        "\n",
        "L.hallucinate('pancake_feet.mp4',\n",
        "              resolution = 360,\n",
        "              duration = 45,\n",
        "              speed_fpm = 0,\n",
        "              motion_percussive = True,\n",
        "              motion_react = 0.8,\n",
        "              contrast_strength = 0.5,\n",
        "              flash_strength = 0.7)\n",
        "\n",
        "files.download(\"pancake_feet.mp4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAy9aNsg_JYq"
      },
      "source": [
        "#### Example 2\n",
        "\n",
        "This is another simple example that combines subtle Pulse, Motion, Contrast, and Flash reactions to complement the overall trippy style. \n",
        "\n",
        "The style weights used here are from a model trained by **Jeremy Torman**. You can check out his artworks on [Twitter](https://twitter.com/tormanjeremy), or see details on his [original Reddit post](https://www.reddit.com/r/deepdream/comments/leqwxs/stylegan2ada_pickle_file_in_comments_with_colab/) if you're interested!\n",
        "\n",
        "The song, meanwhile, is **Raspberry by Saje**. You can listen to the full track on [YouTube](https://www.youtube.com/watch?v=fOLxvL0_aMU) or [Spotify](https://open.spotify.com/artist/3I2596dGk4K3e4qKjwpzQb?si=TbyjmQuAQRWmrE--lNTRMg). \n",
        "\n",
        "Click [here](https://youtu.be/iEFqcMrszH0) to view a full-length sample video without having to run the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGvz9tH_CXrf"
      },
      "source": [
        "# Download Style Weights \n",
        "! gdown --id 19hNptJSXji_9h7DMJBVlEMe-izWXvkYQ\n",
        "\n",
        "L = LucidSonicDream(song = 'raspberry.mp3',\n",
        "                    style = 'VisionaryArt.pkl')\n",
        "\n",
        "L.hallucinate(file_name = 'raspberry.mp4',\n",
        "              resolution = 360,\n",
        "              duration = 60,\n",
        "              pulse_react = 1.2,\n",
        "              motion_react = 0.7,\n",
        "              contrast_strength = 0.5,\n",
        "              flash_strength = 0.5)\n",
        "\n",
        "files.download(\"raspberry.mp4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EraHol-d3FLb"
      },
      "source": [
        "#### Example 3\n",
        "\n",
        "This is a much more complex example that utilizes multiple audio tracks and more fine-tuned parameters. It takes advantage of isolated audio tracks for cleaner Pulse, Class, and Contrast reactions.\n",
        "\n",
        "Note: Numerical labels for classes using the WikiArt style can be found [here](https://colab.research.google.com/github/Norod/my-colab-experiments/blob/master/WikiArt_Example_Generation_By_Peter_Baylies.ipynb). \n",
        "\n",
        "Click [here](https://youtu.be/l-nGC-ve7sI) to view a full-length sample video without having to run the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZL5yNGYV8kN"
      },
      "source": [
        "L = LucidSonicDream(song = 'lucidsonicdreams_main.mp3',\n",
        "                    pulse_audio = 'lucidsonicdreams_pulse.mp3',\n",
        "                    class_audio = 'lucidsonicdreams_class.mp3',\n",
        "                    contrast_audio = 'lucidsonicdreams_pulse.mp3',\n",
        "                    style = 'wikiart')\n",
        "\n",
        "L.hallucinate('lucidsonicdreams.mp4',\n",
        "              resolution = 360,\n",
        "              start = 32, \n",
        "              duration = 60, \n",
        "              pulse_react = 0.25,\n",
        "              motion_react = 0,\n",
        "              classes = [1,5,9,16,23,27,28,30,50,68,71,89],\n",
        "              dominant_classes_first = True,\n",
        "              class_shuffle_seconds = 8,\n",
        "              class_smooth_seconds = 4,\n",
        "              class_pitch_react = 0.2,\n",
        "              contrast_strength = 0.3, \n",
        "              flash_strength = 0.1)\n",
        "\n",
        "files.download(\"lucidsonicdreams.mp4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCtsl9pCeuua"
      },
      "source": [
        "## B.4. Using Custom Effects\n",
        "\n",
        "You can apply your own reactive custom effects to the video by defining an effects function and passing it to an EffectsGenerator object, as seen below. \n",
        "\n",
        "The effects function must contain the following parameters:\n",
        "\n",
        "*   **array** - Refers to the image array that the effect is applied on.\n",
        "*   **strength** - Reactivity parameter, similar to pulse_react, contrast_strength, etc.\n",
        "*   **amplitude** - Refers to the volume of the audio at a given point in time. Simply multiply this to the parameter that controls the \"intensity\" of the effect.\n",
        "\n",
        "The function must output an NumPy array representing the output image\n",
        "\n",
        "The function is then passed to an EffectsGenerator object, which in turn has the following parameters: \n",
        "\n",
        "*   **func** - The effects function\n",
        "*   **audio** - Audio controlling the effect\n",
        "*   **strength** - Strength of the effect\n",
        "*   **percussive** - If True, effect reacts to the audio's percussive elements.\n",
        "\n",
        "The song used in the example below is **Unfaith by Ekali**. You can listen to the full track on [YouTube](https://youtu.be/8C4wgzP1KOI) or [Spotify](https://open.spotify.com/track/5UC6HF9VVgYMHQ7PcwcZNZ?si=hCIA2JMTQTC98zzPZfA3yQ).  \n",
        "\n",
        "Click [here](https://youtu.be/V7jo281HSwM) to view a sample video without having to run the code.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I9s10x-cchM"
      },
      "source": [
        "import numpy as np \n",
        "from skimage.transform import swirl\n",
        "from lucidsonicdreams import EffectsGenerator\n",
        "\n",
        "def swirl_func(array, strength, amplitude):\n",
        "  swirled_image = swirl(array, \n",
        "                        rotation = 0, \n",
        "                        strength = 100 * strength * amplitude,\n",
        "                        radius=650)\n",
        "  return (swirled_image*255).astype(np.uint8)\n",
        "\n",
        "swirl_effect = EffectsGenerator(swirl_func,\n",
        "                                audio = 'unfaith.mp3', \n",
        "                                strength = 0.2, \n",
        "                                percussive = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfuiaKo5SIFK"
      },
      "source": [
        "L = LucidSonicDream('unfaith.mp3',\n",
        "                    style = 'textures')\n",
        "\n",
        "L.hallucinate('unfaith.mp4',\n",
        "              resolution = 360,\n",
        "              duration = 60, \n",
        "              motion_react = 0.15,\n",
        "              speed_fpm = 2,\n",
        "              pulse_react = 1.5,\n",
        "              contrast_strength = 1,\n",
        "              flash_strength = 1, \n",
        "              custom_effects = [swirl_effect])\n",
        "\n",
        "files.download(\"unfaith.mp4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9De3fqCxmTwc"
      },
      "source": [
        "## B.5. Using Custom Visualization Functions\n",
        "\n",
        "Finally, you can choose not to use StyleGAN, and instead define any custom function that takes in a batches of vectors and outputs a Pillow image. The function must take in **noise_batch** and **class_batch** parameters. Moreover, when defining the LucidSonicDream object, **num_possible_classes** and **input_size** must be passed.\n",
        "\n",
        "The example below defines a custom function using a pre-trained PyTorch implementation of the BigGAN, similarly to the [Deep Music Visualizer](https://github.com/msieg/deep-music-visualizer) project by Matt Siegelman. Numerical labels for each class can be found [here](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a). \n",
        "\n",
        "The song used is **Sea of Voices by Porter Robinson**. You can listen to the track on [YouTube](https://www.youtube.com/watch?v=lSooYPG-5Rg) or [Spotify](https://open.spotify.com/track/2lNFWUrxuNaQsf5I1pDTPr?si=MsD7GJUsRma4mkyfjbEhJg). Note that an [instrumental version](https://youtu.be/2Bo0JqTmVwg) was used as input in order to prevent vocals from influencing motion.\n",
        "\n",
        "Click [here](https://youtu.be/_TJCql7O9kU?t=180) to view a full-length sample video without having to run the code!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLYJkeRLfTJE"
      },
      "source": [
        "! pip install pytorch_pretrained_biggan\n",
        "from pytorch_pretrained_biggan import BigGAN, convert_to_images\n",
        "import torch\n",
        "\n",
        "biggan = BigGAN.from_pretrained('biggan-deep-512')\n",
        "biggan.to('cuda:0')\n",
        "\n",
        "def biggan_func(noise_batch, class_batch):\n",
        "  noise_tensor = torch.from_numpy(noise_batch).cuda()\n",
        "  class_tensor = torch.from_numpy(class_batch).cuda()\n",
        "  with torch.no_grad():\n",
        "    output_tensor = biggan(noise_tensor.float(), class_tensor.float(), truncation = 1)\n",
        "  return convert_to_images(output_tensor.cpu())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YheSh3p6m7GI"
      },
      "source": [
        "L = LucidSonicDream('sea_of_voices_inst.mp3',\n",
        "                    style = biggan_func, \n",
        "                    input_shape = 128, \n",
        "                    num_possible_classes = 1000)\n",
        "\n",
        "L.hallucinate('sea_of_voices.mp4',\n",
        "              output_audio = 'sea_of_voices.mp3',\n",
        "              resolution = 360,\n",
        "              duration = 60,\n",
        "              speed_fpm = 3,\n",
        "              classes = [13, 14, 22, 24, 301, 84, 99, 100, 134, 143, 393, 394],\n",
        "              class_shuffle_seconds = 10, \n",
        "              class_shuffle_strength = 0.1,\n",
        "              class_complexity = 0.5,\n",
        "              class_smooth_seconds = 4,\n",
        "              motion_react = 0.35,\n",
        "              flash_strength = 1,\n",
        "              contrast_strength = 1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}