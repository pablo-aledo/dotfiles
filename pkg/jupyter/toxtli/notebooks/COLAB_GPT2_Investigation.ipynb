{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COLAB - GPT2-Investigation.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH8epLEa9O3q"
      },
      "source": [
        "Adapted by: Carlos Toxtli http://www.carlostoxtli.com/#colab-gpt2-1\n",
        "\n",
        "Source: https://github.com/avivajpeyi/investigating-gpt2/blob/master/GPT2_Investigation.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxtrR-4xQLj7"
      },
      "source": [
        "# Investigating OpenAI's GPT-2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IY2d_65z9cOo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAZP0RTAFqh3"
      },
      "source": [
        "In this notebook, we can try out a small version (345M parameter vs their full 1.5B parameter model) of Open AI's GPT-2 model, described from the paper [Language Models are Unsupervised Multitask Learners](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf). OpenAI has also published a more human freindly [blog post](https://openai.com/blog/better-language-models/) about the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08tmn3F5RDWO"
      },
      "source": [
        "## Notes about model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmnLLM0NUJtl"
      },
      "source": [
        "### Background\n",
        "The GPT-2 algorithm was trained on the task of *language modeling*--- which tests a program's ability to predict the next word in a given sentence--by ingesting a shit ton of text data (40GB of articles, blogs, and websites,). By using this data it achieved \n",
        "\n",
        "*   \"*zero-shot learning*\": state-of-the-art scores on a number of unseen language tests\n",
        "*   [Unintentional (albeit not-so-great) Language translation](https://i1.wp.com/slatestarcodex.com/blog_images/english-french.png?zoom=2&w=700)\n",
        "*   *TLDR summarization*\n",
        "*   *Text completion*\n",
        "*  *Reading comprehension*\n",
        "*  [Essay Writing](https://pbs.twimg.com/media/DzYpsJOU0AA1PO9.png:large)\n",
        "*   more...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1daWxZIULF7"
      },
      "source": [
        "### Why this is cool\n",
        "*   Another step to AGI\n",
        "*   Improving qs+a\n",
        "*   Recovering historical data (interpolation through text)\n",
        "*   Help explain difficult to understand texts to non native eglish speakers/novices\n",
        "*   Potentially use it as a tool to weed out \"fake news\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l92gCG9VUG6n"
      },
      "source": [
        "### Why its scary: FAKE NEWS\n",
        "\n",
        "Open AI hasnt released the dataset, training code, or the full GPT-2 model weights. This is due to the concerns about large language models being used to generate deceptive, biased, or abusive language at scale. Some examples of the applications of these models for malicious purposes are:\n",
        "* Generate misleading news articles\n",
        "* Impersonate others online\n",
        "* Automate the production of abusive or faked content to post on social media\n",
        "* Automate the production of spam/phishing content\n",
        "\n",
        "As one can imagine, this combined with recent advances in generation of synthetic imagery, audio, and video implies that it's never been easier to create fake content and spread disinformation at scale (check out [this paper](http://grail.cs.washington.edu/projects/AudioToObama/siggraph17_obama.pdf) on making an AI that synthesizes photorealistic, lip-synced [video](https://www.youtube.com/watch?v=9Yq67CjDqvw) of Obama). The public at large will need to become more skeptical of the content they consume online. \n",
        "\n",
        "Also scary beceause this is yet another step to AGI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO9_2RgBVn_i"
      },
      "source": [
        "### My opinions\n",
        "I think GPT-2 is a brute-force statistical pattern matcher which chews up the internet and gives you back a slightly confusing dump of it when asked... It seems like a plagarism model, that changes so much based on the large dataset that, there is no more of the original context... so its no longer plagarism? \n",
        "\n",
        "From what I understand, there is not really a new algorithmic contribution here. I think they are scaling previous research. But I think seeing exactly how strong these scaled up models an awesome contribution and challenge. It’s easy to say in retrospect “of course more data and compute gives you better models”.\n",
        "\n",
        "#### Skeptical\n",
        "I am a little skeptical on OpenAi's results -- they havent released the full model -- and they probably shouldnt, but have they just cherry-picked their results? Need to look more into this.\n",
        "\n",
        "Maybe trying out their 345M Parameter model will make me a believer! \n",
        "\n",
        "#### Is it really closer to a true AGI?\n",
        "Sure, this could do cool stuff with infinite training data and limitless computing resources, but thats true of alot of ML projects. Scaling the data needed to learn is tough problem. \n",
        "\n",
        "A true AGI will have to be much better at learning from limited datasets with limited computational resources. It will have to investigate the physical world with the same skill that GPT-2 investigates text....\n",
        "\n",
        "#### Wake up non-believers! \n",
        "AIs already pick up abilities that we dont expect them to learn, eg English-to-French translation without any French texts in their training corpus. GPT-2 is a good example of how AIs only learn what you program them to learn, and that they can do more than one specific task.\n",
        "\n",
        "#### Should it be released? Tough qs! \n",
        "The resources needed to train the full model are beyond the average person and small companies which could use this for potentially very interesting non-malicious applications. However large organizations and state actors that are most likely to use this for malicious purposes can and typically do already have easy access to the resources needed to replicate the full model.\n",
        "\n",
        "Therefore by not releasing the full model \"Open\"Ai is in a way ensuring that this sort of AI tech remains in the hands of powerful organizations and state actors that are most likely to misuse it while at the same time unintentionally tricking the general public to think this tech is not \"really\" available yet...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pokp-KpsQy1P"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2qtkGuIQCoq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a56ad8ea-5995-4bcf-d0bf-61c4e65f96e7"
      },
      "source": [
        "# testing GPU connection\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found; Go to Runtime > Change Runtime Type > Harware Accelerator > GPU')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jX80K4gFOpTC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "f2b69906-4bbc-41aa-f792-ca96927e5715"
      },
      "source": [
        "# Clone repo \n",
        "! git clone https://github.com/openai/gpt-2.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gpt-2'...\n",
            "remote: Enumerating objects: 209, done.\u001b[K\n",
            "remote: Total 209 (delta 0), reused 0 (delta 0), pack-reused 209\n",
            "Receiving objects: 100% (209/209), 4.37 MiB | 2.71 MiB/s, done.\n",
            "Resolving deltas: 100% (109/109), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYhj6EaWJRrB"
      },
      "source": [
        "# Move to gpt-2 repo\n",
        "import os\n",
        "os.chdir('gpt-2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUEy5HipOtp0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        },
        "outputId": "23930e19-9541-496e-de21-c88bc7b74727"
      },
      "source": [
        "# download model and install dependencies\n",
        "!python download_model.py 345M\n",
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rFetching checkpoint:   0%|                                              | 0.00/77.0 [00:00<?, ?it/s]\rFetching checkpoint: 1.00kit [00:00, 850kit/s]                                                      \n",
            "\rFetching encoder.json:   0%|                                           | 0.00/1.04M [00:00<?, ?it/s]\rFetching encoder.json: 1.04Mit [00:00, 68.7Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 1.06Mit/s]                                                   \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:16, 88.5Mit/s]                                 \n",
            "Fetching model.ckpt.index: 11.0kit [00:00, 6.28Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 927kit [00:00, 66.8Mit/s]                                                 \n",
            "Fetching vocab.bpe: 457kit [00:00, 53.0Mit/s]                                                       \n",
            "Collecting fire>=0.1.3 (from -r requirements.txt (line 1))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/69/faeaae8687f4de0f5973694d02e9d6c3eb827636a009157352d98de1129e/fire-0.2.1.tar.gz (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 25.7MB/s \n",
            "\u001b[?25hCollecting regex==2017.4.5 (from -r requirements.txt (line 2))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/62/c0c0d762ffd4ffaf39f372eb8561b8d491a11ace5a7884610424a8b40f95/regex-2017.04.05.tar.gz (601kB)\n",
            "\u001b[K     |████████████████████████████████| 604kB 47.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests==2.21.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (2.21.0)\n",
            "Collecting tqdm==4.31.1 (from -r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/4b/c38b5144cf167c4f52288517436ccafefe9dc01b8d1c190e18a6b154cd4a/tqdm-4.31.1-py2.py3-none-any.whl (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 28.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2019.6.16)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2.8)\n",
            "Building wheels for collected packages: fire, regex\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.2.1-py2.py3-none-any.whl size=103527 sha256=a73d18795b94abb98948409ebebc9bf4e969a965dec7f27d594bf6e5b29101d3\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/9c/c0/07b6dc7faf1844bb4688f46b569efe6cafaa2179c95db821da\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2017.4.5-cp36-cp36m-linux_x86_64.whl size=533182 sha256=90bea1dbbf8278de585edd393953724a11843e814e290e9e8d6f6c723db12ac0\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/07/38/3c16b529d50cb4e0cd3dbc7b75cece8a09c132692c74450b01\n",
            "Successfully built fire regex\n",
            "Installing collected packages: fire, regex, tqdm\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Uninstalling tqdm-4.28.1:\n",
            "      Successfully uninstalled tqdm-4.28.1\n",
            "Successfully installed fire-0.2.1 regex-2017.4.5 tqdm-4.31.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHDbz70yf9nj"
      },
      "source": [
        "# Unconditional sample generation\n",
        "Generates text samples on the whim of the AI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAuPcqKngSfn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b769c2e8-69c4-4927-99a0-0477146d58d8"
      },
      "source": [
        "!python3 src/generate_unconditional_samples.py --model_name='345M' --nsamples=3 --top_k=10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From src/generate_unconditional_samples.py:54: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2019-09-22 23:44:37.244138: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-09-22 23:44:37.248675: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-22 23:44:37.249228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-09-22 23:44:37.249535: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-22 23:44:37.250703: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-09-22 23:44:37.252179: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-09-22 23:44:37.252608: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-09-22 23:44:37.253994: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-09-22 23:44:37.254968: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-09-22 23:44:37.258146: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-09-22 23:44:37.258279: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-22 23:44:37.258820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-22 23:44:37.259264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-09-22 23:44:37.264272: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2019-09-22 23:44:37.264484: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x14ef2c0 executing computations on platform Host. Devices:\n",
            "2019-09-22 23:44:37.264510: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-09-22 23:44:37.375659: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-22 23:44:37.376323: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x14ef480 executing computations on platform CUDA. Devices:\n",
            "2019-09-22 23:44:37.376349: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2019-09-22 23:44:37.376525: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-22 23:44:37.377005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-09-22 23:44:37.377072: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-22 23:44:37.377087: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-09-22 23:44:37.377099: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-09-22 23:44:37.377111: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-09-22 23:44:37.377123: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-09-22 23:44:37.377135: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-09-22 23:44:37.377149: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-09-22 23:44:37.377194: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-22 23:44:37.377657: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-22 23:44:37.378147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-09-22 23:44:37.378228: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-22 23:44:37.379282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-09-22 23:44:37.379302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-09-22 23:44:37.379311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-09-22 23:44:37.379396: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-22 23:44:37.379902: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-22 23:44:37.380352: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-09-22 23:44:37.380391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14125 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From src/generate_unconditional_samples.py:56: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:51: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:64: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:16: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:67: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "WARNING:tensorflow:From src/generate_unconditional_samples.py:65: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2019-09-22 23:44:52.075866: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "======================================== SAMPLE 1 ========================================\n",
            "We're sorry that these items are out of stock or not available for pre-order.\n",
            "\n",
            "Please check out these great options:\n",
            "\n",
            "Sell This:<|endoftext|>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial No Derivative Works License ( http://creativecommons.org/licenses/by-nc/4.0 ), which permits use, distribution, and reproduction in any medium, provided the original work is properly cited. The Creative Commons public domain dedication allows others to do the same.\n",
            "\n",
            "This article is based on the article \"Effect of the dietary intake of protein supplementation on blood glucose control in overweight men\".\n",
            "\n",
            "The aim of this study was to compare the effect of a low protein intake (1.5 g/day) and a high protein intake (30 g protein/day) on the serum insulin and glucose responses in overweight men in a randomized controlled trial.\n",
            "\n",
            "In this study, we aimed to compare the effects of the two types of diets on serum insulin and glucose responses. In accordance with prior reports, we compared the two diets on a randomized clinical trial.\n",
            "\n",
            "To our knowledge, there have been only few trials examining the effect of protein intakes in overweight men. The aim of this study was to compare the effect of an low protein intake (1.5 g daily) and a high protein intake (30 g protein/day) on the serum insulin and glucose responses in overweight men in a randomized clinical trial.\n",
            "\n",
            "Although high intakes of protein can be considered beneficial, the evidence base of the evidence base of the evidence base of the evidence base for protein intakes and health effects is limited ( 1 – 6 ).\n",
            "\n",
            "We did not find any evidence to show the effects of dietary protein or of other protein sources on blood glucose and lipid concentrations.\n",
            "\n",
            "We found no difference, however, between the effects of low protein diets and high protein diets and between low and high protein diets in terms of total protein or total carbohydrate or total calories, although the effects were similar in both groups.\n",
            "\n",
            "There has been limited evidence to suggest that protein intake in the low protein diet might increase the risk of type 2 diabetes ( 2 , 6 – 9 ). The evidence base for the effect of protein intakes on blood lipids is not well established, although there are indications that the effects of low protein diets might be beneficial ( 2 , 3 ).\n",
            "\n",
            "In contrast to high-protein diets, low-protein diets may be more beneficial than high-protein diets, but the data available in humans are insufficient ( 2 ).\n",
            "\n",
            "The results of the present study provide evidence that the low-protein diet is not more beneficial than the high-protein diets.\n",
            "\n",
            "To investigate the effect of the two types of diets on serum insulin and glucose responses in overweight and overweight and obese men who were randomly assigned either to a low-protein or a high-protein intake for 12 weeks, we compared the effects on serum insulin and glucose of a low-protein diet and of a high-protein diet in overweight and/or obese men.\n",
            "\n",
            "Our previous study showed that high protein intake (25–35 g/day) is associated with higher fasting glucose concentrations than low-protein intake (< 25 g/day) ( 9 ). This finding is consistent with a recent study ( 10 ) suggesting that higher-protein intake (45 g/day) may increase the incidence of ischaemic heart disease in overweight or obese subjects. The effect size for these two low-protein diets was similar ( P = 0.05).\n",
            "\n",
            "The low-protein diet and the high-protein diet were similar in terms of their relative effects on fasting glucose concentrations.\n",
            "\n",
            "In conclusion, we found that low-protein (1.5 g daily) and high protein intakes (30 g/day) can be equally effective in reducing the fasting glucose levels and thus the risk of type 2 diabetes in overweight or obese men.\n",
            "\n",
            "The low-protein diet and the high-protein diet were similar in terms of their relative effects on fasting lipids; in the low-protein diet, the total dietary protein content was similar to that of a high-protein diet and in the high-protein diet, the total dietary protein content was similar to that of a low-protein diet, although both diets were higher in total cholesterol than in dietary cholesterol (Table S1 in File 1).\n",
            "\n",
            "A similar pattern emerged for blood glucose. The low-protein diet and the high-protein treatment groups, on average, had similar fasting glucose concentrations and the total dietary protein content (P-values > 0.05) in comparison to the other groups. The low-protein diet had the largest effect on total cholesterol concentrations, with no significant difference between the low protein diet and the high-protein group (Table S1 in File 1).\n",
            "\n",
            "The study protocol, which was approved by the ethics committee of TU Dresden, Germany, was performed according to the Declaration of Helsinki and the Declaration of Confidentiality.\n",
            "\n",
            "This is the\n",
            "======================================== SAMPLE 2 ========================================\n",
            "A new poll finds voters approve of Gov. Scott Walker but disapprove of his leadership style.\n",
            "\n",
            "The poll, conducted by the Marquette Law School and conducted for the Milwaukee Journal Sentinel and Marquette University, found Walker's approval rating has climbed to 49 percent. Approval of his leadership style is up to 47 percent. The poll found that voters disapprove of the job Walker is doing as Walker prepares to step down next week. Walker has a 51 percent approval rating.\n",
            "\n",
            "Walker is now the first governor in Wisconsin's history to have at least 50 percent approval of his tenure, but only the first in state history to reach that mark.\n",
            "\n",
            "He's also the only governor in Wisconsin history to have a 50 percent approval rating.\n",
            "\n",
            "The poll was also asked about two recent events that have led to some negative coverage about Walker.\n",
            "\n",
            "A new Marquette poll shows that voters think Milwaukee Mayor Tom Barrett has not done his job as mayor. In fact, they disapprove of Barrett's leadership style, as is typical.\n",
            "\n",
            "The poll also shows Walker and Walker's chief of staff, David Murray, are the most unpopular two people in state office today.\n",
            "\n",
            "Walker and Murray are viewed unfavorably, with only 49 percent of likely voters seeing them positively. And Walker's chief of staff, Chris Schrimpf, has a 50 percent job approval rating, the highest job approval of anyone in state government today.\n",
            "\n",
            "\"I'm not sure how many people can say they've ever been treated worse than we've been treated in the past year,\" said John Lott, a Republican political consultant who has worked with Walker. \"The governor is in a tough spot.\"\n",
            "\n",
            "Lott added that the poll is a reflection of the public's perception of the governor.\n",
            "\n",
            "\"We have a lot of negative feelings about the governor's leadership style,\" he said, noting that he has seen a number of polls show negative results for Walker and his administration. \"The reality is he's doing a really good job at the time.\"\n",
            "\n",
            "The poll shows that Walker has a 50 percent approval rating with Democrats, and a 46 percent approval rating with Republicans. The poll also found that a majority of voters support the tax hike approved by the state Supreme Court.\n",
            "\n",
            "In a statement following the poll, the Milwaukee Journal Sentinel wrote, \"In a state that is increasingly polarized on issues from immigration to the environment, Walker has the best chance of re-establishing his reputation to be the leader we need at a time when we face challenges on everything from the economy to our schools.\"\n",
            "\n",
            "Walker has been dogged by questions about his handling of his recall efforts. His approval rating dropped to 40 percent after the state legislature voted this week to pass a new ethics law.\n",
            "\n",
            "\"It is clear that voters believe he has failed on several issues and he can't govern with a majority of the vote,\" the poll results said.<|endoftext|>This is a list of all the games that were released for the Xbox Live Arcade version of Grand Theft Auto: San Andreas, the version that first launched for the PlayStation Network and later the Xbox 360. This list is not complete. It is based on a list of all games released for the PC version of Grand Theft Auto: Vice City that have been released for the PlayStation Network. For more information see the article on PC versions of Grand Theft Auto: Vice City.\n",
            "\n",
            "This listing does not include games on Xbox 360 which are now in the Xbox 360 version (e.g. Rockstar Games' Grand Theft Auto Online: San Andreas) or those that have not been released for the PlayStation Network (e.g. The Evil Within II: Director's Cut).\n",
            "\n",
            "The list does not include games that were made available on the PlayStation Portable version of Grand Theft Auto: Vice City.\n",
            "\n",
            "The list of titles does not include the game that was released as an Xbox 360 exclusive, which is Grand Theft Auto: Vice City: The Complete Edition.<|endoftext|>The U.S. has the highest number of homeless people in the world, a new report finds.\n",
            "\n",
            "According to the U.S. Department of Housing and Urban Development, about 7 percent of the homeless population is classified as \"unhomeless,\" with the majority of these being those in poverty.\n",
            "\n",
            "The number of people sleeping rough in the U.S. has doubled over the last five years, with nearly 3 million people sleeping rough in 2009 alone, the National Coalition for the Homeless said in a report.\n",
            "\n",
            "The group says this number will continue to rise, with the number of people living in temporary shelter beds expected to jump to nearly 10 million by 2016.\n",
            "\n",
            "The number of homeless families living with children has tripled over the past 15 years as a result of federal and state programs that help to provide services to families who have become homeless, according to the National Conference of State Legislatures.\n",
            "\n",
            "The report also highlights other reasons for the increase in homeless people.\n",
            "\n",
            "\"The rise in the number of homeless children is due to increased demand for affordable\n",
            "======================================== SAMPLE 3 ========================================\n",
            "In the late '70s, when the Beatles were touring the world, John and Yoko's friendship was on the upswing and the band was making their mark across the globe, the Beatles were a major draw, drawing thousands of fans from across Europe to see them at home.\n",
            "\n",
            "\n",
            "The Beatles and John and Yoko at the Abbey Road Studios at the end of the tour in 1976, and then on the cover of Rolling Stone magazine in 1977.\n",
            "\n",
            "At this point in time, John and Yoko were very far from their prime years; John had already turned 60, Yoko was only 22.\n",
            "\n",
            "So when their tour manager, Peter Allen, offered to help John and the band with an early version of their album \"The Beatles Anthology\", Yoko was thrilled.\n",
            "\n",
            "\"I think we'd never done anything like it before because we were young and young boys,\" she recalled.\n",
            "\n",
            "\"But then when the tour came around, we got the idea of working together.\"\n",
            "\n",
            "\n",
            "John and Yoko in the studio at the Abbey Road Studios at the end of the tour in 1976.\n",
            "\n",
            "\n",
            "\"It was quite an experience,\" she says. \"I think we were the first band to play with Yoko in our lives.\"\n",
            "\n",
            "In the studio, they recorded a song called \"I Want To Hold Your Hand\", but the song wasn't finished.\n",
            "\n",
            "Instead they decided to try another song called \"The Love You Don't\" which they called \"The Beatle Song\" in homage to the album's cover.\n",
            "\n",
            "The Beatles had been working on the song for a while, and Yoko had even sung \"The Beatles\" on their first album (which was the first album to feature a solo singer on the album cover).\n",
            "\n",
            "But the two didn't really know each other very well.\n",
            "\n",
            "\"We never really talked about what we wanted to do,\" said Yoko. \"It was just a band that we were all friends with, and it was fun to do. I was very happy about that.\"\n",
            "\n",
            "They started recording the song in November of 1976, and it was recorded at Abbey Road Studios on November 25, 1976.\n",
            "\n",
            "They recorded the song for six days, during which time John recorded \"The Beatles Anthology\", which had already been in the works for months.\n",
            "\n",
            "It was a long time before they started to play the song live, and it wasn't until March of 1977 that John and Yoko actually played the live version of the song on live TV.\n",
            "\n",
            "\"It was a big moment,\" said Yoko. \"It really opened the door for us to get a chance to play live.\"\n",
            "\n",
            "\n",
            "Yoko with her husband George Harrison in the studio at Abbey Road Studios, and then in the Abbey Road Studios at the end of the tour in 1976 (Photo: Peter Allen/Redferns)\n",
            "\n",
            "When they started playing live for the first time, they played at Wembley Arena in London on February 27th, 1977 and it sold out in an hour, setting a record for the biggest sell out of all their tours.\n",
            "\n",
            "The song \"The Beatles Anthology\" was later used in several other television commercials and the song \"I Want To Hold Your Hand\" became a hit worldwide with the song being used in a number of movies, TV series, and commercials.\n",
            "\n",
            "After the success of the song, the band went on to play a number of shows at Wembley on the following year, and played at the Royal Albert Hall in London in 1978 and 1979.\n",
            "\n",
            "The band also had the opportunity to record an original song, \"Let's Dance\", and performed it live at Leeds on October 5th, 1980.\n",
            "\n",
            "But by 1982, John and Yoko were no longer together, so they decided to retire together.\n",
            "\n",
            "When the band played their final gig in October, 1981, John announced that there would be no more live shows.\n",
            "\n",
            "\"We're no longer playing live,\" he said at the end of the band's last show at Wembley stadium. \"It's not going to happen any further.\"\n",
            "\n",
            "John and Yoko retired together at the end of 1981, after which Yoko went on to be married to the singer and rock legend, David Bowie, who had also retired following the '60s, but who was still playing live.\n",
            "\n",
            "The couple had two children together, one named David and the other Yoko, who died of cancer on July 1, 2003.\n",
            "\n",
            "Yoko and John's final concert together, at Wembley stadium on December 5th, 1981.\n",
            "\n",
            "Yoko and George Harrison at the Abbey Road Studios at the end of the tour in 1976 (Photo: Peter Allen/Redferns)\n",
            "\n",
            "In a recent interview for Rolling Stone magazine, John revealed that he was very proud of his children and grandchildren, but was a little sad to be gone.\n",
            "\n",
            "\"They're the most wonderful people I know,\" he said. \"I'm so proud of them and\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOO7SrNKfQYc"
      },
      "source": [
        "# Conditional sample generation\n",
        "Generates text sampels conditional on some user input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTcYA8Xr_S2E"
      },
      "source": [
        "## Notes on flags:\n",
        "The code comes with a few flags available, with a default value:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B97LWti6Dep1"
      },
      "source": [
        "\n",
        "* **seed** = None || a random value is generated unless specified. give a specific integer value if you want to reproduce same results in the future.\n",
        "* **nsamples** = 1 || specify the number of samples you want to print\n",
        "* **length** = None || number of tokens (words) to print on each sample.\n",
        "* **batch_size** = 1 || how many inputs you want to process simultaneously. doesn't seem to affect the results.\n",
        "* **temperature** = 1 || scales logits before sampling prior to softmax.\n",
        "* **top_k** = 0 || truncates the set of logits considered to those with the highest values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNIO4f0iDk9O"
      },
      "source": [
        "## Different usecases:\n",
        "\n",
        "\n",
        "**1.   Text completion**\n",
        "\n",
        "**2.  Question answering**\n",
        "\n",
        "**3.   Summarisation**\n",
        "\n",
        "**4.  Translation**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xfskdff44QlD"
      },
      "source": [
        "### 1. Text Completion\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFB86teG__A-"
      },
      "source": [
        "Feed in some random text and see what the AI generates from that!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9oU0a5LJ0K3"
      },
      "source": [
        "#### Example usage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v-k0G1zJ27W"
      },
      "source": [
        "> `!python3 src/interactive_conditional_samples.py --nsamples=2 --top_k=40 --temperature=.80 --model_name='345M'`\n",
        "\n",
        "\n",
        "> Model prompt >>> \"Our solar system consists of the inner and outer planets, separated by an asteroid belt. It has \"\n",
        "\n",
        "> Model prompt >>> \"The 10 best foods are: 1. Peanut butter jelly sandwiches 2. Marshmallows 3. Broccoli 4.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqv_iC-sJx68"
      },
      "source": [
        "#### Try it out yourself!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QIdaQn5WkSf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7d834c16-df71-4167-8dc1-693b30761f4e"
      },
      "source": [
        "!python3 src/interactive_conditional_samples.py --nsamples=2 --top_k=40 --temperature=.80 --model_name='345M'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:57: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2019-09-22 23:46:07.785955: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-09-22 23:46:07.790603: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-22 23:46:07.791141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-09-22 23:46:07.791429: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-22 23:46:07.792664: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-09-22 23:46:07.794023: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-09-22 23:46:07.794392: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-09-22 23:46:07.795832: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-09-22 23:46:07.796858: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-09-22 23:46:07.800133: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-09-22 23:46:07.800261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-22 23:46:07.800803: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-22 23:46:07.801269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-09-22 23:46:07.806131: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2019-09-22 23:46:07.806389: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x147d2c0 executing computations on platform Host. Devices:\n",
            "2019-09-22 23:46:07.806415: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-09-22 23:46:07.921039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-22 23:46:07.921693: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x147d480 executing computations on platform CUDA. Devices:\n",
            "2019-09-22 23:46:07.921725: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2019-09-22 23:46:07.921942: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-22 23:46:07.922422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-09-22 23:46:07.922500: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-22 23:46:07.922519: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-09-22 23:46:07.922531: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-09-22 23:46:07.922543: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-09-22 23:46:07.922555: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-09-22 23:46:07.922566: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-09-22 23:46:07.922579: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-09-22 23:46:07.922639: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-22 23:46:07.923157: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-22 23:46:07.923612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-09-22 23:46:07.923682: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-22 23:46:07.924759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-09-22 23:46:07.924786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-09-22 23:46:07.924796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-09-22 23:46:07.924899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-22 23:46:07.925418: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-22 23:46:07.925918: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-09-22 23:46:07.925968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14125 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:58: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:60: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:51: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:64: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:16: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:67: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:68: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "Model prompt >>> \n",
            "Prompt should not be empty!\n",
            "Model prompt >>> \n",
            "Prompt should not be empty!\n",
            "Model prompt >>> Our solar system consists of the inner and outer planets, separated by an asteroid belt. It has \n",
            "2019-09-22 23:47:09.273278: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "======================================== SAMPLE 1 ========================================\n",
            "ices that have been frozen over thousands of years, or at least frozen for thousands of years.\n",
            "\n",
            "And as part of its frozen form, as well as the frozen moon, it has a large and beautiful mountain range, which is actually a giant ice mountain. This is the largest mountain range in the Solar System, and it includes some of the closest asteroids around, which means the nearest they may be is around 10,000 light-years away and about 40 light-years away from us.\n",
            "\n",
            "The moon was captured in September of 2012, when it was about 1,000 kilometers from Earth. It's about 100,000 kilometers from Earth. And even though this moon should have been the closest the Sun and its moon orbits ever were, because of the way the planet orbits around the Sun, it was actually closer than we thought. We estimate that it should have been on our left shoulder, right shoulder, and left side of the Earth.\n",
            "\n",
            "So if we were looking at the Moon, even though it would be less than 80,000 kilometers from us, we would never actually be seeing it, because the Earth is too far away to have it. But this was where we found it.\n",
            "\n",
            "The Moon can only be seen with the full Moon as a background, because we're not looking at sunlight. So the image that it gave us on the night of that night was one that the Moon had been shining in for a very long time, and it was the only image that was of the entire Moon, and so we used that.\n",
            "\n",
            "And this is an impressive picture, because in order to get this image, we had to look at a different kind of Moon. We had to look at one that was a lot smaller, and it's the only moon that's on the Moon.\n",
            "\n",
            "And we're also able to see the Earth from that tiny moon, so it's a great way for us to see the Earth from this moon. It could be any of the other moons in the Solar System, even Jupiter to Mars, so it's a great way to get the Earth-Moon system in view.\n",
            "\n",
            "We're also looking at the largest moon of the Solar System. The Moon is around 2,900 kilometers across, and we're using it as a background for the entire Sun-Sky System, so it really shows us where the Sun and the Earth are, and it also shows that if you're looking at the Sun without the Earth as a background, which is what we're doing\n",
            "======================================== SAMPLE 2 ========================================\n",
            "ices rich in heavy elements, including carbon and iron.\n",
            "\n",
            "In an earlier draft of the paper, Professor Gao wrote that there was a \"clear\" case that the moon was a rocky body, with a large surface area and the atmosphere.\n",
            "\n",
            "\"As such, our research suggests that the solar system was formed approximately 3.6bn years ago from the remnants of the giant planet Pluto, which is now an asteroid,\" Professor Gao wrote in the paper.\n",
            "\n",
            "The results, based on the latest information available, support Professor Gao's theory that some planets, such as Jupiter, form around the Moon.\n",
            "\n",
            "He added that there were also other possible candidates. \"Many possible candidates exist, and the current study will provide insights into their formation, orbital periods and formation of planets around the moon,\" Professor Gao wrote.<|endoftext|>In this Jan. 15, 2016 photo, a girl attends a demonstration at the University of Toronto's Mississauga campus in Mississauga, Ont. A controversial bill that was designed to allow students to attend sex ed classes in schools was pulled from the Ontario Legislature as a result of a backlash against the teaching. (Fred Chartrand/Canadian Press via AP)\n",
            "\n",
            "With two days to go until the legislative session ends, Ontario's education minister's office says it is withdrawing a controversial bill that would have let Ontarians opt out of sex ed classes after they've passed a basic introductory sex education course.\n",
            "\n",
            "In a brief release Wednesday, Education Minister Liz Sandals said the bill was \"discarded.\"\n",
            "\n",
            "\"We've been discussing this with people on our side of politics,\" Sandals said, adding that the province is now looking to move on.\n",
            "\n",
            "The bill, introduced by an NDP MP, was designed to ease the transition from sexual education during the first year of secondary school.\n",
            "\n",
            "But some critics took issue with the language used by the minister's office, saying the bill would have allowed kids with pre-existing health conditions to opt out of sex ed — or to take classes that were no longer needed after the age of 12.\n",
            "\n",
            "The bill's language was controversial and a key plank of both Liberal Party and NDP Party candidates for election this fall. (The Canadian Press)\n",
            "\n",
            "Ontario-based Sex Educators Ontario, a group that lobbied for two years to kill the bill, said the minister's office had used \"inappropriate language\" in its release Wednesday.\n",
            "\n",
            "\"I'm sure the minister could have handled this better,\" said Janet Smith, executive\n",
            "================================================================================\n",
            "Model prompt >>> Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/contextlib.py\", line 99, in __exit__\n",
            "    self.gen.throw(type, value, traceback)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 5652, in get_controller\n",
            "    yield g\n",
            "  File \"src/interactive_conditional_samples.py\", line 73, in interact_model\n",
            "    raw_text = input(\"Model prompt >>> \")\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"src/interactive_conditional_samples.py\", line 91, in <module>\n",
            "    fire.Fire(interact_model)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 138, in Fire\n",
            "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 471, in _Fire\n",
            "    target=component.__name__)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 675, in _CallAndUpdateTrace\n",
            "    component = fn(*varargs, **kwargs)\n",
            "  File \"src/interactive_conditional_samples.py\", line 88, in interact_model\n",
            "    print(\"=\" * 80)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1618, in __exit__\n",
            "    close_thread.start()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 846, in start\n",
            "    _start_new_thread(self._bootstrap, ())\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4dnu9FTwLNw"
      },
      "source": [
        "### 2. Question-Answering\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldY01wWnAgDd"
      },
      "source": [
        "Feed in a passage, and then some question/answer pairs (Q: blah blah? A: Blah blah.), and token `A:`. The AI will answer the previous ''`Q:`''\n",
        "\n",
        "\n",
        "Note, for a single word answer (i.e.: Yes/No, city), set flag `length=1`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz7jQrOZJjSU"
      },
      "source": [
        "#### Example usage\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Bbc7cFNJrIO"
      },
      "source": [
        "\n",
        "> `!python3 src/interactive_conditional_samples.py --nsamples=10 --top_k=40 --temperature=.80 --length=1 --model_name='345M'`\n",
        "\n",
        "> Model Prompt >>> \n",
        " \n",
        "> ```\n",
        "The 2008 Summer Olympics torch relay was run from March 24 until August 8, 2008, prior to the 2008 Summer\n",
        "Olympics, with the theme of “one world, one dream”. Plans for the relay were announced on April 26, 2007, in\n",
        "Beijing, China. The relay, also called by the organizers as the “Journey of Harmony”, lasted 129 days and carried\n",
        "the torch 137,000 km (85,000 mi) – the longest distance of any Olympic torch relay since the tradition was started\n",
        "ahead of the 1936 Summer Olympics.\n",
        "After being lit at the birthplace of the Olympic Games in Olympia, Greece on March 24, the torch traveled to the Panathinaiko Stadium in Athens, and then to Beijing, arriving on March 31. From Beijing, the torch was\n",
        "following a route passing through six continents. The torch has visited cities along the Silk Road, symbolizing\n",
        "ancient links between China and the rest of the world. The relay also included an ascent with the flame to the top of\n",
        "Mount Everest on the border of Nepal and Tibet, China from the Chinese side, which was closed specially for the\n",
        "event.\n",
        "Q: What was the length of the race?\n",
        "A: 137,000 km\n",
        "Q: Was it larger than previous ones?\n",
        "A: No\n",
        "Q: Where did the race begin?\n",
        "A: Olympia, Greece\n",
        "Q: Where did they go after?\n",
        "A: Athens\n",
        "Q: How many days was the race?\n",
        "A: seven\n",
        "Q: Did they visit any notable landmarks?\n",
        "A: Panathinaiko Stadium\n",
        "Q: And did they climb any mountains?\n",
        "A:\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4UQUQL-Jtwl"
      },
      "source": [
        "#### Try it out yourself!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJm1OuwrLd2t"
      },
      "source": [
        "!python3 src/interactive_conditional_samples.py --nsamples=10 --top_k=40 --temperature=.80 --length=1 --model_name='345M'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnHDjbSszCOR"
      },
      "source": [
        "### 3. Summarization\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRyFm0nbAjiV"
      },
      "source": [
        "Feed in a passage, and add and text *`TL;DR:`* or *`Summary:`* at the end, and the AI will try to summarise the text.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rn5DaKOiKdK9"
      },
      "source": [
        "#### Example usage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oJCbdPdKfCx"
      },
      "source": [
        "Note the following passage was obtained from a blog post about the [mars-water paradox](http://www.planetary.org/blogs/guest-blogs/2019/mars-water-stable-paradox.html).\n",
        "\n",
        "\n",
        "> `!python3 src/interactive_conditional_samples.py --nsamples=3 --length=100 --temperature=1 --model_name='345M'`\n",
        "\n",
        "> Model Prompt >>>\n",
        "\n",
        ">```\n",
        "Mars has been the most extensively studied planet in the Solar System, except of course Earth. For the last 25 years, these missions have focused on the search for life by “following the water.” Although we have acquired compelling evidence of flowing liquid water on early Mars, the fundamental question about how water could be stable under Martian atmospheric conditions remains unsolved. Everything we have learned about Mars points towards a freezing cold Martian climate that would be incapable of stabilizing liquid water throughout Mars’ history.\n",
        "The two ideas that suggest liquid water could not be stable on early Mars are the “Faint Young Sun Paradox” and the Martian orbit. The following is a summary of two recent papers about the problem of Mars’ early climate: “The climate of early Mars,” by Robin Wordsworth, and a book chapter by Robert Haberle and coauthors, “The Early Mars Climate System.” Mars today as we know it is a cold and dry desert with a thin atmosphere not capable of stabilizing liquid water on its surface. However, there is ample evidence that Mars had flowing liquid water on its surface about 4 to 3.7 billion years ago (named as the Noachian Period). The evidence gathered by Mars orbiters, rovers, and landers is geomorphological; (valley networks, crater lakes, purported Northern ocean, glacial landforms, etc.); mineralogical (iron- and magnesium-rich clay minerals, sulfates, chlorides, iron oxides, and oxyhydroxides, etc.); and isotopic (noble gases, nitrogen, hydrogen, oxygen and carbon).\n",
        "TL;DR: \n",
        "```\n",
        "\n",
        "> Model Prompt >>>\n",
        ">```\n",
        "Theodore McCarrick is the most senior Catholic figure to be dismissed from the priesthood in modern times.\n",
        "US Church officials said allegations he had sexually assaulted a teenager five decades ago were credible.\n",
        "Mr McCarrick, 88, had previously resigned but said he had \"no recollection\" of the alleged abuse.\n",
        "\"No bishop, no matter how influential, is above the law of the Church,\" Cardinal Daniel DiNardo, president of the United States Conference of Catholic Bishops said in a statement.\n",
        "\"For all those McCarrick abused, I pray this judgment will be one small step, among many, toward healing.\"\n",
        "The alleged abuses may have taken place too long ago for criminal charges to be filed because of the statute of limitations.\n",
        "Mr McCarrick was the archbishop of Washington DC from 2001 to 2006. Since his resignation last year from the College of Cardinals, he has been living in seclusion in a monastery in Kansas.\n",
        "He was the first person to resign as a cardinal since 1927.\n",
        "He is among hundreds of members of the clergy accused of sexually abusing children over several decades and his dismissal comes days before the Vatican hosts a summit on preventing child abuse.\n",
        "The Vatican said Pope Francis had ruled Mr McCarrick's expulsion from the clergy as definitive, and would not allow any further appeals against the decision. \n",
        "TL;DR: \n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpw6EKUtKgzP"
      },
      "source": [
        "#### Try it out yourself!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMes5yRQuXs4"
      },
      "source": [
        "!python3 src/interactive_conditional_samples.py --nsamples=3 --length=100 --temperature=1 --model_name='345M'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdw9P3QdzA-e"
      },
      "source": [
        "### 4. Translation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3y8FkqnXAmqg"
      },
      "source": [
        "Provide a few example translations, using the format of *`english_text = other_language_text`*, and then *`english_text =`*  at the end. The AI will try to translate the english text into the other language.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deI6hvnVK8EY"
      },
      "source": [
        "#### Example usage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYbnMqk5K-BO"
      },
      "source": [
        "> `!python3 src/interactive_conditional_samples.py --nsamples=3 --temperature=1 --model_name='345M' `\n",
        "\n",
        "> Model Prompt >>>\n",
        "\n",
        "> ```\n",
        "Good morning. = Buenos días.\n",
        "I am lost. Where is the restroom? = Estoy perdido. ¿Dónde está el baño?\n",
        "How much does it cost? = ¿Cuánto cuesta?\n",
        "How do you say maybe in Spanish? = ¿Cómo se dice maybe en Español?\n",
        "Would you speak slower, please. = Por favor, habla mas despacio.\n",
        "Where is the book store? = ¿Dónde está la librería?\n",
        "At last a feminist comedian who makes jokes about men. = Por fin un cómico feminista que hace chistes sobre hombres.\n",
        "How old are you? = \n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWcB6I4AK_os"
      },
      "source": [
        "#### Try it out yourself!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3pueC6NEm5t"
      },
      "source": [
        "!python3 src/interactive_conditional_samples.py --nsamples=3 --temperature=1 --model_name='345M' "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}