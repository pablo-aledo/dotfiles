{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COLAB - part_a.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "3gg3QzRDr0LW",
        "tdoxjU9EhpCo",
        "PGHWI4T8hpCa",
        "p0BMJn9bhpDd",
        "02hnSx82zVIE",
        "HmQTL7z0j93-",
        "6twRwfypkGP3",
        "8lDZUbAMhpDv",
        "c0ID5qoa3TCX",
        "yZBJM5kH0C7f",
        "JQhAYxt60zmb",
        "v0xWZG1Q1T58",
        "clL80GLK16XP",
        "ThktNeMrhsR7",
        "3EMLY1mvhsSN",
        "vYjx3OiwhsSx",
        "epbVw_cWTj5u",
        "t6fGqfRcsWUN",
        "8YwB6jkoh3iK",
        "ykUsVzMLh3i_",
        "gDSPOrArh3ji",
        "iVdIWpu7WxBh",
        "w4iNUKGAc7Jz",
        "__WkIId_c7J_",
        "-8K3KVu9c7Ka",
        "fVQEoU8Oc7Km",
        "50aw_1RYc7K5",
        "ozXGbWhRc7LK",
        "EDa5iy5fc7Lj",
        "2BOgd-WVc7L-",
        "e5vdiluPc7MK",
        "8dFB_WJ0c7Mc",
        "UPRFiwCMc7Mr",
        "8-yPEm4lc7NC",
        "ud4usvc3c7NS",
        "vNWn6dHVc7Nk",
        "YIaoQIIcc7N0",
        "L0uMuhZlc7OM",
        "85pe5i05c7OV",
        "li5580u5c7Oa",
        "eEpoXV0Dc7Ot",
        "hIrEGlnLc7PB",
        "Y3U_8Bfwc-LP",
        "djXjx8Y7c-LT",
        "ZqvLsLrPc-Lc",
        "1KCtD_HKc-Lk",
        "kuM7yBjnc-Lt",
        "eMcbgBrjc-MI",
        "uHfAdbXic-Ma",
        "9K3tySu_c-Mn",
        "1LC9j271c-Mr",
        "Pcb_J0pCc-M0",
        "imDFjBOgc-NA",
        "z3xm6ZpIc-NN",
        "N7Ke-jYHc-NS",
        "3YxjGgetc-Nf",
        "FMJMJ66ac-Nv",
        "ArwQXvdKc-N9",
        "jQ7JFpAJc-OD",
        "JtQHYs-kc-OO",
        "gqg-K4t2c-Of",
        "xLGzdBcbc-Ov",
        "iQL_r0tsdKkm",
        "HUABbIVzd2Vj",
        "SkLFYCxTd2WD",
        "D6iqp3wB0Ho1",
        "vUbrU7yFdKlQ",
        "2It4ndiZdKle",
        "ccYFS2r0dKlv",
        "XriPg9kbdKl_",
        "VU8hYPf0dKmT",
        "V-vrR1X3dKmv",
        "1X8Mgg9adKm5",
        "Am8nShkEdKnT",
        "xFm9UkG3dKnq",
        "j-NnrcgjdKn7",
        "HMkPP5xBdKoP",
        "lr3fZX-_dKop",
        "zz12-4kXdKo6",
        "poyC78TydKpS",
        "sHCpZRS6dKpc",
        "6S4ZF4dxdKpj",
        "-aT0jqGAdKpx",
        "_FEGw46NdKqJ",
        "yq39E1Oqc_Pq",
        "Ga3b-5Skc_Pv",
        "7kv3cC6jc_P0",
        "Bwz3b3Xbc_P8",
        "9CN7qVSac_QF",
        "H45lmxZbc_QL",
        "6c64RsLhc_QS",
        "XKYBqd8lc_Qg",
        "VaoZy0H2c_Qk",
        "pItroBwxc_Qw",
        "ELvWQ6OCc_Q7",
        "pmy-S9Glc_RG",
        "5NTncQyTc_RL",
        "SP_p-9kxc_RQ",
        "_ySvz9bfc_Ra",
        "2Q0N6LjWc_Rn",
        "nLvU2NTRc_Rr",
        "k8I33L1bc_Rz",
        "NSHpXeBLc_R-",
        "x2CQs6tsc_SG",
        "AUW9kx9cdAEB",
        "7_qt700odAEF",
        "_1wDEgTQdAEM",
        "jzCv0ATedAER",
        "sH-GGN-HdAEW",
        "zs1339R4dAEc",
        "ujcaJgNbdAEg",
        "ovKQMQIJdAEm",
        "BJKZRcFsdAEp",
        "wM7BbE8IdAEt",
        "XUNIMawcdAEx",
        "wsU7u1DudAE2",
        "nJMuEN1KdAE6",
        "1AoM9_pidAFA",
        "wTnocWp2dAFG",
        "jJfKMOdLdAFQ",
        "RASd9_SCdAFU",
        "BfJ8XlKzdAFX",
        "kX-EwpwYdAFn",
        "00HDXb0tdAFv",
        "wdSessvzdA1-",
        "0XeuMuMSdA1_",
        "5RmSuHsmdA2D",
        "6kp4I5C6dA2H",
        "03zkrkvQdA2Q",
        "oDOTG65qdA2W",
        "ckJ474YOdA2c",
        "0ZwUf74DdA2f",
        "AcVaJxqsdA2g",
        "yNBxB67-dA2m",
        "B46BpeKjdA2t",
        "vVVXaFmLdA2x",
        "D0Cq6eTrdA21",
        "0sCUVqBAdA23",
        "kMUv7fA_dA26",
        "srsfIvledA3A",
        "MYY83SNVdA3D",
        "fun3yhXjdA3F",
        "C6BdzXmxdA3J",
        "9ud-K4xSdA3M",
        "1EFURPGGdBp8",
        "T96pwXYadBp9",
        "KjOx8XMqdBp-",
        "UtPDZr9YdBqB",
        "0N__yLekdBqG",
        "ox_hTiL1dBqJ",
        "1C90gRljdBqM",
        "0BmhFwTfdBqO",
        "OM26EgWLdBqR",
        "AoRW5B9zdBqU",
        "XlvmGFI8dBqZ",
        "-vchbdgedBqb",
        "tB8f8zagdBqd",
        "eegvhN2ddBqg",
        "Tz9uPdyEdBql",
        "IQkh6_qcdBqq",
        "hCzKSNsrdBqw",
        "S8qAz14XdBqy",
        "Yu6qo-39dBq6",
        "57ChB4NfdBq9",
        "Jos8sbtAdCcY",
        "sH_S0qmndCcZ",
        "SIfMLXdBdCcb",
        "yKladsPKdCcd",
        "0ik8dM1NdCcg",
        "hldrP7-tdCcj",
        "_8jt7GEldCcm",
        "zVbniiYRdCcq",
        "lNG2-hzNdCcs",
        "OfYNf-VbdCcv",
        "iE2Qv-aOdCcy",
        "eDDMnhYudCc2",
        "5D-uMrLQdCc5",
        "UyluYc5BdCc8",
        "abFSjRezdCc-",
        "HRbf2dw7dCdC",
        "7hN44wZkdCdF",
        "r1VyVhmmdCdI",
        "obMSnPFcdCdM",
        "29wAzFsHdCdP",
        "3BdiaJoOdDS3",
        "gshZSWHJdDTE",
        "xWXvqupXdDTd",
        "jKaQAf_vdDTp",
        "AWIrkhc0dDT6",
        "0Qot8ve7dDUJ",
        "2Jh2cUNddDUe",
        "uzdpd-UBdDUz",
        "EJ6FHzlhdDU9",
        "di_qoNKkdDVI",
        "onhnHUc1dDVa",
        "8kmhwz6MdDVn",
        "f98CWDPadDV3",
        "Y1gIMoVsdDWF",
        "oE4pINN1dDWW",
        "8F0e_0sPdDWu",
        "X5bnSge9dDW3",
        "eKDNqWondDW-",
        "61pHIhWkdDXK",
        "Izes1aXNdDXk"
      ]
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTepIiSVjZ_W"
      },
      "source": [
        "Adapted by Carlos Toxtli http://www.carlostoxtli.com/#colab-ensem-2\n",
        "\n",
        "Source: https://github.com/Adamantios/Ensembles-CSL-Imb_Learning-Models_Comparison/blob/master/part_a.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdL9By6h4S-5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "f7bd2dcb-0564-4685-dbec-90d0f2f62fa8"
      },
      "source": [
        "!git clone https://github.com/Adamantios/Ensembles-CSL-Imb_Learning-Models_Comparison.git\n",
        "%cd Ensembles-CSL-Imb_Learning-Models_Comparison"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Ensembles-CSL-Imb_Learning-Models_Comparison'...\n",
            "remote: Enumerating objects: 191, done.\u001b[K\n",
            "remote: Counting objects: 100% (191/191), done.\u001b[K\n",
            "remote: Compressing objects: 100% (140/140), done.\u001b[K\n",
            "remote: Total 191 (delta 100), reused 136 (delta 48), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (191/191), 3.28 MiB | 6.94 MiB/s, done.\n",
            "Resolving deltas: 100% (100/100), done.\n",
            "/content/Ensembles-CSL-Imb_Learning-Models_Comparison\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgKlxpR-BeDx",
        "pycharm": {}
      },
      "source": [
        "#### Adamantios Zaras AM: 06\n",
        "#### Panagiotis Souranis AM: 17"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVZRwjrXyaX_",
        "pycharm": {}
      },
      "source": [
        "# Description\n",
        "In this part of the project, we created 4 ensemble methods and compared them, \n",
        "using statistical analysis methods in 10 different datasets.\n",
        "#### Ensembles\n",
        "1. Bagging Ensemble using Random Tree Classifier.  \n",
        "We follow the procedure described below:\n",
        "  - Random Search, in order to search fpr hyperparameters.\n",
        "  - Grid Search in the area near the best parameters found from the Random Search.\n",
        "  - 10 fold Cross Validation, in order to plot the accuracy vs the number of classifiers used.\n",
        "  - Prediction using the best estimation for the number of classifiers, combined with the tuned parameters.\n",
        "2. Random Forest Classifier.  \n",
        "We follow the procedure described below:\n",
        "  - Random Search.\n",
        "  - Grid Search.\n",
        "  - Prediction using the tuned parameters.\n",
        "3. Stacking, using a Nearest Neighbors classifier, a Linear SVM, a Decision Tree classifier and a Naive Bayes classifier. The Meta-Classifier is a Logistic Regression Classifier.  \n",
        "We follow the procedure described below:\n",
        "  - Random Search.\n",
        "  - Grid Search.\n",
        "  - Present plots of each model's performance to the dataset and compare them with the stacking model, which combines them all.\n",
        "  - Prediction using the tuned parameters of each model.  \n",
        "  \n",
        "  **Note:** The StackingCVClassifier, uses the concept of cross-validation:  \n",
        "  The dataset is split into k folds and in k successive rounds, \n",
        "  k-1 folds are used to fit the first level classifier. In each round, \n",
        "  the first-level classifiers are then applied to the remaining 1 subset that was not used for model fitting in each iteration. \n",
        "  The resulting predictions are then stacked and provided - as input data - \n",
        "  to the second-level classifier. After the training of the StackingCVClassifier, \n",
        "  the first-level classifiers are fit to the entire dataset.\n",
        "\n",
        "4. Boosting, using XGBoost with Logistic Regression.  \n",
        "We follow the procedure described below:\n",
        "  - Random Search.\n",
        "  - Grid Search.\n",
        "  - Prediction using the tuned parameters of each model.\n",
        "\n",
        "#### Datasets\n",
        "1. [Spambase](https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data)\n",
        "2. **Wine** - Using sklearn' s import.\n",
        "3. **Iris** - Using sklearn' s import.\n",
        "4. [Breast Cancer](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data?fbclid=IwAR2ZT56DdRbU45HMFvq6gwTdjKsS-RLSQ0B1TQM4cskmA27x-upTF0n66BI)\n",
        "5. [Seeds](https://archive.ics.uci.edu/ml/machine-learning-databases/00236/seeds_dataset.txt)\n",
        "6. [Glass Identification](https://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data)\n",
        "7. [Tic Tac Toe](https://archive.ics.uci.edu/ml/machine-learning-databases/tic-tac-toe/tic-tac-toe.data)\n",
        "8. [Wholesale Customers](https://archive.ics.uci.edu/ml/machine-learning-databases/00292/Wholesale%20customers%20data.csv) - Predicting the channel.\n",
        "9. **Digits** - Using sklearn' s import.\n",
        "10. [Chess (King-Rook vs. King-Pawn)](https://archive.ics.uci.edu/ml/machine-learning-databases/chess/king-rook-vs-king-pawn/kr-vs-kp.data)\n",
        "\n",
        "\n",
        "#### Comparison\n",
        "We first create a table containing the accuracy scores of each algorithm in the datasets and note their ranking.  \n",
        "Following, we compute the mean ranking and fill the results table.  \n",
        "Moreover, we run two statistical tests, an alternative of Friedman test (Iman Davenport's correction of Friedman's rank sum test), \n",
        "Nemenyi post hoc and Friedman post-hoc test with Bergmann and Hommelâ€™s correction and present their outcomes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gg3QzRDr0LW",
        "pycharm": {}
      },
      "source": [
        "# Globals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdoxjU9EhpCo",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Import all modules.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzxjcU_hhpCu",
        "pycharm": {
          "is_executing": true,
          "metadata": false,
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "2b96d64f-464d-476b-f781-77d4adaa8868"
      },
      "source": [
        "import io\n",
        "import time\n",
        "\n",
        "import requests\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "from mlxtend.classifier import StackingCVClassifier\n",
        "from pandas import read_csv\n",
        "from scipy.stats import randint as sp_randint\n",
        "from sklearn import preprocessing\n",
        "from sklearn.datasets import load_wine, load_digits, load_iris\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Import util functions.\n",
        "from utils.general import report\n",
        "from utils.part_a import *\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGHWI4T8hpCa",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "# Spambase\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0BMJn9bhpDd",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "## Prepare the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NU9UgAmRhpDi",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "# Read the dataset.\n",
        "url=\"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
        "s=requests.get(url).content\n",
        "dataset=read_csv(io.StringIO(s.decode('utf-8')))\n",
        "\n",
        "# Get x and y.\n",
        "X, y = dataset.iloc[:, :-1].values, dataset.iloc[:, -1].values\n",
        "\n",
        "# Split to training and test pairs.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
        "                                                    random_state=0)\n",
        "\n",
        "# Scale data.\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train.astype(float))\n",
        "X_test = scaler.transform(X_test.astype(float))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02hnSx82zVIE",
        "pycharm": {}
      },
      "source": [
        "## Bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5ByicKb6A2B",
        "pycharm": {}
      },
      "source": [
        "# Define a Decision Tree classifier for the ensemble.\n",
        "clf = DecisionTreeClassifier(random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmQTL7z0j93-",
        "pycharm": {}
      },
      "source": [
        "### Random Search\n",
        "Run a Random Search using 10 fold cross validation, for the classifier which will be used in the bagging."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XmoZwpGhpDz",
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "fbd16825-2cc1-4d17-d473-48d4bc2026d6"
      },
      "source": [
        "\n",
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "param_dist = {'max_depth': sp_randint(1, 30),\n",
        "              'max_features': sp_randint(1, X.shape[1]),\n",
        "              'min_samples_split': sp_randint(2, X_train.shape[0] / 2),\n",
        "              'criterion': ['gini', 'entropy']}\n",
        "candidates = 200\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(clf, param_dist, candidates, cv=10, \n",
        "                                   n_jobs=-1, verbose=5, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.3s\n",
            "[Parallel(n_jobs=-1)]: Done 1912 tasks      | elapsed:   21.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "RandomizedSearchCV took 21.73 seconds for 200 candidates.\n",
            "Model with rank: 1\n",
            "Mean validation score: 0.911 (std: 0.017)\n",
            "Parameters: {'criterion': 'gini', 'max_depth': 19, 'max_features': 25, 'min_samples_split': 15}\n",
            "\n",
            "Model with rank: 2\n",
            "Mean validation score: 0.910 (std: 0.018)\n",
            "Parameters: {'criterion': 'entropy', 'max_depth': 11, 'max_features': 48, 'min_samples_split': 6}\n",
            "\n",
            "Model with rank: 3\n",
            "Mean validation score: 0.904 (std: 0.019)\n",
            "Parameters: {'criterion': 'entropy', 'max_depth': 25, 'max_features': 38, 'min_samples_split': 74}\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:   21.5s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6twRwfypkGP3",
        "pycharm": {}
      },
      "source": [
        "### Grid Search\n",
        "Run a Grid search, using 10 fold cross validation for the area around the best results found with the Random Search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLxTx7SdkdD3",
        "pycharm": {},
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "16c302ec-6d18-42c6-c093-e4cf28194c42"
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "param_grid = {'max_depth': range(10, 14),\n",
        "              'max_features': range(54, 57),\n",
        "              'min_samples_split': range(23, 26),\n",
        "              'criterion': ['gini', 'entropy']}\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=10, n_jobs=-1, verbose=5, \n",
        "                           iid=True)\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'\n",
        "      .format((time.time() - start)))\n",
        "report(grid_search.cv_results_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    1.8s\n",
            "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   11.8s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV took 23.03 seconds.\n",
            "Model with rank: 1\n",
            "Mean validation score: 0.913 (std: 0.015)\n",
            "Parameters: {'criterion': 'gini', 'max_depth': 11, 'max_features': 54, 'min_samples_split': 23}\n",
            "\n",
            "Model with rank: 1\n",
            "Mean validation score: 0.913 (std: 0.013)\n",
            "Parameters: {'criterion': 'gini', 'max_depth': 13, 'max_features': 55, 'min_samples_split': 25}\n",
            "\n",
            "Model with rank: 3\n",
            "Mean validation score: 0.912 (std: 0.012)\n",
            "Parameters: {'criterion': 'gini', 'max_depth': 11, 'max_features': 56, 'min_samples_split': 24}\n",
            "\n",
            "Model with rank: 3\n",
            "Mean validation score: 0.912 (std: 0.013)\n",
            "Parameters: {'criterion': 'gini', 'max_depth': 13, 'max_features': 55, 'min_samples_split': 24}\n",
            "\n",
            "Model with rank: 3\n",
            "Mean validation score: 0.912 (std: 0.013)\n",
            "Parameters: {'criterion': 'gini', 'max_depth': 13, 'max_features': 56, 'min_samples_split': 23}\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:   23.0s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lDZUbAMhpDv",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Create the Bagging Ensemble.\n",
        "Create the Bagging Ensemble, using the best parameters found from the above procedure.  \n",
        "Since the mean accuracy is the same, we are using the best scores with the minimum std, between the different CV folds.  \n",
        "We make prediction to the test data, which were left out at the train-test-split procedure and not to the training data again.  \n",
        "We are using a 10 fold cross validation method, in order to visualize the best number of classifiers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoX_EfUOhpEF",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "81493c7f-651c-45f2-cbd3-f9a9f2ea95f2"
      },
      "source": [
        "\n",
        "# Add best values for the classifier.\n",
        "clf.max_depth = 13\n",
        "clf.max_features = 55\n",
        "clf.min_samples_split = 25\n",
        "clf.criterion = 'gini'\n",
        "\n",
        "# Plot accuracy vs number of estimators for [100, 200, ..., 1000] estimators.\n",
        "estimators_vs_acc(clf, X_train, y_train, estimators_array=range(1, 1100, 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0ID5qoa3TCX",
        "pycharm": {}
      },
      "source": [
        "### Predict\n",
        "Predict using the best number of classifiers, based on the previous cross validation method.  \n",
        "The best number of estimators seems to be 800, since the accuracy is high  \n",
        "and the lower bound of it's deviation is better than the others."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtWsNmS2zGMf",
        "pycharm": {}
      },
      "source": [
        "# Create the bagging classifier.\n",
        "bg_clf = BaggingClassifier(base_estimator=clf, n_estimators=800, random_state=0)\n",
        "\n",
        "# Fit and predict.\n",
        "bg_clf.fit(X_train, y_train)\n",
        "y_pred = bg_clf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred, 'binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "yZBJM5kH0C7f",
        "pycharm": {}
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "CSrJ0ypvVDLe",
        "pycharm": {}
      },
      "source": [
        "# Define a Random Forest classifier.\n",
        "clf = RandomForestClassifier(random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "JQhAYxt60zmb",
        "pycharm": {}
      },
      "source": [
        "### Random Search\n",
        "Run a Random Search using 10 fold cross validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "C2Se5T6T0zmi",
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "param_dist = {'max_depth': sp_randint(2, 50),\n",
        "              'max_features': sp_randint(1, X.shape[1]),\n",
        "              'min_samples_split': sp_randint(2, X_train.shape[0] / 2),\n",
        "              'n_estimators': sp_randint(20, 300),\n",
        "              'criterion': ['gini', 'entropy']}\n",
        "candidates = 50\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(clf, param_dist, candidates, cv=10, \n",
        "                                   n_jobs=-1, verbose=8, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "v0xWZG1Q1T58",
        "pycharm": {}
      },
      "source": [
        "### Grid Search\n",
        "Run a Grid search, using 10 fold cross validation for the area around the best results found with the Random Search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "xirLGV6L1T6U",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "param_grid = {'max_depth': range(32, 34),\n",
        "              'max_features': range(10, 12),\n",
        "              'min_samples_split': range(21, 23),\n",
        "              'n_estimators': range(115, 120),\n",
        "              'criterion': ['entropy', 'gini']}\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=10, n_jobs=-1, verbose=8,\n",
        "                           iid=True)\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'\n",
        "      .format((time.time() - start)))\n",
        "report(grid_search.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "clL80GLK16XP",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Predict using the Random Forest Ensemble.\n",
        "Make prediction with the Random Forest Ensemble, using the best parameters found from the above procedure.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "XTkdwobf2N2r",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Add best values for the classifier.\n",
        "clf.max_depth = 32\n",
        "clf.max_features = 10\n",
        "clf.min_samples_split = 21\n",
        "clf.n_estimators = 116\n",
        "clf.criterion = 'entropy'\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred, 'binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "ThktNeMrhsR7",
        "pycharm": {}
      },
      "source": [
        "## Stacking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "pKKiQ7W2s7Dg",
        "pycharm": {}
      },
      "source": [
        "# Define the stacking classifier.\n",
        "clf1 = KNeighborsClassifier()\n",
        "clf2 = LinearSVC(random_state=0)\n",
        "clf3 = DecisionTreeClassifier(random_state=0)\n",
        "clf4 = GaussianNB()\n",
        "meta_clf = LogisticRegression(solver = 'lbfgs', multi_class = 'auto', \n",
        "                              random_state=0)\n",
        "sclf = StackingCVClassifier(classifiers=[clf1, clf2, clf3, clf4], \n",
        "                            meta_classifier=meta_clf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "3EMLY1mvhsSN",
        "pycharm": {}
      },
      "source": [
        "### Random Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "TwkKOJJQhsSY",
        "pycharm": {}
      },
      "source": [
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "param_dist = {'kneighborsclassifier__n_neighbors': sp_randint(1, 100),\n",
        "              'linearsvc__C': np.logspace(-3, 3),\n",
        "              'decisiontreeclassifier__max_depth': sp_randint(2, 60),\n",
        "              'meta-logisticregression__C': np.logspace(-3, 3)}\n",
        "\n",
        "candidates = 50\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(sclf, param_dist, candidates, cv=10, \n",
        "                                   n_jobs=-1, verbose=9, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds, for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "vYjx3OiwhsSx",
        "pycharm": {}
      },
      "source": [
        "### Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "da7O5ZxshsS2",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "param_grid = {'kneighborsclassifier__n_neighbors': range(39, 41),\n",
        "              'linearsvc__C': np.logspace(-1, 2, 8),\n",
        "              'decisiontreeclassifier__max_depth': range(14, 16),\n",
        "              'meta-logisticregression__C': np.logspace(-1, 2, 4)}\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(sclf, param_grid, cv = 10, n_jobs=-1, verbose=5,\n",
        "                           iid=True)\n",
        "\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'.format((time.time() - start)))\n",
        "report(grid_search.cv_results_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "epbVw_cWTj5u",
        "pycharm": {}
      },
      "source": [
        "### Plot stacking results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "CAwbQKNXToin",
        "pycharm": {}
      },
      "source": [
        "# Use best values for the classifier.\n",
        "clf1.n_neighbors = 40\n",
        "clf2.C = 100\n",
        "clf3.max_depth = 15\n",
        "meta_clf.C = 0.1\n",
        "\n",
        "# Plot accuracy +- std for each model separately\n",
        "# and compare it with the stacking model.\n",
        "clf_names = ['KNN', 'Linear-SVM', 'Decision Tree', 'Naive-Bayes',\n",
        "             'Logistic Regression', 'Stacking']\n",
        "models = clf1, clf2, clf3, clf4, meta_clf, sclf\n",
        "plot_accuracy_stacking(clf_names, models, X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "A_pV6hekJhmH",
        "pycharm": {}
      },
      "source": [
        "*Note:* in this case, the Naive Bayes classifier seems to affect negatively the total performance of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "7oaA3Zs09fo6",
        "pycharm": {}
      },
      "source": [
        "# Plot the learning curves.\n",
        "plot_learning_curve(models, clf_names, X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "t6fGqfRcsWUN",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Predict using the Stacking Ensemble.\n",
        "Create a classification report with the Stacking Ensemble.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "c4sZXToisWUW",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "# Fit and predict.\n",
        "clf2.C = 100\n",
        "sclf.fit(X_train,y_train)\n",
        "y_pred = sclf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred, 'binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YwB6jkoh3iK",
        "pycharm": {}
      },
      "source": [
        "## XGBoosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlY94qweh3ih",
        "pycharm": {}
      },
      "source": [
        "# Create XGBoost, using LogisticRegression classifier\n",
        "xgb_clf = xgb.XGBClassifier(learning_rate=0.03, n_estimators=600, \n",
        "                            objective='binary:logistic', silent=True, nthread=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykUsVzMLh3i_",
        "pycharm": {}
      },
      "source": [
        "### Random Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DtY5g0ch3jN",
        "pycharm": {}
      },
      "source": [
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "params = {'min_child_weight': sp_randint(4, 30),\n",
        "          'gamma': np.random.uniform(0.5, 4,size=5),\n",
        "          'subsample': np.random.uniform(0, 1, size=4),\n",
        "          'colsample_bytree': np.random.uniform(0, 1, size=4),\n",
        "          'max_depth': sp_randint(1, 7)}\n",
        "\n",
        "candidates = 50\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(xgb_clf, params, candidates, cv=10,\n",
        "                                   n_jobs=-1, verbose=5, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDSPOrArh3ji",
        "pycharm": {}
      },
      "source": [
        "### Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oi2qhFK6h3jm",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "params = {'min_child_weight': range(4, 6),\n",
        "          'gamma': np.arange(1.1, 1.3, 0.1),\n",
        "          'max_depth': range(1, 8)}\n",
        "xgb_clf.subsample = 0.78\n",
        "xgb_clf.colsample_bytree = 0.16\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(xgb_clf, params , cv = 10, n_jobs=-1, verbose=5,\n",
        "                           iid=True)\n",
        "\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'\n",
        "      .format((time.time() - start)))\n",
        "report(grid_search.cv_results_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVdIWpu7WxBh",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Predict using the boosted model.\n",
        "Make prediction with the XGBoosting method, using the best parameters found from the procedure above.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P78KRtL4WxBt",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Add best values for the classifier.\n",
        "xgb_clf.min_child_weight = 5\n",
        "xgb_clf.gamma = 1.1\n",
        "xgb_clf.max_depth = 7\n",
        "\n",
        "# Fit and predict.\n",
        "xgb_clf.fit(X_train,y_train)\n",
        "y_pred = xgb_clf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred, 'binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4iNUKGAc7Jz",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "# Wine\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__WkIId_c7J_",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "## Prepare the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sLs-pU0c7KJ",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "# Get x and y.\n",
        "X, y = load_wine(True)\n",
        "\n",
        "# Split to training and test pairs.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
        "                                                    random_state=0)\n",
        "\n",
        "# Scale data.\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train.astype(float))\n",
        "X_test = scaler.transform(X_test.astype(float))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8K3KVu9c7Ka",
        "pycharm": {}
      },
      "source": [
        "## Bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPX06iqYc7Kd",
        "pycharm": {}
      },
      "source": [
        "# Define a Decision Tree classifier for the ensemble.\n",
        "clf = DecisionTreeClassifier(random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVQEoU8Oc7Km",
        "pycharm": {}
      },
      "source": [
        "### Random Search\n",
        "Run a Random Search using 10 fold cross validation, for the classifier which will be used in the bagging."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyKy9iYxc7Kp",
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "param_dist = {'max_depth': sp_randint(1, 50),\n",
        "              'max_features': sp_randint(1, X.shape[1]),\n",
        "              'min_samples_split': sp_randint(2, X_train.shape[0] / 2),\n",
        "              'criterion': ['gini', 'entropy']}\n",
        "candidates = 1000\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(clf, param_dist, candidates, cv=10, \n",
        "                                   n_jobs=-1, verbose=5, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50aw_1RYc7K5",
        "pycharm": {}
      },
      "source": [
        "### Grid Search\n",
        "Run a Grid search, using 10 fold cross validation for the area around the best results found with the Random Search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tukYKudtc7K7",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "param_grid = {'max_depth': range(2, 12),\n",
        "              'max_features': range(2, 11),\n",
        "              'min_samples_split': range(25, 40),\n",
        "              'criterion': ['gini', 'entropy']}\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=10, n_jobs=-1, verbose=5, \n",
        "                           iid=True)\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'\n",
        "      .format((time.time() - start)))\n",
        "report(grid_search.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozXGbWhRc7LK",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Create the Bagging Ensemble.\n",
        "Create the Bagging Ensemble, using the best parameters found from the above procedure.  \n",
        "Since the mean accuracy is the same, we are using the best scores with the minimum std, between the different CV folds.  \n",
        "We make prediction to the test data, which were left out at the train-test-split procedure and not to the training data again.  \n",
        "We are using a 10 fold cross validation method, in order to visualize the best number of classifiers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8MzfrcDc7LS",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Add best values for the classifier.\n",
        "clf.max_depth = 3\n",
        "clf.max_features = 6\n",
        "clf.min_samples_split = 32\n",
        "clf.criterion = 'gini'\n",
        "\n",
        "# Plot accuracy vs number of estimators for [100, 200, ..., 1000] estimators.\n",
        "estimators_vs_acc(clf, X_train, y_train, estimators_array=range(1, 1100, 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDa5iy5fc7Lj",
        "pycharm": {}
      },
      "source": [
        "### Predict\n",
        "Predict using the best number of classifiers, based on the previous cross validation method.  \n",
        "The best number of estimators seems to be 100, since the accuracy is high  \n",
        "and the lower bound of it's deviation is better than the others."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdWUNlKnc7Lo",
        "pycharm": {}
      },
      "source": [
        "# Create the bagging classifier.\n",
        "bg_clf = BaggingClassifier(base_estimator=clf, n_estimators=100, random_state=0)\n",
        "\n",
        "# Fit and predict.\n",
        "bg_clf.fit(X_train, y_train)\n",
        "y_pred = bg_clf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BOgd-WVc7L-",
        "pycharm": {}
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxRWpM-kc7MB",
        "pycharm": {}
      },
      "source": [
        "# Define a Random Forest classifier.\n",
        "clf = RandomForestClassifier(random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5vdiluPc7MK",
        "pycharm": {}
      },
      "source": [
        "### Random Search\n",
        "Run a Random Search using 10 fold cross validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XxnQTeec7MN",
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "param_dist = {'max_depth': sp_randint(2, 50),\n",
        "              'max_features': sp_randint(1, X.shape[1]),\n",
        "              'min_samples_split': sp_randint(2, X_train.shape[0] / 2),\n",
        "              'n_estimators': sp_randint(20, 300),\n",
        "              'criterion': ['gini', 'entropy']}\n",
        "candidates = 50\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(clf, param_dist, candidates, cv=10, \n",
        "                                   n_jobs=-1, verbose=8, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dFB_WJ0c7Mc",
        "pycharm": {}
      },
      "source": [
        "### Grid Search\n",
        "Run a Grid search, using 10 fold cross validation for the area around the best results found with the Random Search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvUaZtAGc7Me",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "param_grid = {'max_depth': range(36, 40),\n",
        "              'max_features': range(6, 10),\n",
        "              'min_samples_split': range(12, 14),\n",
        "              'n_estimators': range(34, 44, 2),\n",
        "              'criterion': ['entropy', 'gini']}\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=10, n_jobs=-1, verbose=8,\n",
        "                           iid=True)\n",
        "start = time.time()\n",
        "grid_search.fit(X, y)\n",
        "print('GridSearchCV took {:.2f} seconds.'\n",
        "      .format((time.time() - start)))\n",
        "report(grid_search.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPRFiwCMc7Mr",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Predict using the Random Forest Ensemble.\n",
        "Make prediction with the Random Forest Ensemble, using the best parameters found from the above procedure.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e727SNs4c7Mx",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Add best values for the classifier.\n",
        "clf.max_depth = 36\n",
        "clf.max_features = 6\n",
        "clf.min_samples_split = 12\n",
        "clf.n_estimators = 34\n",
        "clf.criterion = 'entropy'\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-yPEm4lc7NC",
        "pycharm": {}
      },
      "source": [
        "## Stacking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOQaqb9Ac7NE",
        "pycharm": {}
      },
      "source": [
        "# Define the stacking classifier.\n",
        "clf1 = KNeighborsClassifier()\n",
        "clf2 = LinearSVC(random_state=0)\n",
        "clf3 = DecisionTreeClassifier(random_state=0)\n",
        "clf4 = GaussianNB()\n",
        "meta_clf = LogisticRegression(solver = 'lbfgs', multi_class = 'auto', \n",
        "                              random_state=0)\n",
        "sclf = StackingCVClassifier(classifiers=[clf1, clf2, clf3, clf4], \n",
        "                            meta_classifier=meta_clf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ud4usvc3c7NS",
        "pycharm": {}
      },
      "source": [
        "### Random Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ublzn6ukc7NV",
        "pycharm": {}
      },
      "source": [
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "param_dist = {'kneighborsclassifier__n_neighbors': sp_randint(1, 50),\n",
        "              'linearsvc__C': [0.01, 0.1, 1, 10, 100],\n",
        "              'decisiontreeclassifier__max_depth': sp_randint(2, 60),\n",
        "              'meta-logisticregression__C': [0.01, 0.1, 1, 10, 100, 1000]}\n",
        "\n",
        "candidates = 50\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(sclf, param_dist, candidates, cv=10, \n",
        "                                   n_jobs=-1, verbose=9, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds, for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNWn6dHVc7Nk",
        "pycharm": {}
      },
      "source": [
        "### Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nCUawOkc7Nn",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "param_grid = {'kneighborsclassifier__n_neighbors': range(40, 44),\n",
        "              'decisiontreeclassifier__max_depth': range(42, 46),\n",
        "              'linearsvc__C': np.logspace(-1, 1, 8),\n",
        "              'meta-logisticregression__C': range(90, 110, 2)}\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(sclf, param_grid, cv = 10, n_jobs=-1, verbose=5,\n",
        "                           iid=True)\n",
        "\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'.format((time.time() - start)))\n",
        "report(grid_search.cv_results_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIaoQIIcc7N0",
        "pycharm": {}
      },
      "source": [
        "### Plot stacking results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGI4iP5Bc7N4",
        "pycharm": {}
      },
      "source": [
        "# Use best values for the classifier.\n",
        "clf1.n_neighbors = 42\n",
        "clf2.C = 1\n",
        "clf3.max_depth = 44\n",
        "meta_clf.C = 100\n",
        "\n",
        "# Plot accuracy +- std for each model separately\n",
        "# and compare it with the stacking model.\n",
        "clf_names = ['KNN', 'Linear-SVM', 'Decision Tree', 'Naive-Bayes',\n",
        "             'Logistic Regression', 'Stacking']\n",
        "models = clf1, clf2, clf3, clf4, meta_clf, sclf\n",
        "plot_accuracy_stacking(clf_names, models, X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjD67PPgc7OF",
        "pycharm": {}
      },
      "source": [
        "*Note:* in this case, we notice that the logistic regression model would not have managed to classify the samples well. However, it is very useful for the classification of the meta-samples. By changing the value of C above to 0.1, it becomes clear, because the model's accuracy to the initial data becomes higher, while the stacking model's accuracy decreases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0uMuhZlc7OM",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Predict using the Stacking Ensemble.\n",
        "Create a classification report with the Stacking Ensemble.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdBLiMcpc7ON",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "# Fit and predict.\n",
        "sclf.fit(X_train,y_train)\n",
        "y_pred = sclf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85pe5i05c7OV",
        "pycharm": {}
      },
      "source": [
        "## XGBoosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjFZaYHZc7OX",
        "pycharm": {}
      },
      "source": [
        "# Create XGBoost, using LogisticRegression classifier\n",
        "xgb_clf = xgb.XGBClassifier(learning_rate=0.03, n_estimators=600, \n",
        "                            objective='binary:logistic', silent=True, nthread=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "li5580u5c7Oa",
        "pycharm": {}
      },
      "source": [
        "### Random Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6lRtgisc7Oi",
        "pycharm": {}
      },
      "source": [
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "params = {'min_child_weight': sp_randint(4, 30),\n",
        "          'gamma': np.random.uniform(0.5, 4,size=5),\n",
        "          'subsample': np.random.uniform(0, 1, size=4),\n",
        "          'colsample_bytree': np.random.uniform(0, 1, size=4),\n",
        "          'max_depth': sp_randint(1, 7)}\n",
        "\n",
        "candidates = 200\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(xgb_clf, params, candidates, cv=10,\n",
        "                                   n_jobs=-1, verbose=5, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEpoXV0Dc7Ot",
        "pycharm": {}
      },
      "source": [
        "### Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGBzhUMkc7Ov",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "params = {'min_child_weight': range(7, 12),\n",
        "          'gamma': np.arange(2.6, 2.8, 0.1),\n",
        "          'max_depth': range(2, 4)}\n",
        "xgb_clf.subsample = 0.82\n",
        "xgb_clf.colsample_bytree = 0.23\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(xgb_clf, params , cv = 10, n_jobs=-1, verbose=5,\n",
        "                           iid=True)\n",
        "\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'\n",
        "      .format((time.time() - start)))\n",
        "report(grid_search.cv_results_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIrEGlnLc7PB",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Predict using the boosted model.\n",
        "Make prediction with the XGBoosting method, using the best parameters found from the procedure above.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkLCL_bLc7PD",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Add best values for the classifier.\n",
        "xgb_clf.min_child_weight = 7\n",
        "xgb_clf.gamma = 2.6\n",
        "xgb_clf.max_depth = 2\n",
        "\n",
        "# Fit and predict.\n",
        "xgb_clf.fit(X_train,y_train)\n",
        "y_pred = xgb_clf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3U_8Bfwc-LP",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "# Iris\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djXjx8Y7c-LT",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "## Prepare the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iZFvLqgc-LU",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "# Read the dataset.\n",
        "iris = load_iris()\n",
        "\n",
        "# Get x and y.\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split to training and test pairs.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
        "                                                    random_state=0)\n",
        "\n",
        "# Scale data.\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train.astype(float))\n",
        "X_test = scaler.transform(X_test.astype(float))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqvLsLrPc-Lc",
        "pycharm": {}
      },
      "source": [
        "## Bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw68Xa1Bc-Le",
        "pycharm": {}
      },
      "source": [
        "# Define a Decision Tree classifier for the ensemble.\n",
        "clf = DecisionTreeClassifier(random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KCtD_HKc-Lk",
        "pycharm": {}
      },
      "source": [
        "### Random Search\n",
        "Run a Random Search using 10 fold cross validation, for the classifier which will be used in the bagging."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NASBKBf9c-Ln",
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "param_dist = {'max_depth': sp_randint(1, 30),\n",
        "              'max_features': sp_randint(1, X_train.shape[1]),\n",
        "              'min_samples_split': sp_randint(2, X_train.shape[0] / 2),\n",
        "              'criterion': ['gini', 'entropy']}\n",
        "candidates = 200\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(clf, param_dist, candidates, cv=10, \n",
        "                                   n_jobs=-1, verbose=5, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuM7yBjnc-Lt",
        "pycharm": {}
      },
      "source": [
        "### Grid Search\n",
        "Run a Grid search, using 10 fold cross validation for the area around the best results found with the Random Search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcFVampGc-L0",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "param_grid = {'max_depth': range(8, 12),\n",
        "              'max_features': range(2, 5),\n",
        "              'min_samples_split': range(6, 10),\n",
        "              'criterion': ['gini', 'entropy']}\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=10, n_jobs=-1, verbose=5, \n",
        "                           iid=True)\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'\n",
        "      .format((time.time() - start)))\n",
        "report(grid_search.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMcbgBrjc-MI",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Create the Bagging Ensemble.\n",
        "Create the Bagging Ensemble, using the best parameters found from the above procedure.  \n",
        "Since the mean accuracy is the same, we are using the best scores with the minimum std, between the different CV folds.  \n",
        "We make prediction to the test data, which were left out at the train-test-split procedure and not to the training data again.  \n",
        "We are using a 10 fold cross validation method, in order to visualize the best number of classifiers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nShL4SKVc-ML",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Add best values for the classifier.\n",
        "clf.max_depth = 8\n",
        "clf.max_features = 3\n",
        "clf.min_samples_split = 6\n",
        "clf.criterion = 'gini'\n",
        "\n",
        "# Plot accuracy vs number of estimators.\n",
        "estimators_vs_acc(clf, X_train, y_train, estimators_array=range(1, 1000, 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHfAdbXic-Ma",
        "pycharm": {}
      },
      "source": [
        "### Predict\n",
        "Predict using the best number of classifiers, based on the previous cross validation method.  \n",
        "There isn't a difference between the numbers of the estimators so we will take the minimum and thats 100 since\n",
        "accuracy and standard deviation seem to be on the same levels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xs5u-gAc-Ma",
        "pycharm": {}
      },
      "source": [
        "# Create the bagging classifier.\n",
        "bg_clf = BaggingClassifier(base_estimator=clf, n_estimators=100, random_state=0)\n",
        "\n",
        "# Fit and predict.\n",
        "bg_clf.fit(X_train, y_train)\n",
        "y_pred = bg_clf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9K3tySu_c-Mn",
        "pycharm": {}
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKezK8k0c-Mp",
        "pycharm": {}
      },
      "source": [
        "# Define a Random Forest classifier.\n",
        "clf = RandomForestClassifier(random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LC9j271c-Mr",
        "pycharm": {}
      },
      "source": [
        "### Random Search\n",
        "Run a Random Search using 10 fold cross validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjufsTwrc-Ms",
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "param_dist = {'max_depth': sp_randint(2, 50),\n",
        "              'max_features': sp_randint(1, X.shape[1]),\n",
        "              'min_samples_split': sp_randint(2, X.shape[0] / 2),\n",
        "              'n_estimators': sp_randint(20, 300),\n",
        "              'criterion': ['gini', 'entropy']}\n",
        "candidates = 50\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(clf, param_dist, candidates, cv=10, \n",
        "                                   n_jobs=-1, verbose=8, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pcb_J0pCc-M0",
        "pycharm": {}
      },
      "source": [
        "### Grid Search\n",
        "Run a Grid search, using 10 fold cross validation for the area around the best results found with the Random Search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbORsKhTc-M0",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "param_grid = {'max_depth': range(38, 42),\n",
        "              'max_features': range(1, 4),\n",
        "              'min_samples_split': range(10, 14),\n",
        "              'n_estimators': range(290, 305, 5),\n",
        "              'criterion': ['gini']}\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=10, n_jobs=-1, verbose=8,\n",
        "                           iid=True)\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'\n",
        "      .format((time.time() - start)))\n",
        "report(grid_search.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imDFjBOgc-NA",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Predict using the Random Forest Ensemble.\n",
        "Make prediction with the Random Forest Ensemble, using the best parameters found from the above procedure.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffRmH1yKc-NE",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Add best values for the classifier.\n",
        "clf.max_depth = 38\n",
        "clf.max_features = 1\n",
        "clf.min_samples_split = 10\n",
        "clf.n_estimators = 290\n",
        "clf.criterion = 'gini'\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3xm6ZpIc-NN",
        "pycharm": {}
      },
      "source": [
        "## Stacking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho1VFZjyc-NQ",
        "pycharm": {}
      },
      "source": [
        "# Define the stacking classifier.\n",
        "clf1 = KNeighborsClassifier()\n",
        "clf2 = LinearSVC(random_state=0)\n",
        "clf3 = DecisionTreeClassifier(random_state=0)\n",
        "clf4 = GaussianNB()\n",
        "meta_clf = LogisticRegression(solver = 'lbfgs', multi_class = 'auto', \n",
        "                              random_state=0)\n",
        "sclf = StackingCVClassifier(classifiers=[clf1, clf2, clf3, clf4], \n",
        "                            meta_classifier=meta_clf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7Ke-jYHc-NS",
        "pycharm": {}
      },
      "source": [
        "### Random Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6TlkUSSc-NT",
        "pycharm": {}
      },
      "source": [
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "param_dist = {'kneighborsclassifier__n_neighbors': sp_randint(1, 40),\n",
        "              'linearsvc__C': [0.01, 0.1, 1, 10, 100],\n",
        "              'decisiontreeclassifier__max_depth': sp_randint(2, 60),\n",
        "              'meta-logisticregression__C': [0.01, 0.1, 1, 10, 100, 1000]}\n",
        "\n",
        "candidates = 50\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(sclf, param_dist, candidates, cv=10, \n",
        "                                   n_jobs=-1, verbose=9, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds, for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YxjGgetc-Nf",
        "pycharm": {}
      },
      "source": [
        "### Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpfVImf8c-Nh",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "param_grid = {'kneighborsclassifier__n_neighbors': range(10, 13),\n",
        "              'linearsvc__C': [0.1,0.2,0.3,0.4,0.5],\n",
        "              'decisiontreeclassifier__max_depth': range(8, 12),\n",
        "              'meta-logisticregression__C': [0.5, 1, 1.5]}\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(sclf, param_grid, cv = 10, n_jobs=-1, verbose=5,\n",
        "                           iid=True)\n",
        "\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'.format((time.time() - start)))\n",
        "report(grid_search.cv_results_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMJMJ66ac-Nv",
        "pycharm": {}
      },
      "source": [
        "### Plot stacking results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td4gGJlJc-N1",
        "pycharm": {}
      },
      "source": [
        "# Use best values for the classifier.\n",
        "clf1.n_neighbors = 11\n",
        "clf2.C = 0.2\n",
        "clf3.max_depth = 8\n",
        "meta_clf.C = 0.5\n",
        "\n",
        "# Plot accuracy +- std for each model separately\n",
        "# and compare it with the stacking model.\n",
        "clf_names = ['KNN', 'Linear-SVM', 'Decision Tree', 'Naive-Bayes',\n",
        "             'Logistic Regression', 'Stacking']\n",
        "models = clf1, clf2, clf3, clf4, meta_clf, sclf\n",
        "plot_accuracy_stacking(clf_names, models, X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09VJeNSZc-N8",
        "pycharm": {}
      },
      "source": [
        "*Note:* in this case, the Linear SVM classifier seems to affect negatively the total performance of the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjh88cHw-tvv",
        "pycharm": {}
      },
      "source": [
        "# Plot the learning curves.\n",
        "plot_learning_curve(models, clf_names, X_train, y_train,train_sizes=np.linspace(0.4, 1.0, 5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArwQXvdKc-N9",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Predict using the Stacking Ensemble.\n",
        "Create a classification report with the Stacking Ensemble.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfvAvY7hc-N-",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "# Fit and predict.\n",
        "sclf.fit(X_train,y_train)\n",
        "y_pred = sclf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQ7JFpAJc-OD",
        "pycharm": {}
      },
      "source": [
        "## XGBoosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PT2SvVJwc-OH",
        "pycharm": {}
      },
      "source": [
        "# Create XGBoost, using LogisticRegression classifier\n",
        "xgb_clf = xgb.XGBClassifier(learning_rate=0.03, n_estimators=600, \n",
        "                            objective='binary:logistic', silent=True, nthread=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtQHYs-kc-OO",
        "pycharm": {}
      },
      "source": [
        "### Random Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHPGX1Foc-OP",
        "pycharm": {}
      },
      "source": [
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "params = {'min_child_weight': sp_randint(4, 30),\n",
        "          'gamma': np.random.uniform(0.5, 4,size=5),\n",
        "          'subsample': np.random.uniform(0, 1, size=4),\n",
        "          'colsample_bytree': np.random.uniform(0, 1, size=4),\n",
        "          'max_depth': sp_randint(1, 7)}\n",
        "\n",
        "candidates = 50\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(xgb_clf, params, candidates, cv=10,\n",
        "                                   n_jobs=-1, verbose=5, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqg-K4t2c-Of",
        "pycharm": {}
      },
      "source": [
        "### Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iML3Ks7tc-Og",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "params = {'min_child_weight': range(7, 12),\n",
        "          'gamma': [2.4, 2.5, 2.6],\n",
        "          'max_depth': range(3, 7)}\n",
        "xgb_clf.subsample = 0.91\n",
        "xgb_clf.colsample_bytree = 0.19\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(xgb_clf, params , cv = 10, n_jobs=-1, verbose=5,\n",
        "                           iid=True)\n",
        "\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'\n",
        "      .format((time.time() - start)))\n",
        "report(grid_search.cv_results_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQv3VCAuc-Ot",
        "pycharm": {}
      },
      "source": [
        "*Note:* The Grid Search procedure did not give better accuracy score, but lead to better std."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLGzdBcbc-Ov",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Predict using the boosted model.\n",
        "Make prediction with the XGBoosting method, using the best parameters found from the procedure above.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLegkFlRc-Ov",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Add best values for the classifier.\n",
        "xgb_clf.min_child_weight = 7\n",
        "xgb_clf.gamma = 2.4\n",
        "xgb_clf.max_depth = 3\n",
        "\n",
        "# Fit and predict.\n",
        "xgb_clf.fit(X_train,y_train)\n",
        "y_pred = xgb_clf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQL_r0tsdKkm",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "# Breast Cancer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUABbIVzd2Vj",
        "pycharm": {}
      },
      "source": [
        "## Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUH0baphd2Vy",
        "pycharm": {}
      },
      "source": [
        "data = read_csv('C:/Users/User/Desktop/Project ml/datasets/breast-cancer-wisconsin-data/data.csv')\n",
        "y = data['diagnosis']\n",
        "unnecessary = ['Unnamed: 32','id','diagnosis']\n",
        "X = data.drop(unnecessary,axis = 1 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkLFYCxTd2WD",
        "pycharm": {}
      },
      "source": [
        "### Visualize number of data per class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFAa0-sUd2WK",
        "pycharm": {}
      },
      "source": [
        "ax = sns.countplot(y,label=\"Count\")       # M = 212, B = 357\n",
        "B, M = y.value_counts()\n",
        "print('Number of Benign: ',B)\n",
        "print('Number of Malignant : ',M)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "D6iqp3wB0Ho1"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {},
        "id": "FBdWg3le0Ho1"
      },
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(y)\n",
        "y = le.transform(y)\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "# Scale data.\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train.astype(float))\n",
        "X_test = scaler.transform(X_test.astype(float))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUbrU7yFdKlQ",
        "pycharm": {}
      },
      "source": [
        "## Bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B03fZ9rYdKlV",
        "pycharm": {}
      },
      "source": [
        "# Define a Decision Tree classifier for the ensemble.\n",
        "clf = DecisionTreeClassifier(random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2It4ndiZdKle",
        "pycharm": {}
      },
      "source": [
        "### Random Search\n",
        "Run a Random Search using 10 fold cross validation, for the classifier which will be used in the bagging."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBRx1nx_dKlh",
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "param_dist = {'max_depth': sp_randint(1, 30),\n",
        "              'max_features': sp_randint(1, X.shape[1]),\n",
        "              'min_samples_split': sp_randint(2, X.shape[0] / 2),\n",
        "              'criterion': ['gini', 'entropy']}\n",
        "candidates = 200\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(clf, param_dist, candidates, cv=10, \n",
        "                                   n_jobs=-1, verbose=5, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccYFS2r0dKlv",
        "pycharm": {}
      },
      "source": [
        "### Grid Search\n",
        "Run a Grid search, using 10 fold cross validation for the area around the best results found with the Random Search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNKgXDfodKly",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "param_grid = {'max_depth': range(12, 14),\n",
        "              'max_features': range(13, 18),\n",
        "              'min_samples_split': range(6, 9),\n",
        "              'criterion': ['gini', 'entropy']}\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=10, n_jobs=-1, verbose=5, \n",
        "                           iid=True)\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'\n",
        "      .format((time.time() - start)))\n",
        "report(grid_search.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XriPg9kbdKl_",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Create the Bagging Ensemble.\n",
        "Create the Bagging Ensemble, using the best parameters found from the above procedure.  \n",
        "Since the mean accuracy is the same, we are using the best scores with the minimum std, between the different CV folds.  \n",
        "We make prediction to the test data, which were left out at the train-test-split procedure and not to the training data again.  \n",
        "We are using a 10 fold cross validation method, in order to visualize the best number of classifiers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cgn_zCLXdKmB",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Add best values for the classifier.\n",
        "clf.max_depth = 12\n",
        "clf.max_features = 13\n",
        "clf.min_samples_split = 7\n",
        "clf.criterion = 'entropy'\n",
        "\n",
        "# Plot accuracy vs number of estimators.\n",
        "estimators_vs_acc(clf, X_train, y_train, estimators_array=range(1, 1000, 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VU8hYPf0dKmT",
        "pycharm": {}
      },
      "source": [
        "### Predict\n",
        "Predict using the best number of classifiers, based on the previous cross validation method.  \n",
        "The best number of estimators seems to be 600 and 700, since the accuracy is high,  \n",
        "the lower bound of it's deviation is better than the others and the higher bound, is the best."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qfxzc_NMdKmX",
        "pycharm": {}
      },
      "source": [
        "# Create the bagging classifier.\n",
        "bg_clf = BaggingClassifier(base_estimator=clf, n_estimators=600, random_state=0)\n",
        "\n",
        "# Fit and predict.\n",
        "bg_clf.fit(X_train, y_train)\n",
        "y_pred = bg_clf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-vrR1X3dKmv",
        "pycharm": {}
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eSExU3gdKmy",
        "pycharm": {}
      },
      "source": [
        "# Define a Random Forest classifier.\n",
        "clf = RandomForestClassifier(random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1X8Mgg9adKm5",
        "pycharm": {}
      },
      "source": [
        "### Random Search\n",
        "Run a Random Search using 10 fold cross validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mm7kByjdKnD",
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "param_dist = {'max_depth': sp_randint(2, 50),\n",
        "              'max_features': sp_randint(1, X.shape[1]),\n",
        "              'min_samples_split': sp_randint(2, X.shape[0] / 2),\n",
        "              'n_estimators': sp_randint(20, 300),\n",
        "              'criterion': ['gini', 'entropy']}\n",
        "candidates = 50\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(clf, param_dist, candidates, cv=10, \n",
        "                                   n_jobs=-1, verbose=8, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am8nShkEdKnT",
        "pycharm": {}
      },
      "source": [
        "### Grid Search\n",
        "Run a Grid search, using 10 fold cross validation for the area around the best results found with the Random Search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlSjmWeudKnW",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "param_grid = {'max_depth': range(19,22),\n",
        "              'max_features': range(1,4),\n",
        "              'min_samples_split': range(8,11),\n",
        "              'n_estimators': range(80, 90, 2),\n",
        "              'criterion': ['entropy', 'gini']}\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=5, n_jobs=-1, verbose=8,\n",
        "                           iid=True)\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'\n",
        "      .format((time.time() - start)))\n",
        "report(grid_search.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFm9UkG3dKnq",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Predict using the Random Forest Ensemble.\n",
        "Make prediction with the Random Forest Ensemble, using the best parameters found from the above procedure.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqnZxOhRdKnt",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Add best values for the classifier.\n",
        "clf.max_depth = 19\n",
        "clf.max_features = 2\n",
        "clf.min_samples_split = 10\n",
        "clf.n_estimators = 84\n",
        "clf.criterion = 'entropy'\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-NnrcgjdKn7",
        "pycharm": {}
      },
      "source": [
        "## Stacking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URuBdJH3dKn_",
        "pycharm": {}
      },
      "source": [
        "# Define the stacking classifier.\n",
        "clf1 = KNeighborsClassifier()\n",
        "clf2 = LinearSVC(random_state=0)\n",
        "clf3 = DecisionTreeClassifier(random_state=0)\n",
        "clf4 = GaussianNB()\n",
        "meta_clf = LogisticRegression(solver = 'lbfgs', multi_class = 'auto', \n",
        "                              random_state=0)\n",
        "sclf = StackingCVClassifier(classifiers=[clf1, clf2, clf3, clf4], \n",
        "                            meta_classifier=meta_clf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMkPP5xBdKoP",
        "pycharm": {}
      },
      "source": [
        "### Random Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHi5xBX-dKoS",
        "pycharm": {}
      },
      "source": [
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "param_dist = {'kneighborsclassifier__n_neighbors': sp_randint(1, 100),\n",
        "              'linearsvc__C': [0.01, 0.1, 1, 10, 100],\n",
        "              'decisiontreeclassifier__max_depth': sp_randint(2, 60),\n",
        "              'meta-logisticregression__C': [0.01, 0.1, 1, 10, 100, 1000]}\n",
        "\n",
        "candidates = 50\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(sclf, param_dist, candidates, cv=10, \n",
        "                                   n_jobs=-1, verbose=9, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds, for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr3fZX-_dKop",
        "pycharm": {}
      },
      "source": [
        "### Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23hSFsqEdKos",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "param_grid = {'kneighborsclassifier__n_neighbors': range(21,25),\n",
        "              'linearsvc__C': [1,1.2,1.5,2],\n",
        "              'decisiontreeclassifier__max_depth': range(39, 44),\n",
        "              'meta-logisticregression__C': range(98,103)}\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(sclf, param_grid, cv = 5, n_jobs=-1, verbose=5,\n",
        "                           iid=True)\n",
        "\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'.format((time.time() - start)))\n",
        "report(grid_search.cv_results_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zz12-4kXdKo6",
        "pycharm": {}
      },
      "source": [
        "### Plot stacking results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZKsMa_zdKpB",
        "pycharm": {}
      },
      "source": [
        "# Use best values for the classifier.\n",
        "clf1.n_neighbors = 21\n",
        "clf2.C = 1.2\n",
        "clf3.max_depth = 39\n",
        "meta_clf.C = 100\n",
        "\n",
        "# Plot accuracy +- std for each model separately\n",
        "# and compare it with the stacking model.\n",
        "clf_names = ['KNN', 'Linear-SVM', 'Decision Tree', 'Naive-Bayes',\n",
        "             'Logistic Regression', 'Stacking']\n",
        "models = clf1, clf2, clf3, clf4, meta_clf, sclf\n",
        "plot_accuracy_stacking(clf_names, models, X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BQ4Vqi6dKpQ",
        "pycharm": {}
      },
      "source": [
        "*Note:* in this case, the Naive Bayes classifier and Decision Tree Classifier seem to affect negatively the total performance of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6vboCXW-0M3",
        "pycharm": {}
      },
      "source": [
        "# Plot the learning curves.\n",
        "plot_learning_curve(models, clf_names, X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poyC78TydKpS",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Predict using the Stacking Ensemble.\n",
        "Create a classification report with the Stacking Ensemble.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DqUR156dKpV",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "# Fit and predict.\n",
        "sclf.fit(X_train,y_train)\n",
        "y_pred = sclf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHCpZRS6dKpc",
        "pycharm": {}
      },
      "source": [
        "## XGBoosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxoQgPfkdKpe",
        "pycharm": {}
      },
      "source": [
        "# Create XGBoost, using LogisticRegression classifier\n",
        "xgb_clf = xgb.XGBClassifier(learning_rate=0.03, n_estimators=600, \n",
        "                            objective='binary:logistic', silent=True, nthread=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6S4ZF4dxdKpj",
        "pycharm": {}
      },
      "source": [
        "### Random Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-DXcXQkdKpr",
        "pycharm": {}
      },
      "source": [
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "params = {'min_child_weight': sp_randint(4, 30),\n",
        "          'gamma': np.random.uniform(0.5, 4,size=5),\n",
        "          'subsample': np.random.uniform(0, 1, size=4),\n",
        "          'colsample_bytree': np.random.uniform(0, 1, size=4),\n",
        "          'max_depth': sp_randint(1, 7)}\n",
        "\n",
        "candidates = 50\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(xgb_clf, params, candidates, cv=10,\n",
        "                                   n_jobs=-1, verbose=5, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aT0jqGAdKpx",
        "pycharm": {}
      },
      "source": [
        "### Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKa0sNY_dKp4",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "params = {'min_child_weight': range(8, 13),\n",
        "          'gamma': [3.1, 3.2, 3.4,3.5],\n",
        "          'max_depth': range(4, 8)}\n",
        "xgb_clf.subsample = 0.97\n",
        "xgb_clf.colsample_bytree = 0.79\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(xgb_clf, params , cv = 10, n_jobs=-1, verbose=5,\n",
        "                           iid=True)\n",
        "\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'\n",
        "      .format((time.time() - start)))\n",
        "report(grid_search.cv_results_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMo0rMfcdKqI",
        "pycharm": {}
      },
      "source": [
        "*Note:* The Grid Search procedure did not give better accuracy score, but lead to better std."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FEGw46NdKqJ",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Predict using the boosted model.\n",
        "Make prediction with the XGBoosting method, using the best parameters found from the procedure above.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXPbvOhLdKqL",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Add best values for the classifier.\n",
        "xgb_clf.min_child_weight = 8\n",
        "xgb_clf.gamma = 3.1\n",
        "xgb_clf.max_depth = 4\n",
        "\n",
        "# Fit and predict.\n",
        "xgb_clf.fit(X_train,y_train)\n",
        "y_pred = xgb_clf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yq39E1Oqc_Pq",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "# Seeds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga3b-5Skc_Pv",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "## Prepare the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d2bqwdmc_Px",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Read the dataset.\n",
        "url=\"https://archive.ics.uci.edu/ml/machine-learning-databases/00236/seeds_dataset.txt\"\n",
        "s=requests.get(url).content\n",
        "dataset=read_csv(io.StringIO(s.decode('utf-8')), sep='\\t+', engine='python', lineterminator='\\n')\n",
        "\n",
        "# Get x and y.\n",
        "X, y = dataset.iloc[:, :-1].values, dataset.iloc[:, -1].values\n",
        "\n",
        "# Split to training and test pairs.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
        "                                                    stratify=y, random_state=0)\n",
        "\n",
        "# Scale data.\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train.astype(float))\n",
        "X_test = scaler.transform(X_test.astype(float))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kv3cC6jc_P0",
        "pycharm": {}
      },
      "source": [
        "## Bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKU7EDQ6c_P4",
        "pycharm": {}
      },
      "source": [
        "# Define a Decision Tree classifier for the ensemble.\n",
        "clf = DecisionTreeClassifier(random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bwz3b3Xbc_P8",
        "pycharm": {}
      },
      "source": [
        "### Random Search\n",
        "Run a Random Search using 10 fold cross validation, for the classifier which will be used in the bagging."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJAtM7Bbc_P9",
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "param_dist = {'max_depth': sp_randint(1, 30),\n",
        "              'max_features': sp_randint(1, X.shape[1]),\n",
        "              'min_samples_split': sp_randint(2, X.shape[0] / 2),\n",
        "              'criterion': ['gini', 'entropy']}\n",
        "candidates = 200\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(clf, param_dist, candidates, cv=10, \n",
        "                                   n_jobs=-1, verbose=5, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CN7qVSac_QF",
        "pycharm": {}
      },
      "source": [
        "### Grid Search\n",
        "Run a Grid search, using 10 fold cross validation for the area around the best results found with the Random Search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONkVhYG-c_QH",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "param_grid = {'max_depth': range(7, 15),\n",
        "              'max_features': range(1, X.shape[1]),\n",
        "              'min_samples_split': range(35, 55),\n",
        "              'criterion': ['gini', 'entropy']}\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=10, n_jobs=-1, verbose=5, \n",
        "                           iid=True)\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'\n",
        "      .format((time.time() - start)))\n",
        "report(grid_search.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H45lmxZbc_QL",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Create the Bagging Ensemble.\n",
        "Create the Bagging Ensemble, using the best parameters found from the above procedure.  \n",
        "Since the mean accuracy is the same, we are using the best scores with the minimum std, between the different CV folds.  \n",
        "We make prediction to the test data, which were left out at the train-test-split procedure and not to the training data again.  \n",
        "We are using a 10 fold cross validation method, in order to visualize the best number of classifiers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u9gT0Stc_QM",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Add best values for the classifier.\n",
        "clf.max_depth = 7\n",
        "clf.max_features = 5\n",
        "clf.min_samples_split = 45\n",
        "clf.criterion = 'gini'\n",
        "\n",
        "# Plot accuracy vs number of estimators.\n",
        "estimators_vs_acc(clf, X_train, y_train, estimators_array=range(1, 1000, 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TNU_i5ybgNW",
        "pycharm": {}
      },
      "source": [
        "*Note:* The method in this dataset seems to result in a model with big variance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c64RsLhc_QS",
        "pycharm": {}
      },
      "source": [
        "### Predict\n",
        "Predict using the best number of classifiers, based on the previous cross validation method.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIwr1F6Dc_QU",
        "pycharm": {}
      },
      "source": [
        "# Create the bagging classifier.\n",
        "bg_clf = BaggingClassifier(base_estimator=clf, n_estimators=600, random_state=0)\n",
        "\n",
        "# Fit and predict.\n",
        "bg_clf.fit(X_train, y_train)\n",
        "y_pred = bg_clf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fq4hn2ib2UB",
        "pycharm": {}
      },
      "source": [
        "Due to the big vaiance of the model, the result is lower than the expected, but within the accepted limits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKYBqd8lc_Qg",
        "pycharm": {}
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGMjOL_Ic_Qh",
        "pycharm": {}
      },
      "source": [
        "# Define a Random Forest classifier.\n",
        "clf = RandomForestClassifier(random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaoZy0H2c_Qk",
        "pycharm": {}
      },
      "source": [
        "### Random Search\n",
        "Run a Random Search using 10 fold cross validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZBWimyVc_Ql",
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "param_dist = {'max_depth': sp_randint(2, 50),\n",
        "              'max_features': sp_randint(1, X.shape[1]),\n",
        "              'min_samples_split': sp_randint(2, X.shape[0] / 2),\n",
        "              'n_estimators': sp_randint(20, 300),\n",
        "              'criterion': ['gini', 'entropy']}\n",
        "candidates = 50\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(clf, param_dist, candidates, cv=10, \n",
        "                                   n_jobs=-1, verbose=8, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pItroBwxc_Qw",
        "pycharm": {}
      },
      "source": [
        "### Grid Search\n",
        "Run a Grid search, using 10 fold cross validation for the area around the best results found with the Random Search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQpCXYOxc_Q1",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "param_grid = {'max_depth': range(23, 31),\n",
        "              'max_features': range(4, 6),\n",
        "              'min_samples_split': range(47, 51),\n",
        "              'n_estimators': range(110, 160, 10),\n",
        "              'criterion': ['entropy', 'gini']}\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=10, n_jobs=-1, verbose=8,\n",
        "                           iid=True)\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'\n",
        "      .format((time.time() - start)))\n",
        "report(grid_search.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELvWQ6OCc_Q7",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Predict using the Random Forest Ensemble.\n",
        "Make prediction with the Random Forest Ensemble, using the best parameters found from the above procedure.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqjSQlfNc_Q9",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Add best values for the classifier.\n",
        "clf.max_depth = 30\n",
        "clf.max_features = 5\n",
        "clf.min_samples_split = 50\n",
        "clf.n_estimators = 130\n",
        "clf.criterion = 'gini'\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmy-S9Glc_RG",
        "pycharm": {}
      },
      "source": [
        "## Stacking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sEFzV-yc_RH",
        "pycharm": {}
      },
      "source": [
        "# Define the stacking classifier.\n",
        "clf1 = KNeighborsClassifier()\n",
        "clf2 = LinearSVC(random_state=0)\n",
        "clf3 = DecisionTreeClassifier(random_state=0)\n",
        "clf4 = GaussianNB()\n",
        "meta_clf = LogisticRegression(solver = 'lbfgs', multi_class = 'auto', \n",
        "                              random_state=0)\n",
        "sclf = StackingCVClassifier(classifiers=[clf1, clf2, clf3, clf4], \n",
        "                            meta_classifier=meta_clf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NTncQyTc_RL",
        "pycharm": {}
      },
      "source": [
        "### Random Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5eSxrt4c_RL",
        "pycharm": {}
      },
      "source": [
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "param_dist = {'kneighborsclassifier__n_neighbors': sp_randint(1, X.shape[1]),\n",
        "              'linearsvc__C': np.logspace(-3, 3),\n",
        "              'decisiontreeclassifier__max_depth': sp_randint(2, 60),\n",
        "              'meta-logisticregression__C': np.logspace(-3, 3)}\n",
        "\n",
        "candidates = 200\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(sclf, param_dist, candidates, cv=10, \n",
        "                                   n_jobs=-1, verbose=9, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds, for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SP_p-9kxc_RQ",
        "pycharm": {}
      },
      "source": [
        "### Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAmi5pvyc_RR",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "param_grid = {'kneighborsclassifier__n_neighbors': range(1, 6),\n",
        "              'linearsvc__C': range(170, 190, 4),\n",
        "              'decisiontreeclassifier__max_depth': range(30, 35),\n",
        "              'meta-logisticregression__C': [20, 30, 2]}\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(sclf, param_grid, cv = 10, n_jobs=-1, verbose=5,\n",
        "                           iid=True)\n",
        "\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'.format((time.time() - start)))\n",
        "report(grid_search.cv_results_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ySvz9bfc_Ra",
        "pycharm": {}
      },
      "source": [
        "### Plot stacking results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-toeVDNc_Rd",
        "pycharm": {}
      },
      "source": [
        "# Use best values for the classifier.\n",
        "clf1.n_neighbors = 5\n",
        "clf2.C = 170\n",
        "clf3.max_depth = 33\n",
        "meta_clf.C = 30\n",
        "\n",
        "# Plot accuracy +- std for each model separately\n",
        "# and compare it with the stacking model.\n",
        "clf_names = ['KNN', 'Linear-SVM', 'Decision Tree', 'Naive-Bayes',\n",
        "             'Logistic Regression', 'Stacking']\n",
        "models = clf1, clf2, clf3, clf4, meta_clf, sclf\n",
        "plot_accuracy_stacking(clf_names, models, X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tySOCaa2-5mo",
        "pycharm": {}
      },
      "source": [
        "# Plot the learning curves.\n",
        "plot_learning_curve(models, clf_names, X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Q0N6LjWc_Rn",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Predict using the Stacking Ensemble.\n",
        "Create a classification report with the Stacking Ensemble.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t71y4uH1c_Rn",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "# Fit and predict.\n",
        "sclf.fit(X_train,y_train)\n",
        "y_pred = sclf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLvU2NTRc_Rr",
        "pycharm": {}
      },
      "source": [
        "## XGBoosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1C4GPPiKc_Rs",
        "pycharm": {}
      },
      "source": [
        "# Create XGBoost, using LogisticRegression classifier\n",
        "xgb_clf = xgb.XGBClassifier(learning_rate=0.03, n_estimators=600, \n",
        "                            objective='binary:logistic', silent=True, nthread=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8I33L1bc_Rz",
        "pycharm": {}
      },
      "source": [
        "### Random Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zu47riUgc_R3",
        "pycharm": {}
      },
      "source": [
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "params = {'min_child_weight': sp_randint(4, 30),\n",
        "          'gamma': np.random.uniform(0.5, 4,size=5),\n",
        "          'subsample': np.random.uniform(0, 1, size=4),\n",
        "          'colsample_bytree': np.random.uniform(0, 1, size=4),\n",
        "          'max_depth': sp_randint(1, 7)}\n",
        "\n",
        "candidates = 50\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(xgb_clf, params, candidates, cv=10,\n",
        "                                   n_jobs=-1, verbose=5, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSHpXeBLc_R-",
        "pycharm": {}
      },
      "source": [
        "### Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHd7vOQSc_R_",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "params = {'min_child_weight': range(12, 16),\n",
        "          'gamma': [0.5, 1.6, 0.2],\n",
        "          'colsample_bytree': np.arange(0.5, 0.7, 0.05),\n",
        "          'max_depth': range(4, 6)}\n",
        "xgb_clf.subsample = 0.82\n",
        "xgb_clf.colsample_bytree = 0.62\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(xgb_clf, params , cv = 10, n_jobs=-1, verbose=5,\n",
        "                           iid=True)\n",
        "\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'\n",
        "      .format((time.time() - start)))\n",
        "report(grid_search.cv_results_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2CQs6tsc_SG",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Predict using the boosted model.\n",
        "Make prediction with the XGBoosting method, using the best parameters found from the procedure above.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdVMAWD2c_SG",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Add best values for the classifier.\n",
        "xgb_clf.min_child_weight = 13\n",
        "xgb_clf.gamma = 0.2\n",
        "xgb_clf.max_depth = 4\n",
        "xgb_clf.colsample_bytree = 0.65\n",
        "\n",
        "# Fit and predict.\n",
        "xgb_clf.fit(X_train,y_train)\n",
        "y_pred = xgb_clf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUW9kx9cdAEB",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "# Glass Identification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_qt700odAEF",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "## Prepare the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8cX6DrFdAEH",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Read the dataset.\n",
        "url=\"https://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data\"\n",
        "s=requests.get(url).content\n",
        "dataset=read_csv(io.StringIO(s.decode('utf-8')))\n",
        "\n",
        "# Get x and y.\n",
        "X, y = dataset.iloc[:, :-1].values, dataset.iloc[:, -1].values\n",
        "\n",
        "# Split to training and test pairs.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,shuffle=True,\n",
        "                                                    random_state=0,stratify = y)\n",
        "\n",
        "# Scale data.\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train.astype(float))\n",
        "X_test = scaler.transform(X_test.astype(float))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1wDEgTQdAEM",
        "pycharm": {}
      },
      "source": [
        "## Bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNUA5pktdAEP",
        "pycharm": {}
      },
      "source": [
        "# Define a Decision Tree classifier for the ensemble.\n",
        "clf = DecisionTreeClassifier(random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzCv0ATedAER",
        "pycharm": {}
      },
      "source": [
        "### Random Search\n",
        "Run a Random Search using 10 fold cross validation, for the classifier which will be used in the bagging."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_2E8yQIdAES",
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "param_dist = {'max_depth': sp_randint(1, 30),\n",
        "              'max_features': sp_randint(1, X.shape[1]),\n",
        "              'min_samples_split': sp_randint(2, X.shape[0] / 2),\n",
        "              'criterion': ['gini', 'entropy']}\n",
        "candidates = 200\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(clf, param_dist, candidates, cv=10, \n",
        "                                   n_jobs=-1, verbose=5, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sH-GGN-HdAEW",
        "pycharm": {}
      },
      "source": [
        "### Grid Search\n",
        "Run a Grid search, using 10 fold cross validation for the area around the best results found with the Random Search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7BS2pdodAEY",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "param_grid = {'max_depth': range(12, 16),\n",
        "              'max_features': range(8, 11),\n",
        "              'min_samples_split': range(13, 16),\n",
        "              'criterion': ['gini', 'entropy']}\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=10, n_jobs=-1, verbose=5, \n",
        "                           iid=True)\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'\n",
        "      .format((time.time() - start)))\n",
        "report(grid_search.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zs1339R4dAEc",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Create the Bagging Ensemble.\n",
        "Create the Bagging Ensemble, using the best parameters found from the above procedure.  \n",
        "Since the mean accuracy is the same, we are using the best scores with the minimum std, between the different CV folds.  \n",
        "We make prediction to the test data, which were left out at the train-test-split procedure and not to the training data again.  \n",
        "We are using a 10 fold cross validation method, in order to visualize the best number of classifiers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MdC9kqEdAEd",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Add best values for the classifier.\n",
        "clf.max_depth = 12\n",
        "clf.max_features = 10\n",
        "clf.min_samples_split = 13\n",
        "clf.criterion = 'gini'\n",
        "\n",
        "# Plot accuracy vs number of estimators.\n",
        "estimators_vs_acc(clf, X_train, y_train, estimators_array=range(1, 1000, 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujcaJgNbdAEg",
        "pycharm": {}
      },
      "source": [
        "### Predict\n",
        "Predict using the best number of classifiers, based on the previous cross validation method.  \n",
        "It seems that there is not significant difference between the number of estimators so for convenience\n",
        "we choose 100 estimators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlxHSCg1dAEh",
        "pycharm": {}
      },
      "source": [
        "# Create the bagging classifier.\n",
        "bg_clf = BaggingClassifier(base_estimator=clf, n_estimators=100, random_state=0)\n",
        "\n",
        "# Fit and predict.\n",
        "bg_clf.fit(X_train, y_train)\n",
        "y_pred = bg_clf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovKQMQIJdAEm",
        "pycharm": {}
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p31vBAXQdAEn",
        "pycharm": {}
      },
      "source": [
        "# Define a Random Forest classifier.\n",
        "clf = RandomForestClassifier(random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJKZRcFsdAEp",
        "pycharm": {}
      },
      "source": [
        "### Random Search\n",
        "Run a Random Search using 10 fold cross validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9Fp49ZJdAEq",
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "param_dist = {'max_depth': sp_randint(2, 50),\n",
        "              'max_features': sp_randint(1, X.shape[1]),\n",
        "              'min_samples_split': sp_randint(2, X.shape[0] / 2),\n",
        "              'n_estimators': sp_randint(20, 300),\n",
        "              'criterion': ['gini', 'entropy']}\n",
        "candidates = 50\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(clf, param_dist, candidates, cv=10, \n",
        "                                   n_jobs=-1, verbose=8, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM7BbE8IdAEt",
        "pycharm": {}
      },
      "source": [
        "### Grid Search\n",
        "Run a Grid search, using 10 fold cross validation for the area around the best results found with the Random Search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbdaugBLdAEu",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "param_grid = {'max_depth': range(34, 37),\n",
        "              'max_features': range(4, 7),\n",
        "              'min_samples_split': range(11, 14),\n",
        "              'n_estimators': range(195, 210, 5),\n",
        "              'criterion': ['entropy', 'gini']}\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=6, n_jobs=-1, verbose=8,\n",
        "                           iid=True)\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'\n",
        "      .format((time.time() - start)))\n",
        "report(grid_search.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUNIMawcdAEx",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Predict using the Random Forest Ensemble.\n",
        "Make prediction with the Random Forest Ensemble, using the best parameters found from the above procedure.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUZ3ZrM4dAEx",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Add best values for the classifier.\n",
        "clf.max_depth = 34\n",
        "clf.max_features = 4\n",
        "clf.min_samples_split = 11\n",
        "clf.n_estimators = 200\n",
        "clf.criterion = 'entropy'\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsU7u1DudAE2",
        "pycharm": {}
      },
      "source": [
        "## Stacking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3UwIrj0dAE2",
        "pycharm": {}
      },
      "source": [
        "# Define the stacking classifier.\n",
        "clf1 = KNeighborsClassifier()\n",
        "clf2 = LinearSVC(random_state=0)\n",
        "clf3 = DecisionTreeClassifier(random_state=0)\n",
        "clf4 = GaussianNB()\n",
        "meta_clf = LogisticRegression(solver = 'lbfgs', multi_class = 'auto', \n",
        "                              random_state=0)\n",
        "sclf = StackingCVClassifier(classifiers=[clf1, clf2, clf3, clf4], \n",
        "                            meta_classifier=meta_clf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJMuEN1KdAE6",
        "pycharm": {}
      },
      "source": [
        "### Random Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSqdI_hRdAE7",
        "pycharm": {}
      },
      "source": [
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "param_dist = {'kneighborsclassifier__n_neighbors': sp_randint(1, X_train.shape[0]//4),\n",
        "              'linearsvc__C': [0.01, 0.1, 1, 10, 100],\n",
        "              'decisiontreeclassifier__max_depth': sp_randint(2, 60),\n",
        "              'meta-logisticregression__C': [0.01, 0.1, 1, 10, 100, 1000]}\n",
        "\n",
        "candidates = 50\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(sclf, param_dist, candidates, cv=5, \n",
        "                                   n_jobs=-1, verbose=9, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds, for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AoM9_pidAFA",
        "pycharm": {}
      },
      "source": [
        "### Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkF3kQD3dAFA",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "param_grid = {'kneighborsclassifier__n_neighbors': range(4, 9),\n",
        "              'linearsvc__C': range(99, 103),\n",
        "              'decisiontreeclassifier__max_depth': range(34, 38),\n",
        "              'meta-logisticregression__C': [99.5,100, 101, 102]}\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(sclf, param_grid, cv = 6, n_jobs=-1, verbose=5,\n",
        "                           iid=True)\n",
        "\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'.format((time.time() - start)))\n",
        "report(grid_search.cv_results_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTnocWp2dAFG",
        "pycharm": {}
      },
      "source": [
        "### Plot stacking results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgwOmq13dAFH",
        "pycharm": {}
      },
      "source": [
        "# Use best values for the classifier.\n",
        "clf1.n_neighbors = 4\n",
        "clf2.C = 102\n",
        "clf3.max_depth = 34\n",
        "meta_clf.C = 102\n",
        "\n",
        "# Plot accuracy +- std for each model separately\n",
        "# and compare it with the stacking model.\n",
        "clf_names = ['KNN', 'Linear-SVM', 'Decision Tree', 'Naive-Bayes',\n",
        "             'Logistic Regression', 'Stacking']\n",
        "models = clf1, clf2, clf3, clf4, meta_clf, sclf\n",
        "plot_accuracy_stacking(clf_names, models, X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MQX-g0fdAFP",
        "pycharm": {}
      },
      "source": [
        "*Note:* in this case, the Naive Bayes classifier seems to affect negatively the total performance of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icVHv9lF-9sH",
        "pycharm": {}
      },
      "source": [
        "# Plot the learning curves.\n",
        "plot_learning_curve(models, clf_names, X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJfKMOdLdAFQ",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Predict using the Stacking Ensemble.\n",
        "Create a classification report with the Stacking Ensemble.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFgVTZd2dAFQ",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "# Fit and predict.\n",
        "sclf.fit(X_train,y_train)\n",
        "y_pred = sclf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RASd9_SCdAFU",
        "pycharm": {}
      },
      "source": [
        "## XGBoosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBzZA9ZBdAFV",
        "pycharm": {}
      },
      "source": [
        "# Create XGBoost, using LogisticRegression classifier\n",
        "xgb_clf = xgb.XGBClassifier(learning_rate=0.03, n_estimators=600, \n",
        "                            objective='multi:softmax', silent=True, n_jobs=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfJ8XlKzdAFX",
        "pycharm": {}
      },
      "source": [
        "### Random Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWgqnqnYdAFY",
        "pycharm": {}
      },
      "source": [
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "params = {'min_child_weight': sp_randint(4, 30),\n",
        "          'gamma': np.random.uniform(0.5, 4,size=5),\n",
        "          'subsample': np.random.uniform(0, 1, size=4),\n",
        "          'colsample_bytree': np.random.uniform(0, 1, size=4),\n",
        "          'max_depth': sp_randint(1, 7)}\n",
        "\n",
        "candidates = 50\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(xgb_clf, params, candidates, cv=10,\n",
        "                                   n_jobs=-1, verbose=5, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX-EwpwYdAFn",
        "pycharm": {}
      },
      "source": [
        "### Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbYEHF_sdAFo",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "params = {'min_child_weight': range(4, 7),\n",
        "          'gamma': [0.85, 0.87,0.90],\n",
        "          'max_depth': range(4, 9)}\n",
        "xgb_clf.subsample = 0.63\n",
        "xgb_clf.colsample_bytree = 0.37\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(xgb_clf, params , cv = 10, n_jobs=-1, verbose=5,\n",
        "                           iid=True)\n",
        "\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'\n",
        "      .format((time.time() - start)))\n",
        "report(grid_search.cv_results_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axsI1XM1dAFt",
        "pycharm": {}
      },
      "source": [
        "*Note:* The Grid Search procedure did not give better accuracy score, but lead to better std."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00HDXb0tdAFv",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Predict using the boosted model.\n",
        "Make prediction with the XGBoosting method, using the best parameters found from the procedure above.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "py4YCWP9dAFx",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Add best values for the classifier.\n",
        "xgb_clf.min_child_weight = 4\n",
        "xgb_clf.gamma = 0.85\n",
        "xgb_clf.max_depth = 4\n",
        "\n",
        "# Fit and predict.\n",
        "xgb_clf.fit(X_train,y_train)\n",
        "y_pred = xgb_clf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdSessvzdA1-",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "# Tic Tac Toe\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XeuMuMSdA1_",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "## Prepare the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoofCn62dA2B",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "# Read the dataset.\n",
        "url=\"https://archive.ics.uci.edu/ml/machine-learning-databases/tic-tac-toe/tic-tac-toe.data\"\n",
        "s=requests.get(url).content\n",
        "dataset=read_csv(io.StringIO(s.decode('utf-8')))\n",
        "\n",
        "# Get x and y.\n",
        "X, y = dataset.iloc[:, :-1].values, dataset.iloc[:, -1].values\n",
        "\n",
        "X_new = OrdinalEncoder().fit_transform(X)\n",
        "y_new = LabelEncoder().fit_transform(y)\n",
        "\n",
        "# Split to training and test pairs.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size=0.3,shuffle=True,stratify =y_new,\n",
        "                                                    random_state=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RmSuHsmdA2D",
        "pycharm": {}
      },
      "source": [
        "## Bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bypt5fsOdA2F",
        "pycharm": {}
      },
      "source": [
        "# Define a Decision Tree classifier for the ensemble.\n",
        "clf = DecisionTreeClassifier(random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kp4I5C6dA2H",
        "pycharm": {}
      },
      "source": [
        "### Random Search\n",
        "Run a Random Search using 10 fold cross validation, for the classifier which will be used in the bagging."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R921_fcqdA2I",
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "param_dist = {'max_depth': sp_randint(1, 30),\n",
        "              'max_features': sp_randint(1, X.shape[1]),\n",
        "              'min_samples_split': sp_randint(2, X.shape[0] / 2),\n",
        "              'criterion': ['gini', 'entropy']}\n",
        "candidates = 200\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(clf, param_dist, candidates, cv=10, \n",
        "                                   n_jobs=-1, verbose=5, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03zkrkvQdA2Q",
        "pycharm": {}
      },
      "source": [
        "### Grid Search\n",
        "Run a Grid search, using 10 fold cross validation for the area around the best results found with the Random Search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f_D0UyIdA2R",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "param_grid = {'max_depth': range(14, 17),\n",
        "              'max_features': range(6, 9),\n",
        "              'min_samples_split': range(2, 8),\n",
        "              'criterion': ['gini', 'entropy']}\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=10, n_jobs=-1, verbose=5, \n",
        "                           iid=True)\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'\n",
        "      .format((time.time() - start)))\n",
        "report(grid_search.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDOTG65qdA2W",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Create the Bagging Ensemble.\n",
        "Create the Bagging Ensemble, using the best parameters found from the above procedure.  \n",
        "Since the mean accuracy is the same, we are using the best scores with the minimum std, between the different CV folds.  \n",
        "We make prediction to the test data, which were left out at the train-test-split procedure and not to the training data again.  \n",
        "We are using a 10 fold cross validation method, in order to visualize the best number of classifiers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO6JMBM0dA2Z",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Add best values for the classifier.\n",
        "clf.max_depth = 14\n",
        "clf.max_features = 7\n",
        "clf.min_samples_split = 3\n",
        "clf.criterion = 'gini'\n",
        "\n",
        "# Plot accuracy vs number of estimators.\n",
        "estimators_vs_acc(clf, X_train, y_train, estimators_array=range(1, 1000, 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckJ474YOdA2c",
        "pycharm": {}
      },
      "source": [
        "### Predict\n",
        "Predict using the best number of classifiers, based on the previous cross validation method.  \n",
        "The best number of estimators seems to be 400, since the accuracy is high and the std is low,  \n",
        "the lower bound of it's deviation is better than the others even though the higher bound, is not the best."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4bdcTVGdA2c",
        "pycharm": {}
      },
      "source": [
        "# Create the bagging classifier.\n",
        "bg_clf = BaggingClassifier(base_estimator=clf, n_estimators=400, random_state=0)\n",
        "\n",
        "# Fit and predict.\n",
        "bg_clf.fit(X_train, y_train)\n",
        "y_pred = bg_clf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred, 'binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZwUf74DdA2f",
        "pycharm": {}
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbhiRM1jdA2f",
        "pycharm": {}
      },
      "source": [
        "# Define a Random Forest classifier.\n",
        "clf = RandomForestClassifier(random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcVaJxqsdA2g",
        "pycharm": {}
      },
      "source": [
        "### Random Search\n",
        "Run a Random Search using 10 fold cross validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3fIQGeSdA2i",
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "param_dist = {'max_depth': sp_randint(2, 50),\n",
        "              'max_features': sp_randint(1, X.shape[1]),\n",
        "              'min_samples_split': sp_randint(2, X.shape[0] / 2),\n",
        "              'n_estimators': sp_randint(20, 300),\n",
        "              'criterion': ['gini', 'entropy']}\n",
        "candidates = 50\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(clf, param_dist, candidates, cv=10, \n",
        "                                   n_jobs=-1, verbose=8, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNBxB67-dA2m",
        "pycharm": {}
      },
      "source": [
        "### Grid Search\n",
        "Run a Grid search, using 10 fold cross validation for the area around the best results found with the Random Search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--CYyMK_dA2n",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "param_grid = {'max_depth': range(21, 24),\n",
        "              'max_features': range(3, 6),\n",
        "              'min_samples_split': range(11, 14),\n",
        "              'n_estimators': range(290, 305, 5),\n",
        "              'criterion': ['entropy', 'gini']}\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=6, n_jobs=-1, verbose=8,\n",
        "                           iid=True)\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'\n",
        "      .format((time.time() - start)))\n",
        "report(grid_search.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B46BpeKjdA2t",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Predict using the Random Forest Ensemble.\n",
        "Make prediction with the Random Forest Ensemble, using the best parameters found from the above procedure.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmFVCjt6dA2t",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Add best values for the classifier.\n",
        "clf.max_depth = 21\n",
        "clf.max_features = 5\n",
        "clf.min_samples_split = 11\n",
        "clf.n_estimators = 290\n",
        "clf.criterion = 'entropy'\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred, 'binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVVXaFmLdA2x",
        "pycharm": {}
      },
      "source": [
        "## Stacking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBidBP_GdA2y",
        "pycharm": {}
      },
      "source": [
        "# Define the stacking classifier.\n",
        "clf1 = KNeighborsClassifier()\n",
        "clf2 = LinearSVC(random_state=0)\n",
        "clf3 = DecisionTreeClassifier(random_state=0)\n",
        "clf4 = GaussianNB()\n",
        "meta_clf = LogisticRegression(solver = 'lbfgs', multi_class = 'auto', \n",
        "                              random_state=0)\n",
        "sclf = StackingCVClassifier(classifiers=[clf1, clf2, clf3, clf4], \n",
        "                            meta_classifier=meta_clf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0Cq6eTrdA21",
        "pycharm": {}
      },
      "source": [
        "### Random Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxlgnkTndA21",
        "pycharm": {}
      },
      "source": [
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "param_dist = {'kneighborsclassifier__n_neighbors': sp_randint(1, 100),\n",
        "              'linearsvc__C': [0.01, 0.1, 1, 10, 100],\n",
        "              'decisiontreeclassifier__max_depth': sp_randint(2, 60),\n",
        "              'meta-logisticregression__C': [0.01, 0.1, 1, 10, 100, 1000]}\n",
        "\n",
        "candidates = 50\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(sclf, param_dist, candidates, cv=10, \n",
        "                                   n_jobs=-1, verbose=9, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds, for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sCUVqBAdA23",
        "pycharm": {}
      },
      "source": [
        "### Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qrOfjBcdA24",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "param_grid = {'kneighborsclassifier__n_neighbors': range(21,24),\n",
        "              'linearsvc__C': range(98, 104, 2),\n",
        "              'decisiontreeclassifier__max_depth': range(39, 43),\n",
        "              'meta-logisticregression__C': [99,100,102,104]}\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(sclf, param_grid, cv = 6, n_jobs=-1, verbose=5,\n",
        "                           iid=True)\n",
        "\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'.format((time.time() - start)))\n",
        "report(grid_search.cv_results_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMUv7fA_dA26",
        "pycharm": {}
      },
      "source": [
        "### Plot stacking results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_u-qQEzdA28",
        "pycharm": {}
      },
      "source": [
        "# Use best values for the classifier.\n",
        "clf1.n_neighbors = 22\n",
        "clf2.C = 100\n",
        "clf3.max_depth = 42\n",
        "meta_clf.C = 104\n",
        "\n",
        "# Plot accuracy +- std for each model separately\n",
        "# and compare it with the stacking model.\n",
        "clf_names = ['KNN', 'Linear-SVM', 'Decision Tree', 'Naive-Bayes',\n",
        "             'Logistic Regression', 'Stacking']\n",
        "models = clf1, clf2, clf3, clf4, meta_clf, sclf\n",
        "plot_accuracy_stacking(clf_names, models, X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYnJWl3vdA2_",
        "pycharm": {}
      },
      "source": [
        "*Note:* in this case, the Linear SVM classifier seems to affect negatively the total performance of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQRFTyWx_AY2",
        "pycharm": {}
      },
      "source": [
        "# Plot the learning curves.\n",
        "plot_learning_curve(models, clf_names, X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srsfIvledA3A",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Predict using the Stacking Ensemble.\n",
        "Create a classification report with the Stacking Ensemble.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ_oKAB3dA3A",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "# Fit and predict.\n",
        "sclf.fit(X_train,y_train)\n",
        "y_pred = sclf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred, 'binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYY83SNVdA3D",
        "pycharm": {}
      },
      "source": [
        "## XGBoosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV5ww0YEdA3D",
        "pycharm": {}
      },
      "source": [
        "# Create XGBoost, using LogisticRegression classifier\n",
        "xgb_clf = xgb.XGBClassifier(learning_rate=0.03, n_estimators=600, \n",
        "                            objective='binary:logistic', silent=True, nthread=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fun3yhXjdA3F",
        "pycharm": {}
      },
      "source": [
        "### Random Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4KzqWPrdA3F",
        "pycharm": {}
      },
      "source": [
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "params = {'min_child_weight': sp_randint(4, 30),\n",
        "          'gamma': np.random.uniform(0.5, 4,size=5),\n",
        "          'subsample': np.random.uniform(0, 1, size=4),\n",
        "          'colsample_bytree': np.random.uniform(0, 1, size=4),\n",
        "          'max_depth': sp_randint(1, 7)}\n",
        "\n",
        "candidates = 50\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(xgb_clf, params, candidates, cv=10,\n",
        "                                   n_jobs=-1, verbose=5, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6BdzXmxdA3J",
        "pycharm": {}
      },
      "source": [
        "### Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0yVBNVWdA3J",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "params = {'min_child_weight': range(5, 8),\n",
        "          'gamma': [2.23, 2.3, 2.4],\n",
        "          'max_depth': range(5, 9)}\n",
        "xgb_clf.subsample = 0.959\n",
        "xgb_clf.colsample_bytree = 0.9266\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(xgb_clf, params , cv = 10, n_jobs=-1, verbose=5,\n",
        "                           iid=True)\n",
        "\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'\n",
        "      .format((time.time() - start)))\n",
        "report(grid_search.cv_results_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PQZZPXOdA3L",
        "pycharm": {}
      },
      "source": [
        "*Note:* The Grid Search procedure did not give better accuracy score, but lead to better std."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ud-K4xSdA3M",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Predict using the boosted model.\n",
        "Make prediction with the XGBoosting method, using the best parameters found from the procedure above.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8unnq87dA3N",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Add best values for the classifier.\n",
        "xgb_clf.min_child_weight = 5\n",
        "xgb_clf.gamma = 2.23\n",
        "xgb_clf.max_depth = 5\n",
        "\n",
        "# Fit and predict.\n",
        "xgb_clf.fit(X_train,y_train)\n",
        "y_pred = xgb_clf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred, 'binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EFURPGGdBp8",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "# Wholesale Customers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T96pwXYadBp9",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "## Prepare the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMIOvu3EdBp9",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Read the dataset.\n",
        "url=\"https://archive.ics.uci.edu/ml/machine-learning-databases/00292/Wholesale%20customers%20data.csv\"\n",
        "s=requests.get(url).content\n",
        "dataset=read_csv(io.StringIO(s.decode('utf-8')))\n",
        "\n",
        "# Get x and channel column as y.\n",
        "X, y = dataset.iloc[:, 1:].values, dataset.iloc[:, 0].values\n",
        "\n",
        "# Split to training and test pairs.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
        "                                                    random_state=0)\n",
        "\n",
        "# Scale data.\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train.astype(float))\n",
        "X_test = scaler.transform(X_test.astype(float))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "KjOx8XMqdBp-",
        "pycharm": {}
      },
      "source": [
        "## Bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "Yu_CxGyIdBp_",
        "pycharm": {}
      },
      "source": [
        "# Define a Decision Tree classifier for the ensemble.\n",
        "clf = DecisionTreeClassifier(random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "UtPDZr9YdBqB",
        "pycharm": {}
      },
      "source": [
        "### Random Search\n",
        "Run a Random Search using 10 fold cross validation, for the classifier which will be used in the bagging."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "Oyz1MtZJdBqC",
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "param_dist = {'max_depth': sp_randint(1, 30),\n",
        "              'max_features': sp_randint(1, X.shape[1]),\n",
        "              'min_samples_split': sp_randint(2, X.shape[0] / 2),\n",
        "              'criterion': ['gini', 'entropy']}\n",
        "candidates = 200\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(clf, param_dist, candidates, cv=10, \n",
        "                                   n_jobs=-1, verbose=5, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "0N__yLekdBqG",
        "pycharm": {}
      },
      "source": [
        "### Grid Search\n",
        "Run a Grid search, using 10 fold cross validation for the area around the best results found with the Random Search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "jZHQAQ_edBqG",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "param_grid = {'max_depth': range(1, 7),\n",
        "              'max_features': range(1, 8),\n",
        "              'min_samples_split': range(35, 55),\n",
        "              'criterion': ['gini', 'entropy']}\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=10, n_jobs=-1, verbose=5, \n",
        "                           iid=True)\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'\n",
        "      .format((time.time() - start)))\n",
        "report(grid_search.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "ox_hTiL1dBqJ",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Create the Bagging Ensemble.\n",
        "Create the Bagging Ensemble, using the best parameters found from the above procedure.  \n",
        "Since the mean accuracy is the same, we are using the best scores with the minimum std, between the different CV folds.  \n",
        "We make prediction to the test data, which were left out at the train-test-split procedure and not to the training data again.  \n",
        "We are using a 10 fold cross validation method, in order to visualize the best number of classifiers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "H0dtLauvdBqJ",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Add best values for the classifier.\n",
        "clf.max_depth = 6\n",
        "clf.max_features = 4\n",
        "clf.min_samples_split = 48\n",
        "clf.criterion = 'entropy'\n",
        "\n",
        "# Plot accuracy vs number of estimators.\n",
        "estimators_vs_acc(clf, X_train, y_train, estimators_array=range(1, 1000, 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "1C90gRljdBqM",
        "pycharm": {}
      },
      "source": [
        "### Predict\n",
        "Predict using the best number of classifiers, based on the previous cross validation method.  \n",
        "The best number of estimators seems to be 500 - 900."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "eZAnjTJXdBqN",
        "pycharm": {}
      },
      "source": [
        "# Create the bagging classifier.\n",
        "bg_clf = BaggingClassifier(base_estimator=clf, n_estimators=600, random_state=0)\n",
        "\n",
        "# Fit and predict.\n",
        "bg_clf.fit(X_train, y_train)\n",
        "y_pred = bg_clf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred, 'binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "0BmhFwTfdBqO",
        "pycharm": {}
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "wSv4NAvOdBqQ",
        "pycharm": {}
      },
      "source": [
        "# Define a Random Forest classifier.\n",
        "clf = RandomForestClassifier(random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "OM26EgWLdBqR",
        "pycharm": {}
      },
      "source": [
        "### Random Search\n",
        "Run a Random Search using 10 fold cross validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "AORvAFGudBqS",
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "param_dist = {'max_depth': sp_randint(2, 50),\n",
        "              'max_features': sp_randint(1, X.shape[1]),\n",
        "              'min_samples_split': sp_randint(2, X.shape[0] / 2),\n",
        "              'n_estimators': sp_randint(20, 300),\n",
        "              'criterion': ['gini', 'entropy']}\n",
        "candidates = 50\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(clf, param_dist, candidates, cv=10, \n",
        "                                   n_jobs=-1, verbose=8, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "AoRW5B9zdBqU",
        "pycharm": {}
      },
      "source": [
        "### Grid Search\n",
        "Run a Grid search, using 10 fold cross validation for the area around the best results found with the Random Search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "Ohbr38mRdBqV",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "param_grid = {'max_depth': range(28, 34),\n",
        "              'max_features': range(3, 5),\n",
        "              'min_samples_split': range(7, 9),\n",
        "              'n_estimators': range(155, 160),\n",
        "              'criterion': ['entropy', 'gini']}\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=10, n_jobs=-1, verbose=8,\n",
        "                           iid=True)\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'\n",
        "      .format((time.time() - start)))\n",
        "report(grid_search.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "XlvmGFI8dBqZ",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Predict using the Random Forest Ensemble.\n",
        "Make prediction with the Random Forest Ensemble, using the best parameters found from the above procedure.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "dgho_TJ7dBqZ",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Add best values for the classifier.\n",
        "clf.max_depth = 28\n",
        "clf.max_features = 4\n",
        "clf.min_samples_split = 7\n",
        "clf.n_estimators = 155\n",
        "clf.criterion = 'entropy'\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred, 'binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "-vchbdgedBqb",
        "pycharm": {}
      },
      "source": [
        "## Stacking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "S9IGFq15dBqc",
        "pycharm": {}
      },
      "source": [
        "# Define the stacking classifier.\n",
        "clf1 = KNeighborsClassifier()\n",
        "clf2 = LinearSVC(random_state=0)\n",
        "clf3 = DecisionTreeClassifier(random_state=0)\n",
        "clf4 = GaussianNB()\n",
        "meta_clf = LogisticRegression(solver = 'lbfgs', multi_class = 'auto', \n",
        "                              random_state=0)\n",
        "sclf = StackingCVClassifier(classifiers=[clf1, clf2, clf3, clf4], \n",
        "                            meta_classifier=meta_clf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "tB8f8zagdBqd",
        "pycharm": {}
      },
      "source": [
        "### Random Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "5w_g4AfOdBqe",
        "pycharm": {}
      },
      "source": [
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "param_dist = {'kneighborsclassifier__n_neighbors': sp_randint(1, 80),\n",
        "              'linearsvc__C': np.logspace(-3, 3, 1000),\n",
        "              'decisiontreeclassifier__max_depth': sp_randint(2, 60),\n",
        "              'meta-logisticregression__C': np.logspace(-3, 3, 1000)}\n",
        "\n",
        "candidates = 50\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(sclf, param_dist, candidates, cv=10, \n",
        "                                   n_jobs=-1, verbose=9, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds, for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "eegvhN2ddBqg",
        "pycharm": {}
      },
      "source": [
        "### Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "mtWQ45VddBqg",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "param_grid = {'kneighborsclassifier__n_neighbors': range(14, 22),\n",
        "              'linearsvc__C': range(356, 362, 2),\n",
        "              'decisiontreeclassifier__max_depth': range(51, 55),\n",
        "              'meta-logisticregression__C': np.arange(0.01, 0.04, 0.01)}\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(sclf, param_grid, cv = 10, n_jobs=-1, verbose=5,\n",
        "                           iid=True)\n",
        "\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'.format((time.time() - start)))\n",
        "report(grid_search.cv_results_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "Tz9uPdyEdBql",
        "pycharm": {}
      },
      "source": [
        "### Plot stacking results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "1UnOpfeKdBqm",
        "pycharm": {}
      },
      "source": [
        "# Use best values for the classifier.\n",
        "clf1.n_neighbors = 14\n",
        "clf2.C = 356\n",
        "clf3.max_depth = 51\n",
        "meta_clf.C = 0.03\n",
        "\n",
        "# Plot accuracy +- std for each model separately\n",
        "# and compare it with the stacking model.\n",
        "clf_names = ['KNN', 'Linear-SVM', 'Decision Tree', 'Naive-Bayes',\n",
        "             'Logistic Regression', 'Stacking']\n",
        "models = clf1, clf2, clf3, clf4, meta_clf, sclf\n",
        "plot_accuracy_stacking(clf_names, models, X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "2Sgv5woE_EKb",
        "pycharm": {}
      },
      "source": [
        "# Plot the learning curves.\n",
        "plot_learning_curve(models, clf_names, X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "IQkh6_qcdBqq",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Predict using the Stacking Ensemble.\n",
        "Create a classification report with the Stacking Ensemble.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "xBxdGoMEdBqr",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "# Fit and predict.\n",
        "sclf.fit(X_train,y_train)\n",
        "y_pred = sclf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred, 'binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "hCzKSNsrdBqw",
        "pycharm": {}
      },
      "source": [
        "## XGBoosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "KbQy2mYNdBqx",
        "pycharm": {}
      },
      "source": [
        "# Create XGBoost, using LogisticRegression classifier\n",
        "xgb_clf = xgb.XGBClassifier(learning_rate=0.03, n_estimators=600, \n",
        "                            objective='binary:logistic', silent=True, nthread=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "S8qAz14XdBqy",
        "pycharm": {}
      },
      "source": [
        "### Random Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "J3nR3VaPdBqz",
        "pycharm": {}
      },
      "source": [
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "params = {'min_child_weight': sp_randint(4, 30),\n",
        "          'gamma': np.random.uniform(0.5, 4,size=5),\n",
        "          'subsample': np.random.uniform(0, 1, size=4),\n",
        "          'colsample_bytree': np.random.uniform(0, 1, size=4),\n",
        "          'max_depth': sp_randint(1, 7)}\n",
        "\n",
        "candidates = 50\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(xgb_clf, params, candidates, cv=10,\n",
        "                                   n_jobs=-1, verbose=5, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "Yu6qo-39dBq6",
        "pycharm": {}
      },
      "source": [
        "### Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "f7NmbnzldBq6",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "params = {'min_child_weight': range(2, 8),\n",
        "          'gamma': np.arange(2, 4, 0.2),\n",
        "          'max_depth': range(1, 8)}\n",
        "xgb_clf.subsample = 0.24\n",
        "xgb_clf.colsample_bytree = 0.74\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(xgb_clf, params , cv = 10, n_jobs=-1, verbose=5,\n",
        "                           iid=True)\n",
        "\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'\n",
        "      .format((time.time() - start)))\n",
        "report(grid_search.cv_results_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "57ChB4NfdBq9",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Predict using the boosted model.\n",
        "Make prediction with the XGBoosting method, using the best parameters found from the procedure above.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "DlN-TWy8dBq-",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Add best values for the classifier.\n",
        "xgb_clf.min_child_weight = 2\n",
        "xgb_clf.gamma = 2\n",
        "xgb_clf.max_depth = 1\n",
        "\n",
        "# Fit and predict.\n",
        "xgb_clf.fit(X_train,y_train)\n",
        "y_pred = xgb_clf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred, 'binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jos8sbtAdCcY",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Digits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sH_S0qmndCcZ",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "## Prepare the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UD-PXR1HdCca",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "# Get x and y.\n",
        "X, y = load_digits(return_X_y=True)\n",
        "\n",
        "# Split to training and test pairs.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
        "                                                    random_state=0)\n",
        "\n",
        "# Scale data.\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train.astype(float))\n",
        "X_test = scaler.transform(X_test.astype(float))\n",
        "\n",
        "pca = PCA(0.95)\n",
        "X_train = pca.fit_transform(X_train)\n",
        "X_test = pca.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIfMLXdBdCcb",
        "pycharm": {}
      },
      "source": [
        "## Bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHKQSfpzdCcc",
        "pycharm": {}
      },
      "source": [
        "# Define a Decision Tree classifier for the ensemble.\n",
        "clf = DecisionTreeClassifier(random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKladsPKdCcd",
        "pycharm": {}
      },
      "source": [
        "### Random Search\n",
        "Run a Random Search using 10 fold cross validation, for the classifier which will be used in the bagging."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R09S7mf9dCce",
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "param_dist = {'max_depth': sp_randint(1, 80),\n",
        "              'max_features': sp_randint(1, X_train.shape[1]),\n",
        "              'min_samples_split': sp_randint(2, X_train.shape[0] / 2),\n",
        "              'criterion': ['gini', 'entropy']}\n",
        "candidates = 200\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(clf, param_dist, candidates, cv=10, \n",
        "                                   n_jobs=-1, verbose=5, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ik8dM1NdCcg",
        "pycharm": {}
      },
      "source": [
        "### Grid Search\n",
        "Run a Grid search, using 10 fold cross validation for the area around the best results found with the Random Search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9B2aypydCch",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "param_grid = {'max_depth': range(10, 16),\n",
        "              'max_features': range(22, 28),\n",
        "              'min_samples_split': range(10, 14),\n",
        "              'criterion': ['gini', 'entropy']}\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=10, n_jobs=-1, verbose=5, \n",
        "                           iid=True)\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'\n",
        "      .format((time.time() - start)))\n",
        "report(grid_search.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hldrP7-tdCcj",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Create the Bagging Ensemble.\n",
        "Create the Bagging Ensemble, using the best parameters found from the above procedure.  \n",
        "Since the mean accuracy is the same, we are using the best scores with the minimum std, between the different CV folds.  \n",
        "We make prediction to the test data, which were left out at the train-test-split procedure and not to the training data again.  \n",
        "We are using a 10 fold cross validation method, in order to visualize the best number of classifiers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3-J0Tv7dCck",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Add best values for the classifier.\n",
        "clf.max_depth = 15\n",
        "clf.max_features = 24\n",
        "clf.min_samples_split = 12\n",
        "clf.criterion = 'gini'\n",
        "\n",
        "# Plot accuracy vs number of estimators.\n",
        "estimators_vs_acc(clf, X_train, y_train, estimators_array=range(1, 1000, 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8jt7GEldCcm",
        "pycharm": {}
      },
      "source": [
        "### Predict\n",
        "Predict using the best number of classifiers, based on the previous cross validation method.  \n",
        "The best number of estimators seems to be 500, since the accuracy is high,  \n",
        "the lower bound of it's deviation is better than the others and the higher bound, is the best."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCBjEOLPdCcn",
        "pycharm": {}
      },
      "source": [
        "# Create the bagging classifier.\n",
        "bg_clf = BaggingClassifier(base_estimator=clf, n_estimators=500, random_state=0)\n",
        "\n",
        "# Fit and predict.\n",
        "bg_clf.fit(X_train, y_train)\n",
        "y_pred = bg_clf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVbniiYRdCcq",
        "pycharm": {}
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TE2nTuqHdCcq",
        "pycharm": {}
      },
      "source": [
        "# Define a Random Forest classifier.\n",
        "clf = RandomForestClassifier(random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNG2-hzNdCcs",
        "pycharm": {}
      },
      "source": [
        "### Random Search\n",
        "Run a Random Search using 10 fold cross validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbkipxgUdCcs",
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "param_dist = {'max_depth': sp_randint(2, 50),\n",
        "              'max_features': sp_randint(1, X_train.shape[1]),\n",
        "              'min_samples_split': sp_randint(2, X_train.shape[0] / 2),\n",
        "              'n_estimators': sp_randint(20, 300),\n",
        "              'criterion': ['gini', 'entropy']}\n",
        "candidates = 50\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(clf, param_dist, candidates, cv=10, \n",
        "                                   n_jobs=-1, verbose=8, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfYNf-VbdCcv",
        "pycharm": {}
      },
      "source": [
        "### Grid Search\n",
        "Run a Grid search, using 10 fold cross validation for the area around the best results found with the Random Search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RPiFWUddCcv",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "param_grid = {'max_depth': range(27, 29),\n",
        "              'max_features': range(5, 7),\n",
        "              'n_estimators': range(129, 139, 2),\n",
        "              'criterion': ['entropy', 'gini']}\n",
        "\n",
        "clf.min_samples_split = 7\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=10, n_jobs=-1, verbose=8,\n",
        "                           iid=True)\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'\n",
        "      .format((time.time() - start)))\n",
        "report(grid_search.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iE2Qv-aOdCcy",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Predict using the Random Forest Ensemble.\n",
        "Make prediction with the Random Forest Ensemble, using the best parameters found from the above procedure.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f-KjBY4dCcz",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Add best values for the classifier.\n",
        "clf.max_depth = 27\n",
        "clf.max_features = 6\n",
        "clf.n_estimators = 129\n",
        "clf.criterion = 'gini'\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDDMnhYudCc2",
        "pycharm": {}
      },
      "source": [
        "## Stacking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQrWIMd0dCc3",
        "pycharm": {}
      },
      "source": [
        "# Define the stacking classifier.\n",
        "clf1 = KNeighborsClassifier()\n",
        "clf2 = LinearSVC(random_state=0)\n",
        "clf3 = DecisionTreeClassifier(random_state=0)\n",
        "clf4 = GaussianNB()\n",
        "meta_clf = LogisticRegression(solver = 'lbfgs', multi_class = 'auto', \n",
        "                              random_state=0)\n",
        "sclf = StackingCVClassifier(classifiers=[clf1, clf2, clf3, clf4], \n",
        "                            meta_classifier=meta_clf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5D-uMrLQdCc5",
        "pycharm": {}
      },
      "source": [
        "### Random Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uunTG5ZkdCc5",
        "pycharm": {}
      },
      "source": [
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "param_dist = {'kneighborsclassifier__n_neighbors': sp_randint(1, 80),\n",
        "              'linearsvc__C': np.logspace(-3, 3, 1000),\n",
        "              'decisiontreeclassifier__max_depth': sp_randint(2, 80),\n",
        "              'meta-logisticregression__C': np.logspace(-3, 3, 1000)}\n",
        "\n",
        "candidates = 50\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(sclf, param_dist, candidates, cv=10, \n",
        "                                   n_jobs=-1, verbose=9, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds, for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyluYc5BdCc8",
        "pycharm": {}
      },
      "source": [
        "### Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4kM5pbZdCc8",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "param_grid = {'kneighborsclassifier__n_neighbors': range(2, 4),\n",
        "              'linearsvc__C': np.arange(0.1, 0.2, 0.02),\n",
        "              'decisiontreeclassifier__max_depth': range(12, 14),\n",
        "              'meta-logisticregression__C': range(120, 125)}\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(sclf, param_grid, cv = 10, n_jobs=-1, verbose=5,\n",
        "                           iid=True)\n",
        "\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'.format((time.time() - start)))\n",
        "report(grid_search.cv_results_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abFSjRezdCc-",
        "pycharm": {}
      },
      "source": [
        "### Plot stacking results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6m-VT0PdCc_",
        "pycharm": {}
      },
      "source": [
        "# Use best values for the classifier.\n",
        "clf1.n_neighbors = 3\n",
        "clf2.C = 0.1\n",
        "clf3.max_depth = 13\n",
        "meta_clf.C = 120\n",
        "\n",
        "# Plot accuracy +- std for each model separately\n",
        "# and compare it with the stacking model.\n",
        "clf_names = ['KNN', 'Linear-SVM', 'Decision Tree', 'Naive-Bayes',\n",
        "             'Logistic Regression', 'Stacking']\n",
        "models = clf1, clf2, clf3, clf4, meta_clf, sclf\n",
        "plot_accuracy_stacking(clf_names, models, X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aY77KrddCdC",
        "pycharm": {}
      },
      "source": [
        "*Note:* in this case, the Decision Tree classifier seems to affect negatively the total performance of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0ezbRvy_HXO",
        "pycharm": {}
      },
      "source": [
        "# Plot the learning curves.\n",
        "plot_learning_curve(models, clf_names, X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRbf2dw7dCdC",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Predict using the Stacking Ensemble.\n",
        "Create a classification report with the Stacking Ensemble.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wb7z82IdCdD",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "# Fit and predict.\n",
        "sclf.fit(X_train,y_train)\n",
        "y_pred = sclf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hN44wZkdCdF",
        "pycharm": {}
      },
      "source": [
        "## XGBoosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fGmg1pmdCdF",
        "pycharm": {}
      },
      "source": [
        "# Create XGBoost, using LogisticRegression classifier\n",
        "xgb_clf = xgb.XGBClassifier(learning_rate=0.03, n_estimators=600, \n",
        "                            objective='binary:logistic', silent=True, nthread=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1VyVhmmdCdI",
        "pycharm": {}
      },
      "source": [
        "### Random Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlEfelwPdCdI",
        "pycharm": {}
      },
      "source": [
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "params = {'min_child_weight': sp_randint(4, 30),\n",
        "          'gamma': np.random.uniform(0.5, 4,size=5),\n",
        "          'subsample': np.random.uniform(0, 1, size=4),\n",
        "          'colsample_bytree': np.random.uniform(0, 1, size=4),\n",
        "          'max_depth': sp_randint(1, 30)}\n",
        "\n",
        "candidates = 50\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(xgb_clf, params, candidates, cv=10,\n",
        "                                   n_jobs=-1, verbose=5, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obMSnPFcdCdM",
        "pycharm": {}
      },
      "source": [
        "### Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HS18y7UdCdM",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "params = {'min_child_weight': range(7, 9),\n",
        "          'gamma': [0.66, 0.7, 0.02],\n",
        "          'max_depth': range(10, 13)}\n",
        "xgb_clf.subsample = 0.75\n",
        "xgb_clf.colsample_bytree = 0.16\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(xgb_clf, params , cv = 10, n_jobs=-1, verbose=5,\n",
        "                           iid=True)\n",
        "\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'\n",
        "      .format((time.time() - start)))\n",
        "report(grid_search.cv_results_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29wAzFsHdCdP",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Predict using the boosted model.\n",
        "Make prediction with the XGBoosting method, using the best parameters found from the procedure above.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIJIqsJHdCdQ",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Add best values for the classifier.\n",
        "xgb_clf.min_child_weight = 7\n",
        "xgb_clf.gamma = 0.02\n",
        "xgb_clf.max_depth = 10\n",
        "\n",
        "# Fit and predict.\n",
        "xgb_clf.fit(X_train,y_train)\n",
        "y_pred = xgb_clf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BdiaJoOdDS3",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "# Chess (King-Rook vs. King-Pawn)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gshZSWHJdDTE",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "## Prepare the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdPwIjULdDTO",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Read the dataset.\n",
        "url=\"https://archive.ics.uci.edu/ml/machine-learning-databases/chess/king-rook-vs-king-pawn/kr-vs-kp.data\"\n",
        "s=requests.get(url).content\n",
        "dataset=read_csv(io.StringIO(s.decode('utf-8')))\n",
        "\n",
        "# Get x and y.\n",
        "X, y = dataset.iloc[:, :-1].values, dataset.iloc[:, -1].values\n",
        "\n",
        "# Split to training and test pairs.\n",
        "X_new = OrdinalEncoder().fit_transform(X)\n",
        "y_new = LabelEncoder().fit_transform(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size=0.3, \n",
        "                                                    random_state=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWXvqupXdDTd",
        "pycharm": {}
      },
      "source": [
        "## Bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkPbMhmBdDTg",
        "pycharm": {}
      },
      "source": [
        "# Define a Decision Tree classifier for the ensemble.\n",
        "clf = DecisionTreeClassifier(random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKaQAf_vdDTp",
        "pycharm": {}
      },
      "source": [
        "### Random Search\n",
        "Run a Random Search using 10 fold cross validation, for the classifier which will be used in the bagging."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQIyrkJNdDTr",
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "param_dist = {'max_depth': sp_randint(1, 30),\n",
        "              'max_features': sp_randint(1, X_train.shape[1]),\n",
        "              'min_samples_split': sp_randint(2, X_train.shape[0] / 2),\n",
        "              'criterion': ['gini', 'entropy']}\n",
        "candidates = 200\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(clf, param_dist, candidates, cv=10, \n",
        "                                   n_jobs=-1, verbose=5, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWIrkhc0dDT6",
        "pycharm": {}
      },
      "source": [
        "### Grid Search\n",
        "Run a Grid search, using 10 fold cross validation for the area around the best results found with the Random Search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dy83ZsVdDT8",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "param_grid = {'max_depth': range(15, 19),\n",
        "              'max_features': range(31, 34),\n",
        "              'min_samples_split': range(14, 17),\n",
        "              'criterion': ['gini', 'entropy']}\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=10, n_jobs=-1, verbose=5, \n",
        "                           iid=True)\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'\n",
        "      .format((time.time() - start)))\n",
        "report(grid_search.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Qot8ve7dDUJ",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Create the Bagging Ensemble.\n",
        "Create the Bagging Ensemble, using the best parameters found from the above procedure.  \n",
        "Since the mean accuracy is the same, we are using the best scores with the minimum std, between the different CV folds.  \n",
        "We make prediction to the test data, which were left out at the train-test-split procedure and not to the training data again.  \n",
        "We are using a 10 fold cross validation method, in order to visualize the best number of classifiers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rTclrrwdDUM",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Add best values for the classifier.\n",
        "clf.max_depth = 15\n",
        "clf.max_features = 31\n",
        "clf.min_samples_split = 14\n",
        "clf.criterion = 'entropy'\n",
        "\n",
        "# Plot accuracy vs number of estimators.\n",
        "estimators_vs_acc(clf, X_train, y_train, estimators_array=range(1, 1000, 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Jh2cUNddDUe",
        "pycharm": {}
      },
      "source": [
        "### Predict\n",
        "Predict using the best number of classifiers, based on the previous cross validation method.  \n",
        "The best number of estimators seems to be 1000, since the accuracy is high,  \n",
        "the lower bound of it's deviation is better than the others and the higher bound, is the best, after 500."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZbFT10EdDUg",
        "pycharm": {}
      },
      "source": [
        "# Create the bagging classifier.\n",
        "bg_clf = BaggingClassifier(base_estimator=clf, n_estimators=1000, random_state=0)\n",
        "\n",
        "# Fit and predict.\n",
        "bg_clf.fit(X_train, y_train)\n",
        "y_pred = bg_clf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred, 'binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzdpd-UBdDUz",
        "pycharm": {}
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7otj2ZWdDU2",
        "pycharm": {}
      },
      "source": [
        "# Define a Random Forest classifier.\n",
        "clf = RandomForestClassifier(random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ6FHzlhdDU9",
        "pycharm": {}
      },
      "source": [
        "### Random Search\n",
        "Run a Random Search using 10 fold cross validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-ne8iS2dDVA",
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "param_dist = {'max_depth': sp_randint(2, 50),\n",
        "              'max_features': sp_randint(1, X_train.shape[1]),\n",
        "              'min_samples_split': sp_randint(2, X_train.shape[0] / 2),\n",
        "              'n_estimators': sp_randint(20, 300),\n",
        "              'criterion': ['gini', 'entropy']}\n",
        "candidates = 50\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(clf, param_dist, candidates, cv=10, \n",
        "                                   n_jobs=-1, verbose=8, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "di_qoNKkdDVI",
        "pycharm": {}
      },
      "source": [
        "### Grid Search\n",
        "Run a Grid search, using 10 fold cross validation for the area around the best results found with the Random Search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8juCtGCydDVJ",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "param_grid = {'max_depth': range(41, 45),\n",
        "              'max_features': range(22, 26),\n",
        "              'min_samples_split': range(11, 14),\n",
        "              'n_estimators': range(50, 70, 5),\n",
        "              'criterion': ['entropy', 'gini']}\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=5, n_jobs=-1, verbose=8,\n",
        "                           iid=True)\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'\n",
        "      .format((time.time() - start)))\n",
        "report(grid_search.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onhnHUc1dDVa",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Predict using the Random Forest Ensemble.\n",
        "Make prediction with the Random Forest Ensemble, using the best parameters found from the above procedure.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Udn4OCjgdDVc",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Add best values for the classifier.\n",
        "clf.max_depth = 41\n",
        "clf.max_features = 22\n",
        "clf.min_samples_split = 11\n",
        "clf.n_estimators = 50\n",
        "clf.criterion = 'entropy'\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred, 'binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kmhwz6MdDVn",
        "pycharm": {}
      },
      "source": [
        "## Stacking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY7LhWZkdDVs",
        "pycharm": {}
      },
      "source": [
        "# Define the stacking classifier.\n",
        "clf1 = KNeighborsClassifier()\n",
        "clf2 = LinearSVC(random_state=0)\n",
        "clf3 = DecisionTreeClassifier(random_state=0)\n",
        "clf4 = GaussianNB()\n",
        "meta_clf = LogisticRegression(solver = 'lbfgs', multi_class = 'auto', \n",
        "                              random_state=0)\n",
        "sclf = StackingCVClassifier(classifiers=[clf1, clf2, clf3, clf4], \n",
        "                            meta_classifier=meta_clf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f98CWDPadDV3",
        "pycharm": {}
      },
      "source": [
        "### Random Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdqflPLLdDV4",
        "pycharm": {}
      },
      "source": [
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "param_dist = {'kneighborsclassifier__n_neighbors': sp_randint(1, X_train.shape[0]/3),\n",
        "              'linearsvc__C': [0.01, 0.1, 1, 10, 100],\n",
        "              'decisiontreeclassifier__max_depth': sp_randint(2, 60),\n",
        "              'meta-logisticregression__C': [0.01, 0.1, 1, 10, 100, 1000]}\n",
        "\n",
        "candidates = 50\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(sclf, param_dist, candidates, cv=10, \n",
        "                                   n_jobs=-1, verbose=9, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds, for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1gIMoVsdDWF",
        "pycharm": {}
      },
      "source": [
        "### Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0otY3jhdDWH",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "param_grid = {'kneighborsclassifier__n_neighbors': range(410, 415),\n",
        "              'linearsvc__C': [10,12,14,16],\n",
        "              'decisiontreeclassifier__max_depth': range(25,28),\n",
        "              'meta-logisticregression__C': [99,100,101,104]}\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(sclf, param_grid, cv = 5, n_jobs=-1, verbose=5,\n",
        "                           iid=True)\n",
        "\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'.format((time.time() - start)))\n",
        "report(grid_search.cv_results_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE4pINN1dDWW",
        "pycharm": {}
      },
      "source": [
        "### Plot stacking results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On6LCA7jdDWd",
        "pycharm": {}
      },
      "source": [
        "# Use best values for the classifier.\n",
        "clf1.n_neighbors = 410\n",
        "clf2.C = 14\n",
        "clf3.max_depth = 25\n",
        "meta_clf.C = 100\n",
        "\n",
        "# Plot accuracy +- std for each model separately\n",
        "# and compare it with the stacking model.\n",
        "clf_names = ['KNN', 'Linear-SVM', 'Decision Tree', 'Naive-Bayes',\n",
        "             'Logistic Regression', 'Stacking']\n",
        "models = clf1, clf2, clf3, clf4, meta_clf, sclf\n",
        "plot_accuracy_stacking(clf_names, models, X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzYHLduqdDWs",
        "pycharm": {}
      },
      "source": [
        "*Note:* in this case, the Naive Bayes classifier seems to affect negatively the total performance of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8xcmL0O_K4G",
        "pycharm": {}
      },
      "source": [
        "# Plot the learning curves.\n",
        "plot_learning_curve(models, clf_names, X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8F0e_0sPdDWu",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Predict using the Stacking Ensemble.\n",
        "Create a classification report with the Stacking Ensemble.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SP0Ajc9dDWu",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "# Fit and predict.\n",
        "sclf.fit(X_train,y_train)\n",
        "y_pred = sclf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred, 'binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5bnSge9dDW3",
        "pycharm": {}
      },
      "source": [
        "## XGBoosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kXripJ3dDW5",
        "pycharm": {}
      },
      "source": [
        "# Create XGBoost, using LogisticRegression classifier\n",
        "xgb_clf = xgb.XGBClassifier(learning_rate=0.03, n_estimators=600, \n",
        "                            objective='binary:logistic', silent=True, nthread=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKDNqWondDW-",
        "pycharm": {}
      },
      "source": [
        "### Random Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uc0KF4UedDXE",
        "pycharm": {}
      },
      "source": [
        "# Specify parameters and distributions to sample from \n",
        "# and candidates to be created.\n",
        "params = {'min_child_weight': sp_randint(4, 30),\n",
        "          'gamma': np.random.uniform(0.5, 4,size=5),\n",
        "          'subsample': np.random.uniform(0, 1, size=4),\n",
        "          'colsample_bytree': np.random.uniform(0, 1, size=4),\n",
        "          'max_depth': sp_randint(1, 7)}\n",
        "\n",
        "candidates = 50\n",
        "\n",
        "# Run a random search CV.\n",
        "random_search = RandomizedSearchCV(xgb_clf, params, candidates, cv=10,\n",
        "                                   n_jobs=-1, verbose=5, iid=True)\n",
        "start = time.time()\n",
        "random_search.fit(X_train, y_train)\n",
        "print('RandomizedSearchCV took {:.2f} seconds for {} candidates.'\n",
        "      .format((time.time() - start), candidates))\n",
        "report(random_search.cv_results_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61pHIhWkdDXK",
        "pycharm": {}
      },
      "source": [
        "### Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPLqAxkMdDXQ",
        "pycharm": {}
      },
      "source": [
        "# Specify parameter_grid for the search.\n",
        "params = {'min_child_weight': range(4, 7),\n",
        "          'gamma': [0.75,0.79,0.84,0.9],\n",
        "          'max_depth': range(4, 7)}\n",
        "xgb_clf.subsample = 0.667\n",
        "xgb_clf.colsample_bytree = 0.363\n",
        "\n",
        "# Run a grid search CV.\n",
        "grid_search = GridSearchCV(xgb_clf, params , cv = 10, n_jobs=-1, verbose=5,\n",
        "                           iid=True)\n",
        "\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "print('GridSearchCV took {:.2f} seconds.'\n",
        "      .format((time.time() - start)))\n",
        "report(grid_search.cv_results_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lbKsAvLdDXi",
        "pycharm": {}
      },
      "source": [
        "*Note:* The Grid Search procedure did not give better accuracy score, but lead to better std."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Izes1aXNdDXk",
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "### Predict using the boosted model.\n",
        "Make prediction with the XGBoosting method, using the best parameters found from the procedure above.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMDV6JpGdDXm",
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "# Add best values for the classifier.\n",
        "xgb_clf.min_child_weight = 4\n",
        "xgb_clf.gamma = 0.75\n",
        "xgb_clf.max_depth = 6\n",
        "\n",
        "# Fit and predict.\n",
        "xgb_clf.fit(X_train,y_train)\n",
        "y_pred = xgb_clf.predict(X_test)\n",
        "\n",
        "# Print a classification report.\n",
        "full_report(y_test, y_pred, 'binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTKlCNtAyDRT",
        "pycharm": {}
      },
      "source": [
        "# Results\n",
        "![Comparison Table](https://github.com/Adamantios/Ensembles-CSL-Imb_Learning-Models_Comparison/blob/master/images/Comparison_Table.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "05FQQuFTx6Mu",
        "pycharm": {}
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "As wee can see, Bagging has the most wins, next in the ranking are Random Forest and XGBoost\n",
        "with Stacking having the last position.  \n",
        "In order to further compare the algorithms, we ran the following statistical test procedure:  \n",
        "\n",
        "## Iman Davenport's correction of Friedman's rank sum\n",
        "\n",
        "* Corrected Friedman's chi-squared = 0.13706\n",
        "* df1 = 3, df2 = 27 - the test's degrees of freedom.\n",
        "* p-value = 0.937\n",
        "\n",
        "We noticed that the p-value is higher than 0.05, \n",
        "which means that there is not a statistically significant difference among the 4 algorithms.  \n",
        "However, we also ran the Nemenyi post-hoc test and the Friedman post-hoc test with Bergmann and Hommelâ€™s correction.\n",
        "\n",
        "## Nemenyi post-hoc\n",
        "\n",
        "* Critical difference = 1.5549\n",
        "* k = 4 - the number of groups (or treatments)\n",
        "* df = 36 - the test's degree of freedom.\n",
        "\n",
        "| Algorithm         | Bagging| Random Forest| Stacking| XGBoost|\n",
        "|:-----------------:|:------:|:------------:|:-------:|:------:|\n",
        "| **Bagging**       | *0.00* | -0.35        |  0.00   | -0.15  |\n",
        "| **Random Forest** | -0.35  | *0.00*       |  0.05   |  0.20  |\n",
        "| **Stacking**      | -0.30  |  0.05        | *0.00*  |  0.15  |\n",
        "| **XGBoost**       | -0.15  |  0.20        |  0.15   | *0.00* |\n",
        "\n",
        "![Nemenyi](https://github.com/Adamantios/Ensembles-CSL-Imb_Learning-Models_Comparison/blob/master/images/Nemenyi.png?raw=1)  \n",
        "If two algorithms had a bigger distance than the CD, then it would mean that they have a significant difference, \n",
        "which is not valid for our case.\n",
        "\n",
        "## Friedman post-hoc test with Bergmann and Hommelâ€™s correction\n",
        "\n",
        "| Algorithm         | Bagging | Random Forest| Stacking| XGBoost |\n",
        "|:-----------------:|:-------:|:------------:|:-------:|:-------:|\n",
        "| **Bagging**       |  *ÎÎ‘*   | 0.5443701    |0.6033318|0.7950122|\n",
        "| **Random Forest** |0.5443701| *ÎÎ‘*         |0.9309874|0.7290345|\n",
        "| **Stacking**      |0.6033318| 0.9309874    |  *ÎÎ‘*   |0.7950122|\n",
        "| **XGBoost**       |0.7950122| 0.7290345    |0.7950122|  *ÎÎ‘*   |\n",
        "\n",
        "The above test is considering the p-value for all the pairs of algorithms.  \n",
        "We noticed in this test too, that there is not a statistically significant difference.\n"
      ]
    }
  ]
}