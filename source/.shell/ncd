gzip_distance(){
    rm -fr /tmp/s1 /tmp/s2
    summarize "$1" /tmp/s1
    summarize "$2" /tmp/s2
    s1=$( cat /tmp/s1 | gzip -f | wc -c )
    s2=$( cat /tmp/s2 | gzip -f | wc -c )
    s12=$( cat /tmp/s1 /tmp/s2 | gzip | wc -c )

   python -c "print float($s12 - min($s1, $s2))/float(max($s1,$s2))"
}

softhash () {
	for file in ~/softhash_base/*
	do
		d=$(gzip_distance $1 $file) 
		echo $d,
	done | paste -d"  " -s | sed -e 's/^/[/g' -e 's/,$/]/g' | read distances
	python -c "
distances=$distances;
normalized=distances
normalized=[ i-min(normalized) for i in normalized ]
normalized=[ i/max(normalized) for i in normalized ]
with open('/tmp/softhash', 'w') as file:
    print >> file, normalized
chars=\"0123456789\"
hash=[ chars[int((1-i)*(len(chars)-1))] for i in normalized ]
print ''.join(hash)
"
}

softhash_pca () {
	for file in ~/softhash_base/*
	do
		d=$(gzip_distance $1 $file) 
		echo $d,
	done | paste -d"  " -s | sed -e 's/^/[/g' -e 's/,$/]/g' | read distances
	python -c "
import numpy as np
distances=$distances;
normalized=distances
normalized=[ i-min(normalized) for i in normalized ]
normalized=[ i/max(normalized) for i in normalized ]
pca=np.loadtxt('/tmp/pca')
normalized=[ i - 0.5 for i in normalized ]
normalized=np.matmul(normalized, pca)
normalized=[ i + 0.5 for i in normalized ]
normalized=[ i-min(normalized) for i in normalized ]
normalized=[ i/max(normalized) for i in normalized ]
chars=\"0123456789\"
hash=[ chars[int((1-i)*(len(chars)-1))] for i in normalized ]
print ''.join(hash)
"
}

softhash_fit(){
    rm -fr /tmp/softhashes
    for file in ~/softhash_base/*
    do
        softhash $file
        cat /tmp/softhash >> /tmp/softhashes
    done
    sed -i -e 's/\[//g' -e 's/\]//g' -e 's/,//g' /tmp/softhashes
	python -c "
import numpy as np
from sklearn.decomposition import PCA
X=np.loadtxt('/tmp/softhashes')
pca=PCA()
pca.fit(X)
np.savetxt('/tmp/pca',pca.components_)
"
}

