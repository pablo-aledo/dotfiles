gzip_distance(){
    rm -fr /tmp/s1 /tmp/s2
    summarize "$1" /tmp/s1
    summarize "$2" /tmp/s2
    s1=$( cat /tmp/s1 | gzip -f | wc -c )
    s2=$( cat /tmp/s2 | gzip -f | wc -c )
    s12=$( cat /tmp/s1 /tmp/s2 | gzip | wc -c )

   python -c "print float($s12 - min($s1, $s2))/float(max($s1,$s2))"
}

mindist(){
	for file in ~/softhash_base/*
	do
		d=$(gzip_distance $1 $file) 
		echo \"$(basename "$file")\" ":" $d ","
	done | paste -d"  " -s | sed -e 's/^/{/g' -e 's/,$/}/g' | read distances
	python -c "
distances=$distances;
print min(distances, key=distances.get)
"
}

sortdist(){
	for file in ~/softhash_base/*
	do
		d=$(gzip_distance $1 $file) 
		echo \"$(basename "$file")\" ":" $d ","
	done | paste -d"  " -s | sed -e 's/^/{/g' -e 's/,$/}/g' | read distances
	python -c "
distances=$distances;
for key, value in sorted(distances.iteritems(), key=lambda (k,v): (v,k)):
  print '%s: %s' % (key, value)
"
}

softhash () {
	for file in ~/softhash_base/*
	do
		d=$(gzip_distance $1 $file) 
		echo $d,
	done | paste -d"  " -s | sed -e 's/^/[/g' -e 's/,$/]/g' | read distances
	python -c "
distances=$distances;
normalized=distances
normalized=[ i-min(normalized) for i in normalized ]
normalized=[ i/max(normalized) for i in normalized ]
with open('/tmp/softhash', 'w') as file:
    print >> file, normalized
chars=\"0123456789\"
hash=[ chars[int((1-i)*(len(chars)-1))] for i in normalized ]
print ''.join(hash)
"
}

softhash_pca() {
	for file in ~/softhash_base/*
	do
		d=$(gzip_distance $1 $file)
		echo $d,
	done | paste -d"  " -s | sed -e 's/^/[/g' -e 's/,$/]/g' | read distances
	python -c "
import numpy as np
distances=$distances;
normalized=distances
normalized=[ i-min(normalized) for i in normalized ]
normalized=[ i/max(normalized) for i in normalized ]
pca=np.loadtxt('/tmp/pca')
eigenv=np.loadtxt('/tmp/eigenv')
normalized=[ i - 0.5 for i in normalized ]
normalized=np.matmul(pca, normalized)
normalized=np.divide( normalized, eigenv )
with open('/tmp/softhash', 'w') as file:
    print >> file, normalized
normalized=[ i + 0.5 for i in normalized ]
with open('/tmp/softhash', 'a') as file:
    print >> file, normalized
normalized=[ max(min(i,1.0),0.0) for i in normalized ]
chars=\"0123456789\"
hash=[ chars[int((i)*(len(chars)-1))] for i in normalized ]
print ''.join(hash)

"
}

softhash_fit(){
    rm -fr /tmp/softhashes
    for file in ~/softhash_base/*
    do
        softhash $file
        cat /tmp/softhash >> /tmp/softhashes
    done
    sed -i -e 's/\[//g' -e 's/\]//g' -e 's/,//g' /tmp/softhashes
	python -c "
import numpy as np
from sklearn.decomposition import PCA
X=np.loadtxt('/tmp/softhashes')
pca=PCA()
pca.fit(X)
np.savetxt('/tmp/pca',pca.components_)
np.savetxt('/tmp/eigenv',pca.explained_variance_)
"
}
