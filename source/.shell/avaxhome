[ -e /tmp/avh_proxy ] && source /tmp/avh_proxy
outbox=~/servers/outbox
avxmail_webcontent=true

# Contents of /tmp/avh_proxy:
# AVH_PROXY_IP=
# AVH_PROXY_USER=$USER
# AVH_PROXY_PEM=/tmp/avh_proxy_pem

# Test:
# ssh -i $AVH_PROXY_PEM $AVH_PROXY_USER@$AVH_PROXY_IP
# ssh -i $AVH_PROXY_PEM $AVH_PROXY_USER@$AVH_PROXY_IP "wget -q https://avxhm.se/ebooks/hardware -O -"

DESCARGAS_NAS=/media/DATA/NAS/Descargas
DESCARGAS_LOCAL=/media/DATA/Descargas
EBOOKS=/media/DATA/ebooks
ALEJANDRIA=/media/DATA/NAS/Alejandria
avxmail_ml=true

avhome(){
name=$EBOOKS/ebooks-`date +%y%m%d-%H%M`
mkdir -p $name
cd $name
for a in `seq 1 100`
do
	wget http://avxhome.se/ebooks/pages/$a
	echo "-------$a-------" >> list.list
	cat $a | grep '<h1>' | sed 's/.*">\([^<]*\).*/\1/g' >> list.list
done
}

avhome_cut(){
	if [ $# -eq 2 ]
	then
		last_a=`basename $1`
		last_b=`basename $2`
	else
		last_a=`ls $EBOOKS | sort -g | tail -n2 | head -n1`
		last_b=`ls $EBOOKS | sort -g | tail -n1 | head -n1`
	fi
	last_line=`cat $EBOOKS/$last_a/list.list | head -n2 | tail -n1`
	last_line=`cat $EBOOKS/$last_a/1 | grep '<h1>' | sed 's/.*">\([^<]*\).*/\1/g' | head -n1`
	rm -f $EBOOKS/$last_b/list_cut.list
	cat $EBOOKS/$last_b/list.list | while read line
	do
		echo $line >> $EBOOKS/$last_b/list_cut.list
		[ $line = $last_line ] && break
	done
}

avhome_create_list(){
rm $DESCARGAS_LOCAL/list.list
ls $DESCARGAS_NAS | while read line;
do
    echo $line "%" $line >> $DESCARGAS_LOCAL/list.list
done
}

avhome_isbns(){
rm  $DESCARGAS_LOCAL/list2.list
cat $DESCARGAS_LOCAL/list.list | while read line;
do
    file=`echo $line | cut -d"%" -f1 | sed 's/^ //g'`
    keyw=`echo $line | cut -d"%" -f2 | sed 's/^ //g'`
    url="http://www.amazon.com/s/ref=nb_sb_noss/185-8854576-4677633?url=search-alias%3Daps&field-keywords=$keyw"
    \rm /tmp/index; wget $url -O /tmp/index
    title=`cat /tmp/index | grep 'atfResults' | head -n1 | awk 'BEGIN{FS="\""}{print $58}'`
    echo $file "%" $title >> $DESCARGAS_LOCAL/list2.list
done
}

avhome_mv(){
cat $DESCARGAS_LOCAL/list{2,3}.list | while read line;
do
    file=`echo $line | cut -d"%" -f1 | sed 's/^ //g' | sed 's/ $//g'`
    folder=`echo $line | cut -d"%" -f2 | sed 's/^ //g'`
    folder2=$ALEJANDRIA/$folder/
    echo mkdir -p $folder2
    echo mv \"$DESCARGAS_NAS/$file\" \"$folder2\"
done
}

avhome_uncompress(){
rm $DESCARGAS_LOCAL/list.list
ls $DESCARGAS_NAS/*.rar | while read line;
do
    mkdir /tmp/unrar/; cd /tmp/unrar && rm -rf *
    rar x "$line"
    files="`ls | xargs echo`"
    echo $line "%" $files >> $DESCARGAS_LOCAL/list.list
done

ls $DESCARGAS_NAS/*.zip | while read line;
do
    mkdir /tmp/unrar/; cd /tmp/unrar && rm -rf *
    unzip "$line"
    files="`ls | xargs echo`"
    echo $line "%" $files >> $DESCARGAS_LOCAL/list.list
done
}

avhome_links(){
    rm links.list
    n=0;
    cat list.list | grep -v '\-\-\-' | while read title
    do
        n=$(($n+1));
        line=`echo "$title" | sed 's/ /+/g' | sed 's/^\(.*\)$/http:\/\/avaxsearch.net\/avaxhome_search?q=\1\&commit=Go/g'`

        wget "$line" -O page
        linkline=`cat page | grep links -A3 | grep href | head -n1`
        [[ $linkline == "" ]] && echo $title % $line >> links.list && continue

        link=`echo $linkline | cut -d'"' -f2`
        [[ $link == "" ]] && echo $title % $linkline >> links.list && continue

        wget $link -O page
        finallink=`cat page | grep -o -E 'href="([^"#]+)"' | cut -d'"' -f2 | sort | uniq | grep -E "ul.to|uploaded.to|uploaded.net|keep2share.cc|k2s.cc"`
        [[ $finallink == "" ]] && echo $title % $link >> links.list && continue

        echo $n : $finallink >> links.list
    done
}


avhome_google(){
	cat links.list | sed -e 's/[0-9]* : //g' -e 's/.* % //g' | xargs google-chrome
}

book(){
	mkdir -p /media/DATA/NAS/Alejandria/$2
	mv $1 /media/DATA/NAS/Alejandria/$2
}

avhdaily(){
	mkdir -p /home/ubuntu/ebooks
	while true
	do 
		export EBOOKS=/home/ubuntu/ebooks
		if [ `date +%H%M` = 1400 ]
		then
			avhome
			avhome_cut
			sleep $((60*5))
		fi
		sleep 10
	done
}

avhome_remaining(){
   for a in `cat list`; do [ -e $DESCARGAS_LOCAL/`basename $a` ] || echo $a ; done
}

avhome_dlscript(){
	cd $EBOOKS
	rm -fr /tmp/finallist
	for a in *
	do
		cd $a
		[ -e script ] || download list_cut.list | sed 's/^download/echo/g' | grep echo > /tmp/script; source /tmp/script >> /tmp/finallist
	       	cd ..
	done


	for a in *
	do 
		cd $a
		[ -e script ] || download list_cut.list | sed 's/^download/echo/g' | grep echo > /tmp/script; source /tmp/script > script
	       	cd ..
       	done
}

avhome_get_titles(){
    mkdir -p ~/servers/avxhome
    cd ~/servers/avxhome
    wget -q --no-check-certificate https://avxhm.se/ebooks/$1 -O dl
    cat dl | grep title-link | sed 's/^[^"]*"\([^"]*\)"[^>]*>\([^<]*\)<.*/\1|\2/g' | grep '|' > $1
}

avhome_get_new_titles(){
    mkdir -p ~/servers/avxhome
    cd ~/servers/avxhome

    if [ "$AVH_PROXY_IP" != "" ]
    then
        ssh -i $AVH_PROXY_PEM -o ServerAliveInterval=15 -o ServerAliveCountMax=4 -o ExitOnForwardFailure=yes -o StrictHostKeyChecking=no -o ConnectTimeout=10 -o PasswordAuthentication=no $AVH_PROXY_USER@$AVH_PROXY_IP "wget -q --no-check-certificate https://avxhm.se/ebooks/$1 -O -" > dl
    else
        wget -q --no-check-certificate https://avxhm.se/ebooks/$1 -O dl 2>/dev/null
    fi

    cat dl | grep title-link | sed 's/^[^"]*"\([^"]*\)"[^>]*>\([^<]*\)<.*/\1|\2/g' | grep '|' > ${1}_new
    comm -13 <(cat $1 | sort) <(cat ${1}_new | sort)
    \mv ${1}_new $1
}

avhome_get_titles_2(){
    #url='https://avxhm.se/ebooks/facet/Development/Drawing/Finance/Painting/Physics/Programming/SCIENCE/Science/science'
    url='https://avxhm.se/ebooks'
    mkdir -p ~/servers/avxhome
    cd ~/servers/avxhome
    wget -q --no-check-certificate $url -O dl
    cat dl | grep title-link | sed 's/^[^"]*"\([^"]*\)"[^>]*>\([^<]*\)<.*/\1|\2/g' | grep '|' > facets
}

avhome_get_new_titles_2(){
    mkdir -p ~/servers/avxhome
    cd ~/servers/avxhome

    url='https://avxhm.se/ebooks/facet/Development/Drawing/Finance/Painting/Physics/Programming/SCIENCE/Science/science'

    if [ "$AVH_PROXY_IP" != "" ]
    then
        ssh -i $AVH_PROXY_PEM -o ServerAliveInterval=15 -o ServerAliveCountMax=4 -o ExitOnForwardFailure=yes -o StrictHostKeyChecking=no -o ConnectTimeout=10 -o PasswordAuthentication=no $AVH_PROXY_USER@$AVH_PROXY_IP "wget -q --no-check-certificate $url -O -" > dl
    else
        wget -q --no-check-certificate $url -O dl 2>/dev/null
    fi

    cat dl | grep title-link | sed 's/^[^"]*"\([^"]*\)"[^>]*>\([^<]*\)<.*/\1|\2/g' | grep '|' > facets_new
    comm -13 <(cat facets | sort) <(cat facets_new | sort)
    \mv facets_new facets
}

avhome_mail_server(){
    [ "$avxmail_ml" = "true" ] && learning.configure $HOME/servers/rssmail/learning >/dev/null
    mkdir -p ~/servers/avxhome
    cd ~/servers/avxhome

    rm -fr to_send

    # for topic in programming_development graphics_drawing_design engeneering_technology hardware science_books security_info software
    # do
    #     [ -e /tmp/avh_proxy ] && source /tmp/avh_proxy && chmod 0600 $AVH_PROXY_PEM
    #     if [ "$AVH_PROXY_IP" != "" ]
    #     then
    #         ssh -i $AVH_PROXY_PEM -o ServerAliveInterval=15 -o ServerAliveCountMax=4 -o ExitOnForwardFailure=yes -o StrictHostKeyChecking=no -o ConnectTimeout=10 -o PasswordAuthentication=no $AVH_PROXY_USER@$AVH_PROXY_IP "echo '===== Connected ====='"
    #     fi
    #     avhome_get_new_titles $topic | while read line
    #     do
    #         echo $line >> to_send
    #     done
    # done
    [ -e /tmp/avh_proxy ] && source /tmp/avh_proxy && chmod 0600 $AVH_PROXY_PEM
    if [ "$AVH_PROXY_IP" != "" ]
    then
        ssh -i $AVH_PROXY_PEM -o ServerAliveInterval=15 -o ServerAliveCountMax=4 -o ExitOnForwardFailure=yes -o StrictHostKeyChecking=no -o ConnectTimeout=10 -o PasswordAuthentication=no $AVH_PROXY_USER@$AVH_PROXY_IP "echo '===== Connected ====='"
    fi
    avhome_get_new_titles_2 | while read line
    do
        echo $line >> to_send
    done

   rm -fr new
   if [ -e to_send ]
   then
      cat to_send | sort | uniq | while read line
      do
          echo $line >> new
      done
   fi

   if [ -e new ]
   then
       comm -13 <(cat old | sort) <(cat new | sort) | while read line
       do
              title=$(echo $line | cut -d'|' -f2)
              title_ml=$title
              source ~/.dotfiles/source/.shell/learning
              [ "$avxmail_ml" = "true" ] && learning.configure $HOME/servers/rssmail/learning >/dev/null
              [ "$avxmail_ml" = "true" ] && [ $(echo $title | learning.classify - ) = "true" ] && title_ml="[kword] $title"
              title_outbox=$(echo $title_ml | sed -e 's|/||g')
              link=http://avxhm.se$(echo $line | cut -d'|' -f1)
              echo "\e[34m $title_ml \e[0m: $link"
              title_escaped=`echo $title | sed -e 's/\[/\\\[/g' -e 's/\]/\\\]/g' -e 's/\*/\\\*/g'`
              grep "^$title_escaped\$" ~/servers/avxhome/avxtitles >/dev/null && continue
              echo $title >> ~/servers/avxhome/avxtitles
              echo "$title_ml -> $link" >> ~/servers/avxhome/map

              [ $avxmail_webcontent = false ] && (echo $link)                   > /tmp/avxmailcontent
              [ $avxmail_webcontent = true ]  && (echo $link; webcontent $link) > /tmp/avxmailcontent

              [ "$outbox" != "" ] && cat /tmp/avxmailcontent > $outbox/$(date +%y%m%d-%H%M%S)_$title_outbox
              cat /tmp/avxmailcontent | $MAILCMD -F ~/.mutt/muttrc_$(( $(date +%s) % $(ls ~/.mutt/muttrc_* | wc -l) )) -s "$title_ml" -- pablo.aledo.rss@gmail.com
       done
   fi

   [ -e new ] && \mv new old

}

avhloop(){

    if [ $# != 0 ]
    then
        n=0
        while true
        do
            rm -f /tmp/ipname
            [ $n != $(( $1 - 1 )) ] && echo avx$RANDOM > /tmp/ipname

            avhloop

            n=$(( $n + 1 ))
            [ $n = $1 ] && break
            [ $n = 5 ] && break
        done
        return
    fi

    shc stop
    server novnc4 4000
    sleep 10
    night_avh
    shc stop
    ( cd ~/Descargas_aux/ && ls ../Descargas | Xargs touch )
    ( cd ~/Descargas_aux/ && cat /tmp/s2files | grep -v '^Title:' | grep -v '^$' | sed 's/^[^ ]* //g' | Xargs touch )
    find ~/Descargas/ -maxdepth 1 -empty -type f -delete
}

avlskip(){
    touch /tmp/avl_skip
    ps aux | grep short | grep '3$' | awk '{print $2}' | xargs kill
}

avhsearch(){

wget 'https://tavaz.xyz/generative-adversarial-networks/article_904124.asp?page=1' -q -O - | grep Details | grep -E 'avxhm\...' | sed 's|href="\(https://avxhm\.../ebooks/[^"]*\)"|\n\1\n|g' | grep -E 'avxhm\...' | while read link
do

	title=$( wget $link -q -O - | grep 'h1 class="title-link' | cut -d'>' -f2 | cut -d'<' -f1 )
	echo "$title -> $link"
done

}

1libsearch(){
    search=''
    for a in $*
    do
        search="${search}%20$(echo $a | sed 's| |%20|g')"
    done
    search=$(echo $search | sed 's/^%20//g')

    (
    cd /tmp/
    wget -q "https://1lib.eu/s/$search" -O 1libsearch
    csplit -s 1libsearch '/fit your search query/' '{*}'
    )

    cat /tmp/xx00 | sed 's|.*href="\([^"]*\)" style="text-decoration: underline;">\([^<]*\)*<.*|=== \2 -> \1|g' | grep '^===' | sed 's|=== \(.*\) -> \(.*\)|\1 -> http://1lib.eu\2|g'
}

1libsearch_new(){
    echo "===== $* ====="
    1libsearch $* > /tmp/search_result
    comm -23 <( cat /tmp/search_result | sed 's/ ->.*//g' | sort | uniq ) <(cat downloaded_titles | sort | uniq) | while read line
    do
        cat /tmp/search_result | grep -F "$line"
    done
}

s2link_filter(){
    file=s2link
    nl ${file} > ${file}.copy1
    cat ${file} | sed 's/ ->.*//g' | nl > ${file}.copy2
    vim ${file}.copy2
    cat ${file}.copy2 | while read line
    do
        [ "$(echo $line | grep '=====')" != "" ] && echo $line && continue
        linenr=$(echo $line | sed 's/^ *\([0-9]*\).*/\1/g')
        linecontent=$(echo $line | sed 's/^ *[0-9]*.//g')
        cmd="mgrep downloaded_titles $(echo $linecontent | tokenize | paste -d' ' -s)"
        echo $cmd > /tmp/cmd
        [ "$(source /tmp/cmd)" = "" ] && cat ${file}.copy1 | grep -P "^ *${linenr}\t"
    done | sed 's/^ *[0-9]*.//g' | tee s2link_filtered
}

s2link_deduplicate(){
rm -fr indexes
mkdir indexes
cat s2link | while read line
do

    if [ "$(echo $line | grep '=====')" = "" ]
    then
        title=$(echo $line | sed 's/^\(.*\) -> \(.*\)$/\1/g')
        link=$(echo $line | sed 's/^\(.*\) -> \(.*\)$/\2/g')
        title_norm=$(echo $title \
            | tr '[A-Z]' '[a-z]' \
            | sed -e 's/á/a/g' -e 's/é/e/g' -e 's/í/i/g' -e 's/ó/o/g' -e 's/ú/u/g' \
                -e 's/à/a/g' -e 's/è/e/g' -e 's/ì/i/g' -e 's/ò/o/g' -e 's/ù/u/g' \
                -e 's/ä/a/g' -e 's/ë/e/g' -e 's/ï/i/g' -e 's/ö/o/g' -e 's/ü/u/g' \
                -e 's/\///g' -e 's/\+//g' -e 's/,//g' -e 's/;//g' -e 's/\*//g' -e 's/>//g' -e 's/<//g' -e 's/_//g' -e 's/"//g' -e 's/%//g' \
                -e 's/&//g' -e 's/(//g' -e 's/)//g' -e 's/\[//g' -e 's/\]//g' -e 's/{//g' -e 's/}//g' -e 's/=//g' -e 's/!//g' -e 's/@//g' \
                -e 's/://g' -e "s/'//g" -e "s/?//g" -e "s/|//g" -e "s/\\$//g" -e "s/\`//g" -e "s/\^//g" -e 's/~//g' -e 's/\.//g' -e 's/  / /' \
                -e 's/ $//g' )
        md5title=$(echo $title_norm | md5sum | awk '{print $1}')
        [ -e indexes/$md5title ] || echo "$title -> $link"
        touch indexes/$md5title
    else
        echo $line
    fi
done | tee s2link_dedup
}

zlib_metadata(){
cat s2link | awk '/=====/{$1=""; $NF=""; zsearch=$0; next}{gsub(/ ->.*/,""); print $0 " ->" zsearch}' > title_2_zsearch
# for categ in *; do cat $categ | sed "s/ -> .*/ -> $categ/g"; done > ../title_2_categ
cat /tmp/s2files | awk '/Title:/{$1=""; title=$0; next}/^$/{next}{gsub(/^[^ ]* /,""); print $0 " ->" title}' > file_2_title
ls ../Descargas/ > files
rm -fr metadata
mkdir metadata

cat files | while read line
do
    file="$line"
    title=$(cat file_2_title | grep -F $file | sed 's/^.* -> //g')
    search=$(cat title_2_zsearch | grep -F $title | sed 's/^.* -> //g')
    #categ=$(cat title_2_categ | grep -F $title | sed 's/^.* -> //g')

    #echo ".$file. -> .$title. -> .$search. -> .$categ."
    echo $file

    mkdir "metadata/$file"
    echo "$title" > "metadata/$file/title"
    echo "$search" > "metadata/$file/zsearch"
    #echo "$categ" > "metadata/$file/zcateg"
done

}
